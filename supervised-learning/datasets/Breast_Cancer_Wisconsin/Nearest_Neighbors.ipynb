{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using CSV\n",
    "using MLJ\n",
    "using Plots\n",
    "using StatsBase\n",
    "\n",
    "include(\"../../lib.jl\")\n",
    "\n",
    "ENV[\"LINES\"]=50;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread = 1 warning: only found 32 / 33 columns around data row: 2. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 3. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 4. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 5. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 6. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 7. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 8. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 9. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 10. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 11. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 12. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 13. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 14. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 15. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 16. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 17. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 18. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 19. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 20. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 21. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 22. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 23. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 24. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 25. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 26. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 27. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 28. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 29. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 30. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 31. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 32. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 33. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 34. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 35. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 36. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 37. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 38. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 39. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 40. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 41. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 42. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 43. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 44. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 45. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 46. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 47. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 48. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 49. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 50. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 51. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 52. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 53. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 54. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 55. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 56. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 57. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 58. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 59. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 60. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 61. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 62. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 63. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 64. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 65. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 66. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 67. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 68. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 69. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 70. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 71. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 72. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 73. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 74. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 75. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 76. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 77. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 78. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 79. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 80. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 81. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 82. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 83. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 84. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 85. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 86. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 87. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 88. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 89. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 90. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 91. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 92. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 93. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 94. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 95. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 96. Filling remaining columns with `missing`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread = 1 warning: only found 32 / 33 columns around data row: 97. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 98. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 99. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 100. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 101. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 102. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 103. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 104. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 105. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 106. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 107. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 108. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 109. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 110. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 111. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 112. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 113. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 114. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 115. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 116. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 117. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 118. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 119. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 120. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 121. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 122. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 123. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 124. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 125. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 126. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 127. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 128. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 129. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 130. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 131. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 132. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 133. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 134. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 135. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 136. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 137. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 138. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 139. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 140. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 141. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 142. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 143. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 144. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 145. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 146. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 147. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 148. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 149. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 150. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 151. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 152. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 153. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 154. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 155. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 156. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 157. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 158. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 159. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 160. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 161. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 162. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 163. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 164. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 165. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 166. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 167. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 168. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 169. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 170. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 171. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 172. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 173. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 174. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 175. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 176. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 177. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 178. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 179. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 180. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 181. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 182. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 183. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 184. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 185. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 186. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 187. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 188. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 189. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 190. Filling remaining columns with `missing`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread = 1 warning: only found 32 / 33 columns around data row: 191. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 192. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 193. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 194. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 195. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 196. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 197. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 198. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 199. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 200. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 201. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 202. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 203. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 204. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 205. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 206. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 207. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 208. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 209. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 210. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 211. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 212. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 213. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 214. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 215. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 216. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 217. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 218. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 219. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 220. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 221. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 222. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 223. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 224. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 225. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 226. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 227. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 228. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 229. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 230. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 231. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 232. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 233. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 234. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 235. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 236. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 237. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 238. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 239. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 240. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 241. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 242. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 243. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 244. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 245. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 246. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 247. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 248. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 249. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 250. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 251. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 252. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 253. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 254. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 255. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 256. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 257. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 258. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 259. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 260. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 261. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 262. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 263. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 264. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 265. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 266. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 267. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 268. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 269. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 270. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 271. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 272. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 273. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 274. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 275. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 276. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 277. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 278. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 279. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 280. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 281. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 282. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 283. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 284. Filling remaining columns with `missing`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread = 1 warning: only found 32 / 33 columns around data row: 285. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 286. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 287. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 288. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 289. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 290. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 291. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 292. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 293. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 294. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 295. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 296. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 297. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 298. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 299. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 300. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 301. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 302. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 303. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 304. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 305. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 306. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 307. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 308. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 309. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 310. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 311. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 312. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 313. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 314. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 315. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 316. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 317. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 318. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 319. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 320. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 321. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 322. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 323. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 324. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 325. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 326. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 327. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 328. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 329. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 330. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 331. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 332. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 333. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 334. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 335. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 336. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 337. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 338. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 339. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 340. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 341. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 342. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 343. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 344. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 345. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 346. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 347. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 348. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 349. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 350. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 351. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 352. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 353. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 354. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 355. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 356. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 357. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 358. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 359. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 360. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 361. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 362. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 363. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 364. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 365. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 366. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 367. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 368. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 369. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 370. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 371. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 372. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 373. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 374. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 375. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 376. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 377. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 378. Filling remaining columns with `missing`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread = 1 warning: only found 32 / 33 columns around data row: 379. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 380. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 381. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 382. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 383. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 384. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 385. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 386. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 387. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 388. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 389. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 390. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 391. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 392. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 393. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 394. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 395. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 396. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 397. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 398. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 399. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 400. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 401. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 402. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 403. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 404. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 405. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 406. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 407. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 408. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 409. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 410. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 411. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 412. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 413. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 414. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 415. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 416. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 417. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 418. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 419. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 420. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 421. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 422. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 423. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 424. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 425. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 426. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 427. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 428. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 429. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 430. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 431. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 432. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 433. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 434. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 435. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 436. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 437. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 438. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 439. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 440. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 441. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 442. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 443. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 444. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 445. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 446. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 447. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 448. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 449. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 450. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 451. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 452. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 453. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 454. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 455. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 456. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 457. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 458. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 459. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 460. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 461. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 462. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 463. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 464. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 465. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 466. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 467. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 468. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 469. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 470. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 471. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 472. Filling remaining columns with `missing`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread = 1 warning: only found 32 / 33 columns around data row: 473. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 474. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 475. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 476. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 477. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 478. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 479. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 480. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 481. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 482. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 483. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 484. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 485. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 486. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 487. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 488. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 489. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 490. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 491. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 492. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 493. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 494. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 495. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 496. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 497. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 498. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 499. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 500. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 501. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 502. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 503. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 504. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 505. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 506. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 507. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 508. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 509. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 510. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 511. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 512. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 513. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 514. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 515. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 516. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 517. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 518. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 519. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 520. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 521. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 522. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 523. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 524. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 525. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 526. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 527. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 528. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 529. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 530. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 531. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 532. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 533. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 534. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 535. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 536. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 537. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 538. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 539. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 540. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 541. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 542. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 543. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 544. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 545. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 546. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 547. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 548. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 549. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 550. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 551. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 552. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 553. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 554. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 555. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 556. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 557. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 558. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 559. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 560. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 561. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 562. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 563. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 564. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 565. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 566. Filling remaining columns with `missing`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread = 1 warning: only found 32 / 33 columns around data row: 567. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 568. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 569. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 570. Filling remaining columns with `missing`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>id</th><th>diagnosis</th><th>radius_mean</th><th>texture_mean</th><th>perimeter_mean</th><th>area_mean</th><th>smoothness_mean</th></tr><tr><th></th><th>Int64</th><th>String</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>569 rows  33 columns (omitted printing of 26 columns)</p><tr><th>1</th><td>842302</td><td>M</td><td>17.99</td><td>10.38</td><td>122.8</td><td>1001.0</td><td>0.1184</td></tr><tr><th>2</th><td>842517</td><td>M</td><td>20.57</td><td>17.77</td><td>132.9</td><td>1326.0</td><td>0.08474</td></tr><tr><th>3</th><td>84300903</td><td>M</td><td>19.69</td><td>21.25</td><td>130.0</td><td>1203.0</td><td>0.1096</td></tr><tr><th>4</th><td>84348301</td><td>M</td><td>11.42</td><td>20.38</td><td>77.58</td><td>386.1</td><td>0.1425</td></tr><tr><th>5</th><td>84358402</td><td>M</td><td>20.29</td><td>14.34</td><td>135.1</td><td>1297.0</td><td>0.1003</td></tr><tr><th>6</th><td>843786</td><td>M</td><td>12.45</td><td>15.7</td><td>82.57</td><td>477.1</td><td>0.1278</td></tr><tr><th>7</th><td>844359</td><td>M</td><td>18.25</td><td>19.98</td><td>119.6</td><td>1040.0</td><td>0.09463</td></tr><tr><th>8</th><td>84458202</td><td>M</td><td>13.71</td><td>20.83</td><td>90.2</td><td>577.9</td><td>0.1189</td></tr><tr><th>9</th><td>844981</td><td>M</td><td>13.0</td><td>21.82</td><td>87.5</td><td>519.8</td><td>0.1273</td></tr><tr><th>10</th><td>84501001</td><td>M</td><td>12.46</td><td>24.04</td><td>83.97</td><td>475.9</td><td>0.1186</td></tr><tr><th>11</th><td>845636</td><td>M</td><td>16.02</td><td>23.24</td><td>102.7</td><td>797.8</td><td>0.08206</td></tr><tr><th>12</th><td>84610002</td><td>M</td><td>15.78</td><td>17.89</td><td>103.6</td><td>781.0</td><td>0.0971</td></tr><tr><th>13</th><td>846226</td><td>M</td><td>19.17</td><td>24.8</td><td>132.4</td><td>1123.0</td><td>0.0974</td></tr><tr><th>14</th><td>846381</td><td>M</td><td>15.85</td><td>23.95</td><td>103.7</td><td>782.7</td><td>0.08401</td></tr><tr><th>15</th><td>84667401</td><td>M</td><td>13.73</td><td>22.61</td><td>93.6</td><td>578.3</td><td>0.1131</td></tr><tr><th>16</th><td>84799002</td><td>M</td><td>14.54</td><td>27.54</td><td>96.73</td><td>658.8</td><td>0.1139</td></tr><tr><th>17</th><td>848406</td><td>M</td><td>14.68</td><td>20.13</td><td>94.74</td><td>684.5</td><td>0.09867</td></tr><tr><th>18</th><td>84862001</td><td>M</td><td>16.13</td><td>20.68</td><td>108.1</td><td>798.8</td><td>0.117</td></tr><tr><th>19</th><td>849014</td><td>M</td><td>19.81</td><td>22.15</td><td>130.0</td><td>1260.0</td><td>0.09831</td></tr><tr><th>20</th><td>8510426</td><td>B</td><td>13.54</td><td>14.36</td><td>87.46</td><td>566.3</td><td>0.09779</td></tr><tr><th>21</th><td>8510653</td><td>B</td><td>13.08</td><td>15.71</td><td>85.63</td><td>520.0</td><td>0.1075</td></tr><tr><th>22</th><td>8510824</td><td>B</td><td>9.504</td><td>12.44</td><td>60.34</td><td>273.9</td><td>0.1024</td></tr><tr><th>23</th><td>8511133</td><td>M</td><td>15.34</td><td>14.26</td><td>102.5</td><td>704.4</td><td>0.1073</td></tr><tr><th>24</th><td>851509</td><td>M</td><td>21.16</td><td>23.04</td><td>137.2</td><td>1404.0</td><td>0.09428</td></tr><tr><th>25</th><td>852552</td><td>M</td><td>16.65</td><td>21.38</td><td>110.0</td><td>904.6</td><td>0.1121</td></tr><tr><th>26</th><td>852631</td><td>M</td><td>17.14</td><td>16.4</td><td>116.0</td><td>912.7</td><td>0.1186</td></tr><tr><th>27</th><td>852763</td><td>M</td><td>14.58</td><td>21.53</td><td>97.41</td><td>644.8</td><td>0.1054</td></tr><tr><th>28</th><td>852781</td><td>M</td><td>18.61</td><td>20.25</td><td>122.1</td><td>1094.0</td><td>0.0944</td></tr><tr><th>29</th><td>852973</td><td>M</td><td>15.3</td><td>25.27</td><td>102.4</td><td>732.4</td><td>0.1082</td></tr><tr><th>30</th><td>853201</td><td>M</td><td>17.57</td><td>15.05</td><td>115.0</td><td>955.1</td><td>0.09847</td></tr><tr><th>31</th><td>853401</td><td>M</td><td>18.63</td><td>25.11</td><td>124.8</td><td>1088.0</td><td>0.1064</td></tr><tr><th>32</th><td>853612</td><td>M</td><td>11.84</td><td>18.7</td><td>77.93</td><td>440.6</td><td>0.1109</td></tr><tr><th>33</th><td>85382601</td><td>M</td><td>17.02</td><td>23.98</td><td>112.8</td><td>899.3</td><td>0.1197</td></tr><tr><th>34</th><td>854002</td><td>M</td><td>19.27</td><td>26.47</td><td>127.9</td><td>1162.0</td><td>0.09401</td></tr><tr><th>35</th><td>854039</td><td>M</td><td>16.13</td><td>17.88</td><td>107.0</td><td>807.2</td><td>0.104</td></tr><tr><th>36</th><td>854253</td><td>M</td><td>16.74</td><td>21.59</td><td>110.1</td><td>869.5</td><td>0.0961</td></tr><tr><th>37</th><td>854268</td><td>M</td><td>14.25</td><td>21.72</td><td>93.63</td><td>633.0</td><td>0.09823</td></tr><tr><th>38</th><td>854941</td><td>B</td><td>13.03</td><td>18.42</td><td>82.61</td><td>523.8</td><td>0.08983</td></tr><tr><th>39</th><td>855133</td><td>M</td><td>14.99</td><td>25.2</td><td>95.54</td><td>698.8</td><td>0.09387</td></tr><tr><th>40</th><td>855138</td><td>M</td><td>13.48</td><td>20.82</td><td>88.4</td><td>559.2</td><td>0.1016</td></tr><tr><th>41</th><td>855167</td><td>M</td><td>13.44</td><td>21.58</td><td>86.18</td><td>563.0</td><td>0.08162</td></tr><tr><th>42</th><td>855563</td><td>M</td><td>10.95</td><td>21.35</td><td>71.9</td><td>371.1</td><td>0.1227</td></tr><tr><th>43</th><td>855625</td><td>M</td><td>19.07</td><td>24.81</td><td>128.3</td><td>1104.0</td><td>0.09081</td></tr><tr><th>44</th><td>856106</td><td>M</td><td>13.28</td><td>20.28</td><td>87.32</td><td>545.2</td><td>0.1041</td></tr><tr><th>45</th><td>85638502</td><td>M</td><td>13.17</td><td>21.81</td><td>85.42</td><td>531.5</td><td>0.09714</td></tr><tr><th>46</th><td>857010</td><td>M</td><td>18.65</td><td>17.6</td><td>123.7</td><td>1076.0</td><td>0.1099</td></tr><tr><th>47</th><td>85713702</td><td>B</td><td>8.196</td><td>16.84</td><td>51.71</td><td>201.9</td><td>0.086</td></tr><tr><th>48</th><td>85715</td><td>M</td><td>13.17</td><td>18.66</td><td>85.98</td><td>534.6</td><td>0.1158</td></tr><tr><th>49</th><td>857155</td><td>B</td><td>12.05</td><td>14.63</td><td>78.04</td><td>449.3</td><td>0.1031</td></tr><tr><th>50</th><td>857156</td><td>B</td><td>13.49</td><td>22.3</td><td>86.91</td><td>561.0</td><td>0.08752</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& id & diagnosis & radius\\_mean & texture\\_mean & perimeter\\_mean & area\\_mean & smoothness\\_mean & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 842302 & M & 17.99 & 10.38 & 122.8 & 1001.0 & 0.1184 & $\\dots$ \\\\\n",
       "\t2 & 842517 & M & 20.57 & 17.77 & 132.9 & 1326.0 & 0.08474 & $\\dots$ \\\\\n",
       "\t3 & 84300903 & M & 19.69 & 21.25 & 130.0 & 1203.0 & 0.1096 & $\\dots$ \\\\\n",
       "\t4 & 84348301 & M & 11.42 & 20.38 & 77.58 & 386.1 & 0.1425 & $\\dots$ \\\\\n",
       "\t5 & 84358402 & M & 20.29 & 14.34 & 135.1 & 1297.0 & 0.1003 & $\\dots$ \\\\\n",
       "\t6 & 843786 & M & 12.45 & 15.7 & 82.57 & 477.1 & 0.1278 & $\\dots$ \\\\\n",
       "\t7 & 844359 & M & 18.25 & 19.98 & 119.6 & 1040.0 & 0.09463 & $\\dots$ \\\\\n",
       "\t8 & 84458202 & M & 13.71 & 20.83 & 90.2 & 577.9 & 0.1189 & $\\dots$ \\\\\n",
       "\t9 & 844981 & M & 13.0 & 21.82 & 87.5 & 519.8 & 0.1273 & $\\dots$ \\\\\n",
       "\t10 & 84501001 & M & 12.46 & 24.04 & 83.97 & 475.9 & 0.1186 & $\\dots$ \\\\\n",
       "\t11 & 845636 & M & 16.02 & 23.24 & 102.7 & 797.8 & 0.08206 & $\\dots$ \\\\\n",
       "\t12 & 84610002 & M & 15.78 & 17.89 & 103.6 & 781.0 & 0.0971 & $\\dots$ \\\\\n",
       "\t13 & 846226 & M & 19.17 & 24.8 & 132.4 & 1123.0 & 0.0974 & $\\dots$ \\\\\n",
       "\t14 & 846381 & M & 15.85 & 23.95 & 103.7 & 782.7 & 0.08401 & $\\dots$ \\\\\n",
       "\t15 & 84667401 & M & 13.73 & 22.61 & 93.6 & 578.3 & 0.1131 & $\\dots$ \\\\\n",
       "\t16 & 84799002 & M & 14.54 & 27.54 & 96.73 & 658.8 & 0.1139 & $\\dots$ \\\\\n",
       "\t17 & 848406 & M & 14.68 & 20.13 & 94.74 & 684.5 & 0.09867 & $\\dots$ \\\\\n",
       "\t18 & 84862001 & M & 16.13 & 20.68 & 108.1 & 798.8 & 0.117 & $\\dots$ \\\\\n",
       "\t19 & 849014 & M & 19.81 & 22.15 & 130.0 & 1260.0 & 0.09831 & $\\dots$ \\\\\n",
       "\t20 & 8510426 & B & 13.54 & 14.36 & 87.46 & 566.3 & 0.09779 & $\\dots$ \\\\\n",
       "\t21 & 8510653 & B & 13.08 & 15.71 & 85.63 & 520.0 & 0.1075 & $\\dots$ \\\\\n",
       "\t22 & 8510824 & B & 9.504 & 12.44 & 60.34 & 273.9 & 0.1024 & $\\dots$ \\\\\n",
       "\t23 & 8511133 & M & 15.34 & 14.26 & 102.5 & 704.4 & 0.1073 & $\\dots$ \\\\\n",
       "\t24 & 851509 & M & 21.16 & 23.04 & 137.2 & 1404.0 & 0.09428 & $\\dots$ \\\\\n",
       "\t25 & 852552 & M & 16.65 & 21.38 & 110.0 & 904.6 & 0.1121 & $\\dots$ \\\\\n",
       "\t26 & 852631 & M & 17.14 & 16.4 & 116.0 & 912.7 & 0.1186 & $\\dots$ \\\\\n",
       "\t27 & 852763 & M & 14.58 & 21.53 & 97.41 & 644.8 & 0.1054 & $\\dots$ \\\\\n",
       "\t28 & 852781 & M & 18.61 & 20.25 & 122.1 & 1094.0 & 0.0944 & $\\dots$ \\\\\n",
       "\t29 & 852973 & M & 15.3 & 25.27 & 102.4 & 732.4 & 0.1082 & $\\dots$ \\\\\n",
       "\t30 & 853201 & M & 17.57 & 15.05 & 115.0 & 955.1 & 0.09847 & $\\dots$ \\\\\n",
       "\t31 & 853401 & M & 18.63 & 25.11 & 124.8 & 1088.0 & 0.1064 & $\\dots$ \\\\\n",
       "\t32 & 853612 & M & 11.84 & 18.7 & 77.93 & 440.6 & 0.1109 & $\\dots$ \\\\\n",
       "\t33 & 85382601 & M & 17.02 & 23.98 & 112.8 & 899.3 & 0.1197 & $\\dots$ \\\\\n",
       "\t34 & 854002 & M & 19.27 & 26.47 & 127.9 & 1162.0 & 0.09401 & $\\dots$ \\\\\n",
       "\t35 & 854039 & M & 16.13 & 17.88 & 107.0 & 807.2 & 0.104 & $\\dots$ \\\\\n",
       "\t36 & 854253 & M & 16.74 & 21.59 & 110.1 & 869.5 & 0.0961 & $\\dots$ \\\\\n",
       "\t37 & 854268 & M & 14.25 & 21.72 & 93.63 & 633.0 & 0.09823 & $\\dots$ \\\\\n",
       "\t38 & 854941 & B & 13.03 & 18.42 & 82.61 & 523.8 & 0.08983 & $\\dots$ \\\\\n",
       "\t39 & 855133 & M & 14.99 & 25.2 & 95.54 & 698.8 & 0.09387 & $\\dots$ \\\\\n",
       "\t40 & 855138 & M & 13.48 & 20.82 & 88.4 & 559.2 & 0.1016 & $\\dots$ \\\\\n",
       "\t41 & 855167 & M & 13.44 & 21.58 & 86.18 & 563.0 & 0.08162 & $\\dots$ \\\\\n",
       "\t42 & 855563 & M & 10.95 & 21.35 & 71.9 & 371.1 & 0.1227 & $\\dots$ \\\\\n",
       "\t43 & 855625 & M & 19.07 & 24.81 & 128.3 & 1104.0 & 0.09081 & $\\dots$ \\\\\n",
       "\t44 & 856106 & M & 13.28 & 20.28 & 87.32 & 545.2 & 0.1041 & $\\dots$ \\\\\n",
       "\t45 & 85638502 & M & 13.17 & 21.81 & 85.42 & 531.5 & 0.09714 & $\\dots$ \\\\\n",
       "\t46 & 857010 & M & 18.65 & 17.6 & 123.7 & 1076.0 & 0.1099 & $\\dots$ \\\\\n",
       "\t47 & 85713702 & B & 8.196 & 16.84 & 51.71 & 201.9 & 0.086 & $\\dots$ \\\\\n",
       "\t48 & 85715 & M & 13.17 & 18.66 & 85.98 & 534.6 & 0.1158 & $\\dots$ \\\\\n",
       "\t49 & 857155 & B & 12.05 & 14.63 & 78.04 & 449.3 & 0.1031 & $\\dots$ \\\\\n",
       "\t50 & 857156 & B & 13.49 & 22.3 & 86.91 & 561.0 & 0.08752 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "56933 DataFrame. Omitted printing of 28 columns\n",
       " Row  id        diagnosis  radius_mean  texture_mean  perimeter_mean \n",
       "      \u001b[90mInt64\u001b[39m     \u001b[90mString\u001b[39m     \u001b[90mFloat64\u001b[39m      \u001b[90mFloat64\u001b[39m       \u001b[90mFloat64\u001b[39m        \n",
       "\n",
       " 1    842302    M          17.99        10.38         122.8          \n",
       " 2    842517    M          20.57        17.77         132.9          \n",
       " 3    84300903  M          19.69        21.25         130.0          \n",
       " 4    84348301  M          11.42        20.38         77.58          \n",
       " 5    84358402  M          20.29        14.34         135.1          \n",
       " 6    843786    M          12.45        15.7          82.57          \n",
       " 7    844359    M          18.25        19.98         119.6          \n",
       " 8    84458202  M          13.71        20.83         90.2           \n",
       " 9    844981    M          13.0         21.82         87.5           \n",
       " 10   84501001  M          12.46        24.04         83.97          \n",
       " 11   845636    M          16.02        23.24         102.7          \n",
       " 12   84610002  M          15.78        17.89         103.6          \n",
       " 13   846226    M          19.17        24.8          132.4          \n",
       " 14   846381    M          15.85        23.95         103.7          \n",
       " 15   84667401  M          13.73        22.61         93.6           \n",
       " 16   84799002  M          14.54        27.54         96.73          \n",
       " 17   848406    M          14.68        20.13         94.74          \n",
       " 18   84862001  M          16.13        20.68         108.1          \n",
       " 19   849014    M          19.81        22.15         130.0          \n",
       " 20   8510426   B          13.54        14.36         87.46          \n",
       "\n",
       " 549  923169    B          9.683        19.34         61.05          \n",
       " 550  923465    B          10.82        24.21         68.89          \n",
       " 551  923748    B          10.86        21.48         68.51          \n",
       " 552  923780    B          11.13        22.44         71.49          \n",
       " 553  924084    B          12.77        29.43         81.35          \n",
       " 554  924342    B          9.333        21.94         59.01          \n",
       " 555  924632    B          12.88        28.92         82.5           \n",
       " 556  924934    B          10.29        27.61         65.67          \n",
       " 557  924964    B          10.16        19.59         64.73          \n",
       " 558  925236    B          9.423        27.88         59.26          \n",
       " 559  925277    B          14.59        22.68         96.39          \n",
       " 560  925291    B          11.51        23.93         74.52          \n",
       " 561  925292    B          14.05        27.15         91.38          \n",
       " 562  925311    B          11.2         29.37         70.67          \n",
       " 563  925622    M          15.22        30.62         103.4          \n",
       " 564  926125    M          20.92        25.09         143.0          \n",
       " 565  926424    M          21.56        22.39         142.0          \n",
       " 566  926682    M          20.13        28.25         131.2          \n",
       " 567  926954    M          16.6         28.08         108.3          \n",
       " 568  927241    M          20.6         29.33         140.1          \n",
       " 569  92751     B          7.76         24.54         47.92          "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = CSV.read(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at class labels to see if dataset is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Int64} with 2 entries:\n",
       "  \"B\" => 357\n",
       "  \"M\" => 212"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = countmap(data[:diagnosis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 0.6274165202108963\n",
       " 0.37258347978910367"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect(label_counts[i] / size(data)[1] for i in keys(label_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data ready for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th><th>nunique</th><th>nmissing</th></tr><tr><th></th><th>Symbol</th><th>Union</th><th>Any</th><th>Union</th><th>Any</th><th>Union</th><th>Nothing</th></tr></thead><tbody><p>31 rows  8 columns (omitted printing of 1 columns)</p><tr><th>1</th><td>diagnosis</td><td></td><td>B</td><td></td><td>M</td><td>2</td><td></td></tr><tr><th>2</th><td>radius_mean</td><td>14.1273</td><td>6.981</td><td>13.37</td><td>28.11</td><td></td><td></td></tr><tr><th>3</th><td>texture_mean</td><td>19.2896</td><td>9.71</td><td>18.84</td><td>39.28</td><td></td><td></td></tr><tr><th>4</th><td>perimeter_mean</td><td>91.969</td><td>43.79</td><td>86.24</td><td>188.5</td><td></td><td></td></tr><tr><th>5</th><td>area_mean</td><td>654.889</td><td>143.5</td><td>551.1</td><td>2501.0</td><td></td><td></td></tr><tr><th>6</th><td>smoothness_mean</td><td>0.0963603</td><td>0.05263</td><td>0.09587</td><td>0.1634</td><td></td><td></td></tr><tr><th>7</th><td>compactness_mean</td><td>0.104341</td><td>0.01938</td><td>0.09263</td><td>0.3454</td><td></td><td></td></tr><tr><th>8</th><td>concavity_mean</td><td>0.0887993</td><td>0.0</td><td>0.06154</td><td>0.4268</td><td></td><td></td></tr><tr><th>9</th><td>concave points_mean</td><td>0.0489191</td><td>0.0</td><td>0.0335</td><td>0.2012</td><td></td><td></td></tr><tr><th>10</th><td>symmetry_mean</td><td>0.181162</td><td>0.106</td><td>0.1792</td><td>0.304</td><td></td><td></td></tr><tr><th>11</th><td>fractal_dimension_mean</td><td>0.0627976</td><td>0.04996</td><td>0.06154</td><td>0.09744</td><td></td><td></td></tr><tr><th>12</th><td>radius_se</td><td>0.405172</td><td>0.1115</td><td>0.3242</td><td>2.873</td><td></td><td></td></tr><tr><th>13</th><td>texture_se</td><td>1.21685</td><td>0.3602</td><td>1.108</td><td>4.885</td><td></td><td></td></tr><tr><th>14</th><td>perimeter_se</td><td>2.86606</td><td>0.757</td><td>2.287</td><td>21.98</td><td></td><td></td></tr><tr><th>15</th><td>area_se</td><td>40.3371</td><td>6.802</td><td>24.53</td><td>542.2</td><td></td><td></td></tr><tr><th>16</th><td>smoothness_se</td><td>0.00704098</td><td>0.001713</td><td>0.00638</td><td>0.03113</td><td></td><td></td></tr><tr><th>17</th><td>compactness_se</td><td>0.0254781</td><td>0.002252</td><td>0.02045</td><td>0.1354</td><td></td><td></td></tr><tr><th>18</th><td>concavity_se</td><td>0.0318937</td><td>0.0</td><td>0.02589</td><td>0.396</td><td></td><td></td></tr><tr><th>19</th><td>concave points_se</td><td>0.0117961</td><td>0.0</td><td>0.01093</td><td>0.05279</td><td></td><td></td></tr><tr><th>20</th><td>symmetry_se</td><td>0.0205423</td><td>0.007882</td><td>0.01873</td><td>0.07895</td><td></td><td></td></tr><tr><th>21</th><td>fractal_dimension_se</td><td>0.0037949</td><td>0.0008948</td><td>0.003187</td><td>0.02984</td><td></td><td></td></tr><tr><th>22</th><td>radius_worst</td><td>16.2692</td><td>7.93</td><td>14.97</td><td>36.04</td><td></td><td></td></tr><tr><th>23</th><td>texture_worst</td><td>25.6772</td><td>12.02</td><td>25.41</td><td>49.54</td><td></td><td></td></tr><tr><th>24</th><td>perimeter_worst</td><td>107.261</td><td>50.41</td><td>97.66</td><td>251.2</td><td></td><td></td></tr><tr><th>25</th><td>area_worst</td><td>880.583</td><td>185.2</td><td>686.5</td><td>4254.0</td><td></td><td></td></tr><tr><th>26</th><td>smoothness_worst</td><td>0.132369</td><td>0.07117</td><td>0.1313</td><td>0.2226</td><td></td><td></td></tr><tr><th>27</th><td>compactness_worst</td><td>0.254265</td><td>0.02729</td><td>0.2119</td><td>1.058</td><td></td><td></td></tr><tr><th>28</th><td>concavity_worst</td><td>0.272188</td><td>0.0</td><td>0.2267</td><td>1.252</td><td></td><td></td></tr><tr><th>29</th><td>concave points_worst</td><td>0.114606</td><td>0.0</td><td>0.09993</td><td>0.291</td><td></td><td></td></tr><tr><th>30</th><td>symmetry_worst</td><td>0.290076</td><td>0.1565</td><td>0.2822</td><td>0.6638</td><td></td><td></td></tr><tr><th>31</th><td>fractal_dimension_worst</td><td>0.0839458</td><td>0.05504</td><td>0.08004</td><td>0.2075</td><td></td><td></td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& variable & mean & min & median & max & nunique & nmissing & \\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Union & Any & Union & Any & Union & Nothing & \\\\\n",
       "\t\\hline\n",
       "\t1 & diagnosis &  & B &  & M & 2 &  & $\\dots$ \\\\\n",
       "\t2 & radius\\_mean & 14.1273 & 6.981 & 13.37 & 28.11 &  &  & $\\dots$ \\\\\n",
       "\t3 & texture\\_mean & 19.2896 & 9.71 & 18.84 & 39.28 &  &  & $\\dots$ \\\\\n",
       "\t4 & perimeter\\_mean & 91.969 & 43.79 & 86.24 & 188.5 &  &  & $\\dots$ \\\\\n",
       "\t5 & area\\_mean & 654.889 & 143.5 & 551.1 & 2501.0 &  &  & $\\dots$ \\\\\n",
       "\t6 & smoothness\\_mean & 0.0963603 & 0.05263 & 0.09587 & 0.1634 &  &  & $\\dots$ \\\\\n",
       "\t7 & compactness\\_mean & 0.104341 & 0.01938 & 0.09263 & 0.3454 &  &  & $\\dots$ \\\\\n",
       "\t8 & concavity\\_mean & 0.0887993 & 0.0 & 0.06154 & 0.4268 &  &  & $\\dots$ \\\\\n",
       "\t9 & concave points\\_mean & 0.0489191 & 0.0 & 0.0335 & 0.2012 &  &  & $\\dots$ \\\\\n",
       "\t10 & symmetry\\_mean & 0.181162 & 0.106 & 0.1792 & 0.304 &  &  & $\\dots$ \\\\\n",
       "\t11 & fractal\\_dimension\\_mean & 0.0627976 & 0.04996 & 0.06154 & 0.09744 &  &  & $\\dots$ \\\\\n",
       "\t12 & radius\\_se & 0.405172 & 0.1115 & 0.3242 & 2.873 &  &  & $\\dots$ \\\\\n",
       "\t13 & texture\\_se & 1.21685 & 0.3602 & 1.108 & 4.885 &  &  & $\\dots$ \\\\\n",
       "\t14 & perimeter\\_se & 2.86606 & 0.757 & 2.287 & 21.98 &  &  & $\\dots$ \\\\\n",
       "\t15 & area\\_se & 40.3371 & 6.802 & 24.53 & 542.2 &  &  & $\\dots$ \\\\\n",
       "\t16 & smoothness\\_se & 0.00704098 & 0.001713 & 0.00638 & 0.03113 &  &  & $\\dots$ \\\\\n",
       "\t17 & compactness\\_se & 0.0254781 & 0.002252 & 0.02045 & 0.1354 &  &  & $\\dots$ \\\\\n",
       "\t18 & concavity\\_se & 0.0318937 & 0.0 & 0.02589 & 0.396 &  &  & $\\dots$ \\\\\n",
       "\t19 & concave points\\_se & 0.0117961 & 0.0 & 0.01093 & 0.05279 &  &  & $\\dots$ \\\\\n",
       "\t20 & symmetry\\_se & 0.0205423 & 0.007882 & 0.01873 & 0.07895 &  &  & $\\dots$ \\\\\n",
       "\t21 & fractal\\_dimension\\_se & 0.0037949 & 0.0008948 & 0.003187 & 0.02984 &  &  & $\\dots$ \\\\\n",
       "\t22 & radius\\_worst & 16.2692 & 7.93 & 14.97 & 36.04 &  &  & $\\dots$ \\\\\n",
       "\t23 & texture\\_worst & 25.6772 & 12.02 & 25.41 & 49.54 &  &  & $\\dots$ \\\\\n",
       "\t24 & perimeter\\_worst & 107.261 & 50.41 & 97.66 & 251.2 &  &  & $\\dots$ \\\\\n",
       "\t25 & area\\_worst & 880.583 & 185.2 & 686.5 & 4254.0 &  &  & $\\dots$ \\\\\n",
       "\t26 & smoothness\\_worst & 0.132369 & 0.07117 & 0.1313 & 0.2226 &  &  & $\\dots$ \\\\\n",
       "\t27 & compactness\\_worst & 0.254265 & 0.02729 & 0.2119 & 1.058 &  &  & $\\dots$ \\\\\n",
       "\t28 & concavity\\_worst & 0.272188 & 0.0 & 0.2267 & 1.252 &  &  & $\\dots$ \\\\\n",
       "\t29 & concave points\\_worst & 0.114606 & 0.0 & 0.09993 & 0.291 &  &  & $\\dots$ \\\\\n",
       "\t30 & symmetry\\_worst & 0.290076 & 0.1565 & 0.2822 & 0.6638 &  &  & $\\dots$ \\\\\n",
       "\t31 & fractal\\_dimension\\_worst & 0.0839458 & 0.05504 & 0.08004 & 0.2075 &  &  & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "318 DataFrame. Omitted printing of 3 columns\n",
       " Row  variable                 mean        min        median    max     \n",
       "      \u001b[90mSymbol\u001b[39m                   \u001b[90mUnion\u001b[39m      \u001b[90mAny\u001b[39m        \u001b[90mUnion\u001b[39m    \u001b[90mAny\u001b[39m     \n",
       "\n",
       " 1    diagnosis                            B                    M       \n",
       " 2    radius_mean              14.1273     6.981      13.37     28.11   \n",
       " 3    texture_mean             19.2896     9.71       18.84     39.28   \n",
       " 4    perimeter_mean           91.969      43.79      86.24     188.5   \n",
       " 5    area_mean                654.889     143.5      551.1     2501.0  \n",
       " 6    smoothness_mean          0.0963603   0.05263    0.09587   0.1634  \n",
       " 7    compactness_mean         0.104341    0.01938    0.09263   0.3454  \n",
       " 8    concavity_mean           0.0887993   0.0        0.06154   0.4268  \n",
       " 9    concave points_mean      0.0489191   0.0        0.0335    0.2012  \n",
       " 10   symmetry_mean            0.181162    0.106      0.1792    0.304   \n",
       " 11   fractal_dimension_mean   0.0627976   0.04996    0.06154   0.09744 \n",
       " 12   radius_se                0.405172    0.1115     0.3242    2.873   \n",
       " 13   texture_se               1.21685     0.3602     1.108     4.885   \n",
       " 14   perimeter_se             2.86606     0.757      2.287     21.98   \n",
       " 15   area_se                  40.3371     6.802      24.53     542.2   \n",
       " 16   smoothness_se            0.00704098  0.001713   0.00638   0.03113 \n",
       " 17   compactness_se           0.0254781   0.002252   0.02045   0.1354  \n",
       " 18   concavity_se             0.0318937   0.0        0.02589   0.396   \n",
       " 19   concave points_se        0.0117961   0.0        0.01093   0.05279 \n",
       " 20   symmetry_se              0.0205423   0.007882   0.01873   0.07895 \n",
       " 21   fractal_dimension_se     0.0037949   0.0008948  0.003187  0.02984 \n",
       " 22   radius_worst             16.2692     7.93       14.97     36.04   \n",
       " 23   texture_worst            25.6772     12.02      25.41     49.54   \n",
       " 24   perimeter_worst          107.261     50.41      97.66     251.2   \n",
       " 25   area_worst               880.583     185.2      686.5     4254.0  \n",
       " 26   smoothness_worst         0.132369    0.07117    0.1313    0.2226  \n",
       " 27   compactness_worst        0.254265    0.02729    0.2119    1.058   \n",
       " 28   concavity_worst          0.272188    0.0        0.2267    1.252   \n",
       " 29   concave points_worst     0.114606    0.0        0.09993   0.291   \n",
       " 30   symmetry_worst           0.290076    0.1565     0.2822    0.6638  \n",
       " 31   fractal_dimension_worst  0.0839458   0.05504    0.08004   0.2075  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[:, Not([33, 1])]\n",
    "describe(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[22m _.names                 \u001b[0m\u001b[0m\u001b[22m _.types                         \u001b[0m\u001b[0m\u001b[22m _.scitypes    \u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "\u001b[0m diagnosis               \u001b[0m\u001b[0m CategoricalValue{String,UInt32} \u001b[0m\u001b[0m Multiclass{2} \u001b[0m\u001b[0m\n",
       "\u001b[0m radius_mean             \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m texture_mean            \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m perimeter_mean          \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m area_mean               \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m smoothness_mean         \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m compactness_mean        \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m concavity_mean          \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m concave points_mean     \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m symmetry_mean           \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m fractal_dimension_mean  \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m radius_se               \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m texture_se              \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m perimeter_se            \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m area_se                 \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m smoothness_se           \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m compactness_se          \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m concavity_se            \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m concave points_se       \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m symmetry_se             \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m fractal_dimension_se    \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m radius_worst            \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m texture_worst           \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m perimeter_worst         \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m area_worst              \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m smoothness_worst        \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m compactness_worst       \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m concavity_worst         \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m concave points_worst    \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m symmetry_worst          \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m fractal_dimension_worst \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "_.nrows = 569\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coerce!(data, :diagnosis=>Multiclass)\n",
    "schema(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CategoricalValue{String,UInt32}[\"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\"    \"B\", \"B\", \"B\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"B\"], 56930 DataFrame. Omitted printing of 26 columns\n",
       " Row  radius_mean  texture_mean  perimeter_mean  area_mean \n",
       "      \u001b[90mFloat64\u001b[39m      \u001b[90mFloat64\u001b[39m       \u001b[90mFloat64\u001b[39m         \u001b[90mFloat64\u001b[39m   \n",
       "\n",
       " 1    17.99        10.38         122.8           1001.0    \n",
       " 2    20.57        17.77         132.9           1326.0    \n",
       " 3    19.69        21.25         130.0           1203.0    \n",
       " 4    11.42        20.38         77.58           386.1     \n",
       " 5    20.29        14.34         135.1           1297.0    \n",
       " 6    12.45        15.7          82.57           477.1     \n",
       " 7    18.25        19.98         119.6           1040.0    \n",
       " 8    13.71        20.83         90.2            577.9     \n",
       " 9    13.0         21.82         87.5            519.8     \n",
       " 10   12.46        24.04         83.97           475.9     \n",
       " 11   16.02        23.24         102.7           797.8     \n",
       " 12   15.78        17.89         103.6           781.0     \n",
       " 13   19.17        24.8          132.4           1123.0    \n",
       " 14   15.85        23.95         103.7           782.7     \n",
       " 15   13.73        22.61         93.6            578.3     \n",
       " 16   14.54        27.54         96.73           658.8     \n",
       " 17   14.68        20.13         94.74           684.5     \n",
       " 18   16.13        20.68         108.1           798.8     \n",
       " 19   19.81        22.15         130.0           1260.0    \n",
       " 20   13.54        14.36         87.46           566.3     \n",
       "\n",
       " 549  9.683        19.34         61.05           285.7     \n",
       " 550  10.82        24.21         68.89           361.6     \n",
       " 551  10.86        21.48         68.51           360.5     \n",
       " 552  11.13        22.44         71.49           378.4     \n",
       " 553  12.77        29.43         81.35           507.9     \n",
       " 554  9.333        21.94         59.01           264.0     \n",
       " 555  12.88        28.92         82.5            514.3     \n",
       " 556  10.29        27.61         65.67           321.4     \n",
       " 557  10.16        19.59         64.73           311.7     \n",
       " 558  9.423        27.88         59.26           271.3     \n",
       " 559  14.59        22.68         96.39           657.1     \n",
       " 560  11.51        23.93         74.52           403.5     \n",
       " 561  14.05        27.15         91.38           600.4     \n",
       " 562  11.2         29.37         70.67           386.0     \n",
       " 563  15.22        30.62         103.4           716.9     \n",
       " 564  20.92        25.09         143.0           1347.0    \n",
       " 565  21.56        22.39         142.0           1479.0    \n",
       " 566  20.13        28.25         131.2           1261.0    \n",
       " 567  16.6         28.08         108.3           858.1     \n",
       " 568  20.6         29.33         140.1           1265.0    \n",
       " 569  7.76         24.54         47.92           181.0     )"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, X = unpack(data, ==(:diagnosis), colname->true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition train and test data accoring to class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([483, 534, 159, 31, 170, 416, 231, 43, 161, 286    134, 500, 395, 533, 112, 396, 297, 106, 303, 261], [392, 390, 320, 27, 328, 477, 19, 356, 518, 444    136, 559, 505, 274, 508, 358, 90, 296, 79, 415])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data to use when trying to fit a single validation set\n",
    "train, test = partition(eachindex(y), 0.7, shuffle=true, rng=123, stratify=values(data[:diagnosis])) # gives 70:30 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 0.628140703517588\n",
       " 0.37185929648241206"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_counts = countmap(data[train,:diagnosis])\n",
    "collect(train_counts[i] / size(train)[1] for i in keys(train_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 0.6257309941520468\n",
       " 0.3742690058479532"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_counts = countmap(data[test,:diagnosis])\n",
    "collect(test_counts[i] / size(test)[1] for i in keys(test_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Five Learning Algorithms\n",
    "\n",
    "* Decision trees with some form of pruning\n",
    "* Neural networks\n",
    "* Boosting\n",
    "* Support Vector Machines\n",
    "* k-nearest neighbors\n",
    "\n",
    "\n",
    "##### Testing\n",
    "* Implement the algorithms\n",
    "* Design two *interesting* classification problems. For the purposes of this assignment, a classification problem is just a set of training examples and a set of test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43-element Array{NamedTuple{(:name, :package_name, :is_supervised, :docstring, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :is_pure_julia, :is_wrapper, :load_path, :package_license, :package_url, :package_uuid, :prediction_type, :supports_online, :supports_weights, :input_scitype, :target_scitype, :output_scitype),T} where T<:Tuple,1}:\n",
       " (name = AdaBoostClassifier, package_name = ScikitLearn, ... )\n",
       " (name = AdaBoostStumpClassifier, package_name = DecisionTree, ... )\n",
       " (name = BaggingClassifier, package_name = ScikitLearn, ... )\n",
       " (name = BayesianLDA, package_name = MultivariateStats, ... )\n",
       " (name = BayesianLDA, package_name = ScikitLearn, ... )\n",
       " (name = BayesianQDA, package_name = ScikitLearn, ... )\n",
       " (name = BayesianSubspaceLDA, package_name = MultivariateStats, ... )\n",
       " (name = ConstantClassifier, package_name = MLJModels, ... )\n",
       " (name = DecisionTreeClassifier, package_name = DecisionTree, ... )\n",
       " (name = DeterministicConstantClassifier, package_name = MLJModels, ... )\n",
       " (name = DummyClassifier, package_name = ScikitLearn, ... )\n",
       " (name = EvoTreeClassifier, package_name = EvoTrees, ... )\n",
       " (name = ExtraTreesClassifier, package_name = ScikitLearn, ... )\n",
       " (name = GaussianNBClassifier, package_name = NaiveBayes, ... )\n",
       " (name = GaussianNBClassifier, package_name = ScikitLearn, ... )\n",
       " (name = GaussianProcessClassifier, package_name = ScikitLearn, ... )\n",
       " (name = GradientBoostingClassifier, package_name = ScikitLearn, ... )\n",
       " (name = KNNClassifier, package_name = NearestNeighbors, ... )\n",
       " (name = KNeighborsClassifier, package_name = ScikitLearn, ... )\n",
       " (name = LDA, package_name = MultivariateStats, ... )\n",
       " (name = LGBMClassifier, package_name = LightGBM, ... )\n",
       " (name = LinearBinaryClassifier, package_name = GLM, ... )\n",
       " (name = LinearSVC, package_name = LIBSVM, ... )\n",
       " (name = LogisticCVClassifier, package_name = ScikitLearn, ... )\n",
       " (name = LogisticClassifier, package_name = MLJLinearModels, ... )\n",
       " (name = LogisticClassifier, package_name = ScikitLearn, ... )\n",
       " (name = MultinomialClassifier, package_name = MLJLinearModels, ... )\n",
       " (name = NeuralNetworkClassifier, package_name = MLJFlux, ... )\n",
       " (name = NuSVC, package_name = LIBSVM, ... )\n",
       " (name = PassiveAggressiveClassifier, package_name = ScikitLearn, ... )\n",
       " (name = PerceptronClassifier, package_name = ScikitLearn, ... )\n",
       " (name = ProbabilisticSGDClassifier, package_name = ScikitLearn, ... )\n",
       " (name = RandomForestClassifier, package_name = DecisionTree, ... )\n",
       " (name = RandomForestClassifier, package_name = ScikitLearn, ... )\n",
       " (name = RidgeCVClassifier, package_name = ScikitLearn, ... )\n",
       " (name = RidgeClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SGDClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SVC, package_name = LIBSVM, ... )\n",
       " (name = SVMClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SVMLinearClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SVMNuClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SubspaceLDA, package_name = MultivariateStats, ... )\n",
       " (name = XGBoostClassifier, package_name = XGBoost, ... )"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models(matching(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJModels \n",
      "import NearestNeighbors "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Info: Loading into module \"Main\": \n",
      " @ MLJModels /home/andrew/.julia/packages/MLJModels/5DFoi/src/loading.jl:70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import MLJModels.NearestNeighbors_ \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNNClassifier(\n",
       "    K = 5,\n",
       "    algorithm = :kdtree,\n",
       "    metric = Distances.Euclidean(0.0),\n",
       "    leafsize = 10,\n",
       "    reorder = true,\n",
       "    weights = :uniform)\u001b[34m @077\u001b[39m"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@load KNNClassifier verbosity=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors\n",
    "* Use different values of k.\n",
    "\n",
    "1. https://alan-turing-institute.github.io/MLJ.jl/dev/composing_models/\n",
    "1. https://github.com/KristofferC/NearestNeighbors.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNNClassifier(\n",
       "    K = 5,\n",
       "    algorithm = :kdtree,\n",
       "    metric = Distances.Euclidean(0.0),\n",
       "    leafsize = 10,\n",
       "    reorder = true,\n",
       "    weights = :uniform)\u001b[34m @472\u001b[39m"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNNClassifier(K=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{KNNClassifier} @213\u001b[39m trained 0 times.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @530\u001b[39m  `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @508\u001b[39m  `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN = machine(knn, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Info: Training \u001b[34mMachine{KNNClassifier} @213\u001b[39m.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/machines.jl:322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{KNNClassifier} @213\u001b[39m trained 1 time.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @530\u001b[39m  `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @508\u001b[39m  `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(KNN, rows=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 6 folds: 100%[=========================] Time: 0:00:05\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[22m _.measure        \u001b[0m\u001b[0m\u001b[22m _.measurement \u001b[0m\u001b[0m\u001b[22m _.per_fold                                 \u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "\u001b[0m cross_entropy    \u001b[0m\u001b[0m 0.922         \u001b[0m\u001b[0m [0.068, 1.23, 0.885, 2.0, 0.878, 0.478]    \u001b[0m\u001b[0m\n",
       "\u001b[0m acc              \u001b[0m\u001b[0m 0.93          \u001b[0m\u001b[0m [0.979, 0.937, 0.916, 0.884, 0.916, 0.947] \u001b[0m\u001b[0m\n",
       "\u001b[0m area_under_curve \u001b[0m\u001b[0m 0.971         \u001b[0m\u001b[0m [0.999, 0.966, 0.972, 0.946, 0.958, 0.987] \u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "_.per_observation = [[[2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [1.61, 2.22e-16, ..., 0.916], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16]], missing, missing]\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_acc = evaluate!(KNN, resampling=CV(shuffle=true), measure=[cross_entropy, acc, area_under_curve], verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tree = NearestNeighbors.KDTree{StaticArrays.SArray{Tuple{30},Float64,1,30},Distances.Euclidean,Float64}\n",
       "  Number of points: 475\n",
       "  Dimensions: 30\n",
       "  Metric: Distances.Euclidean(0.0)\n",
       "  Reordered: true,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_params(KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNNClassifier(\n",
       "    K = 5,\n",
       "    algorithm = :kdtree,\n",
       "    metric = Distances.Euclidean(0.0),\n",
       "    leafsize = 10,\n",
       "    reorder = true,\n",
       "    weights = :uniform)\u001b[34m @888\u001b[39m"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNNClassifier(K=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Info: Training \u001b[34mMachine{Standardizer} @500\u001b[39m.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/machines.jl:322\n"
     ]
    }
   ],
   "source": [
    "standardizer = Standardizer()\n",
    "stand = machine(standardizer, X[train,:])\n",
    "fit!(stand)\n",
    "X_stand = MLJ.transform(stand, X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{KNNClassifier} @749\u001b[39m trained 0 times.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @992\u001b[39m  `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @898\u001b[39m  `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN = machine(knn, X_stand, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Info: Training \u001b[34mMachine{KNNClassifier} @749\u001b[39m.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/machines.jl:322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{KNNClassifier} @749\u001b[39m trained 1 time.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @992\u001b[39m  `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @898\u001b[39m  `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(KNN, rows=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 6 folds: 100%[=========================] Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[22m _.measure     \u001b[0m\u001b[0m\u001b[22m _.measurement \u001b[0m\u001b[0m\u001b[22m _.per_fold                                    \u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "\u001b[0m cross_entropy \u001b[0m\u001b[0m 0.264         \u001b[0m\u001b[0m [0.49, 0.0768, 0.831, 0.0714, 0.0488, 0.0663] \u001b[0m\u001b[0m\n",
       "\u001b[0m acc           \u001b[0m\u001b[0m 0.967         \u001b[0m\u001b[0m [0.947, 0.968, 0.947, 0.968, 0.979, 0.989]    \u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "_.per_observation = [[[2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 0.511]], missing]\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_acc = evaluate!(KNN, resampling=CV(shuffle=true), measure=[cross_entropy, acc], verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Warning: The classes are un-ordered,\n",
      " using: negative='B' and positive='M'.\n",
      " To suppress this warning, consider coercing to OrderedFactor.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n",
      " Warning: The classes are un-ordered,\n",
      " using: negative='B' and positive='M'.\n",
      " To suppress this warning, consider coercing to OrderedFactor.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n",
      " Warning: The classes are un-ordered,\n",
      " using: negative='B' and positive='M'.\n",
      " To suppress this warning, consider coercing to OrderedFactor.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n",
      " Warning: The classes are un-ordered,\n",
      " using: negative='B' and positive='M'.\n",
      " To suppress this warning, consider coercing to OrderedFactor.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n",
      "\u001b[33mEvaluating over 6 folds:  17%[====>                    ]  ETA: 0:00:02\u001b[39m Warning: The classes are un-ordered,\n",
      " using: negative='B' and positive='M'.\n",
      " To suppress this warning, consider coercing to OrderedFactor.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n",
      " Warning: The classes are un-ordered,\n",
      " using: negative='B' and positive='M'.\n",
      " To suppress this warning, consider coercing to OrderedFactor.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n",
      " Warning: The classes are un-ordered,\n",
      " using: negative='B' and positive='M'.\n",
      " To suppress this warning, consider coercing to OrderedFactor.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n",
      " Warning: The classes are un-ordered,\n",
      " using: negative='B' and positive='M'.\n",
      " To suppress this warning, consider coercing to OrderedFactor.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n",
      "\u001b[33mEvaluating over 6 folds:  33%[========>                ]  ETA: 0:00:01\u001b[39m Warning: The classes are un-ordered,\n",
      " using: negative='B' and positive='M'.\n",
      " To suppress this warning, consider coercing to OrderedFactor.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n",
      " Warning: The classes are un-ordered,\n",
      " using: negative='B' and positive='M'.\n",
      " To suppress this warning, consider coercing to OrderedFactor.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n",
      " Warning: The classes are un-ordered,\n",
      " using: negative='B' and positive='M'.\n",
      " To suppress this warning, consider coercing to OrderedFactor.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n",
      " Warning: The classes are un-ordered,\n",
      " using: negative='B' and positive='M'.\n",
      " To suppress this warning, consider coercing to OrderedFactor.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n",
      "\u001b[33mEvaluating over 6 folds:  50%[============>            ]  ETA: 0:00:00\u001b[39m Warning: The classes are un-ordered,\n",
      " using: negative='B' and positive='M'.\n",
      " To suppress this warning, consider coercing to OrderedFactor.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n",
      " Warning: The classes are un-ordered,\n",
      " using: negative='B' and positive='M'.\n",
      " To suppress this warning, consider coercing to OrderedFactor.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n",
      " Warning: The classes are un-ordered,\n",
      " using: negative='B' and positive='M'.\n",
      " To suppress this warning, consider coercing to OrderedFactor.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n",
      " Warning: The classes are un-ordered,\n",
      " using: negative='B' and positive='M'.\n",
      " To suppress this warning, consider coercing to OrderedFactor.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n",
      "\u001b[33mEvaluating over 6 folds:  67%[================>        ]  ETA: 0:00:00\u001b[39m Warning: The classes are un-ordered,\n",
      " using: negative='B' and positive='M'.\n",
      " To suppress this warning, consider coercing to OrderedFactor.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n",
      " Warning: The classes are un-ordered,\n",
      " using: negative='B' and positive='M'.\n",
      " To suppress this warning, consider coercing to OrderedFactor.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n",
      " Warning: The classes are un-ordered,\n",
      " using: negative='B' and positive='M'.\n",
      " To suppress this warning, consider coercing to OrderedFactor.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n",
      " Warning: The classes are un-ordered,\n",
      " using: negative='B' and positive='M'.\n",
      " To suppress this warning, consider coercing to OrderedFactor.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n",
      "\u001b[33mEvaluating over 6 folds:  83%[====================>    ]  ETA: 0:00:00\u001b[39m Warning: The classes are un-ordered,\n",
      " using: negative='B' and positive='M'.\n",
      " To suppress this warning, consider coercing to OrderedFactor.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n",
      " Warning: The classes are un-ordered,\n",
      " using: negative='B' and positive='M'.\n",
      " To suppress this warning, consider coercing to OrderedFactor.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n",
      " Warning: The classes are un-ordered,\n",
      " using: negative='B' and positive='M'.\n",
      " To suppress this warning, consider coercing to OrderedFactor.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n",
      " Warning: The classes are un-ordered,\n",
      " using: negative='B' and positive='M'.\n",
      " To suppress this warning, consider coercing to OrderedFactor.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n",
      "\u001b[33mEvaluating over 6 folds: 100%[=========================] Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[22m _.measure           \u001b[0m\u001b[0m\u001b[22m _.measurement \u001b[0m\u001b[0m\u001b[22m _.per_fold                                   \u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "\u001b[0m true_negative_rate  \u001b[0m\u001b[0m 0.992         \u001b[0m\u001b[0m [0.982, 0.984, 1.0, 1.0, 1.0, 0.984]         \u001b[0m\u001b[0m\n",
       "\u001b[0m true_positive_rate  \u001b[0m\u001b[0m 0.927         \u001b[0m\u001b[0m [0.868, 0.909, 0.943, 1.0, 0.909, 0.933]     \u001b[0m\u001b[0m\n",
       "\u001b[0m false_negative_rate \u001b[0m\u001b[0m 0.0729        \u001b[0m\u001b[0m [0.132, 0.0909, 0.0571, 0.0, 0.0909, 0.0667] \u001b[0m\u001b[0m\n",
       "\u001b[0m false_positive_rate \u001b[0m\u001b[0m 0.00822       \u001b[0m\u001b[0m [0.0175, 0.0161, 0.0, 0.0, 0.0, 0.0156]      \u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "_.per_observation = [missing, missing, missing, missing]\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate!(KNN, resampling=CV(shuffle=true), measure=[tnr,tpr,fnr,fpr], verbosity=1, operation=predict_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tree = NearestNeighbors.KDTree{StaticArrays.SArray{Tuple{30},Float64,1,30},Distances.Euclidean,Float64}\n",
       "  Number of points: 475\n",
       "  Dimensions: 30\n",
       "  Metric: Distances.Euclidean(0.0)\n",
       "  Reordered: true,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_params(KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch / RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNNClassifier(\n",
       "    K = 5,\n",
       "    algorithm = :kdtree,\n",
       "    metric = Distances.Euclidean(0.0),\n",
       "    leafsize = 10,\n",
       "    reorder = true,\n",
       "    weights = :uniform)\u001b[34m @282\u001b[39m"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid = KNNClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLJBase.NumericRange(Int64, :K, ... )"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param1 = :K\n",
    "\n",
    "r1 = range(knn_grid, param1, lower=1, upper=20, scale=:linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProbabilisticTunedModel(\n",
       "    model = KNNClassifier(\n",
       "            K = 5,\n",
       "            algorithm = :kdtree,\n",
       "            metric = Distances.Euclidean(0.0),\n",
       "            leafsize = 10,\n",
       "            reorder = true,\n",
       "            weights = :uniform),\n",
       "    tuning = Grid(\n",
       "            goal = 100,\n",
       "            resolution = 10,\n",
       "            shuffle = true,\n",
       "            rng = Random._GLOBAL_RNG()),\n",
       "    resampling = CV(\n",
       "            nfolds = 6,\n",
       "            shuffle = false,\n",
       "            rng = Random._GLOBAL_RNG()),\n",
       "    measure = cross_entropy(\n",
       "            eps = 2.220446049250313e-16),\n",
       "    weights = nothing,\n",
       "    operation = MLJModelInterface.predict,\n",
       "    range = MLJBase.NumericRange{Int64,MLJBase.Bounded,Symbol}[\u001b[34mNumericRange{Int64,} @031\u001b[39m],\n",
       "    train_best = true,\n",
       "    repeats = 1,\n",
       "    n = nothing,\n",
       "    acceleration = CPUThreads{Int64}(1),\n",
       "    acceleration_resampling = CPU1{Nothing}(nothing),\n",
       "    check_measure = true)\u001b[34m @886\u001b[39m"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_tuning_knn_model = TunedModel(model=knn_grid,\n",
    "                                    tuning=Grid(goal=100),\n",
    "                                    resampling=CV(), \n",
    "                                    measure=cross_entropy,\n",
    "                                    acceleration=CPUThreads(),\n",
    "                                    range=[r1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{ProbabilisticTunedModel{Grid,}} @993\u001b[39m trained 0 times.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @061\u001b[39m  `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @910\u001b[39m  `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_tuning_knn = machine(self_tuning_knn_model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Info: Training \u001b[34mMachine{ProbabilisticTunedModel{Grid,}} @993\u001b[39m.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/machines.jl:322\n",
      " Info: Attempting to evaluate 20 models.\n",
      " @ MLJTuning /home/andrew/.julia/packages/MLJTuning/nuvTc/src/tuned_models.jl:501\n",
      "\u001b[33mEvaluating over 20 metamodels: 100%[=========================] Time: 0:00:01\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{ProbabilisticTunedModel{Grid,}} @993\u001b[39m trained 1 time.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @061\u001b[39m  `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @910\u001b[39m  `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = fit!(self_tuning_knn, rows=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(best_model = \u001b[34mKNNClassifier @058\u001b[39m,\n",
       " best_fitted_params = (tree = NearestNeighbors.KDTree{StaticArrays.SArray{Tuple{30},Float64,1,30},Distances.Euclidean,Float64}\n",
       "  Number of points: 398\n",
       "  Dimensions: 30\n",
       "  Metric: Distances.Euclidean(0.0)\n",
       "  Reordered: true,),)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = fitted_params(self_tuning_knn)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNNClassifier(\n",
       "    K = 9,\n",
       "    algorithm = :kdtree,\n",
       "    metric = Distances.Euclidean(0.0),\n",
       "    leafsize = 10,\n",
       "    reorder = true,\n",
       "    weights = :uniform)\u001b[34m @058\u001b[39m"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(d, train_metric, valid_metric) = (10, 0.8, 0.6875)\n",
      "(d, train_metric, valid_metric) = (11, 0.7272727272727273, 0.6875)\n",
      "(d, train_metric, valid_metric) = (12, 0.75, 0.6875)\n",
      "(d, train_metric, valid_metric) = (13, 0.7692307692307693, 0.6875)\n",
      "(d, train_metric, valid_metric) = (14, 0.7142857142857143, 0.6875)\n",
      "(d, train_metric, valid_metric) = (15, 0.7333333333333333, 0.6875)\n",
      "(d, train_metric, valid_metric) = (16, 0.75, 0.6875)\n",
      "(d, train_metric, valid_metric) = (17, 0.8235294117647058, 0.725)\n",
      "(d, train_metric, valid_metric) = (18, 0.8333333333333334, 0.7875)\n",
      "(d, train_metric, valid_metric) = (19, 0.7894736842105263, 0.7875)\n",
      "(d, train_metric, valid_metric) = (20, 0.8, 0.7875)\n",
      "(d, train_metric, valid_metric) = (21, 0.9047619047619048, 0.875)\n",
      "(d, train_metric, valid_metric) = (22, 0.9090909090909091, 0.875)\n",
      "(d, train_metric, valid_metric) = (23, 0.9130434782608695, 0.875)\n",
      "(d, train_metric, valid_metric) = (24, 0.9166666666666666, 0.875)\n",
      "(d, train_metric, valid_metric) = (25, 0.92, 0.875)\n",
      "(d, train_metric, valid_metric) = (26, 0.9230769230769231, 0.875)\n",
      "(d, train_metric, valid_metric) = (27, 0.9259259259259259, 0.8875)\n",
      "(d, train_metric, valid_metric) = (28, 0.9285714285714286, 0.8875)\n",
      "(d, train_metric, valid_metric) = (29, 0.9310344827586207, 0.8875)\n",
      "(d, train_metric, valid_metric) = (30, 0.9666666666666667, 0.925)\n",
      "(d, train_metric, valid_metric) = (31, 0.967741935483871, 0.925)\n",
      "(d, train_metric, valid_metric) = (32, 0.96875, 0.925)\n",
      "(d, train_metric, valid_metric) = (33, 0.9696969696969697, 0.925)\n",
      "(d, train_metric, valid_metric) = (34, 0.9705882352941176, 0.925)\n",
      "(d, train_metric, valid_metric) = (35, 0.9714285714285714, 0.925)\n",
      "(d, train_metric, valid_metric) = (36, 0.9722222222222222, 0.925)\n",
      "(d, train_metric, valid_metric) = (37, 0.972972972972973, 0.925)\n",
      "(d, train_metric, valid_metric) = (38, 0.9473684210526315, 0.9375)\n",
      "(d, train_metric, valid_metric) = (39, 0.9487179487179487, 0.9375)\n",
      "(d, train_metric, valid_metric) = (40, 0.95, 0.9375)\n",
      "(d, train_metric, valid_metric) = (41, 0.9512195121951219, 0.9375)\n",
      "(d, train_metric, valid_metric) = (42, 0.9523809523809523, 0.9375)\n",
      "(d, train_metric, valid_metric) = (43, 0.9302325581395349, 0.9375)\n",
      "(d, train_metric, valid_metric) = (44, 0.9318181818181818, 0.9375)\n",
      "(d, train_metric, valid_metric) = (45, 0.9333333333333333, 0.9375)\n",
      "(d, train_metric, valid_metric) = (46, 0.9130434782608695, 0.9375)\n",
      "(d, train_metric, valid_metric) = (47, 0.9148936170212766, 0.9375)\n",
      "(d, train_metric, valid_metric) = (48, 0.9166666666666666, 0.9375)\n",
      "(d, train_metric, valid_metric) = (49, 0.9183673469387755, 0.9375)\n",
      "(d, train_metric, valid_metric) = (50, 0.92, 0.9375)\n",
      "(d, train_metric, valid_metric) = (51, 0.9215686274509803, 0.9375)\n",
      "(d, train_metric, valid_metric) = (52, 0.9230769230769231, 0.9375)\n",
      "(d, train_metric, valid_metric) = (53, 0.9245283018867925, 0.9375)\n",
      "(d, train_metric, valid_metric) = (54, 0.9259259259259259, 0.9375)\n",
      "(d, train_metric, valid_metric) = (55, 0.9272727272727272, 0.9375)\n",
      "(d, train_metric, valid_metric) = (56, 0.9285714285714286, 0.9375)\n",
      "(d, train_metric, valid_metric) = (57, 0.9298245614035088, 0.9375)\n",
      "(d, train_metric, valid_metric) = (58, 0.9137931034482759, 0.9375)\n",
      "(d, train_metric, valid_metric) = (59, 0.9152542372881356, 0.9375)\n",
      "(d, train_metric, valid_metric) = (60, 0.9166666666666666, 0.9375)\n",
      "(d, train_metric, valid_metric) = (61, 0.9180327868852459, 0.9375)\n",
      "(d, train_metric, valid_metric) = (62, 0.9516129032258065, 0.925)\n",
      "(d, train_metric, valid_metric) = (63, 0.9523809523809523, 0.925)\n",
      "(d, train_metric, valid_metric) = (64, 0.953125, 0.925)\n",
      "(d, train_metric, valid_metric) = (65, 0.9538461538461539, 0.925)\n",
      "(d, train_metric, valid_metric) = (66, 0.9545454545454546, 0.925)\n",
      "(d, train_metric, valid_metric) = (67, 0.9552238805970149, 0.925)\n",
      "(d, train_metric, valid_metric) = (68, 0.9558823529411765, 0.925)\n",
      "(d, train_metric, valid_metric) = (69, 0.9565217391304348, 0.925)\n",
      "(d, train_metric, valid_metric) = (70, 0.9571428571428572, 0.925)\n",
      "(d, train_metric, valid_metric) = (71, 0.9577464788732394, 0.9375)\n",
      "(d, train_metric, valid_metric) = (72, 0.9583333333333334, 0.9375)\n",
      "(d, train_metric, valid_metric) = (73, 0.958904109589041, 0.9375)\n",
      "(d, train_metric, valid_metric) = (74, 0.9594594594594594, 0.9375)\n",
      "(d, train_metric, valid_metric) = (75, 0.9466666666666667, 0.9375)\n",
      "(d, train_metric, valid_metric) = (76, 0.9473684210526315, 0.9375)\n",
      "(d, train_metric, valid_metric) = (77, 0.948051948051948, 0.9375)\n",
      "(d, train_metric, valid_metric) = (78, 0.9487179487179487, 0.9375)\n",
      "(d, train_metric, valid_metric) = (79, 0.9367088607594937, 0.9375)\n",
      "(d, train_metric, valid_metric) = (80, 0.9375, 0.9375)\n",
      "(d, train_metric, valid_metric) = (81, 0.9382716049382716, 0.9375)\n",
      "(d, train_metric, valid_metric) = (82, 0.926829268292683, 0.9375)\n",
      "(d, train_metric, valid_metric) = (83, 0.927710843373494, 0.9375)\n",
      "(d, train_metric, valid_metric) = (84, 0.9285714285714286, 0.9375)\n",
      "(d, train_metric, valid_metric) = (85, 0.9294117647058824, 0.9375)\n",
      "(d, train_metric, valid_metric) = (86, 0.9302325581395349, 0.9375)\n",
      "(d, train_metric, valid_metric) = (87, 0.9425287356321839, 0.9375)\n",
      "(d, train_metric, valid_metric) = (88, 0.9431818181818182, 0.9375)\n",
      "(d, train_metric, valid_metric) = (89, 0.9438202247191011, 0.9375)\n",
      "(d, train_metric, valid_metric) = (90, 0.9444444444444444, 0.9375)\n",
      "(d, train_metric, valid_metric) = (91, 0.9340659340659341, 0.925)\n",
      "(d, train_metric, valid_metric) = (92, 0.9347826086956522, 0.925)\n",
      "(d, train_metric, valid_metric) = (93, 0.9354838709677419, 0.925)\n",
      "(d, train_metric, valid_metric) = (94, 0.9361702127659575, 0.925)\n",
      "(d, train_metric, valid_metric) = (95, 0.9157894736842105, 0.925)\n",
      "(d, train_metric, valid_metric) = (96, 0.9166666666666666, 0.925)\n",
      "(d, train_metric, valid_metric) = (97, 0.9175257731958762, 0.925)\n",
      "(d, train_metric, valid_metric) = (98, 0.9183673469387755, 0.925)\n",
      "(d, train_metric, valid_metric) = (99, 0.9191919191919192, 0.925)\n",
      "(d, train_metric, valid_metric) = (100, 0.92, 0.925)\n",
      "(d, train_metric, valid_metric) = (101, 0.9207920792079208, 0.925)\n",
      "(d, train_metric, valid_metric) = (102, 0.9215686274509803, 0.925)\n",
      "(d, train_metric, valid_metric) = (103, 0.9223300970873787, 0.925)\n",
      "(d, train_metric, valid_metric) = (104, 0.9230769230769231, 0.925)\n",
      "(d, train_metric, valid_metric) = (105, 0.9238095238095239, 0.925)\n",
      "(d, train_metric, valid_metric) = (106, 0.9245283018867925, 0.925)\n",
      "(d, train_metric, valid_metric) = (107, 0.9252336448598131, 0.925)\n",
      "(d, train_metric, valid_metric) = (108, 0.9259259259259259, 0.925)\n",
      "(d, train_metric, valid_metric) = (109, 0.9174311926605505, 0.925)\n",
      "(d, train_metric, valid_metric) = (110, 0.9181818181818182, 0.925)\n",
      "(d, train_metric, valid_metric) = (111, 0.918918918918919, 0.925)\n",
      "(d, train_metric, valid_metric) = (112, 0.9196428571428571, 0.925)\n",
      "(d, train_metric, valid_metric) = (113, 0.9203539823008849, 0.925)\n",
      "(d, train_metric, valid_metric) = (114, 0.9210526315789473, 0.925)\n",
      "(d, train_metric, valid_metric) = (115, 0.9217391304347826, 0.925)\n",
      "(d, train_metric, valid_metric) = (116, 0.9224137931034483, 0.925)\n",
      "(d, train_metric, valid_metric) = (117, 0.9230769230769231, 0.925)\n",
      "(d, train_metric, valid_metric) = (118, 0.923728813559322, 0.925)\n",
      "(d, train_metric, valid_metric) = (119, 0.9243697478991597, 0.925)\n",
      "(d, train_metric, valid_metric) = (120, 0.9166666666666666, 0.925)\n",
      "(d, train_metric, valid_metric) = (121, 0.9173553719008265, 0.925)\n",
      "(d, train_metric, valid_metric) = (122, 0.9180327868852459, 0.925)\n",
      "(d, train_metric, valid_metric) = (123, 0.9186991869918699, 0.925)\n",
      "(d, train_metric, valid_metric) = (124, 0.9354838709677419, 0.925)\n",
      "(d, train_metric, valid_metric) = (125, 0.928, 0.925)\n",
      "(d, train_metric, valid_metric) = (126, 0.9285714285714286, 0.925)\n",
      "(d, train_metric, valid_metric) = (127, 0.9291338582677166, 0.925)\n",
      "(d, train_metric, valid_metric) = (128, 0.9296875, 0.925)\n",
      "(d, train_metric, valid_metric) = (129, 0.9302325581395349, 0.9125)\n",
      "(d, train_metric, valid_metric) = (130, 0.9307692307692308, 0.9125)\n",
      "(d, train_metric, valid_metric) = (131, 0.9312977099236641, 0.9125)\n",
      "(d, train_metric, valid_metric) = (132, 0.9318181818181818, 0.9125)\n",
      "(d, train_metric, valid_metric) = (133, 0.9323308270676691, 0.9125)\n",
      "(d, train_metric, valid_metric) = (134, 0.9328358208955224, 0.9125)\n",
      "(d, train_metric, valid_metric) = (135, 0.9333333333333333, 0.9125)\n",
      "(d, train_metric, valid_metric) = (136, 0.9411764705882353, 0.9125)\n",
      "(d, train_metric, valid_metric) = (137, 0.9416058394160584, 0.9125)\n",
      "(d, train_metric, valid_metric) = (138, 0.9420289855072463, 0.9125)\n",
      "(d, train_metric, valid_metric) = (139, 0.9424460431654677, 0.9125)\n",
      "(d, train_metric, valid_metric) = (140, 0.9428571428571428, 0.9125)\n",
      "(d, train_metric, valid_metric) = (141, 0.9432624113475178, 0.9125)\n",
      "(d, train_metric, valid_metric) = (142, 0.9436619718309859, 0.9125)\n",
      "(d, train_metric, valid_metric) = (143, 0.9440559440559441, 0.9125)\n",
      "(d, train_metric, valid_metric) = (144, 0.9444444444444444, 0.9125)\n",
      "(d, train_metric, valid_metric) = (145, 0.9310344827586207, 0.9125)\n",
      "(d, train_metric, valid_metric) = (146, 0.9315068493150684, 0.9125)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(d, train_metric, valid_metric) = (147, 0.9251700680272109, 0.9125)\n",
      "(d, train_metric, valid_metric) = (148, 0.9256756756756757, 0.9125)\n",
      "(d, train_metric, valid_metric) = (149, 0.9194630872483222, 0.925)\n",
      "(d, train_metric, valid_metric) = (150, 0.92, 0.925)\n",
      "(d, train_metric, valid_metric) = (151, 0.9139072847682119, 0.925)\n",
      "(d, train_metric, valid_metric) = (152, 0.9144736842105263, 0.925)\n",
      "(d, train_metric, valid_metric) = (153, 0.9150326797385621, 0.925)\n",
      "(d, train_metric, valid_metric) = (154, 0.9155844155844156, 0.925)\n",
      "(d, train_metric, valid_metric) = (155, 0.9161290322580645, 0.925)\n",
      "(d, train_metric, valid_metric) = (156, 0.9166666666666666, 0.925)\n",
      "(d, train_metric, valid_metric) = (157, 0.9171974522292994, 0.925)\n",
      "(d, train_metric, valid_metric) = (158, 0.9177215189873418, 0.925)\n",
      "(d, train_metric, valid_metric) = (159, 0.9182389937106918, 0.925)\n",
      "(d, train_metric, valid_metric) = (160, 0.91875, 0.925)\n",
      "(d, train_metric, valid_metric) = (161, 0.9192546583850931, 0.925)\n",
      "(d, train_metric, valid_metric) = (162, 0.9197530864197531, 0.925)\n",
      "(d, train_metric, valid_metric) = (163, 0.9202453987730062, 0.925)\n",
      "(d, train_metric, valid_metric) = (164, 0.9207317073170732, 0.925)\n",
      "(d, train_metric, valid_metric) = (165, 0.9212121212121213, 0.925)\n",
      "(d, train_metric, valid_metric) = (166, 0.9216867469879518, 0.925)\n",
      "(d, train_metric, valid_metric) = (167, 0.9221556886227545, 0.925)\n",
      "(d, train_metric, valid_metric) = (168, 0.9226190476190477, 0.925)\n",
      "(d, train_metric, valid_metric) = (169, 0.9171597633136095, 0.925)\n",
      "(d, train_metric, valid_metric) = (170, 0.9176470588235294, 0.925)\n",
      "(d, train_metric, valid_metric) = (171, 0.9181286549707602, 0.925)\n",
      "(d, train_metric, valid_metric) = (172, 0.9186046511627907, 0.925)\n",
      "(d, train_metric, valid_metric) = (173, 0.9190751445086706, 0.925)\n",
      "(d, train_metric, valid_metric) = (174, 0.9195402298850575, 0.9125)\n",
      "(d, train_metric, valid_metric) = (175, 0.92, 0.9125)\n",
      "(d, train_metric, valid_metric) = (176, 0.9318181818181818, 0.9125)\n",
      "(d, train_metric, valid_metric) = (177, 0.9322033898305084, 0.9125)\n",
      "(d, train_metric, valid_metric) = (178, 0.9325842696629213, 0.9125)\n",
      "(d, train_metric, valid_metric) = (179, 0.9329608938547486, 0.9125)\n",
      "(d, train_metric, valid_metric) = (180, 0.9333333333333333, 0.9125)\n",
      "(d, train_metric, valid_metric) = (181, 0.9337016574585635, 0.9125)\n",
      "(d, train_metric, valid_metric) = (182, 0.9340659340659341, 0.9125)\n",
      "(d, train_metric, valid_metric) = (183, 0.9344262295081968, 0.9125)\n",
      "(d, train_metric, valid_metric) = (184, 0.9347826086956522, 0.9125)\n",
      "(d, train_metric, valid_metric) = (185, 0.9351351351351351, 0.9125)\n",
      "(d, train_metric, valid_metric) = (186, 0.9354838709677419, 0.9125)\n",
      "(d, train_metric, valid_metric) = (187, 0.9358288770053476, 0.9125)\n",
      "(d, train_metric, valid_metric) = (188, 0.9414893617021277, 0.925)\n",
      "(d, train_metric, valid_metric) = (189, 0.9417989417989417, 0.925)\n",
      "(d, train_metric, valid_metric) = (190, 0.9421052631578948, 0.925)\n",
      "(d, train_metric, valid_metric) = (191, 0.9476439790575916, 0.925)\n",
      "(d, train_metric, valid_metric) = (192, 0.9479166666666666, 0.9375)\n",
      "(d, train_metric, valid_metric) = (193, 0.9481865284974094, 0.9375)\n",
      "(d, train_metric, valid_metric) = (194, 0.9484536082474226, 0.9375)\n",
      "(d, train_metric, valid_metric) = (195, 0.9487179487179487, 0.9375)\n",
      "(d, train_metric, valid_metric) = (196, 0.9489795918367347, 0.9375)\n",
      "(d, train_metric, valid_metric) = (197, 0.949238578680203, 0.9375)\n",
      "(d, train_metric, valid_metric) = (198, 0.9494949494949495, 0.9375)\n",
      "(d, train_metric, valid_metric) = (199, 0.949748743718593, 0.9375)\n",
      "(d, train_metric, valid_metric) = (200, 0.95, 0.9375)\n",
      "(d, train_metric, valid_metric) = (201, 0.9502487562189055, 0.9375)\n",
      "(d, train_metric, valid_metric) = (202, 0.9504950495049505, 0.9375)\n",
      "(d, train_metric, valid_metric) = (203, 0.9507389162561576, 0.9375)\n",
      "(d, train_metric, valid_metric) = (204, 0.9509803921568627, 0.9375)\n",
      "(d, train_metric, valid_metric) = (205, 0.9512195121951219, 0.925)\n",
      "(d, train_metric, valid_metric) = (206, 0.9514563106796117, 0.925)\n",
      "(d, train_metric, valid_metric) = (207, 0.9516908212560387, 0.925)\n",
      "(d, train_metric, valid_metric) = (208, 0.9519230769230769, 0.925)\n",
      "(d, train_metric, valid_metric) = (209, 0.9521531100478469, 0.925)\n",
      "(d, train_metric, valid_metric) = (210, 0.9523809523809523, 0.925)\n",
      "(d, train_metric, valid_metric) = (211, 0.95260663507109, 0.925)\n",
      "(d, train_metric, valid_metric) = (212, 0.9528301886792453, 0.925)\n",
      "(d, train_metric, valid_metric) = (213, 0.9530516431924883, 0.925)\n",
      "(d, train_metric, valid_metric) = (214, 0.9485981308411215, 0.925)\n",
      "(d, train_metric, valid_metric) = (215, 0.9488372093023256, 0.925)\n",
      "(d, train_metric, valid_metric) = (216, 0.9490740740740741, 0.925)\n",
      "(d, train_metric, valid_metric) = (217, 0.9493087557603687, 0.925)\n",
      "(d, train_metric, valid_metric) = (218, 0.9495412844036697, 0.925)\n",
      "(d, train_metric, valid_metric) = (219, 0.9497716894977168, 0.925)\n",
      "(d, train_metric, valid_metric) = (220, 0.95, 0.925)\n",
      "(d, train_metric, valid_metric) = (221, 0.9502262443438914, 0.925)\n",
      "(d, train_metric, valid_metric) = (222, 0.9504504504504504, 0.925)\n",
      "(d, train_metric, valid_metric) = (223, 0.9506726457399103, 0.925)\n",
      "(d, train_metric, valid_metric) = (224, 0.9508928571428571, 0.925)\n",
      "(d, train_metric, valid_metric) = (225, 0.9511111111111111, 0.925)\n",
      "(d, train_metric, valid_metric) = (226, 0.9513274336283186, 0.925)\n",
      "(d, train_metric, valid_metric) = (227, 0.9515418502202643, 0.925)\n",
      "(d, train_metric, valid_metric) = (228, 0.9429824561403509, 0.9375)\n",
      "(d, train_metric, valid_metric) = (229, 0.9432314410480349, 0.9375)\n",
      "(d, train_metric, valid_metric) = (230, 0.9434782608695652, 0.9375)\n",
      "(d, train_metric, valid_metric) = (231, 0.9437229437229437, 0.9375)\n",
      "(d, train_metric, valid_metric) = (232, 0.9396551724137931, 0.9375)\n",
      "(d, train_metric, valid_metric) = (233, 0.9399141630901288, 0.9375)\n",
      "(d, train_metric, valid_metric) = (234, 0.9358974358974359, 0.9375)\n",
      "(d, train_metric, valid_metric) = (235, 0.9361702127659575, 0.9375)\n",
      "(d, train_metric, valid_metric) = (236, 0.9364406779661016, 0.9375)\n",
      "(d, train_metric, valid_metric) = (237, 0.9367088607594937, 0.9375)\n",
      "(d, train_metric, valid_metric) = (238, 0.9369747899159664, 0.9375)\n",
      "(d, train_metric, valid_metric) = (239, 0.9372384937238494, 0.9375)\n",
      "(d, train_metric, valid_metric) = (240, 0.9375, 0.9375)\n",
      "(d, train_metric, valid_metric) = (241, 0.9377593360995851, 0.9375)\n",
      "(d, train_metric, valid_metric) = (242, 0.9380165289256198, 0.9375)\n",
      "(d, train_metric, valid_metric) = (243, 0.9382716049382716, 0.9375)\n",
      "(d, train_metric, valid_metric) = (244, 0.9344262295081968, 0.9375)\n",
      "(d, train_metric, valid_metric) = (245, 0.9346938775510204, 0.9375)\n",
      "(d, train_metric, valid_metric) = (246, 0.9349593495934959, 0.9375)\n",
      "(d, train_metric, valid_metric) = (247, 0.9352226720647774, 0.9375)\n",
      "(d, train_metric, valid_metric) = (248, 0.9354838709677419, 0.9375)\n",
      "(d, train_metric, valid_metric) = (249, 0.9357429718875502, 0.9375)\n",
      "(d, train_metric, valid_metric) = (250, 0.936, 0.9375)\n",
      "(d, train_metric, valid_metric) = (251, 0.9362549800796812, 0.9375)\n",
      "(d, train_metric, valid_metric) = (252, 0.9365079365079365, 0.9375)\n",
      "(d, train_metric, valid_metric) = (253, 0.9367588932806324, 0.9375)\n",
      "(d, train_metric, valid_metric) = (254, 0.937007874015748, 0.9375)\n",
      "(d, train_metric, valid_metric) = (255, 0.9372549019607843, 0.9375)\n",
      "(d, train_metric, valid_metric) = (256, 0.9375, 0.9375)\n",
      "(d, train_metric, valid_metric) = (257, 0.9377431906614786, 0.9375)\n",
      "(d, train_metric, valid_metric) = (258, 0.937984496124031, 0.9375)\n",
      "(d, train_metric, valid_metric) = (259, 0.9382239382239382, 0.9375)\n",
      "(d, train_metric, valid_metric) = (260, 0.9384615384615385, 0.9375)\n",
      "(d, train_metric, valid_metric) = (261, 0.9386973180076629, 0.9375)\n",
      "(d, train_metric, valid_metric) = (262, 0.9389312977099237, 0.9375)\n",
      "(d, train_metric, valid_metric) = (263, 0.9391634980988594, 0.9375)\n",
      "(d, train_metric, valid_metric) = (264, 0.9393939393939394, 0.9375)\n",
      "(d, train_metric, valid_metric) = (265, 0.939622641509434, 0.9375)\n",
      "(d, train_metric, valid_metric) = (266, 0.9398496240601504, 0.9375)\n",
      "(d, train_metric, valid_metric) = (267, 0.9400749063670412, 0.9375)\n",
      "(d, train_metric, valid_metric) = (268, 0.9365671641791045, 0.9375)\n",
      "(d, train_metric, valid_metric) = (269, 0.9368029739776952, 0.9375)\n",
      "(d, train_metric, valid_metric) = (270, 0.937037037037037, 0.9375)\n",
      "(d, train_metric, valid_metric) = (271, 0.933579335793358, 0.9375)\n",
      "(d, train_metric, valid_metric) = (272, 0.9301470588235294, 0.9375)\n",
      "(d, train_metric, valid_metric) = (273, 0.9304029304029304, 0.9375)\n",
      "(d, train_metric, valid_metric) = (274, 0.9306569343065694, 0.9375)\n",
      "(d, train_metric, valid_metric) = (275, 0.9309090909090909, 0.9375)\n",
      "(d, train_metric, valid_metric) = (276, 0.9311594202898551, 0.9375)\n",
      "(d, train_metric, valid_metric) = (277, 0.9314079422382672, 0.9375)\n",
      "(d, train_metric, valid_metric) = (278, 0.9280575539568345, 0.9375)\n",
      "(d, train_metric, valid_metric) = (279, 0.9283154121863799, 0.9375)\n",
      "(d, train_metric, valid_metric) = (280, 0.9285714285714286, 0.9375)\n",
      "(d, train_metric, valid_metric) = (281, 0.9288256227758007, 0.9375)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(d, train_metric, valid_metric) = (282, 0.9326241134751773, 0.9375)\n",
      "(d, train_metric, valid_metric) = (283, 0.9328621908127208, 0.9375)\n",
      "(d, train_metric, valid_metric) = (284, 0.9330985915492958, 0.9375)\n",
      "(d, train_metric, valid_metric) = (285, 0.9333333333333333, 0.9375)\n",
      "(d, train_metric, valid_metric) = (286, 0.9335664335664335, 0.9375)\n",
      "(d, train_metric, valid_metric) = (287, 0.9337979094076655, 0.9375)\n",
      "(d, train_metric, valid_metric) = (288, 0.9340277777777778, 0.9375)\n",
      "(d, train_metric, valid_metric) = (289, 0.9342560553633218, 0.9375)\n",
      "(d, train_metric, valid_metric) = (290, 0.9344827586206896, 0.9375)\n",
      "(d, train_metric, valid_metric) = (291, 0.9347079037800687, 0.9375)\n",
      "(d, train_metric, valid_metric) = (292, 0.934931506849315, 0.9375)\n",
      "(d, train_metric, valid_metric) = (293, 0.9351535836177475, 0.9375)\n",
      "(d, train_metric, valid_metric) = (294, 0.935374149659864, 0.9375)\n",
      "(d, train_metric, valid_metric) = (295, 0.9355932203389831, 0.9375)\n",
      "(d, train_metric, valid_metric) = (296, 0.9358108108108109, 0.9375)\n",
      "(d, train_metric, valid_metric) = (297, 0.936026936026936, 0.9375)\n",
      "(d, train_metric, valid_metric) = (298, 0.9362416107382551, 0.9375)\n",
      "(d, train_metric, valid_metric) = (299, 0.9331103678929766, 0.9375)\n",
      "(d, train_metric, valid_metric) = (300, 0.9333333333333333, 0.9375)\n",
      "(d, train_metric, valid_metric) = (301, 0.9335548172757475, 0.9375)\n",
      "(d, train_metric, valid_metric) = (302, 0.9337748344370861, 0.9375)\n",
      "(d, train_metric, valid_metric) = (303, 0.933993399339934, 0.9375)\n",
      "(d, train_metric, valid_metric) = (304, 0.930921052631579, 0.9375)\n",
      "(d, train_metric, valid_metric) = (305, 0.9311475409836065, 0.9375)\n",
      "(d, train_metric, valid_metric) = (306, 0.9313725490196079, 0.9375)\n",
      "(d, train_metric, valid_metric) = (307, 0.9315960912052117, 0.9375)\n",
      "(d, train_metric, valid_metric) = (308, 0.9318181818181818, 0.9375)\n",
      "(d, train_metric, valid_metric) = (309, 0.9320388349514563, 0.9375)\n",
      "(d, train_metric, valid_metric) = (310, 0.932258064516129, 0.9375)\n",
      "(d, train_metric, valid_metric) = (311, 0.932475884244373, 0.9375)\n",
      "(d, train_metric, valid_metric) = (312, 0.9326923076923077, 0.9375)\n",
      "(d, train_metric, valid_metric) = (313, 0.9329073482428115, 0.9375)\n",
      "(d, train_metric, valid_metric) = (314, 0.9331210191082803, 0.9375)\n",
      "(d, train_metric, valid_metric) = (315, 0.9333333333333333, 0.9375)\n",
      "(d, train_metric, valid_metric) = (316, 0.9335443037974683, 0.9375)\n",
      "(d, train_metric, valid_metric) = (317, 0.9305993690851735, 0.9375)\n",
      "(d, train_metric, valid_metric) = (318, 0.9308176100628931, 0.9375)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10:1:318, Any[0.8, 0.7272727272727273, 0.75, 0.7692307692307693, 0.7142857142857143, 0.7333333333333333, 0.75, 0.8235294117647058, 0.8333333333333334, 0.7894736842105263    0.9320388349514563, 0.932258064516129, 0.932475884244373, 0.9326923076923077, 0.9329073482428115, 0.9331210191082803, 0.9333333333333333, 0.9335443037974683, 0.9305993690851735, 0.9308176100628931], Any[0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.725, 0.7875, 0.7875    0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_schedule, training_losses, valid_losses = learn_curve(best.best_model, X[train,:], y[train], acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip650\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip650)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip651\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip650)\" d=\"\n",
       "M174.769 1486.45 L2352.76 1486.45 L2352.76 47.2441 L174.769 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip652\">\n",
       "    <rect x=\"174\" y=\"47\" width=\"2179\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip652)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  503.255,1486.45 503.255,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip652)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  836.811,1486.45 836.811,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip652)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1170.37,1486.45 1170.37,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip652)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1503.92,1486.45 1503.92,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip652)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1837.48,1486.45 1837.48,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip652)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2171.03,1486.45 2171.03,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip652)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  174.769,1386.26 2352.76,1386.26 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip652)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  174.769,1148.46 2352.76,1148.46 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip652)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  174.769,910.654 2352.76,910.654 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip652)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  174.769,672.849 2352.76,672.849 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip652)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  174.769,435.043 2352.76,435.043 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip652)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  174.769,197.238 2352.76,197.238 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip650)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.769,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip650)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.769,1486.45 174.769,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip650)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  503.255,1486.45 503.255,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip650)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  836.811,1486.45 836.811,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip650)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1170.37,1486.45 1170.37,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip650)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1503.92,1486.45 1503.92,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip650)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1837.48,1486.45 1837.48,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip650)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2171.03,1486.45 2171.03,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip650)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.769,1386.26 200.905,1386.26 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip650)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.769,1148.46 200.905,1148.46 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip650)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.769,910.654 200.905,910.654 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip650)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.769,672.849 200.905,672.849 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip650)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.769,435.043 200.905,435.043 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip650)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.769,197.238 200.905,197.238 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip650)\" d=\"M 0 0 M480.026 1505.36 L498.383 1505.36 L498.383 1509.3 L484.309 1509.3 L484.309 1517.77 Q485.327 1517.42 486.346 1517.26 Q487.364 1517.07 488.383 1517.07 Q494.17 1517.07 497.549 1520.24 Q500.929 1523.42 500.929 1528.83 Q500.929 1534.41 497.457 1537.51 Q493.984 1540.59 487.665 1540.59 Q485.489 1540.59 483.221 1540.22 Q480.975 1539.85 478.568 1539.11 L478.568 1534.41 Q480.651 1535.54 482.873 1536.1 Q485.096 1536.66 487.572 1536.66 Q491.577 1536.66 493.915 1534.55 Q496.253 1532.44 496.253 1528.83 Q496.253 1525.22 493.915 1523.11 Q491.577 1521.01 487.572 1521.01 Q485.697 1521.01 483.822 1521.42 Q481.971 1521.84 480.026 1522.72 L480.026 1505.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M515.998 1508.44 Q512.387 1508.44 510.558 1512 Q508.753 1515.55 508.753 1522.67 Q508.753 1529.78 510.558 1533.35 Q512.387 1536.89 515.998 1536.89 Q519.632 1536.89 521.438 1533.35 Q523.267 1529.78 523.267 1522.67 Q523.267 1515.55 521.438 1512 Q519.632 1508.44 515.998 1508.44 M515.998 1504.73 Q521.808 1504.73 524.864 1509.34 Q527.943 1513.92 527.943 1522.67 Q527.943 1531.4 524.864 1536.01 Q521.808 1540.59 515.998 1540.59 Q510.188 1540.59 507.109 1536.01 Q504.054 1531.4 504.054 1522.67 Q504.054 1513.92 507.109 1509.34 Q510.188 1504.73 515.998 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M800.179 1535.98 L807.818 1535.98 L807.818 1509.62 L799.508 1511.29 L799.508 1507.03 L807.772 1505.36 L812.448 1505.36 L812.448 1535.98 L820.087 1535.98 L820.087 1539.92 L800.179 1539.92 L800.179 1535.98 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M835.156 1508.44 Q831.545 1508.44 829.716 1512 Q827.911 1515.55 827.911 1522.67 Q827.911 1529.78 829.716 1533.35 Q831.545 1536.89 835.156 1536.89 Q838.79 1536.89 840.596 1533.35 Q842.425 1529.78 842.425 1522.67 Q842.425 1515.55 840.596 1512 Q838.79 1508.44 835.156 1508.44 M835.156 1504.73 Q840.966 1504.73 844.022 1509.34 Q847.1 1513.92 847.1 1522.67 Q847.1 1531.4 844.022 1536.01 Q840.966 1540.59 835.156 1540.59 Q829.346 1540.59 826.267 1536.01 Q823.212 1531.4 823.212 1522.67 Q823.212 1513.92 826.267 1509.34 Q829.346 1504.73 835.156 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M862.17 1508.44 Q858.559 1508.44 856.73 1512 Q854.924 1515.55 854.924 1522.67 Q854.924 1529.78 856.73 1533.35 Q858.559 1536.89 862.17 1536.89 Q865.804 1536.89 867.61 1533.35 Q869.438 1529.78 869.438 1522.67 Q869.438 1515.55 867.61 1512 Q865.804 1508.44 862.17 1508.44 M862.17 1504.73 Q867.98 1504.73 871.035 1509.34 Q874.114 1513.92 874.114 1522.67 Q874.114 1531.4 871.035 1536.01 Q867.98 1540.59 862.17 1540.59 Q856.36 1540.59 853.281 1536.01 Q850.225 1531.4 850.225 1522.67 Q850.225 1513.92 853.281 1509.34 Q856.36 1504.73 862.17 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M1134.23 1535.98 L1141.87 1535.98 L1141.87 1509.62 L1133.56 1511.29 L1133.56 1507.03 L1141.83 1505.36 L1146.5 1505.36 L1146.5 1535.98 L1154.14 1535.98 L1154.14 1539.92 L1134.23 1539.92 L1134.23 1535.98 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M1159.26 1505.36 L1177.61 1505.36 L1177.61 1509.3 L1163.54 1509.3 L1163.54 1517.77 Q1164.56 1517.42 1165.58 1517.26 Q1166.59 1517.07 1167.61 1517.07 Q1173.4 1517.07 1176.78 1520.24 Q1180.16 1523.42 1180.16 1528.83 Q1180.16 1534.41 1176.69 1537.51 Q1173.21 1540.59 1166.89 1540.59 Q1164.72 1540.59 1162.45 1540.22 Q1160.21 1539.85 1157.8 1539.11 L1157.8 1534.41 Q1159.88 1535.54 1162.1 1536.1 Q1164.33 1536.66 1166.8 1536.66 Q1170.81 1536.66 1173.14 1534.55 Q1175.48 1532.44 1175.48 1528.83 Q1175.48 1525.22 1173.14 1523.11 Q1170.81 1521.01 1166.8 1521.01 Q1164.93 1521.01 1163.05 1521.42 Q1161.2 1521.84 1159.26 1522.72 L1159.26 1505.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M1195.23 1508.44 Q1191.62 1508.44 1189.79 1512 Q1187.98 1515.55 1187.98 1522.67 Q1187.98 1529.78 1189.79 1533.35 Q1191.62 1536.89 1195.23 1536.89 Q1198.86 1536.89 1200.67 1533.35 Q1202.5 1529.78 1202.5 1522.67 Q1202.5 1515.55 1200.67 1512 Q1198.86 1508.44 1195.23 1508.44 M1195.23 1504.73 Q1201.04 1504.73 1204.09 1509.34 Q1207.17 1513.92 1207.17 1522.67 Q1207.17 1531.4 1204.09 1536.01 Q1201.04 1540.59 1195.23 1540.59 Q1189.42 1540.59 1186.34 1536.01 Q1183.28 1531.4 1183.28 1522.67 Q1183.28 1513.92 1186.34 1509.34 Q1189.42 1504.73 1195.23 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M1471.56 1535.98 L1487.88 1535.98 L1487.88 1539.92 L1465.94 1539.92 L1465.94 1535.98 Q1468.6 1533.23 1473.18 1528.6 Q1477.79 1523.95 1478.97 1522.61 Q1481.21 1520.08 1482.09 1518.35 Q1483 1516.59 1483 1514.9 Q1483 1512.14 1481.05 1510.41 Q1479.13 1508.67 1476.03 1508.67 Q1473.83 1508.67 1471.38 1509.43 Q1468.95 1510.2 1466.17 1511.75 L1466.17 1507.03 Q1468.99 1505.89 1471.45 1505.31 Q1473.9 1504.73 1475.94 1504.73 Q1481.31 1504.73 1484.5 1507.42 Q1487.7 1510.11 1487.7 1514.6 Q1487.7 1516.73 1486.89 1518.65 Q1486.1 1520.54 1483.99 1523.14 Q1483.41 1523.81 1480.31 1527.03 Q1477.21 1530.22 1471.56 1535.98 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M1502.95 1508.44 Q1499.34 1508.44 1497.51 1512 Q1495.71 1515.55 1495.71 1522.67 Q1495.71 1529.78 1497.51 1533.35 Q1499.34 1536.89 1502.95 1536.89 Q1506.58 1536.89 1508.39 1533.35 Q1510.22 1529.78 1510.22 1522.67 Q1510.22 1515.55 1508.39 1512 Q1506.58 1508.44 1502.95 1508.44 M1502.95 1504.73 Q1508.76 1504.73 1511.82 1509.34 Q1514.9 1513.92 1514.9 1522.67 Q1514.9 1531.4 1511.82 1536.01 Q1508.76 1540.59 1502.95 1540.59 Q1497.14 1540.59 1494.06 1536.01 Q1491.01 1531.4 1491.01 1522.67 Q1491.01 1513.92 1494.06 1509.34 Q1497.14 1504.73 1502.95 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M1529.96 1508.44 Q1526.35 1508.44 1524.52 1512 Q1522.72 1515.55 1522.72 1522.67 Q1522.72 1529.78 1524.52 1533.35 Q1526.35 1536.89 1529.96 1536.89 Q1533.6 1536.89 1535.4 1533.35 Q1537.23 1529.78 1537.23 1522.67 Q1537.23 1515.55 1535.4 1512 Q1533.6 1508.44 1529.96 1508.44 M1529.96 1504.73 Q1535.77 1504.73 1538.83 1509.34 Q1541.91 1513.92 1541.91 1522.67 Q1541.91 1531.4 1538.83 1536.01 Q1535.77 1540.59 1529.96 1540.59 Q1524.15 1540.59 1521.08 1536.01 Q1518.02 1531.4 1518.02 1522.67 Q1518.02 1513.92 1521.08 1509.34 Q1524.15 1504.73 1529.96 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M1805.62 1535.98 L1821.93 1535.98 L1821.93 1539.92 L1799.99 1539.92 L1799.99 1535.98 Q1802.65 1533.23 1807.24 1528.6 Q1811.84 1523.95 1813.02 1522.61 Q1815.27 1520.08 1816.15 1518.35 Q1817.05 1516.59 1817.05 1514.9 Q1817.05 1512.14 1815.11 1510.41 Q1813.18 1508.67 1810.08 1508.67 Q1807.88 1508.67 1805.43 1509.43 Q1803 1510.2 1800.22 1511.75 L1800.22 1507.03 Q1803.05 1505.89 1805.5 1505.31 Q1807.95 1504.73 1809.99 1504.73 Q1815.36 1504.73 1818.56 1507.42 Q1821.75 1510.11 1821.75 1514.6 Q1821.75 1516.73 1820.94 1518.65 Q1820.15 1520.54 1818.05 1523.14 Q1817.47 1523.81 1814.37 1527.03 Q1811.26 1530.22 1805.62 1535.98 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M1827.05 1505.36 L1845.41 1505.36 L1845.41 1509.3 L1831.33 1509.3 L1831.33 1517.77 Q1832.35 1517.42 1833.37 1517.26 Q1834.39 1517.07 1835.41 1517.07 Q1841.19 1517.07 1844.57 1520.24 Q1847.95 1523.42 1847.95 1528.83 Q1847.95 1534.41 1844.48 1537.51 Q1841.01 1540.59 1834.69 1540.59 Q1832.51 1540.59 1830.25 1540.22 Q1828 1539.85 1825.59 1539.11 L1825.59 1534.41 Q1827.68 1535.54 1829.9 1536.1 Q1832.12 1536.66 1834.6 1536.66 Q1838.6 1536.66 1840.94 1534.55 Q1843.28 1532.44 1843.28 1528.83 Q1843.28 1525.22 1840.94 1523.11 Q1838.6 1521.01 1834.6 1521.01 Q1832.72 1521.01 1830.85 1521.42 Q1829 1521.84 1827.05 1522.72 L1827.05 1505.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M1863.02 1508.44 Q1859.41 1508.44 1857.58 1512 Q1855.78 1515.55 1855.78 1522.67 Q1855.78 1529.78 1857.58 1533.35 Q1859.41 1536.89 1863.02 1536.89 Q1866.66 1536.89 1868.46 1533.35 Q1870.29 1529.78 1870.29 1522.67 Q1870.29 1515.55 1868.46 1512 Q1866.66 1508.44 1863.02 1508.44 M1863.02 1504.73 Q1868.83 1504.73 1871.89 1509.34 Q1874.97 1513.92 1874.97 1522.67 Q1874.97 1531.4 1871.89 1536.01 Q1868.83 1540.59 1863.02 1540.59 Q1857.21 1540.59 1854.13 1536.01 Q1851.08 1531.4 1851.08 1522.67 Q1851.08 1513.92 1854.13 1509.34 Q1857.21 1504.73 1863.02 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M2148.27 1521.29 Q2151.63 1522 2153.5 1524.27 Q2155.4 1526.54 2155.4 1529.87 Q2155.4 1534.99 2151.88 1537.79 Q2148.36 1540.59 2141.88 1540.59 Q2139.7 1540.59 2137.39 1540.15 Q2135.1 1539.73 2132.64 1538.88 L2132.64 1534.36 Q2134.59 1535.5 2136.9 1536.08 Q2139.22 1536.66 2141.74 1536.66 Q2146.14 1536.66 2148.43 1534.92 Q2150.75 1533.18 2150.75 1529.87 Q2150.75 1526.82 2148.59 1525.11 Q2146.46 1523.37 2142.64 1523.37 L2138.62 1523.37 L2138.62 1519.53 L2142.83 1519.53 Q2146.28 1519.53 2148.11 1518.16 Q2149.94 1516.77 2149.94 1514.18 Q2149.94 1511.52 2148.04 1510.11 Q2146.16 1508.67 2142.64 1508.67 Q2140.72 1508.67 2138.52 1509.09 Q2136.32 1509.5 2133.69 1510.38 L2133.69 1506.22 Q2136.35 1505.48 2138.66 1505.11 Q2141 1504.73 2143.06 1504.73 Q2148.38 1504.73 2151.49 1507.17 Q2154.59 1509.57 2154.59 1513.69 Q2154.59 1516.56 2152.94 1518.55 Q2151.3 1520.52 2148.27 1521.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M2170.47 1508.44 Q2166.86 1508.44 2165.03 1512 Q2163.22 1515.55 2163.22 1522.67 Q2163.22 1529.78 2165.03 1533.35 Q2166.86 1536.89 2170.47 1536.89 Q2174.1 1536.89 2175.91 1533.35 Q2177.74 1529.78 2177.74 1522.67 Q2177.74 1515.55 2175.91 1512 Q2174.1 1508.44 2170.47 1508.44 M2170.47 1504.73 Q2176.28 1504.73 2179.33 1509.34 Q2182.41 1513.92 2182.41 1522.67 Q2182.41 1531.4 2179.33 1536.01 Q2176.28 1540.59 2170.47 1540.59 Q2164.66 1540.59 2161.58 1536.01 Q2158.52 1531.4 2158.52 1522.67 Q2158.52 1513.92 2161.58 1509.34 Q2164.66 1504.73 2170.47 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M2197.48 1508.44 Q2193.87 1508.44 2192.04 1512 Q2190.24 1515.55 2190.24 1522.67 Q2190.24 1529.78 2192.04 1533.35 Q2193.87 1536.89 2197.48 1536.89 Q2201.12 1536.89 2202.92 1533.35 Q2204.75 1529.78 2204.75 1522.67 Q2204.75 1515.55 2202.92 1512 Q2201.12 1508.44 2197.48 1508.44 M2197.48 1504.73 Q2203.29 1504.73 2206.35 1509.34 Q2209.43 1513.92 2209.43 1522.67 Q2209.43 1531.4 2206.35 1536.01 Q2203.29 1540.59 2197.48 1540.59 Q2191.67 1540.59 2188.59 1536.01 Q2185.54 1531.4 2185.54 1522.67 Q2185.54 1513.92 2188.59 1509.34 Q2191.67 1504.73 2197.48 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M75.7467 1372.06 Q72.1356 1372.06 70.3069 1375.63 Q68.5014 1379.17 68.5014 1386.3 Q68.5014 1393.41 70.3069 1396.97 Q72.1356 1400.51 75.7467 1400.51 Q79.3809 1400.51 81.1865 1396.97 Q83.0152 1393.41 83.0152 1386.3 Q83.0152 1379.17 81.1865 1375.63 Q79.3809 1372.06 75.7467 1372.06 M75.7467 1368.36 Q81.5568 1368.36 84.6124 1372.97 Q87.6911 1377.55 87.6911 1386.3 Q87.6911 1395.03 84.6124 1399.63 Q81.5568 1404.22 75.7467 1404.22 Q69.9365 1404.22 66.8578 1399.63 Q63.8023 1395.03 63.8023 1386.3 Q63.8023 1377.55 66.8578 1372.97 Q69.9365 1368.36 75.7467 1368.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M92.7605 1397.66 L97.6447 1397.66 L97.6447 1403.54 L92.7605 1403.54 L92.7605 1397.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M101.534 1368.98 L123.756 1368.98 L123.756 1370.98 L111.209 1403.54 L106.325 1403.54 L118.131 1372.92 L101.534 1372.92 L101.534 1368.98 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M138.825 1372.06 Q135.214 1372.06 133.385 1375.63 Q131.58 1379.17 131.58 1386.3 Q131.58 1393.41 133.385 1396.97 Q135.214 1400.51 138.825 1400.51 Q142.459 1400.51 144.265 1396.97 Q146.094 1393.41 146.094 1386.3 Q146.094 1379.17 144.265 1375.63 Q142.459 1372.06 138.825 1372.06 M138.825 1368.36 Q144.635 1368.36 147.691 1372.97 Q150.769 1377.55 150.769 1386.3 Q150.769 1395.03 147.691 1399.63 Q144.635 1404.22 138.825 1404.22 Q133.015 1404.22 129.936 1399.63 Q126.881 1395.03 126.881 1386.3 Q126.881 1377.55 129.936 1372.97 Q133.015 1368.36 138.825 1368.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M76.7421 1134.26 Q73.131 1134.26 71.3023 1137.82 Q69.4967 1141.36 69.4967 1148.49 Q69.4967 1155.6 71.3023 1159.17 Q73.131 1162.71 76.7421 1162.71 Q80.3763 1162.71 82.1818 1159.17 Q84.0105 1155.6 84.0105 1148.49 Q84.0105 1141.36 82.1818 1137.82 Q80.3763 1134.26 76.7421 1134.26 M76.7421 1130.55 Q82.5522 1130.55 85.6077 1135.16 Q88.6864 1139.74 88.6864 1148.49 Q88.6864 1157.22 85.6077 1161.83 Q82.5522 1166.41 76.7421 1166.41 Q70.9319 1166.41 67.8532 1161.83 Q64.7977 1157.22 64.7977 1148.49 Q64.7977 1139.74 67.8532 1135.16 Q70.9319 1130.55 76.7421 1130.55 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M93.7559 1159.86 L98.6401 1159.86 L98.6401 1165.74 L93.7559 1165.74 L93.7559 1159.86 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M102.529 1131.18 L124.751 1131.18 L124.751 1133.17 L112.205 1165.74 L107.321 1165.74 L119.126 1135.11 L102.529 1135.11 L102.529 1131.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M129.867 1131.18 L148.223 1131.18 L148.223 1135.11 L134.149 1135.11 L134.149 1143.59 Q135.168 1143.24 136.186 1143.08 Q137.205 1142.89 138.223 1142.89 Q144.01 1142.89 147.39 1146.06 Q150.769 1149.23 150.769 1154.65 Q150.769 1160.23 147.297 1163.33 Q143.825 1166.41 137.506 1166.41 Q135.33 1166.41 133.061 1166.04 Q130.816 1165.67 128.408 1164.93 L128.408 1160.23 Q130.492 1161.36 132.714 1161.92 Q134.936 1162.48 137.413 1162.48 Q141.418 1162.48 143.756 1160.37 Q146.094 1158.26 146.094 1154.65 Q146.094 1151.04 143.756 1148.93 Q141.418 1146.83 137.413 1146.83 Q135.538 1146.83 133.663 1147.24 Q131.811 1147.66 129.867 1148.54 L129.867 1131.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M74.9365 896.453 Q71.3254 896.453 69.4967 900.017 Q67.6912 903.559 67.6912 910.689 Q67.6912 917.795 69.4967 921.36 Q71.3254 924.901 74.9365 924.901 Q78.5707 924.901 80.3763 921.36 Q82.205 917.795 82.205 910.689 Q82.205 903.559 80.3763 900.017 Q78.5707 896.453 74.9365 896.453 M74.9365 892.749 Q80.7467 892.749 83.8022 897.355 Q86.8809 901.939 86.8809 910.689 Q86.8809 919.415 83.8022 924.022 Q80.7467 928.605 74.9365 928.605 Q69.1264 928.605 66.0477 924.022 Q62.9921 919.415 62.9921 910.689 Q62.9921 901.939 66.0477 897.355 Q69.1264 892.749 74.9365 892.749 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M91.9503 922.054 L96.8345 922.054 L96.8345 927.934 L91.9503 927.934 L91.9503 922.054 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M111.904 911.522 Q108.571 911.522 106.649 913.304 Q104.751 915.087 104.751 918.212 Q104.751 921.337 106.649 923.119 Q108.571 924.901 111.904 924.901 Q115.237 924.901 117.159 923.119 Q119.08 921.314 119.08 918.212 Q119.08 915.087 117.159 913.304 Q115.26 911.522 111.904 911.522 M107.228 909.531 Q104.219 908.79 102.529 906.73 Q100.862 904.67 100.862 901.707 Q100.862 897.564 103.802 895.156 Q106.765 892.749 111.904 892.749 Q117.066 892.749 120.006 895.156 Q122.946 897.564 122.946 901.707 Q122.946 904.67 121.256 906.73 Q119.589 908.79 116.603 909.531 Q119.983 910.318 121.858 912.61 Q123.756 914.902 123.756 918.212 Q123.756 923.235 120.677 925.92 Q117.621 928.605 111.904 928.605 Q106.186 928.605 103.108 925.92 Q100.052 923.235 100.052 918.212 Q100.052 914.902 101.95 912.61 Q103.848 910.318 107.228 909.531 M105.515 902.147 Q105.515 904.832 107.182 906.337 Q108.872 907.841 111.904 907.841 Q114.913 907.841 116.603 906.337 Q118.316 904.832 118.316 902.147 Q118.316 899.462 116.603 897.957 Q114.913 896.453 111.904 896.453 Q108.872 896.453 107.182 897.957 Q105.515 899.462 105.515 902.147 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M138.825 896.453 Q135.214 896.453 133.385 900.017 Q131.58 903.559 131.58 910.689 Q131.58 917.795 133.385 921.36 Q135.214 924.901 138.825 924.901 Q142.459 924.901 144.265 921.36 Q146.094 917.795 146.094 910.689 Q146.094 903.559 144.265 900.017 Q142.459 896.453 138.825 896.453 M138.825 892.749 Q144.635 892.749 147.691 897.355 Q150.769 901.939 150.769 910.689 Q150.769 919.415 147.691 924.022 Q144.635 928.605 138.825 928.605 Q133.015 928.605 129.936 924.022 Q126.881 919.415 126.881 910.689 Q126.881 901.939 129.936 897.355 Q133.015 892.749 138.825 892.749 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M75.9319 658.647 Q72.3208 658.647 70.4921 662.212 Q68.6865 665.754 68.6865 672.883 Q68.6865 679.99 70.4921 683.555 Q72.3208 687.096 75.9319 687.096 Q79.5661 687.096 81.3717 683.555 Q83.2004 679.99 83.2004 672.883 Q83.2004 665.754 81.3717 662.212 Q79.5661 658.647 75.9319 658.647 M75.9319 654.944 Q81.742 654.944 84.7976 659.55 Q87.8763 664.133 87.8763 672.883 Q87.8763 681.61 84.7976 686.217 Q81.742 690.8 75.9319 690.8 Q70.1217 690.8 67.043 686.217 Q63.9875 681.61 63.9875 672.883 Q63.9875 664.133 67.043 659.55 Q70.1217 654.944 75.9319 654.944 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M92.9457 684.249 L97.8299 684.249 L97.8299 690.129 L92.9457 690.129 L92.9457 684.249 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M112.899 673.717 Q109.566 673.717 107.645 675.499 Q105.747 677.281 105.747 680.406 Q105.747 683.531 107.645 685.314 Q109.566 687.096 112.899 687.096 Q116.233 687.096 118.154 685.314 Q120.075 683.508 120.075 680.406 Q120.075 677.281 118.154 675.499 Q116.256 673.717 112.899 673.717 M108.223 671.726 Q105.214 670.985 103.524 668.925 Q101.858 666.865 101.858 663.902 Q101.858 659.758 104.797 657.351 Q107.76 654.944 112.899 654.944 Q118.061 654.944 121.001 657.351 Q123.941 659.758 123.941 663.902 Q123.941 666.865 122.251 668.925 Q120.584 670.985 117.598 671.726 Q120.978 672.513 122.853 674.805 Q124.751 677.096 124.751 680.406 Q124.751 685.43 121.672 688.115 Q118.617 690.8 112.899 690.8 Q107.182 690.8 104.103 688.115 Q101.047 685.43 101.047 680.406 Q101.047 677.096 102.946 674.805 Q104.844 672.513 108.223 671.726 M106.51 664.342 Q106.51 667.027 108.177 668.532 Q109.867 670.036 112.899 670.036 Q115.909 670.036 117.598 668.532 Q119.311 667.027 119.311 664.342 Q119.311 661.657 117.598 660.152 Q115.909 658.647 112.899 658.647 Q109.867 658.647 108.177 660.152 Q106.51 661.657 106.51 664.342 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M129.867 655.569 L148.223 655.569 L148.223 659.504 L134.149 659.504 L134.149 667.976 Q135.168 667.629 136.186 667.467 Q137.205 667.282 138.223 667.282 Q144.01 667.282 147.39 670.453 Q150.769 673.624 150.769 679.041 Q150.769 684.619 147.297 687.721 Q143.825 690.8 137.506 690.8 Q135.33 690.8 133.061 690.43 Q130.816 690.059 128.408 689.318 L128.408 684.619 Q130.492 685.754 132.714 686.309 Q134.936 686.865 137.413 686.865 Q141.418 686.865 143.756 684.758 Q146.094 682.652 146.094 679.041 Q146.094 675.43 143.756 673.323 Q141.418 671.217 137.413 671.217 Q135.538 671.217 133.663 671.633 Q131.811 672.05 129.867 672.93 L129.867 655.569 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M75.0291 420.842 Q71.418 420.842 69.5893 424.407 Q67.7838 427.949 67.7838 435.078 Q67.7838 442.185 69.5893 445.749 Q71.418 449.291 75.0291 449.291 Q78.6633 449.291 80.4689 445.749 Q82.2976 442.185 82.2976 435.078 Q82.2976 427.949 80.4689 424.407 Q78.6633 420.842 75.0291 420.842 M75.0291 417.138 Q80.8393 417.138 83.8948 421.745 Q86.9735 426.328 86.9735 435.078 Q86.9735 443.805 83.8948 448.411 Q80.8393 452.995 75.0291 452.995 Q69.2189 452.995 66.1403 448.411 Q63.0847 443.805 63.0847 435.078 Q63.0847 426.328 66.1403 421.745 Q69.2189 417.138 75.0291 417.138 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M92.0429 446.444 L96.9271 446.444 L96.9271 452.323 L92.0429 452.323 L92.0429 446.444 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M102.135 451.606 L102.135 447.347 Q103.895 448.18 105.7 448.62 Q107.506 449.06 109.242 449.06 Q113.871 449.06 116.302 445.958 Q118.756 442.833 119.103 436.49 Q117.76 438.481 115.7 439.546 Q113.64 440.61 111.14 440.61 Q105.955 440.61 102.922 437.486 Q99.9132 434.337 99.9132 428.898 Q99.9132 423.574 103.061 420.356 Q106.209 417.138 111.441 417.138 Q117.436 417.138 120.584 421.745 Q123.756 426.328 123.756 435.078 Q123.756 443.249 119.867 448.134 Q116.001 452.995 109.45 452.995 Q107.691 452.995 105.885 452.647 Q104.08 452.3 102.135 451.606 M111.441 436.953 Q114.589 436.953 116.418 434.8 Q118.27 432.648 118.27 428.898 Q118.27 425.171 116.418 423.018 Q114.589 420.842 111.441 420.842 Q108.293 420.842 106.441 423.018 Q104.612 425.171 104.612 428.898 Q104.612 432.648 106.441 434.8 Q108.293 436.953 111.441 436.953 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M138.825 420.842 Q135.214 420.842 133.385 424.407 Q131.58 427.949 131.58 435.078 Q131.58 442.185 133.385 445.749 Q135.214 449.291 138.825 449.291 Q142.459 449.291 144.265 445.749 Q146.094 442.185 146.094 435.078 Q146.094 427.949 144.265 424.407 Q142.459 420.842 138.825 420.842 M138.825 417.138 Q144.635 417.138 147.691 421.745 Q150.769 426.328 150.769 435.078 Q150.769 443.805 147.691 448.411 Q144.635 452.995 138.825 452.995 Q133.015 452.995 129.936 448.411 Q126.881 443.805 126.881 435.078 Q126.881 426.328 129.936 421.745 Q133.015 417.138 138.825 417.138 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M76.0245 183.037 Q72.4134 183.037 70.5847 186.602 Q68.7791 190.143 68.7791 197.273 Q68.7791 204.379 70.5847 207.944 Q72.4134 211.486 76.0245 211.486 Q79.6587 211.486 81.4642 207.944 Q83.2929 204.379 83.2929 197.273 Q83.2929 190.143 81.4642 186.602 Q79.6587 183.037 76.0245 183.037 M76.0245 179.333 Q81.8346 179.333 84.8902 183.94 Q87.9688 188.523 87.9688 197.273 Q87.9688 206 84.8902 210.606 Q81.8346 215.189 76.0245 215.189 Q70.2143 215.189 67.1356 210.606 Q64.0801 206 64.0801 197.273 Q64.0801 188.523 67.1356 183.94 Q70.2143 179.333 76.0245 179.333 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M93.0383 208.639 L97.9225 208.639 L97.9225 214.518 L93.0383 214.518 L93.0383 208.639 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M103.131 213.801 L103.131 209.541 Q104.89 210.375 106.696 210.814 Q108.501 211.254 110.237 211.254 Q114.867 211.254 117.297 208.152 Q119.751 205.027 120.098 198.685 Q118.756 200.676 116.696 201.74 Q114.635 202.805 112.135 202.805 Q106.95 202.805 103.918 199.68 Q100.909 196.532 100.909 191.092 Q100.909 185.768 104.057 182.551 Q107.205 179.333 112.436 179.333 Q118.432 179.333 121.58 183.94 Q124.751 188.523 124.751 197.273 Q124.751 205.444 120.862 210.328 Q116.996 215.189 110.446 215.189 Q108.686 215.189 106.881 214.842 Q105.075 214.495 103.131 213.801 M112.436 199.148 Q115.584 199.148 117.413 196.995 Q119.265 194.842 119.265 191.092 Q119.265 187.366 117.413 185.213 Q115.584 183.037 112.436 183.037 Q109.288 183.037 107.436 185.213 Q105.608 187.366 105.608 191.092 Q105.608 194.842 107.436 196.995 Q109.288 199.148 112.436 199.148 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M129.867 179.958 L148.223 179.958 L148.223 183.893 L134.149 183.893 L134.149 192.365 Q135.168 192.018 136.186 191.856 Q137.205 191.671 138.223 191.671 Q144.01 191.671 147.39 194.842 Q150.769 198.014 150.769 203.43 Q150.769 209.009 147.297 212.111 Q143.825 215.189 137.506 215.189 Q135.33 215.189 133.061 214.819 Q130.816 214.449 128.408 213.708 L128.408 209.009 Q130.492 210.143 132.714 210.699 Q134.936 211.254 137.413 211.254 Q141.418 211.254 143.756 209.148 Q146.094 207.041 146.094 203.43 Q146.094 199.819 143.756 197.713 Q141.418 195.606 137.413 195.606 Q135.538 195.606 133.663 196.023 Q131.811 196.44 129.867 197.319 L129.867 179.958 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip652)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  236.411,910.654 243.082,1256.55 249.753,1148.46 256.424,1057 263.095,1318.32 269.766,1227.73 276.437,1148.46 283.108,798.746 289.78,752.117 296.451,960.718 \n",
       "  303.122,910.654 309.793,412.395 316.464,391.806 323.135,373.007 329.806,355.775 336.477,339.921 343.148,325.287 349.82,311.737 356.491,299.155 363.162,287.44 \n",
       "  369.833,117.97 376.504,112.856 383.175,108.061 389.846,103.557 396.517,99.3183 403.188,95.3216 409.86,91.5469 416.531,87.9763 423.202,209.754 429.873,203.336 \n",
       "  436.544,197.238 443.215,191.438 449.886,185.914 456.557,291.254 463.229,283.713 469.9,276.507 476.571,373.007 483.242,364.208 489.913,355.775 496.584,347.686 \n",
       "  503.255,339.921 509.926,332.461 516.597,325.287 523.269,318.384 529.94,311.737 536.611,305.331 543.282,299.155 549.953,293.195 556.624,369.442 563.295,362.493 \n",
       "  569.966,355.775 576.638,349.278 583.309,189.567 589.98,185.914 596.651,182.375 603.322,178.945 609.993,175.619 616.664,172.393 623.335,169.261 630.006,166.22 \n",
       "  636.678,163.266 643.349,160.395 650.02,157.604 656.691,154.889 663.362,152.248 670.033,213.092 676.704,209.754 683.375,206.503 690.047,203.336 696.718,260.452 \n",
       "  703.389,256.689 710.06,253.02 716.731,307.441 723.402,303.248 730.073,299.155 736.744,295.158 743.415,291.254 750.087,232.772 756.758,229.666 763.429,226.63 \n",
       "  770.1,223.661 776.771,273.022 783.442,269.614 790.113,266.278 796.784,263.014 803.456,359.947 810.127,355.775 816.798,351.689 823.469,347.686 830.14,343.765 \n",
       "  836.811,339.921 843.482,336.154 850.153,332.461 856.824,328.839 863.496,325.287 870.167,321.803 876.838,318.384 883.509,315.03 890.18,311.737 896.851,352.139 \n",
       "  903.522,348.569 910.193,345.063 916.865,341.62 923.536,338.238 930.207,334.915 936.878,331.65 943.549,328.441 950.22,325.287 956.891,322.187 963.562,319.138 \n",
       "  970.233,355.775 976.905,352.499 983.576,349.278 990.247,346.108 996.918,266.278 1003.59,301.872 1010.26,299.155 1016.93,296.48 1023.6,293.847 1030.27,291.254 \n",
       "  1036.94,288.702 1043.62,286.188 1050.29,283.713 1056.96,281.275 1063.63,278.873 1070.3,276.507 1076.97,239.204 1083.64,237.162 1090.31,235.149 1096.98,233.166 \n",
       "  1103.66,231.21 1110.33,229.283 1117,227.382 1123.67,225.509 1130.34,223.661 1137.01,287.44 1143.68,285.194 1150.35,315.332 1157.02,312.927 1163.7,342.475 \n",
       "  1170.37,339.921 1177.04,368.899 1183.71,366.205 1190.38,363.546 1197.05,360.922 1203.72,358.332 1210.39,355.775 1217.06,353.251 1223.74,350.758 1230.41,348.297 \n",
       "  1237.08,345.866 1243.75,343.466 1250.42,341.096 1257.09,338.754 1263.76,336.441 1270.43,334.156 1277.1,331.899 1283.78,329.669 1290.45,327.465 1297.12,353.43 \n",
       "  1303.79,351.112 1310.46,348.822 1317.13,346.558 1323.8,344.32 1330.47,342.108 1337.14,339.921 1343.82,283.713 1350.49,281.881 1357.16,280.069 1363.83,278.278 \n",
       "  1370.5,276.507 1377.17,274.755 1383.84,273.022 1390.51,271.309 1397.19,269.614 1403.86,267.937 1410.53,266.278 1417.2,264.637 1423.87,237.716 1430.54,236.243 \n",
       "  1437.21,234.786 1443.88,208.444 1450.55,207.147 1457.23,205.863 1463.9,204.593 1470.57,203.336 1477.24,202.091 1483.91,200.86 1490.58,199.64 1497.25,198.433 \n",
       "  1503.92,197.238 1510.59,196.055 1517.27,194.884 1523.94,193.724 1530.61,192.575 1537.28,191.438 1543.95,190.312 1550.62,189.196 1557.29,188.092 1563.96,186.998 \n",
       "  1570.63,185.914 1577.31,184.841 1583.98,183.777 1590.65,182.724 1597.32,203.906 1603.99,202.769 1610.66,201.642 1617.33,200.526 1624,199.42 1630.67,198.324 \n",
       "  1637.35,197.238 1644.02,196.162 1650.69,195.096 1657.36,194.039 1664.03,192.992 1670.7,191.954 1677.37,190.925 1684.04,189.905 1690.71,230.614 1697.39,229.43 \n",
       "  1704.06,228.256 1710.73,227.092 1717.4,246.439 1724.07,245.207 1730.74,264.311 1737.41,263.014 1744.08,261.728 1750.75,260.452 1757.43,259.187 1764.1,257.933 \n",
       "  1770.77,256.689 1777.44,255.456 1784.11,254.233 1790.78,253.02 1797.45,271.309 1804.12,270.036 1810.79,268.773 1817.47,267.521 1824.14,266.278 1830.81,265.046 \n",
       "  1837.48,263.824 1844.15,262.611 1850.82,261.408 1857.49,260.214 1864.16,259.03 1870.83,257.855 1877.51,256.689 1884.18,255.533 1890.85,254.385 1897.52,253.246 \n",
       "  1904.19,252.116 1910.86,250.995 1917.53,249.882 1924.2,248.778 1930.87,247.682 1937.55,246.594 1944.22,245.514 1950.89,244.443 1957.56,261.126 1964.23,260.005 \n",
       "  1970.9,258.891 1977.57,275.337 1984.24,291.661 1990.91,290.444 1997.59,289.236 2004.26,288.037 2010.93,286.846 2017.6,285.664 2024.27,301.599 2030.94,300.372 \n",
       "  2037.61,299.155 2044.28,297.946 2050.95,279.88 2057.63,278.747 2064.3,277.623 2070.97,276.507 2077.64,275.398 2084.31,274.297 2090.98,273.204 2097.65,272.118 \n",
       "  2104.32,271.04 2110.99,269.969 2117.67,268.905 2124.34,267.849 2131.01,266.8 2137.68,265.758 2144.35,264.723 2151.02,263.696 2157.69,262.674 2164.36,277.567 \n",
       "  2171.03,276.507 2177.71,275.453 2184.38,274.407 2191.05,273.367 2197.72,287.98 2204.39,286.902 2211.06,285.832 2217.73,284.769 2224.4,283.713 2231.07,282.663 \n",
       "  2237.75,281.621 2244.42,280.585 2251.09,279.555 2257.76,278.533 2264.43,277.516 2271.1,276.507 2277.77,275.503 2284.44,289.51 2291.11,288.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip652)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  236.411,1445.72 243.082,1445.72 249.753,1445.72 256.424,1445.72 263.095,1445.72 269.766,1445.72 276.437,1445.72 283.108,1267.36 289.78,970.105 296.451,970.105 \n",
       "  303.122,970.105 309.793,553.946 316.464,553.946 323.135,553.946 329.806,553.946 336.477,553.946 343.148,553.946 349.82,494.495 356.491,494.495 363.162,494.495 \n",
       "  369.833,316.141 376.504,316.141 383.175,316.141 389.846,316.141 396.517,316.141 403.188,316.141 409.86,316.141 416.531,316.141 423.202,256.689 429.873,256.689 \n",
       "  436.544,256.689 443.215,256.689 449.886,256.689 456.557,256.689 463.229,256.689 469.9,256.689 476.571,256.689 483.242,256.689 489.913,256.689 496.584,256.689 \n",
       "  503.255,256.689 509.926,256.689 516.597,256.689 523.269,256.689 529.94,256.689 536.611,256.689 543.282,256.689 549.953,256.689 556.624,256.689 563.295,256.689 \n",
       "  569.966,256.689 576.638,256.689 583.309,316.141 589.98,316.141 596.651,316.141 603.322,316.141 609.993,316.141 616.664,316.141 623.335,316.141 630.006,316.141 \n",
       "  636.678,316.141 643.349,256.689 650.02,256.689 656.691,256.689 663.362,256.689 670.033,256.689 676.704,256.689 683.375,256.689 690.047,256.689 696.718,256.689 \n",
       "  703.389,256.689 710.06,256.689 716.731,256.689 723.402,256.689 730.073,256.689 736.744,256.689 743.415,256.689 750.087,256.689 756.758,256.689 763.429,256.689 \n",
       "  770.1,256.689 776.771,316.141 783.442,316.141 790.113,316.141 796.784,316.141 803.456,316.141 810.127,316.141 816.798,316.141 823.469,316.141 830.14,316.141 \n",
       "  836.811,316.141 843.482,316.141 850.153,316.141 856.824,316.141 863.496,316.141 870.167,316.141 876.838,316.141 883.509,316.141 890.18,316.141 896.851,316.141 \n",
       "  903.522,316.141 910.193,316.141 916.865,316.141 923.536,316.141 930.207,316.141 936.878,316.141 943.549,316.141 950.22,316.141 956.891,316.141 963.562,316.141 \n",
       "  970.233,316.141 976.905,316.141 983.576,316.141 990.247,316.141 996.918,316.141 1003.59,316.141 1010.26,316.141 1016.93,316.141 1023.6,316.141 1030.27,375.592 \n",
       "  1036.94,375.592 1043.62,375.592 1050.29,375.592 1056.96,375.592 1063.63,375.592 1070.3,375.592 1076.97,375.592 1083.64,375.592 1090.31,375.592 1096.98,375.592 \n",
       "  1103.66,375.592 1110.33,375.592 1117,375.592 1123.67,375.592 1130.34,375.592 1137.01,375.592 1143.68,375.592 1150.35,375.592 1157.02,375.592 1163.7,316.141 \n",
       "  1170.37,316.141 1177.04,316.141 1183.71,316.141 1190.38,316.141 1197.05,316.141 1203.72,316.141 1210.39,316.141 1217.06,316.141 1223.74,316.141 1230.41,316.141 \n",
       "  1237.08,316.141 1243.75,316.141 1250.42,316.141 1257.09,316.141 1263.76,316.141 1270.43,316.141 1277.1,316.141 1283.78,316.141 1290.45,316.141 1297.12,316.141 \n",
       "  1303.79,316.141 1310.46,316.141 1317.13,316.141 1323.8,316.141 1330.47,375.592 1337.14,375.592 1343.82,375.592 1350.49,375.592 1357.16,375.592 1363.83,375.592 \n",
       "  1370.5,375.592 1377.17,375.592 1383.84,375.592 1390.51,375.592 1397.19,375.592 1403.86,375.592 1410.53,375.592 1417.2,375.592 1423.87,316.141 1430.54,316.141 \n",
       "  1437.21,316.141 1443.88,316.141 1450.55,256.689 1457.23,256.689 1463.9,256.689 1470.57,256.689 1477.24,256.689 1483.91,256.689 1490.58,256.689 1497.25,256.689 \n",
       "  1503.92,256.689 1510.59,256.689 1517.27,256.689 1523.94,256.689 1530.61,256.689 1537.28,316.141 1543.95,316.141 1550.62,316.141 1557.29,316.141 1563.96,316.141 \n",
       "  1570.63,316.141 1577.31,316.141 1583.98,316.141 1590.65,316.141 1597.32,316.141 1603.99,316.141 1610.66,316.141 1617.33,316.141 1624,316.141 1630.67,316.141 \n",
       "  1637.35,316.141 1644.02,316.141 1650.69,316.141 1657.36,316.141 1664.03,316.141 1670.7,316.141 1677.37,316.141 1684.04,316.141 1690.71,256.689 1697.39,256.689 \n",
       "  1704.06,256.689 1710.73,256.689 1717.4,256.689 1724.07,256.689 1730.74,256.689 1737.41,256.689 1744.08,256.689 1750.75,256.689 1757.43,256.689 1764.1,256.689 \n",
       "  1770.77,256.689 1777.44,256.689 1784.11,256.689 1790.78,256.689 1797.45,256.689 1804.12,256.689 1810.79,256.689 1817.47,256.689 1824.14,256.689 1830.81,256.689 \n",
       "  1837.48,256.689 1844.15,256.689 1850.82,256.689 1857.49,256.689 1864.16,256.689 1870.83,256.689 1877.51,256.689 1884.18,256.689 1890.85,256.689 1897.52,256.689 \n",
       "  1904.19,256.689 1910.86,256.689 1917.53,256.689 1924.2,256.689 1930.87,256.689 1937.55,256.689 1944.22,256.689 1950.89,256.689 1957.56,256.689 1964.23,256.689 \n",
       "  1970.9,256.689 1977.57,256.689 1984.24,256.689 1990.91,256.689 1997.59,256.689 2004.26,256.689 2010.93,256.689 2017.6,256.689 2024.27,256.689 2030.94,256.689 \n",
       "  2037.61,256.689 2044.28,256.689 2050.95,256.689 2057.63,256.689 2064.3,256.689 2070.97,256.689 2077.64,256.689 2084.31,256.689 2090.98,256.689 2097.65,256.689 \n",
       "  2104.32,256.689 2110.99,256.689 2117.67,256.689 2124.34,256.689 2131.01,256.689 2137.68,256.689 2144.35,256.689 2151.02,256.689 2157.69,256.689 2164.36,256.689 \n",
       "  2171.03,256.689 2177.71,256.689 2184.38,256.689 2191.05,256.689 2197.72,256.689 2204.39,256.689 2211.06,256.689 2217.73,256.689 2224.4,256.689 2231.07,256.689 \n",
       "  2237.75,256.689 2244.42,256.689 2251.09,256.689 2257.76,256.689 2264.43,256.689 2271.1,256.689 2277.77,256.689 2284.44,256.689 2291.11,256.689 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip650)\" d=\"\n",
       "M1987.14 276.658 L2280.16 276.658 L2280.16 95.2176 L1987.14 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip650)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1987.14,276.658 2280.16,276.658 2280.16,95.2176 1987.14,95.2176 1987.14,276.658 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip650)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2011.34,155.698 2156.54,155.698 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip650)\" d=\"M 0 0 M2194.58 175.385 Q2192.78 180.015 2191.06 181.427 Q2189.35 182.839 2186.48 182.839 L2183.08 182.839 L2183.08 179.274 L2185.58 179.274 Q2187.34 179.274 2188.31 178.44 Q2189.28 177.607 2190.46 174.505 L2191.22 172.561 L2180.74 147.052 L2185.25 147.052 L2193.35 167.329 L2201.46 147.052 L2205.97 147.052 L2194.58 175.385 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M2211.85 169.042 L2219.49 169.042 L2219.49 142.677 L2211.18 144.343 L2211.18 140.084 L2219.44 138.418 L2224.12 138.418 L2224.12 169.042 L2231.76 169.042 L2231.76 172.978 L2211.85 172.978 L2211.85 169.042 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip650)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2011.34,216.178 2156.54,216.178 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip650)\" d=\"M 0 0 M2194.58 235.865 Q2192.78 240.495 2191.06 241.907 Q2189.35 243.319 2186.48 243.319 L2183.08 243.319 L2183.08 239.754 L2185.58 239.754 Q2187.34 239.754 2188.31 238.92 Q2189.28 238.087 2190.46 234.985 L2191.22 233.041 L2180.74 207.532 L2185.25 207.532 L2193.35 227.809 L2201.46 207.532 L2205.97 207.532 L2194.58 235.865 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip650)\" d=\"M 0 0 M2215.07 229.522 L2231.39 229.522 L2231.39 233.458 L2209.44 233.458 L2209.44 229.522 Q2212.1 226.768 2216.69 222.138 Q2221.29 217.485 2222.47 216.143 Q2224.72 213.62 2225.6 211.884 Q2226.5 210.124 2226.5 208.435 Q2226.5 205.68 2224.56 203.944 Q2222.64 202.208 2219.53 202.208 Q2217.34 202.208 2214.88 202.972 Q2212.45 203.735 2209.67 205.286 L2209.67 200.564 Q2212.5 199.43 2214.95 198.851 Q2217.4 198.273 2219.44 198.273 Q2224.81 198.273 2228.01 200.958 Q2231.2 203.643 2231.2 208.134 Q2231.2 210.263 2230.39 212.185 Q2229.6 214.083 2227.5 216.675 Q2226.92 217.347 2223.82 220.564 Q2220.72 223.759 2215.07 229.522 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(data_schedule, training_losses)\n",
    "plot!(data_schedule, valid_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNNClassifier(\n",
       "    K = 20,\n",
       "    algorithm = :kdtree,\n",
       "    metric = Distances.Euclidean(0.0),\n",
       "    leafsize = 10,\n",
       "    reorder = true,\n",
       "    weights = :uniform)\u001b[34m @259\u001b[39m"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_final = KNNClassifier(K=best.best_model.K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{KNNClassifier} @696\u001b[39m trained 0 times.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @777\u001b[39m  `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @150\u001b[39m  `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_Final = machine(knn_final, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Info: Training \u001b[34mMachine{KNNClassifier} @237\u001b[39m.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/machines.jl:322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{KNNClassifier} @237\u001b[39m trained 8 times.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @205\u001b[39m  `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @709\u001b[39m  `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(KNN, rows=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = predict(KNN, X_stand[test,:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6947795951969478"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(y, y[test]) |> mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(y, y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(mode.(y), y[test])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
