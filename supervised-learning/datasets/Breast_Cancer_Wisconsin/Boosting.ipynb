{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using CSV\n",
    "using MLJ\n",
    "using Plots\n",
    "\n",
    "include(\"../../lib.jl\")\n",
    "\n",
    "ENV[\"LINES\"]=50;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread = 1 warning: only found 32 / 33 columns around data row: 2. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 3. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 4. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 5. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 6. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 7. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 8. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 9. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 10. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 11. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 12. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 13. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 14. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 15. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 16. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 17. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 18. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 19. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 20. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 21. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 22. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 23. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 24. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 25. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 26. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 27. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 28. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 29. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 30. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 31. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 32. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 33. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 34. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 35. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 36. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 37. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 38. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 39. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 40. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 41. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 42. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 43. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 44. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 45. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 46. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 47. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 48. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 49. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 50. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 51. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 52. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 53. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 54. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 55. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 56. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 57. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 58. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 59. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 60. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 61. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 62. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 63. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 64. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 65. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 66. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 67. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 68. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 69. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 70. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 71. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 72. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 73. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 74. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 75. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 76. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 77. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 78. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 79. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 80. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 81. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 82. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 83. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 84. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 85. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 86. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 87. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 88. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 89. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 90. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 91. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 92. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 93. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 94. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 95. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 96. Filling remaining columns with `missing`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread = 1 warning: only found 32 / 33 columns around data row: 97. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 98. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 99. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 100. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 101. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 102. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 103. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 104. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 105. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 106. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 107. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 108. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 109. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 110. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 111. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 112. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 113. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 114. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 115. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 116. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 117. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 118. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 119. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 120. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 121. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 122. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 123. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 124. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 125. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 126. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 127. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 128. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 129. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 130. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 131. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 132. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 133. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 134. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 135. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 136. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 137. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 138. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 139. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 140. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 141. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 142. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 143. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 144. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 145. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 146. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 147. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 148. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 149. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 150. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 151. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 152. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 153. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 154. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 155. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 156. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 157. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 158. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 159. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 160. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 161. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 162. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 163. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 164. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 165. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 166. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 167. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 168. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 169. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 170. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 171. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 172. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 173. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 174. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 175. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 176. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 177. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 178. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 179. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 180. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 181. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 182. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 183. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 184. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 185. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 186. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 187. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 188. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 189. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 190. Filling remaining columns with `missing`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread = 1 warning: only found 32 / 33 columns around data row: 191. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 192. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 193. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 194. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 195. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 196. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 197. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 198. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 199. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 200. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 201. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 202. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 203. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 204. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 205. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 206. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 207. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 208. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 209. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 210. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 211. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 212. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 213. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 214. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 215. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 216. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 217. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 218. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 219. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 220. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 221. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 222. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 223. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 224. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 225. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 226. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 227. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 228. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 229. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 230. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 231. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 232. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 233. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 234. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 235. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 236. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 237. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 238. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 239. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 240. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 241. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 242. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 243. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 244. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 245. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 246. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 247. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 248. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 249. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 250. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 251. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 252. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 253. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 254. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 255. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 256. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 257. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 258. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 259. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 260. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 261. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 262. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 263. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 264. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 265. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 266. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 267. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 268. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 269. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 270. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 271. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 272. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 273. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 274. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 275. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 276. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 277. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 278. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 279. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 280. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 281. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 282. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 283. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 284. Filling remaining columns with `missing`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread = 1 warning: only found 32 / 33 columns around data row: 285. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 286. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 287. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 288. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 289. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 290. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 291. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 292. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 293. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 294. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 295. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 296. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 297. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 298. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 299. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 300. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 301. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 302. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 303. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 304. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 305. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 306. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 307. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 308. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 309. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 310. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 311. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 312. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 313. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 314. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 315. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 316. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 317. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 318. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 319. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 320. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 321. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 322. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 323. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 324. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 325. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 326. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 327. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 328. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 329. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 330. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 331. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 332. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 333. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 334. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 335. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 336. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 337. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 338. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 339. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 340. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 341. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 342. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 343. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 344. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 345. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 346. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 347. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 348. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 349. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 350. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 351. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 352. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 353. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 354. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 355. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 356. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 357. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 358. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 359. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 360. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 361. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 362. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 363. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 364. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 365. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 366. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 367. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 368. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 369. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 370. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 371. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 372. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 373. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 374. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 375. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 376. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 377. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 378. Filling remaining columns with `missing`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread = 1 warning: only found 32 / 33 columns around data row: 379. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 380. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 381. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 382. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 383. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 384. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 385. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 386. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 387. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 388. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 389. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 390. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 391. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 392. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 393. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 394. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 395. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 396. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 397. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 398. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 399. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 400. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 401. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 402. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 403. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 404. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 405. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 406. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 407. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 408. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 409. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 410. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 411. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 412. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 413. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 414. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 415. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 416. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 417. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 418. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 419. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 420. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 421. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 422. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 423. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 424. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 425. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 426. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 427. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 428. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 429. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 430. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 431. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 432. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 433. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 434. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 435. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 436. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 437. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 438. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 439. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 440. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 441. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 442. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 443. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 444. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 445. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 446. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 447. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 448. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 449. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 450. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 451. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 452. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 453. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 454. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 455. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 456. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 457. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 458. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 459. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 460. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 461. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 462. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 463. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 464. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 465. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 466. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 467. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 468. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 469. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 470. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 471. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 472. Filling remaining columns with `missing`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread = 1 warning: only found 32 / 33 columns around data row: 473. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 474. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 475. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 476. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 477. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 478. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 479. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 480. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 481. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 482. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 483. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 484. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 485. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 486. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 487. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 488. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 489. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 490. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 491. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 492. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 493. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 494. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 495. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 496. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 497. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 498. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 499. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 500. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 501. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 502. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 503. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 504. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 505. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 506. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 507. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 508. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 509. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 510. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 511. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 512. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 513. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 514. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 515. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 516. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 517. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 518. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 519. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 520. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 521. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 522. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 523. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 524. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 525. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 526. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 527. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 528. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 529. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 530. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 531. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 532. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 533. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 534. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 535. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 536. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 537. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 538. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 539. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 540. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 541. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 542. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 543. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 544. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 545. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 546. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 547. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 548. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 549. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 550. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 551. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 552. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 553. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 554. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 555. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 556. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 557. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 558. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 559. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 560. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 561. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 562. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 563. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 564. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 565. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 566. Filling remaining columns with `missing`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread = 1 warning: only found 32 / 33 columns around data row: 567. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 568. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 569. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 570. Filling remaining columns with `missing`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>id</th><th>diagnosis</th><th>radius_mean</th><th>texture_mean</th><th>perimeter_mean</th><th>area_mean</th><th>smoothness_mean</th></tr><tr><th></th><th>Int64</th><th>String</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>569 rows  33 columns (omitted printing of 26 columns)</p><tr><th>1</th><td>842302</td><td>M</td><td>17.99</td><td>10.38</td><td>122.8</td><td>1001.0</td><td>0.1184</td></tr><tr><th>2</th><td>842517</td><td>M</td><td>20.57</td><td>17.77</td><td>132.9</td><td>1326.0</td><td>0.08474</td></tr><tr><th>3</th><td>84300903</td><td>M</td><td>19.69</td><td>21.25</td><td>130.0</td><td>1203.0</td><td>0.1096</td></tr><tr><th>4</th><td>84348301</td><td>M</td><td>11.42</td><td>20.38</td><td>77.58</td><td>386.1</td><td>0.1425</td></tr><tr><th>5</th><td>84358402</td><td>M</td><td>20.29</td><td>14.34</td><td>135.1</td><td>1297.0</td><td>0.1003</td></tr><tr><th>6</th><td>843786</td><td>M</td><td>12.45</td><td>15.7</td><td>82.57</td><td>477.1</td><td>0.1278</td></tr><tr><th>7</th><td>844359</td><td>M</td><td>18.25</td><td>19.98</td><td>119.6</td><td>1040.0</td><td>0.09463</td></tr><tr><th>8</th><td>84458202</td><td>M</td><td>13.71</td><td>20.83</td><td>90.2</td><td>577.9</td><td>0.1189</td></tr><tr><th>9</th><td>844981</td><td>M</td><td>13.0</td><td>21.82</td><td>87.5</td><td>519.8</td><td>0.1273</td></tr><tr><th>10</th><td>84501001</td><td>M</td><td>12.46</td><td>24.04</td><td>83.97</td><td>475.9</td><td>0.1186</td></tr><tr><th>11</th><td>845636</td><td>M</td><td>16.02</td><td>23.24</td><td>102.7</td><td>797.8</td><td>0.08206</td></tr><tr><th>12</th><td>84610002</td><td>M</td><td>15.78</td><td>17.89</td><td>103.6</td><td>781.0</td><td>0.0971</td></tr><tr><th>13</th><td>846226</td><td>M</td><td>19.17</td><td>24.8</td><td>132.4</td><td>1123.0</td><td>0.0974</td></tr><tr><th>14</th><td>846381</td><td>M</td><td>15.85</td><td>23.95</td><td>103.7</td><td>782.7</td><td>0.08401</td></tr><tr><th>15</th><td>84667401</td><td>M</td><td>13.73</td><td>22.61</td><td>93.6</td><td>578.3</td><td>0.1131</td></tr><tr><th>16</th><td>84799002</td><td>M</td><td>14.54</td><td>27.54</td><td>96.73</td><td>658.8</td><td>0.1139</td></tr><tr><th>17</th><td>848406</td><td>M</td><td>14.68</td><td>20.13</td><td>94.74</td><td>684.5</td><td>0.09867</td></tr><tr><th>18</th><td>84862001</td><td>M</td><td>16.13</td><td>20.68</td><td>108.1</td><td>798.8</td><td>0.117</td></tr><tr><th>19</th><td>849014</td><td>M</td><td>19.81</td><td>22.15</td><td>130.0</td><td>1260.0</td><td>0.09831</td></tr><tr><th>20</th><td>8510426</td><td>B</td><td>13.54</td><td>14.36</td><td>87.46</td><td>566.3</td><td>0.09779</td></tr><tr><th>21</th><td>8510653</td><td>B</td><td>13.08</td><td>15.71</td><td>85.63</td><td>520.0</td><td>0.1075</td></tr><tr><th>22</th><td>8510824</td><td>B</td><td>9.504</td><td>12.44</td><td>60.34</td><td>273.9</td><td>0.1024</td></tr><tr><th>23</th><td>8511133</td><td>M</td><td>15.34</td><td>14.26</td><td>102.5</td><td>704.4</td><td>0.1073</td></tr><tr><th>24</th><td>851509</td><td>M</td><td>21.16</td><td>23.04</td><td>137.2</td><td>1404.0</td><td>0.09428</td></tr><tr><th>25</th><td>852552</td><td>M</td><td>16.65</td><td>21.38</td><td>110.0</td><td>904.6</td><td>0.1121</td></tr><tr><th>26</th><td>852631</td><td>M</td><td>17.14</td><td>16.4</td><td>116.0</td><td>912.7</td><td>0.1186</td></tr><tr><th>27</th><td>852763</td><td>M</td><td>14.58</td><td>21.53</td><td>97.41</td><td>644.8</td><td>0.1054</td></tr><tr><th>28</th><td>852781</td><td>M</td><td>18.61</td><td>20.25</td><td>122.1</td><td>1094.0</td><td>0.0944</td></tr><tr><th>29</th><td>852973</td><td>M</td><td>15.3</td><td>25.27</td><td>102.4</td><td>732.4</td><td>0.1082</td></tr><tr><th>30</th><td>853201</td><td>M</td><td>17.57</td><td>15.05</td><td>115.0</td><td>955.1</td><td>0.09847</td></tr><tr><th>31</th><td>853401</td><td>M</td><td>18.63</td><td>25.11</td><td>124.8</td><td>1088.0</td><td>0.1064</td></tr><tr><th>32</th><td>853612</td><td>M</td><td>11.84</td><td>18.7</td><td>77.93</td><td>440.6</td><td>0.1109</td></tr><tr><th>33</th><td>85382601</td><td>M</td><td>17.02</td><td>23.98</td><td>112.8</td><td>899.3</td><td>0.1197</td></tr><tr><th>34</th><td>854002</td><td>M</td><td>19.27</td><td>26.47</td><td>127.9</td><td>1162.0</td><td>0.09401</td></tr><tr><th>35</th><td>854039</td><td>M</td><td>16.13</td><td>17.88</td><td>107.0</td><td>807.2</td><td>0.104</td></tr><tr><th>36</th><td>854253</td><td>M</td><td>16.74</td><td>21.59</td><td>110.1</td><td>869.5</td><td>0.0961</td></tr><tr><th>37</th><td>854268</td><td>M</td><td>14.25</td><td>21.72</td><td>93.63</td><td>633.0</td><td>0.09823</td></tr><tr><th>38</th><td>854941</td><td>B</td><td>13.03</td><td>18.42</td><td>82.61</td><td>523.8</td><td>0.08983</td></tr><tr><th>39</th><td>855133</td><td>M</td><td>14.99</td><td>25.2</td><td>95.54</td><td>698.8</td><td>0.09387</td></tr><tr><th>40</th><td>855138</td><td>M</td><td>13.48</td><td>20.82</td><td>88.4</td><td>559.2</td><td>0.1016</td></tr><tr><th>41</th><td>855167</td><td>M</td><td>13.44</td><td>21.58</td><td>86.18</td><td>563.0</td><td>0.08162</td></tr><tr><th>42</th><td>855563</td><td>M</td><td>10.95</td><td>21.35</td><td>71.9</td><td>371.1</td><td>0.1227</td></tr><tr><th>43</th><td>855625</td><td>M</td><td>19.07</td><td>24.81</td><td>128.3</td><td>1104.0</td><td>0.09081</td></tr><tr><th>44</th><td>856106</td><td>M</td><td>13.28</td><td>20.28</td><td>87.32</td><td>545.2</td><td>0.1041</td></tr><tr><th>45</th><td>85638502</td><td>M</td><td>13.17</td><td>21.81</td><td>85.42</td><td>531.5</td><td>0.09714</td></tr><tr><th>46</th><td>857010</td><td>M</td><td>18.65</td><td>17.6</td><td>123.7</td><td>1076.0</td><td>0.1099</td></tr><tr><th>47</th><td>85713702</td><td>B</td><td>8.196</td><td>16.84</td><td>51.71</td><td>201.9</td><td>0.086</td></tr><tr><th>48</th><td>85715</td><td>M</td><td>13.17</td><td>18.66</td><td>85.98</td><td>534.6</td><td>0.1158</td></tr><tr><th>49</th><td>857155</td><td>B</td><td>12.05</td><td>14.63</td><td>78.04</td><td>449.3</td><td>0.1031</td></tr><tr><th>50</th><td>857156</td><td>B</td><td>13.49</td><td>22.3</td><td>86.91</td><td>561.0</td><td>0.08752</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& id & diagnosis & radius\\_mean & texture\\_mean & perimeter\\_mean & area\\_mean & smoothness\\_mean & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 842302 & M & 17.99 & 10.38 & 122.8 & 1001.0 & 0.1184 & $\\dots$ \\\\\n",
       "\t2 & 842517 & M & 20.57 & 17.77 & 132.9 & 1326.0 & 0.08474 & $\\dots$ \\\\\n",
       "\t3 & 84300903 & M & 19.69 & 21.25 & 130.0 & 1203.0 & 0.1096 & $\\dots$ \\\\\n",
       "\t4 & 84348301 & M & 11.42 & 20.38 & 77.58 & 386.1 & 0.1425 & $\\dots$ \\\\\n",
       "\t5 & 84358402 & M & 20.29 & 14.34 & 135.1 & 1297.0 & 0.1003 & $\\dots$ \\\\\n",
       "\t6 & 843786 & M & 12.45 & 15.7 & 82.57 & 477.1 & 0.1278 & $\\dots$ \\\\\n",
       "\t7 & 844359 & M & 18.25 & 19.98 & 119.6 & 1040.0 & 0.09463 & $\\dots$ \\\\\n",
       "\t8 & 84458202 & M & 13.71 & 20.83 & 90.2 & 577.9 & 0.1189 & $\\dots$ \\\\\n",
       "\t9 & 844981 & M & 13.0 & 21.82 & 87.5 & 519.8 & 0.1273 & $\\dots$ \\\\\n",
       "\t10 & 84501001 & M & 12.46 & 24.04 & 83.97 & 475.9 & 0.1186 & $\\dots$ \\\\\n",
       "\t11 & 845636 & M & 16.02 & 23.24 & 102.7 & 797.8 & 0.08206 & $\\dots$ \\\\\n",
       "\t12 & 84610002 & M & 15.78 & 17.89 & 103.6 & 781.0 & 0.0971 & $\\dots$ \\\\\n",
       "\t13 & 846226 & M & 19.17 & 24.8 & 132.4 & 1123.0 & 0.0974 & $\\dots$ \\\\\n",
       "\t14 & 846381 & M & 15.85 & 23.95 & 103.7 & 782.7 & 0.08401 & $\\dots$ \\\\\n",
       "\t15 & 84667401 & M & 13.73 & 22.61 & 93.6 & 578.3 & 0.1131 & $\\dots$ \\\\\n",
       "\t16 & 84799002 & M & 14.54 & 27.54 & 96.73 & 658.8 & 0.1139 & $\\dots$ \\\\\n",
       "\t17 & 848406 & M & 14.68 & 20.13 & 94.74 & 684.5 & 0.09867 & $\\dots$ \\\\\n",
       "\t18 & 84862001 & M & 16.13 & 20.68 & 108.1 & 798.8 & 0.117 & $\\dots$ \\\\\n",
       "\t19 & 849014 & M & 19.81 & 22.15 & 130.0 & 1260.0 & 0.09831 & $\\dots$ \\\\\n",
       "\t20 & 8510426 & B & 13.54 & 14.36 & 87.46 & 566.3 & 0.09779 & $\\dots$ \\\\\n",
       "\t21 & 8510653 & B & 13.08 & 15.71 & 85.63 & 520.0 & 0.1075 & $\\dots$ \\\\\n",
       "\t22 & 8510824 & B & 9.504 & 12.44 & 60.34 & 273.9 & 0.1024 & $\\dots$ \\\\\n",
       "\t23 & 8511133 & M & 15.34 & 14.26 & 102.5 & 704.4 & 0.1073 & $\\dots$ \\\\\n",
       "\t24 & 851509 & M & 21.16 & 23.04 & 137.2 & 1404.0 & 0.09428 & $\\dots$ \\\\\n",
       "\t25 & 852552 & M & 16.65 & 21.38 & 110.0 & 904.6 & 0.1121 & $\\dots$ \\\\\n",
       "\t26 & 852631 & M & 17.14 & 16.4 & 116.0 & 912.7 & 0.1186 & $\\dots$ \\\\\n",
       "\t27 & 852763 & M & 14.58 & 21.53 & 97.41 & 644.8 & 0.1054 & $\\dots$ \\\\\n",
       "\t28 & 852781 & M & 18.61 & 20.25 & 122.1 & 1094.0 & 0.0944 & $\\dots$ \\\\\n",
       "\t29 & 852973 & M & 15.3 & 25.27 & 102.4 & 732.4 & 0.1082 & $\\dots$ \\\\\n",
       "\t30 & 853201 & M & 17.57 & 15.05 & 115.0 & 955.1 & 0.09847 & $\\dots$ \\\\\n",
       "\t31 & 853401 & M & 18.63 & 25.11 & 124.8 & 1088.0 & 0.1064 & $\\dots$ \\\\\n",
       "\t32 & 853612 & M & 11.84 & 18.7 & 77.93 & 440.6 & 0.1109 & $\\dots$ \\\\\n",
       "\t33 & 85382601 & M & 17.02 & 23.98 & 112.8 & 899.3 & 0.1197 & $\\dots$ \\\\\n",
       "\t34 & 854002 & M & 19.27 & 26.47 & 127.9 & 1162.0 & 0.09401 & $\\dots$ \\\\\n",
       "\t35 & 854039 & M & 16.13 & 17.88 & 107.0 & 807.2 & 0.104 & $\\dots$ \\\\\n",
       "\t36 & 854253 & M & 16.74 & 21.59 & 110.1 & 869.5 & 0.0961 & $\\dots$ \\\\\n",
       "\t37 & 854268 & M & 14.25 & 21.72 & 93.63 & 633.0 & 0.09823 & $\\dots$ \\\\\n",
       "\t38 & 854941 & B & 13.03 & 18.42 & 82.61 & 523.8 & 0.08983 & $\\dots$ \\\\\n",
       "\t39 & 855133 & M & 14.99 & 25.2 & 95.54 & 698.8 & 0.09387 & $\\dots$ \\\\\n",
       "\t40 & 855138 & M & 13.48 & 20.82 & 88.4 & 559.2 & 0.1016 & $\\dots$ \\\\\n",
       "\t41 & 855167 & M & 13.44 & 21.58 & 86.18 & 563.0 & 0.08162 & $\\dots$ \\\\\n",
       "\t42 & 855563 & M & 10.95 & 21.35 & 71.9 & 371.1 & 0.1227 & $\\dots$ \\\\\n",
       "\t43 & 855625 & M & 19.07 & 24.81 & 128.3 & 1104.0 & 0.09081 & $\\dots$ \\\\\n",
       "\t44 & 856106 & M & 13.28 & 20.28 & 87.32 & 545.2 & 0.1041 & $\\dots$ \\\\\n",
       "\t45 & 85638502 & M & 13.17 & 21.81 & 85.42 & 531.5 & 0.09714 & $\\dots$ \\\\\n",
       "\t46 & 857010 & M & 18.65 & 17.6 & 123.7 & 1076.0 & 0.1099 & $\\dots$ \\\\\n",
       "\t47 & 85713702 & B & 8.196 & 16.84 & 51.71 & 201.9 & 0.086 & $\\dots$ \\\\\n",
       "\t48 & 85715 & M & 13.17 & 18.66 & 85.98 & 534.6 & 0.1158 & $\\dots$ \\\\\n",
       "\t49 & 857155 & B & 12.05 & 14.63 & 78.04 & 449.3 & 0.1031 & $\\dots$ \\\\\n",
       "\t50 & 857156 & B & 13.49 & 22.3 & 86.91 & 561.0 & 0.08752 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "56933 DataFrame. Omitted printing of 28 columns\n",
       " Row  id        diagnosis  radius_mean  texture_mean  perimeter_mean \n",
       "      \u001b[90mInt64\u001b[39m     \u001b[90mString\u001b[39m     \u001b[90mFloat64\u001b[39m      \u001b[90mFloat64\u001b[39m       \u001b[90mFloat64\u001b[39m        \n",
       "\n",
       " 1    842302    M          17.99        10.38         122.8          \n",
       " 2    842517    M          20.57        17.77         132.9          \n",
       " 3    84300903  M          19.69        21.25         130.0          \n",
       " 4    84348301  M          11.42        20.38         77.58          \n",
       " 5    84358402  M          20.29        14.34         135.1          \n",
       " 6    843786    M          12.45        15.7          82.57          \n",
       " 7    844359    M          18.25        19.98         119.6          \n",
       " 8    84458202  M          13.71        20.83         90.2           \n",
       " 9    844981    M          13.0         21.82         87.5           \n",
       " 10   84501001  M          12.46        24.04         83.97          \n",
       " 11   845636    M          16.02        23.24         102.7          \n",
       " 12   84610002  M          15.78        17.89         103.6          \n",
       " 13   846226    M          19.17        24.8          132.4          \n",
       " 14   846381    M          15.85        23.95         103.7          \n",
       " 15   84667401  M          13.73        22.61         93.6           \n",
       " 16   84799002  M          14.54        27.54         96.73          \n",
       " 17   848406    M          14.68        20.13         94.74          \n",
       " 18   84862001  M          16.13        20.68         108.1          \n",
       " 19   849014    M          19.81        22.15         130.0          \n",
       " 20   8510426   B          13.54        14.36         87.46          \n",
       "\n",
       " 549  923169    B          9.683        19.34         61.05          \n",
       " 550  923465    B          10.82        24.21         68.89          \n",
       " 551  923748    B          10.86        21.48         68.51          \n",
       " 552  923780    B          11.13        22.44         71.49          \n",
       " 553  924084    B          12.77        29.43         81.35          \n",
       " 554  924342    B          9.333        21.94         59.01          \n",
       " 555  924632    B          12.88        28.92         82.5           \n",
       " 556  924934    B          10.29        27.61         65.67          \n",
       " 557  924964    B          10.16        19.59         64.73          \n",
       " 558  925236    B          9.423        27.88         59.26          \n",
       " 559  925277    B          14.59        22.68         96.39          \n",
       " 560  925291    B          11.51        23.93         74.52          \n",
       " 561  925292    B          14.05        27.15         91.38          \n",
       " 562  925311    B          11.2         29.37         70.67          \n",
       " 563  925622    M          15.22        30.62         103.4          \n",
       " 564  926125    M          20.92        25.09         143.0          \n",
       " 565  926424    M          21.56        22.39         142.0          \n",
       " 566  926682    M          20.13        28.25         131.2          \n",
       " 567  926954    M          16.6         28.08         108.3          \n",
       " 568  927241    M          20.6         29.33         140.1          \n",
       " 569  92751     B          7.76         24.54         47.92          "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = CSV.read(\"./data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th><th>nunique</th><th>nmissing</th></tr><tr><th></th><th>Symbol</th><th>Union</th><th>Any</th><th>Union</th><th>Any</th><th>Union</th><th>Nothing</th></tr></thead><tbody><p>31 rows  8 columns (omitted printing of 1 columns)</p><tr><th>1</th><td>diagnosis</td><td></td><td>B</td><td></td><td>M</td><td>2</td><td></td></tr><tr><th>2</th><td>radius_mean</td><td>14.1273</td><td>6.981</td><td>13.37</td><td>28.11</td><td></td><td></td></tr><tr><th>3</th><td>texture_mean</td><td>19.2896</td><td>9.71</td><td>18.84</td><td>39.28</td><td></td><td></td></tr><tr><th>4</th><td>perimeter_mean</td><td>91.969</td><td>43.79</td><td>86.24</td><td>188.5</td><td></td><td></td></tr><tr><th>5</th><td>area_mean</td><td>654.889</td><td>143.5</td><td>551.1</td><td>2501.0</td><td></td><td></td></tr><tr><th>6</th><td>smoothness_mean</td><td>0.0963603</td><td>0.05263</td><td>0.09587</td><td>0.1634</td><td></td><td></td></tr><tr><th>7</th><td>compactness_mean</td><td>0.104341</td><td>0.01938</td><td>0.09263</td><td>0.3454</td><td></td><td></td></tr><tr><th>8</th><td>concavity_mean</td><td>0.0887993</td><td>0.0</td><td>0.06154</td><td>0.4268</td><td></td><td></td></tr><tr><th>9</th><td>concave points_mean</td><td>0.0489191</td><td>0.0</td><td>0.0335</td><td>0.2012</td><td></td><td></td></tr><tr><th>10</th><td>symmetry_mean</td><td>0.181162</td><td>0.106</td><td>0.1792</td><td>0.304</td><td></td><td></td></tr><tr><th>11</th><td>fractal_dimension_mean</td><td>0.0627976</td><td>0.04996</td><td>0.06154</td><td>0.09744</td><td></td><td></td></tr><tr><th>12</th><td>radius_se</td><td>0.405172</td><td>0.1115</td><td>0.3242</td><td>2.873</td><td></td><td></td></tr><tr><th>13</th><td>texture_se</td><td>1.21685</td><td>0.3602</td><td>1.108</td><td>4.885</td><td></td><td></td></tr><tr><th>14</th><td>perimeter_se</td><td>2.86606</td><td>0.757</td><td>2.287</td><td>21.98</td><td></td><td></td></tr><tr><th>15</th><td>area_se</td><td>40.3371</td><td>6.802</td><td>24.53</td><td>542.2</td><td></td><td></td></tr><tr><th>16</th><td>smoothness_se</td><td>0.00704098</td><td>0.001713</td><td>0.00638</td><td>0.03113</td><td></td><td></td></tr><tr><th>17</th><td>compactness_se</td><td>0.0254781</td><td>0.002252</td><td>0.02045</td><td>0.1354</td><td></td><td></td></tr><tr><th>18</th><td>concavity_se</td><td>0.0318937</td><td>0.0</td><td>0.02589</td><td>0.396</td><td></td><td></td></tr><tr><th>19</th><td>concave points_se</td><td>0.0117961</td><td>0.0</td><td>0.01093</td><td>0.05279</td><td></td><td></td></tr><tr><th>20</th><td>symmetry_se</td><td>0.0205423</td><td>0.007882</td><td>0.01873</td><td>0.07895</td><td></td><td></td></tr><tr><th>21</th><td>fractal_dimension_se</td><td>0.0037949</td><td>0.0008948</td><td>0.003187</td><td>0.02984</td><td></td><td></td></tr><tr><th>22</th><td>radius_worst</td><td>16.2692</td><td>7.93</td><td>14.97</td><td>36.04</td><td></td><td></td></tr><tr><th>23</th><td>texture_worst</td><td>25.6772</td><td>12.02</td><td>25.41</td><td>49.54</td><td></td><td></td></tr><tr><th>24</th><td>perimeter_worst</td><td>107.261</td><td>50.41</td><td>97.66</td><td>251.2</td><td></td><td></td></tr><tr><th>25</th><td>area_worst</td><td>880.583</td><td>185.2</td><td>686.5</td><td>4254.0</td><td></td><td></td></tr><tr><th>26</th><td>smoothness_worst</td><td>0.132369</td><td>0.07117</td><td>0.1313</td><td>0.2226</td><td></td><td></td></tr><tr><th>27</th><td>compactness_worst</td><td>0.254265</td><td>0.02729</td><td>0.2119</td><td>1.058</td><td></td><td></td></tr><tr><th>28</th><td>concavity_worst</td><td>0.272188</td><td>0.0</td><td>0.2267</td><td>1.252</td><td></td><td></td></tr><tr><th>29</th><td>concave points_worst</td><td>0.114606</td><td>0.0</td><td>0.09993</td><td>0.291</td><td></td><td></td></tr><tr><th>30</th><td>symmetry_worst</td><td>0.290076</td><td>0.1565</td><td>0.2822</td><td>0.6638</td><td></td><td></td></tr><tr><th>31</th><td>fractal_dimension_worst</td><td>0.0839458</td><td>0.05504</td><td>0.08004</td><td>0.2075</td><td></td><td></td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& variable & mean & min & median & max & nunique & nmissing & \\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Union & Any & Union & Any & Union & Nothing & \\\\\n",
       "\t\\hline\n",
       "\t1 & diagnosis &  & B &  & M & 2 &  & $\\dots$ \\\\\n",
       "\t2 & radius\\_mean & 14.1273 & 6.981 & 13.37 & 28.11 &  &  & $\\dots$ \\\\\n",
       "\t3 & texture\\_mean & 19.2896 & 9.71 & 18.84 & 39.28 &  &  & $\\dots$ \\\\\n",
       "\t4 & perimeter\\_mean & 91.969 & 43.79 & 86.24 & 188.5 &  &  & $\\dots$ \\\\\n",
       "\t5 & area\\_mean & 654.889 & 143.5 & 551.1 & 2501.0 &  &  & $\\dots$ \\\\\n",
       "\t6 & smoothness\\_mean & 0.0963603 & 0.05263 & 0.09587 & 0.1634 &  &  & $\\dots$ \\\\\n",
       "\t7 & compactness\\_mean & 0.104341 & 0.01938 & 0.09263 & 0.3454 &  &  & $\\dots$ \\\\\n",
       "\t8 & concavity\\_mean & 0.0887993 & 0.0 & 0.06154 & 0.4268 &  &  & $\\dots$ \\\\\n",
       "\t9 & concave points\\_mean & 0.0489191 & 0.0 & 0.0335 & 0.2012 &  &  & $\\dots$ \\\\\n",
       "\t10 & symmetry\\_mean & 0.181162 & 0.106 & 0.1792 & 0.304 &  &  & $\\dots$ \\\\\n",
       "\t11 & fractal\\_dimension\\_mean & 0.0627976 & 0.04996 & 0.06154 & 0.09744 &  &  & $\\dots$ \\\\\n",
       "\t12 & radius\\_se & 0.405172 & 0.1115 & 0.3242 & 2.873 &  &  & $\\dots$ \\\\\n",
       "\t13 & texture\\_se & 1.21685 & 0.3602 & 1.108 & 4.885 &  &  & $\\dots$ \\\\\n",
       "\t14 & perimeter\\_se & 2.86606 & 0.757 & 2.287 & 21.98 &  &  & $\\dots$ \\\\\n",
       "\t15 & area\\_se & 40.3371 & 6.802 & 24.53 & 542.2 &  &  & $\\dots$ \\\\\n",
       "\t16 & smoothness\\_se & 0.00704098 & 0.001713 & 0.00638 & 0.03113 &  &  & $\\dots$ \\\\\n",
       "\t17 & compactness\\_se & 0.0254781 & 0.002252 & 0.02045 & 0.1354 &  &  & $\\dots$ \\\\\n",
       "\t18 & concavity\\_se & 0.0318937 & 0.0 & 0.02589 & 0.396 &  &  & $\\dots$ \\\\\n",
       "\t19 & concave points\\_se & 0.0117961 & 0.0 & 0.01093 & 0.05279 &  &  & $\\dots$ \\\\\n",
       "\t20 & symmetry\\_se & 0.0205423 & 0.007882 & 0.01873 & 0.07895 &  &  & $\\dots$ \\\\\n",
       "\t21 & fractal\\_dimension\\_se & 0.0037949 & 0.0008948 & 0.003187 & 0.02984 &  &  & $\\dots$ \\\\\n",
       "\t22 & radius\\_worst & 16.2692 & 7.93 & 14.97 & 36.04 &  &  & $\\dots$ \\\\\n",
       "\t23 & texture\\_worst & 25.6772 & 12.02 & 25.41 & 49.54 &  &  & $\\dots$ \\\\\n",
       "\t24 & perimeter\\_worst & 107.261 & 50.41 & 97.66 & 251.2 &  &  & $\\dots$ \\\\\n",
       "\t25 & area\\_worst & 880.583 & 185.2 & 686.5 & 4254.0 &  &  & $\\dots$ \\\\\n",
       "\t26 & smoothness\\_worst & 0.132369 & 0.07117 & 0.1313 & 0.2226 &  &  & $\\dots$ \\\\\n",
       "\t27 & compactness\\_worst & 0.254265 & 0.02729 & 0.2119 & 1.058 &  &  & $\\dots$ \\\\\n",
       "\t28 & concavity\\_worst & 0.272188 & 0.0 & 0.2267 & 1.252 &  &  & $\\dots$ \\\\\n",
       "\t29 & concave points\\_worst & 0.114606 & 0.0 & 0.09993 & 0.291 &  &  & $\\dots$ \\\\\n",
       "\t30 & symmetry\\_worst & 0.290076 & 0.1565 & 0.2822 & 0.6638 &  &  & $\\dots$ \\\\\n",
       "\t31 & fractal\\_dimension\\_worst & 0.0839458 & 0.05504 & 0.08004 & 0.2075 &  &  & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "318 DataFrame. Omitted printing of 3 columns\n",
       " Row  variable                 mean        min        median    max     \n",
       "      \u001b[90mSymbol\u001b[39m                   \u001b[90mUnion\u001b[39m      \u001b[90mAny\u001b[39m        \u001b[90mUnion\u001b[39m    \u001b[90mAny\u001b[39m     \n",
       "\n",
       " 1    diagnosis                            B                    M       \n",
       " 2    radius_mean              14.1273     6.981      13.37     28.11   \n",
       " 3    texture_mean             19.2896     9.71       18.84     39.28   \n",
       " 4    perimeter_mean           91.969      43.79      86.24     188.5   \n",
       " 5    area_mean                654.889     143.5      551.1     2501.0  \n",
       " 6    smoothness_mean          0.0963603   0.05263    0.09587   0.1634  \n",
       " 7    compactness_mean         0.104341    0.01938    0.09263   0.3454  \n",
       " 8    concavity_mean           0.0887993   0.0        0.06154   0.4268  \n",
       " 9    concave points_mean      0.0489191   0.0        0.0335    0.2012  \n",
       " 10   symmetry_mean            0.181162    0.106      0.1792    0.304   \n",
       " 11   fractal_dimension_mean   0.0627976   0.04996    0.06154   0.09744 \n",
       " 12   radius_se                0.405172    0.1115     0.3242    2.873   \n",
       " 13   texture_se               1.21685     0.3602     1.108     4.885   \n",
       " 14   perimeter_se             2.86606     0.757      2.287     21.98   \n",
       " 15   area_se                  40.3371     6.802      24.53     542.2   \n",
       " 16   smoothness_se            0.00704098  0.001713   0.00638   0.03113 \n",
       " 17   compactness_se           0.0254781   0.002252   0.02045   0.1354  \n",
       " 18   concavity_se             0.0318937   0.0        0.02589   0.396   \n",
       " 19   concave points_se        0.0117961   0.0        0.01093   0.05279 \n",
       " 20   symmetry_se              0.0205423   0.007882   0.01873   0.07895 \n",
       " 21   fractal_dimension_se     0.0037949   0.0008948  0.003187  0.02984 \n",
       " 22   radius_worst             16.2692     7.93       14.97     36.04   \n",
       " 23   texture_worst            25.6772     12.02      25.41     49.54   \n",
       " 24   perimeter_worst          107.261     50.41      97.66     251.2   \n",
       " 25   area_worst               880.583     185.2      686.5     4254.0  \n",
       " 26   smoothness_worst         0.132369    0.07117    0.1313    0.2226  \n",
       " 27   compactness_worst        0.254265    0.02729    0.2119    1.058   \n",
       " 28   concavity_worst          0.272188    0.0        0.2267    1.252   \n",
       " 29   concave points_worst     0.114606    0.0        0.09993   0.291   \n",
       " 30   symmetry_worst           0.290076    0.1565     0.2822    0.6638  \n",
       " 31   fractal_dimension_worst  0.0839458   0.05504    0.08004   0.2075  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[:, Not([33, 1])]\n",
    "describe(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[22m _.names                 \u001b[0m\u001b[0m\u001b[22m _.types                         \u001b[0m\u001b[0m\u001b[22m _.scitypes    \u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "\u001b[0m diagnosis               \u001b[0m\u001b[0m CategoricalValue{String,UInt32} \u001b[0m\u001b[0m Multiclass{2} \u001b[0m\u001b[0m\n",
       "\u001b[0m radius_mean             \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m texture_mean            \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m perimeter_mean          \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m area_mean               \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m smoothness_mean         \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m compactness_mean        \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m concavity_mean          \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m concave points_mean     \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m symmetry_mean           \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m fractal_dimension_mean  \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m radius_se               \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m texture_se              \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m perimeter_se            \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m area_se                 \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m smoothness_se           \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m compactness_se          \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m concavity_se            \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m concave points_se       \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m symmetry_se             \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m fractal_dimension_se    \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m radius_worst            \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m texture_worst           \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m perimeter_worst         \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m area_worst              \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m smoothness_worst        \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m compactness_worst       \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m concavity_worst         \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m concave points_worst    \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m symmetry_worst          \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m fractal_dimension_worst \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "_.nrows = 569\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coerce!(data, :diagnosis=>Multiclass)\n",
    "schema(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CategoricalValue{String,UInt32}[\"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\"    \"B\", \"B\", \"B\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"B\"], 56930 DataFrame. Omitted printing of 26 columns\n",
       " Row  radius_mean  texture_mean  perimeter_mean  area_mean \n",
       "      \u001b[90mFloat64\u001b[39m      \u001b[90mFloat64\u001b[39m       \u001b[90mFloat64\u001b[39m         \u001b[90mFloat64\u001b[39m   \n",
       "\n",
       " 1    17.99        10.38         122.8           1001.0    \n",
       " 2    20.57        17.77         132.9           1326.0    \n",
       " 3    19.69        21.25         130.0           1203.0    \n",
       " 4    11.42        20.38         77.58           386.1     \n",
       " 5    20.29        14.34         135.1           1297.0    \n",
       " 6    12.45        15.7          82.57           477.1     \n",
       " 7    18.25        19.98         119.6           1040.0    \n",
       " 8    13.71        20.83         90.2            577.9     \n",
       " 9    13.0         21.82         87.5            519.8     \n",
       " 10   12.46        24.04         83.97           475.9     \n",
       " 11   16.02        23.24         102.7           797.8     \n",
       " 12   15.78        17.89         103.6           781.0     \n",
       " 13   19.17        24.8          132.4           1123.0    \n",
       " 14   15.85        23.95         103.7           782.7     \n",
       " 15   13.73        22.61         93.6            578.3     \n",
       " 16   14.54        27.54         96.73           658.8     \n",
       " 17   14.68        20.13         94.74           684.5     \n",
       " 18   16.13        20.68         108.1           798.8     \n",
       " 19   19.81        22.15         130.0           1260.0    \n",
       " 20   13.54        14.36         87.46           566.3     \n",
       "\n",
       " 549  9.683        19.34         61.05           285.7     \n",
       " 550  10.82        24.21         68.89           361.6     \n",
       " 551  10.86        21.48         68.51           360.5     \n",
       " 552  11.13        22.44         71.49           378.4     \n",
       " 553  12.77        29.43         81.35           507.9     \n",
       " 554  9.333        21.94         59.01           264.0     \n",
       " 555  12.88        28.92         82.5            514.3     \n",
       " 556  10.29        27.61         65.67           321.4     \n",
       " 557  10.16        19.59         64.73           311.7     \n",
       " 558  9.423        27.88         59.26           271.3     \n",
       " 559  14.59        22.68         96.39           657.1     \n",
       " 560  11.51        23.93         74.52           403.5     \n",
       " 561  14.05        27.15         91.38           600.4     \n",
       " 562  11.2         29.37         70.67           386.0     \n",
       " 563  15.22        30.62         103.4           716.9     \n",
       " 564  20.92        25.09         143.0           1347.0    \n",
       " 565  21.56        22.39         142.0           1479.0    \n",
       " 566  20.13        28.25         131.2           1261.0    \n",
       " 567  16.6         28.08         108.3           858.1     \n",
       " 568  20.6         29.33         140.1           1265.0    \n",
       " 569  7.76         24.54         47.92           181.0     )"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, X = unpack(data, ==(:diagnosis), colname->true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([381, 537, 95, 43, 151, 502, 459, 348, 49, 93    374, 554, 431, 346, 353, 561, 217, 135, 96, 15], [292, 18, 110, 408, 247, 175, 427, 394, 115, 68    338, 35, 344, 417, 428, 454, 515, 376, 265, 44])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data to use when trying to fit a single validation set\n",
    "train, test = partition(eachindex(y), 0.7, shuffle=true) # gives 70:30 split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Five Learning Algorithms\n",
    "\n",
    "* Decision trees with some form of pruning\n",
    "* Neural networks\n",
    "* Boosting\n",
    "* Support Vector Machines\n",
    "* k-nearest neighbors\n",
    "\n",
    "\n",
    "##### Testing\n",
    "* Implement the algorithms\n",
    "* Design two *interesting* classification problems. For the purposes of this assignment, a classification problem is just a set of training examples and a set of test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43-element Array{NamedTuple{(:name, :package_name, :is_supervised, :docstring, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :is_pure_julia, :is_wrapper, :load_path, :package_license, :package_url, :package_uuid, :prediction_type, :supports_online, :supports_weights, :input_scitype, :target_scitype, :output_scitype),T} where T<:Tuple,1}:\n",
       " (name = AdaBoostClassifier, package_name = ScikitLearn, ... )\n",
       " (name = AdaBoostStumpClassifier, package_name = DecisionTree, ... )\n",
       " (name = BaggingClassifier, package_name = ScikitLearn, ... )\n",
       " (name = BayesianLDA, package_name = MultivariateStats, ... )\n",
       " (name = BayesianLDA, package_name = ScikitLearn, ... )\n",
       " (name = BayesianQDA, package_name = ScikitLearn, ... )\n",
       " (name = BayesianSubspaceLDA, package_name = MultivariateStats, ... )\n",
       " (name = ConstantClassifier, package_name = MLJModels, ... )\n",
       " (name = DecisionTreeClassifier, package_name = DecisionTree, ... )\n",
       " (name = DeterministicConstantClassifier, package_name = MLJModels, ... )\n",
       " (name = DummyClassifier, package_name = ScikitLearn, ... )\n",
       " (name = EvoTreeClassifier, package_name = EvoTrees, ... )\n",
       " (name = ExtraTreesClassifier, package_name = ScikitLearn, ... )\n",
       " (name = GaussianNBClassifier, package_name = NaiveBayes, ... )\n",
       " (name = GaussianNBClassifier, package_name = ScikitLearn, ... )\n",
       " (name = GaussianProcessClassifier, package_name = ScikitLearn, ... )\n",
       " (name = GradientBoostingClassifier, package_name = ScikitLearn, ... )\n",
       " (name = KNNClassifier, package_name = NearestNeighbors, ... )\n",
       " (name = KNeighborsClassifier, package_name = ScikitLearn, ... )\n",
       " (name = LDA, package_name = MultivariateStats, ... )\n",
       " (name = LGBMClassifier, package_name = LightGBM, ... )\n",
       " (name = LinearBinaryClassifier, package_name = GLM, ... )\n",
       " (name = LinearSVC, package_name = LIBSVM, ... )\n",
       " (name = LogisticCVClassifier, package_name = ScikitLearn, ... )\n",
       " (name = LogisticClassifier, package_name = MLJLinearModels, ... )\n",
       " (name = LogisticClassifier, package_name = ScikitLearn, ... )\n",
       " (name = MultinomialClassifier, package_name = MLJLinearModels, ... )\n",
       " (name = NeuralNetworkClassifier, package_name = MLJFlux, ... )\n",
       " (name = NuSVC, package_name = LIBSVM, ... )\n",
       " (name = PassiveAggressiveClassifier, package_name = ScikitLearn, ... )\n",
       " (name = PerceptronClassifier, package_name = ScikitLearn, ... )\n",
       " (name = ProbabilisticSGDClassifier, package_name = ScikitLearn, ... )\n",
       " (name = RandomForestClassifier, package_name = DecisionTree, ... )\n",
       " (name = RandomForestClassifier, package_name = ScikitLearn, ... )\n",
       " (name = RidgeCVClassifier, package_name = ScikitLearn, ... )\n",
       " (name = RidgeClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SGDClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SVC, package_name = LIBSVM, ... )\n",
       " (name = SVMClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SVMLinearClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SVMNuClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SubspaceLDA, package_name = MultivariateStats, ... )\n",
       " (name = XGBoostClassifier, package_name = XGBoost, ... )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models(matching(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJScikitLearnInterface "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Info: Loading into module \"Main\": \n",
      " @ MLJModels /home/andrew/.julia/packages/MLJModels/5DFoi/src/loading.jl:70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import MLJScikitLearnInterface \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(\n",
       "    base_estimator = nothing,\n",
       "    n_estimators = 50,\n",
       "    learning_rate = 1.0,\n",
       "    algorithm = \"SAMME.R\",\n",
       "    random_state = nothing)\u001b[34m @018\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@load AdaBoostClassifier verbosity=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting\n",
    "* Implement or steal a boosted version of your decision trees. \n",
    "* As before, you will want to use some form of pruning, but presumably because you're using boosting you can afford to be much more aggressive about your pruning.\n",
    "\n",
    "**Chooses the hardest examples** talk about in write-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(\n",
       "    base_estimator = nothing,\n",
       "    n_estimators = 50,\n",
       "    learning_rate = 1.0,\n",
       "    algorithm = \"SAMME.R\",\n",
       "    random_state = nothing)\u001b[34m @064\u001b[39m"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_model = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{AdaBoostClassifier} @636\u001b[39m trained 0 times.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @805\u001b[39m  `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @728\u001b[39m  `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_mach = machine(boost_model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Info: Training \u001b[34mMachine{AdaBoostClassifier} @636\u001b[39m.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/machines.jl:322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{AdaBoostClassifier} @636\u001b[39m trained 1 time.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @805\u001b[39m  `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @728\u001b[39m  `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(boost_mach, rows=train, verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 6 folds: 100%[=========================] Time: 0:00:05\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[22m _.measure        \u001b[0m\u001b[0m\u001b[22m _.measurement \u001b[0m\u001b[0m\u001b[22m _.per_fold                                 \u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "\u001b[0m cross_entropy    \u001b[0m\u001b[0m 0.464         \u001b[0m\u001b[0m [0.446, 0.447, 0.491, 0.421, 0.492, 0.486] \u001b[0m\u001b[0m\n",
       "\u001b[0m acc              \u001b[0m\u001b[0m 0.97          \u001b[0m\u001b[0m [0.979, 0.979, 0.968, 0.968, 0.958, 0.968] \u001b[0m\u001b[0m\n",
       "\u001b[0m area_under_curve \u001b[0m\u001b[0m 0.99          \u001b[0m\u001b[0m [0.994, 0.987, 0.99, 0.987, 0.997, 0.988]  \u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "_.per_observation = [[[0.526, 0.361, ..., 0.481], [0.395, 0.467, ..., 0.559], [0.589, 0.493, ..., 0.407], [0.273, 0.624, ..., 0.142], [0.5, 0.558, ..., 0.47], [0.446, 0.404, ..., 0.496]], missing, missing]\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_acc = evaluate!(boost_mach, resampling=CV(shuffle=true), measure=[cross_entropy, acc, area_under_curve], \n",
    "                        verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_params(boost_mach);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch \n",
    "number of estimators vs learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLJBase.NumericRange(Int64, :n_estimators, ... )"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param1 = :learning_rate\n",
    "param2 = :n_estimators\n",
    "\n",
    "r1 = range(boost_model, param1, lower=0.1, upper=1, scale=:linear)\n",
    "r2 = range(boost_model, param2, lower=10, upper=100, scale=:log10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProbabilisticTunedModel(\n",
       "    model = AdaBoostClassifier(\n",
       "            base_estimator = nothing,\n",
       "            n_estimators = 50,\n",
       "            learning_rate = 1.0,\n",
       "            algorithm = \"SAMME.R\",\n",
       "            random_state = nothing),\n",
       "    tuning = Grid(\n",
       "            goal = nothing,\n",
       "            resolution = 10,\n",
       "            shuffle = true,\n",
       "            rng = Random._GLOBAL_RNG()),\n",
       "    resampling = CV(\n",
       "            nfolds = 6,\n",
       "            shuffle = false,\n",
       "            rng = Random._GLOBAL_RNG()),\n",
       "    measure = cross_entropy(\n",
       "            eps = 2.220446049250313e-16),\n",
       "    weights = nothing,\n",
       "    operation = MLJModelInterface.predict,\n",
       "    range = MLJBase.NumericRange{T,MLJBase.Bounded,Symbol} where T[\u001b[34mNumericRange{Float64,} @023\u001b[39m, \u001b[34mNumericRange{Int64,} @909\u001b[39m],\n",
       "    train_best = true,\n",
       "    repeats = 1,\n",
       "    n = nothing,\n",
       "    acceleration = CPUThreads{Int64}(1),\n",
       "    acceleration_resampling = CPU1{Nothing}(nothing),\n",
       "    check_measure = true)\u001b[34m @540\u001b[39m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_tuning_boost_model = TunedModel(model=boost_model,\n",
    "                                    tuning=Grid(),\n",
    "                                    resampling=CV(), \n",
    "                                    measure=cross_entropy,\n",
    "                                    acceleration=CPUThreads(),\n",
    "                                    range=[r1, r2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{ProbabilisticTunedModel{Grid,}} @567\u001b[39m trained 0 times.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @534\u001b[39m  `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @634\u001b[39m  `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_tuning_boost = machine(self_tuning_boost_model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Info: Training \u001b[34mMachine{ProbabilisticTunedModel{Grid,}} @567\u001b[39m.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/machines.jl:322\n",
      " Info: Attempting to evaluate 100 models.\n",
      " @ MLJTuning /home/andrew/.julia/packages/MLJTuning/nuvTc/src/tuned_models.jl:501\n",
      "\u001b[33mEvaluating over 100 metamodels: 100%[=========================] Time: 0:00:44\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{ProbabilisticTunedModel{Grid,}} @567\u001b[39m trained 1 time.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @534\u001b[39m  `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @634\u001b[39m  `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = fit!(self_tuning_boost, rows=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip950\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip950)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip951\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip950)\" d=\"\n",
       "M322.319 1423.18 L2112.76 1423.18 L2112.76 47.2441 L322.319 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip952\">\n",
       "    <rect x=\"322\" y=\"47\" width=\"1791\" height=\"1377\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip952)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  560.669,1423.18 560.669,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip952)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  936.022,1423.18 936.022,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip952)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1311.38,1423.18 1311.38,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip952)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1686.73,1423.18 1686.73,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip952)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2062.08,1423.18 2062.08,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip952)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  322.319,1384.24 2112.76,1384.24 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip952)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  322.319,1059.73 2112.76,1059.73 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip952)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  322.319,735.212 2112.76,735.212 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip952)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  322.319,410.699 2112.76,410.699 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip952)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  322.319,86.1857 2112.76,86.1857 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  322.319,1423.18 2112.76,1423.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  322.319,1423.18 322.319,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  560.669,1423.18 560.669,1406.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  936.022,1423.18 936.022,1406.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1311.38,1423.18 1311.38,1406.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1686.73,1423.18 1686.73,1406.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2062.08,1423.18 2062.08,1406.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  322.319,1384.24 343.805,1384.24 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  322.319,1059.73 343.805,1059.73 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  322.319,735.212 343.805,735.212 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  322.319,410.699 343.805,410.699 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  322.319,86.1857 343.805,86.1857 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip950)\" d=\"M 0 0 M542.984 1445.17 Q539.373 1445.17 537.544 1448.74 Q535.739 1452.28 535.739 1459.41 Q535.739 1466.51 537.544 1470.08 Q539.373 1473.62 542.984 1473.62 Q546.618 1473.62 548.424 1470.08 Q550.252 1466.51 550.252 1459.41 Q550.252 1452.28 548.424 1448.74 Q546.618 1445.17 542.984 1445.17 M542.984 1441.47 Q548.794 1441.47 551.85 1446.07 Q554.928 1450.66 554.928 1459.41 Q554.928 1468.13 551.85 1472.74 Q548.794 1477.32 542.984 1477.32 Q537.174 1477.32 534.095 1472.74 Q531.039 1468.13 531.039 1459.41 Q531.039 1450.66 534.095 1446.07 Q537.174 1441.47 542.984 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M559.998 1470.77 L564.882 1470.77 L564.882 1476.65 L559.998 1476.65 L559.998 1470.77 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M573.979 1472.72 L590.298 1472.72 L590.298 1476.65 L568.354 1476.65 L568.354 1472.72 Q571.016 1469.96 575.599 1465.33 Q580.206 1460.68 581.386 1459.34 Q583.632 1456.81 584.511 1455.08 Q585.414 1453.32 585.414 1451.63 Q585.414 1448.87 583.47 1447.14 Q581.548 1445.4 578.447 1445.4 Q576.248 1445.4 573.794 1446.17 Q571.363 1446.93 568.586 1448.48 L568.586 1443.76 Q571.41 1442.62 573.863 1442.05 Q576.317 1441.47 578.354 1441.47 Q583.724 1441.47 586.919 1444.15 Q590.113 1446.84 590.113 1451.33 Q590.113 1453.46 589.303 1455.38 Q588.516 1457.28 586.41 1459.87 Q585.831 1460.54 582.729 1463.76 Q579.627 1466.95 573.979 1472.72 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M917.296 1445.17 Q913.685 1445.17 911.856 1448.74 Q910.05 1452.28 910.05 1459.41 Q910.05 1466.51 911.856 1470.08 Q913.685 1473.62 917.296 1473.62 Q920.93 1473.62 922.736 1470.08 Q924.564 1466.51 924.564 1459.41 Q924.564 1452.28 922.736 1448.74 Q920.93 1445.17 917.296 1445.17 M917.296 1441.47 Q923.106 1441.47 926.161 1446.07 Q929.24 1450.66 929.24 1459.41 Q929.24 1468.13 926.161 1472.74 Q923.106 1477.32 917.296 1477.32 Q911.486 1477.32 908.407 1472.74 Q905.351 1468.13 905.351 1459.41 Q905.351 1450.66 908.407 1446.07 Q911.486 1441.47 917.296 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M934.31 1470.77 L939.194 1470.77 L939.194 1476.65 L934.31 1476.65 L934.31 1470.77 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M957.11 1446.17 L945.305 1464.61 L957.11 1464.61 L957.11 1446.17 M955.883 1442.09 L961.763 1442.09 L961.763 1464.61 L966.694 1464.61 L966.694 1468.5 L961.763 1468.5 L961.763 1476.65 L957.11 1476.65 L957.11 1468.5 L941.509 1468.5 L941.509 1463.99 L955.883 1442.09 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M1292.81 1445.17 Q1289.2 1445.17 1287.37 1448.74 Q1285.57 1452.28 1285.57 1459.41 Q1285.57 1466.51 1287.37 1470.08 Q1289.2 1473.62 1292.81 1473.62 Q1296.45 1473.62 1298.25 1470.08 Q1300.08 1466.51 1300.08 1459.41 Q1300.08 1452.28 1298.25 1448.74 Q1296.45 1445.17 1292.81 1445.17 M1292.81 1441.47 Q1298.62 1441.47 1301.68 1446.07 Q1304.76 1450.66 1304.76 1459.41 Q1304.76 1468.13 1301.68 1472.74 Q1298.62 1477.32 1292.81 1477.32 Q1287 1477.32 1283.92 1472.74 Q1280.87 1468.13 1280.87 1459.41 Q1280.87 1450.66 1283.92 1446.07 Q1287 1441.47 1292.81 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M1309.83 1470.77 L1314.71 1470.77 L1314.71 1476.65 L1309.83 1476.65 L1309.83 1470.77 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M1330.36 1457.51 Q1327.21 1457.51 1325.36 1459.66 Q1323.53 1461.81 1323.53 1465.56 Q1323.53 1469.29 1325.36 1471.47 Q1327.21 1473.62 1330.36 1473.62 Q1333.51 1473.62 1335.33 1471.47 Q1337.19 1469.29 1337.19 1465.56 Q1337.19 1461.81 1335.33 1459.66 Q1333.51 1457.51 1330.36 1457.51 M1339.64 1442.86 L1339.64 1447.11 Q1337.88 1446.28 1336.07 1445.84 Q1334.29 1445.4 1332.53 1445.4 Q1327.9 1445.4 1325.45 1448.53 Q1323.02 1451.65 1322.67 1457.97 Q1324.04 1455.96 1326.1 1454.89 Q1328.16 1453.8 1330.64 1453.8 Q1335.84 1453.8 1338.85 1456.98 Q1341.89 1460.12 1341.89 1465.56 Q1341.89 1470.89 1338.74 1474.11 Q1335.59 1477.32 1330.36 1477.32 Q1324.36 1477.32 1321.19 1472.74 Q1318.02 1468.13 1318.02 1459.41 Q1318.02 1451.21 1321.91 1446.35 Q1325.8 1441.47 1332.35 1441.47 Q1334.11 1441.47 1335.89 1441.81 Q1337.7 1442.16 1339.64 1442.86 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M1668.29 1445.17 Q1664.68 1445.17 1662.85 1448.74 Q1661.05 1452.28 1661.05 1459.41 Q1661.05 1466.51 1662.85 1470.08 Q1664.68 1473.62 1668.29 1473.62 Q1671.93 1473.62 1673.73 1470.08 Q1675.56 1466.51 1675.56 1459.41 Q1675.56 1452.28 1673.73 1448.74 Q1671.93 1445.17 1668.29 1445.17 M1668.29 1441.47 Q1674.1 1441.47 1677.16 1446.07 Q1680.24 1450.66 1680.24 1459.41 Q1680.24 1468.13 1677.16 1472.74 Q1674.1 1477.32 1668.29 1477.32 Q1662.48 1477.32 1659.4 1472.74 Q1656.35 1468.13 1656.35 1459.41 Q1656.35 1450.66 1659.4 1446.07 Q1662.48 1441.47 1668.29 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M1685.31 1470.77 L1690.19 1470.77 L1690.19 1476.65 L1685.31 1476.65 L1685.31 1470.77 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M1705.26 1460.24 Q1701.93 1460.24 1700.01 1462.02 Q1698.11 1463.8 1698.11 1466.93 Q1698.11 1470.05 1700.01 1471.84 Q1701.93 1473.62 1705.26 1473.62 Q1708.59 1473.62 1710.51 1471.84 Q1712.44 1470.03 1712.44 1466.93 Q1712.44 1463.8 1710.51 1462.02 Q1708.62 1460.24 1705.26 1460.24 M1700.58 1458.25 Q1697.57 1457.51 1695.88 1455.45 Q1694.22 1453.39 1694.22 1450.43 Q1694.22 1446.28 1697.16 1443.87 Q1700.12 1441.47 1705.26 1441.47 Q1710.42 1441.47 1713.36 1443.87 Q1716.3 1446.28 1716.3 1450.43 Q1716.3 1453.39 1714.61 1455.45 Q1712.94 1457.51 1709.96 1458.25 Q1713.34 1459.04 1715.21 1461.33 Q1717.11 1463.62 1717.11 1466.93 Q1717.11 1471.95 1714.03 1474.64 Q1710.98 1477.32 1705.26 1477.32 Q1699.54 1477.32 1696.46 1474.64 Q1693.41 1471.95 1693.41 1466.93 Q1693.41 1463.62 1695.31 1461.33 Q1697.2 1459.04 1700.58 1458.25 M1698.87 1450.86 Q1698.87 1453.55 1700.54 1455.05 Q1702.23 1456.56 1705.26 1456.56 Q1708.27 1456.56 1709.96 1455.05 Q1711.67 1453.55 1711.67 1450.86 Q1711.67 1448.18 1709.96 1446.68 Q1708.27 1445.17 1705.26 1445.17 Q1702.23 1445.17 1700.54 1446.68 Q1698.87 1448.18 1698.87 1450.86 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2033.98 1472.72 L2041.62 1472.72 L2041.62 1446.35 L2033.31 1448.02 L2033.31 1443.76 L2041.57 1442.09 L2046.25 1442.09 L2046.25 1472.72 L2053.89 1472.72 L2053.89 1476.65 L2033.98 1476.65 L2033.98 1472.72 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2058.96 1470.77 L2063.84 1470.77 L2063.84 1476.65 L2058.96 1476.65 L2058.96 1470.77 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2078.91 1445.17 Q2075.3 1445.17 2073.47 1448.74 Q2071.67 1452.28 2071.67 1459.41 Q2071.67 1466.51 2073.47 1470.08 Q2075.3 1473.62 2078.91 1473.62 Q2082.55 1473.62 2084.35 1470.08 Q2086.18 1466.51 2086.18 1459.41 Q2086.18 1452.28 2084.35 1448.74 Q2082.55 1445.17 2078.91 1445.17 M2078.91 1441.47 Q2084.72 1441.47 2087.78 1446.07 Q2090.86 1450.66 2090.86 1459.41 Q2090.86 1468.13 2087.78 1472.74 Q2084.72 1477.32 2078.91 1477.32 Q2073.1 1477.32 2070.02 1472.74 Q2066.97 1468.13 2066.97 1459.41 Q2066.97 1450.66 2070.02 1446.07 Q2073.1 1441.47 2078.91 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M182.694 1404.03 L190.332 1404.03 L190.332 1377.67 L182.022 1379.33 L182.022 1375.07 L190.286 1373.41 L194.962 1373.41 L194.962 1404.03 L202.601 1404.03 L202.601 1407.97 L182.694 1407.97 L182.694 1404.03 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M217.67 1376.48 Q214.059 1376.48 212.23 1380.05 Q210.425 1383.59 210.425 1390.72 Q210.425 1397.83 212.23 1401.39 Q214.059 1404.93 217.67 1404.93 Q221.304 1404.93 223.11 1401.39 Q224.939 1397.83 224.939 1390.72 Q224.939 1383.59 223.11 1380.05 Q221.304 1376.48 217.67 1376.48 M217.67 1372.78 Q223.48 1372.78 226.536 1377.39 Q229.615 1381.97 229.615 1390.72 Q229.615 1399.45 226.536 1404.05 Q223.48 1408.64 217.67 1408.64 Q211.86 1408.64 208.781 1404.05 Q205.726 1399.45 205.726 1390.72 Q205.726 1381.97 208.781 1377.39 Q211.86 1372.78 217.67 1372.78 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M230.16 1377.36 L236.367 1377.36 L236.367 1355.94 L229.615 1357.29 L229.615 1353.83 L236.329 1352.48 L240.128 1352.48 L240.128 1377.36 L246.335 1377.36 L246.335 1380.56 L230.16 1380.56 L230.16 1377.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M250.454 1375.78 L254.422 1375.78 L254.422 1380.56 L250.454 1380.56 L250.454 1375.78 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M266.666 1354.98 Q263.732 1354.98 262.246 1357.87 Q260.779 1360.75 260.779 1366.54 Q260.779 1372.32 262.246 1375.21 Q263.732 1378.09 266.666 1378.09 Q269.619 1378.09 271.086 1375.21 Q272.572 1372.32 272.572 1366.54 Q272.572 1360.75 271.086 1357.87 Q269.619 1354.98 266.666 1354.98 M266.666 1351.97 Q271.387 1351.97 273.869 1355.71 Q276.371 1359.43 276.371 1366.54 Q276.371 1373.63 273.869 1377.38 Q271.387 1381.1 266.666 1381.1 Q261.945 1381.1 259.444 1377.38 Q256.961 1373.63 256.961 1366.54 Q256.961 1359.43 259.444 1355.71 Q261.945 1351.97 266.666 1351.97 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M288.615 1354.98 Q285.681 1354.98 284.195 1357.87 Q282.728 1360.75 282.728 1366.54 Q282.728 1372.32 284.195 1375.21 Q285.681 1378.09 288.615 1378.09 Q291.567 1378.09 293.034 1375.21 Q294.52 1372.32 294.52 1366.54 Q294.52 1360.75 293.034 1357.87 Q291.567 1354.98 288.615 1354.98 M288.615 1351.97 Q293.335 1351.97 295.818 1355.71 Q298.319 1359.43 298.319 1366.54 Q298.319 1373.63 295.818 1377.38 Q293.335 1381.1 288.615 1381.1 Q283.894 1381.1 281.392 1377.38 Q278.91 1373.63 278.91 1366.54 Q278.91 1359.43 281.392 1355.71 Q283.894 1351.97 288.615 1351.97 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M184.8 1079.52 L192.439 1079.52 L192.439 1053.15 L184.129 1054.82 L184.129 1050.56 L192.393 1048.89 L197.069 1048.89 L197.069 1079.52 L204.707 1079.52 L204.707 1083.45 L184.8 1083.45 L184.8 1079.52 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M219.777 1051.97 Q216.166 1051.97 214.337 1055.54 Q212.531 1059.08 212.531 1066.21 Q212.531 1073.31 214.337 1076.88 Q216.166 1080.42 219.777 1080.42 Q223.411 1080.42 225.217 1076.88 Q227.045 1073.31 227.045 1066.21 Q227.045 1059.08 225.217 1055.54 Q223.411 1051.97 219.777 1051.97 M219.777 1048.27 Q225.587 1048.27 228.642 1052.87 Q231.721 1057.46 231.721 1066.21 Q231.721 1074.93 228.642 1079.54 Q225.587 1084.12 219.777 1084.12 Q213.967 1084.12 210.888 1079.54 Q207.832 1074.93 207.832 1066.21 Q207.832 1057.46 210.888 1052.87 Q213.967 1048.27 219.777 1048.27 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M232.267 1052.84 L238.473 1052.84 L238.473 1031.42 L231.721 1032.78 L231.721 1029.32 L238.435 1027.96 L242.235 1027.96 L242.235 1052.84 L248.441 1052.84 L248.441 1056.04 L232.267 1056.04 L232.267 1052.84 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M252.56 1051.27 L256.529 1051.27 L256.529 1056.04 L252.56 1056.04 L252.56 1051.27 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M263.92 1052.84 L277.179 1052.84 L277.179 1056.04 L259.35 1056.04 L259.35 1052.84 Q261.513 1050.61 265.237 1046.85 Q268.979 1043.06 269.938 1041.97 Q271.763 1039.92 272.478 1038.51 Q273.211 1037.08 273.211 1035.71 Q273.211 1033.47 271.631 1032.06 Q270.07 1030.65 267.55 1030.65 Q265.763 1030.65 263.77 1031.27 Q261.795 1031.89 259.538 1033.15 L259.538 1029.32 Q261.832 1028.39 263.826 1027.92 Q265.82 1027.45 267.475 1027.45 Q271.838 1027.45 274.434 1029.64 Q277.029 1031.82 277.029 1035.47 Q277.029 1037.2 276.371 1038.76 Q275.731 1040.3 274.02 1042.41 Q273.55 1042.95 271.029 1045.57 Q268.509 1048.16 263.92 1052.84 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M281.336 1027.96 L296.251 1027.96 L296.251 1031.16 L284.815 1031.16 L284.815 1038.04 Q285.643 1037.76 286.471 1037.63 Q287.298 1037.48 288.126 1037.48 Q292.828 1037.48 295.573 1040.06 Q298.319 1042.63 298.319 1047.03 Q298.319 1051.57 295.498 1054.09 Q292.677 1056.59 287.543 1056.59 Q285.775 1056.59 283.931 1056.29 Q282.107 1055.99 280.151 1055.38 L280.151 1051.57 Q281.844 1052.49 283.649 1052.94 Q285.455 1053.39 287.467 1053.39 Q290.721 1053.39 292.621 1051.68 Q294.52 1049.97 294.52 1047.03 Q294.52 1044.1 292.621 1042.39 Q290.721 1040.68 287.467 1040.68 Q285.944 1040.68 284.42 1041.01 Q282.916 1041.35 281.336 1042.07 L281.336 1027.96 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M183.502 755.004 L191.141 755.004 L191.141 728.639 L182.831 730.305 L182.831 726.046 L191.095 724.38 L195.771 724.38 L195.771 755.004 L203.41 755.004 L203.41 758.94 L183.502 758.94 L183.502 755.004 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M218.479 727.458 Q214.868 727.458 213.039 731.023 Q211.234 734.565 211.234 741.694 Q211.234 748.801 213.039 752.366 Q214.868 755.907 218.479 755.907 Q222.113 755.907 223.919 752.366 Q225.747 748.801 225.747 741.694 Q225.747 734.565 223.919 731.023 Q222.113 727.458 218.479 727.458 M218.479 723.755 Q224.289 723.755 227.345 728.361 Q230.423 732.944 230.423 741.694 Q230.423 750.421 227.345 755.028 Q224.289 759.611 218.479 759.611 Q212.669 759.611 209.59 755.028 Q206.535 750.421 206.535 741.694 Q206.535 732.944 209.59 728.361 Q212.669 723.755 218.479 723.755 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M230.969 728.332 L237.175 728.332 L237.175 706.91 L230.423 708.264 L230.423 704.803 L237.138 703.449 L240.937 703.449 L240.937 728.332 L247.143 728.332 L247.143 731.529 L230.969 731.529 L230.969 728.332 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M251.262 726.752 L255.231 726.752 L255.231 731.529 L251.262 731.529 L251.262 726.752 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M259.387 703.449 L274.302 703.449 L274.302 706.646 L262.867 706.646 L262.867 713.53 Q263.694 713.248 264.522 713.116 Q265.349 712.966 266.177 712.966 Q270.879 712.966 273.625 715.543 Q276.371 718.119 276.371 722.52 Q276.371 727.053 273.55 729.573 Q270.728 732.075 265.594 732.075 Q263.826 732.075 261.983 731.774 Q260.158 731.473 258.202 730.871 L258.202 727.053 Q259.895 727.975 261.701 728.426 Q263.506 728.877 265.519 728.877 Q268.772 728.877 270.672 727.166 Q272.572 725.454 272.572 722.52 Q272.572 719.586 270.672 717.875 Q268.772 716.163 265.519 716.163 Q263.995 716.163 262.472 716.502 Q260.967 716.84 259.387 717.555 L259.387 703.449 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M288.615 705.951 Q285.681 705.951 284.195 708.847 Q282.728 711.725 282.728 717.517 Q282.728 723.291 284.195 726.188 Q285.681 729.065 288.615 729.065 Q291.567 729.065 293.034 726.188 Q294.52 723.291 294.52 717.517 Q294.52 711.725 293.034 708.847 Q291.567 705.951 288.615 705.951 M288.615 702.941 Q293.335 702.941 295.818 706.684 Q298.319 710.408 298.319 717.517 Q298.319 724.608 295.818 728.351 Q293.335 732.075 288.615 732.075 Q283.894 732.075 281.392 728.351 Q278.91 724.608 278.91 717.517 Q278.91 710.408 281.392 706.684 Q283.894 702.941 288.615 702.941 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M184.236 430.491 L191.875 430.491 L191.875 404.126 L183.565 405.792 L183.565 401.533 L191.828 399.866 L196.504 399.866 L196.504 430.491 L204.143 430.491 L204.143 434.426 L184.236 434.426 L184.236 430.491 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M219.212 402.945 Q215.601 402.945 213.773 406.51 Q211.967 410.052 211.967 417.181 Q211.967 424.288 213.773 427.852 Q215.601 431.394 219.212 431.394 Q222.847 431.394 224.652 427.852 Q226.481 424.288 226.481 417.181 Q226.481 410.052 224.652 406.51 Q222.847 402.945 219.212 402.945 M219.212 399.241 Q225.023 399.241 228.078 403.848 Q231.157 408.431 231.157 417.181 Q231.157 425.908 228.078 430.514 Q225.023 435.098 219.212 435.098 Q213.402 435.098 210.324 430.514 Q207.268 425.908 207.268 417.181 Q207.268 408.431 210.324 403.848 Q213.402 399.241 219.212 399.241 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M231.702 403.819 L237.909 403.819 L237.909 382.397 L231.157 383.751 L231.157 380.29 L237.871 378.936 L241.67 378.936 L241.67 403.819 L247.877 403.819 L247.877 407.016 L231.702 407.016 L231.702 403.819 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M251.996 402.239 L255.964 402.239 L255.964 407.016 L251.996 407.016 L251.996 402.239 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M259.124 378.936 L277.179 378.936 L277.179 380.553 L266.986 407.016 L263.017 407.016 L272.609 382.133 L259.124 382.133 L259.124 378.936 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M281.336 378.936 L296.251 378.936 L296.251 382.133 L284.815 382.133 L284.815 389.017 Q285.643 388.735 286.471 388.603 Q287.298 388.453 288.126 388.453 Q292.828 388.453 295.573 391.029 Q298.319 393.606 298.319 398.007 Q298.319 402.54 295.498 405.06 Q292.677 407.561 287.543 407.561 Q285.775 407.561 283.931 407.261 Q282.107 406.96 280.151 406.358 L280.151 402.54 Q281.844 403.461 283.649 403.913 Q285.455 404.364 287.467 404.364 Q290.721 404.364 292.621 402.653 Q294.52 400.941 294.52 398.007 Q294.52 395.073 292.621 393.362 Q290.721 391.65 287.467 391.65 Q285.944 391.65 284.42 391.989 Q282.916 392.327 281.336 393.042 L281.336 378.936 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M181.584 105.978 L189.223 105.978 L189.223 79.6125 L180.913 81.2792 L180.913 77.0199 L189.176 75.3533 L193.852 75.3533 L193.852 105.978 L201.491 105.978 L201.491 109.913 L181.584 109.913 L181.584 105.978 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M216.561 78.432 Q212.95 78.432 211.121 81.9968 Q209.315 85.5384 209.315 92.668 Q209.315 99.7744 211.121 103.339 Q212.95 106.881 216.561 106.881 Q220.195 106.881 222 103.339 Q223.829 99.7744 223.829 92.668 Q223.829 85.5384 222 81.9968 Q220.195 78.432 216.561 78.432 M216.561 74.7283 Q222.371 74.7283 225.426 79.3347 Q228.505 83.918 228.505 92.668 Q228.505 101.395 225.426 106.001 Q222.371 110.585 216.561 110.585 Q210.75 110.585 207.672 106.001 Q204.616 101.395 204.616 92.668 Q204.616 83.918 207.672 79.3347 Q210.75 74.7283 216.561 74.7283 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M233.075 79.3056 L246.335 79.3056 L246.335 82.5029 L228.505 82.5029 L228.505 79.3056 Q230.668 77.0674 234.392 73.3059 Q238.135 69.5255 239.094 68.4347 Q240.918 66.3846 241.633 64.974 Q242.366 63.5446 242.366 62.1717 Q242.366 59.9335 240.786 58.523 Q239.225 57.1124 236.705 57.1124 Q234.918 57.1124 232.925 57.733 Q230.95 58.3537 228.693 59.6138 L228.693 55.777 Q230.988 54.8555 232.981 54.3853 Q234.975 53.9151 236.63 53.9151 Q240.993 53.9151 243.589 56.0968 Q246.184 58.2785 246.184 61.9272 Q246.184 63.6575 245.526 65.2185 Q244.887 66.7608 243.175 68.8672 Q242.705 69.4127 240.185 72.0269 Q237.664 74.6224 233.075 79.3056 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M250.454 77.7257 L254.422 77.7257 L254.422 82.5029 L250.454 82.5029 L250.454 77.7257 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M266.666 56.9243 Q263.732 56.9243 262.246 59.8207 Q260.779 62.6983 260.779 68.4911 Q260.779 74.2651 262.246 77.1615 Q263.732 80.0391 266.666 80.0391 Q269.619 80.0391 271.086 77.1615 Q272.572 74.2651 272.572 68.4911 Q272.572 62.6983 271.086 59.8207 Q269.619 56.9243 266.666 56.9243 M266.666 53.9151 Q271.387 53.9151 273.869 57.6578 Q276.371 61.3817 276.371 68.4911 Q276.371 75.5816 273.869 79.3244 Q271.387 83.0483 266.666 83.0483 Q261.945 83.0483 259.444 79.3244 Q256.961 75.5816 256.961 68.4911 Q256.961 61.3817 259.444 57.6578 Q261.945 53.9151 266.666 53.9151 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M288.615 56.9243 Q285.681 56.9243 284.195 59.8207 Q282.728 62.6983 282.728 68.4911 Q282.728 74.2651 284.195 77.1615 Q285.681 80.0391 288.615 80.0391 Q291.567 80.0391 293.034 77.1615 Q294.52 74.2651 294.52 68.4911 Q294.52 62.6983 293.034 59.8207 Q291.567 56.9243 288.615 56.9243 M288.615 53.9151 Q293.335 53.9151 295.818 57.6578 Q298.319 61.3817 298.319 68.4911 Q298.319 75.5816 295.818 79.3244 Q293.335 83.0483 288.615 83.0483 Q283.894 83.0483 281.392 79.3244 Q278.91 75.5816 278.91 68.4911 Q278.91 61.3817 281.392 57.6578 Q283.894 53.9151 288.615 53.9151 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M1029.61 1506.52 L1035.46 1506.52 L1035.46 1556.04 L1029.61 1556.04 L1029.61 1506.52 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M1072.1 1536.76 L1072.1 1539.62 L1045.17 1539.62 Q1045.55 1545.67 1048.8 1548.85 Q1052.08 1552 1057.9 1552 Q1061.28 1552 1064.43 1551.17 Q1067.61 1550.35 1070.73 1548.69 L1070.73 1554.23 Q1067.58 1555.57 1064.27 1556.27 Q1060.96 1556.97 1057.55 1556.97 Q1049.02 1556.97 1044.02 1552 Q1039.06 1547.04 1039.06 1538.57 Q1039.06 1529.82 1043.77 1524.69 Q1048.51 1519.54 1056.53 1519.54 Q1063.73 1519.54 1067.9 1524.18 Q1072.1 1528.8 1072.1 1536.76 M1066.24 1535.04 Q1066.18 1530.23 1063.54 1527.37 Q1060.93 1524.5 1056.6 1524.5 Q1051.7 1524.5 1048.74 1527.27 Q1045.81 1530.04 1045.36 1535.07 L1066.24 1535.04 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M1094.44 1538.12 Q1087.34 1538.12 1084.61 1539.75 Q1081.87 1541.37 1081.87 1545.29 Q1081.87 1548.4 1083.91 1550.25 Q1085.97 1552.07 1089.51 1552.07 Q1094.38 1552.07 1097.31 1548.63 Q1100.27 1545.16 1100.27 1539.43 L1100.27 1538.12 L1094.44 1538.12 M1106.12 1535.71 L1106.12 1556.04 L1100.27 1556.04 L1100.27 1550.63 Q1098.26 1553.88 1095.27 1555.44 Q1092.28 1556.97 1087.95 1556.97 Q1082.47 1556.97 1079.23 1553.91 Q1076.01 1550.82 1076.01 1545.67 Q1076.01 1539.65 1080.02 1536.6 Q1084.06 1533.54 1092.05 1533.54 L1100.27 1533.54 L1100.27 1532.97 Q1100.27 1528.93 1097.59 1526.73 Q1094.95 1524.5 1090.14 1524.5 Q1087.09 1524.5 1084.19 1525.23 Q1081.3 1525.97 1078.62 1527.43 L1078.62 1522.02 Q1081.84 1520.78 1084.86 1520.17 Q1087.88 1519.54 1090.75 1519.54 Q1098.48 1519.54 1102.3 1523.55 Q1106.12 1527.56 1106.12 1535.71 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M1132.92 1525.87 Q1131.93 1525.3 1130.76 1525.04 Q1129.61 1524.76 1128.21 1524.76 Q1123.25 1524.76 1120.57 1528 Q1117.93 1531.22 1117.93 1537.27 L1117.93 1556.04 L1112.04 1556.04 L1112.04 1520.4 L1117.93 1520.4 L1117.93 1525.93 Q1119.78 1522.69 1122.74 1521.13 Q1125.7 1519.54 1129.93 1519.54 Q1130.53 1519.54 1131.27 1519.63 Q1132 1519.7 1132.89 1519.85 L1132.92 1525.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M1167.55 1534.53 L1167.55 1556.04 L1161.69 1556.04 L1161.69 1534.72 Q1161.69 1529.66 1159.72 1527.14 Q1157.75 1524.63 1153.8 1524.63 Q1149.06 1524.63 1146.32 1527.65 Q1143.58 1530.68 1143.58 1535.9 L1143.58 1556.04 L1137.7 1556.04 L1137.7 1520.4 L1143.58 1520.4 L1143.58 1525.93 Q1145.68 1522.72 1148.52 1521.13 Q1151.38 1519.54 1155.11 1519.54 Q1161.25 1519.54 1164.4 1523.36 Q1167.55 1527.14 1167.55 1534.53 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M1173.69 1520.4 L1179.55 1520.4 L1179.55 1556.04 L1173.69 1556.04 L1173.69 1520.4 M1173.69 1506.52 L1179.55 1506.52 L1179.55 1513.93 L1173.69 1513.93 L1173.69 1506.52 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M1215.33 1534.53 L1215.33 1556.04 L1209.47 1556.04 L1209.47 1534.72 Q1209.47 1529.66 1207.5 1527.14 Q1205.52 1524.63 1201.58 1524.63 Q1196.83 1524.63 1194.1 1527.65 Q1191.36 1530.68 1191.36 1535.9 L1191.36 1556.04 L1185.47 1556.04 L1185.47 1520.4 L1191.36 1520.4 L1191.36 1525.93 Q1193.46 1522.72 1196.29 1521.13 Q1199.16 1519.54 1202.88 1519.54 Q1209.02 1519.54 1212.17 1523.36 Q1215.33 1527.14 1215.33 1534.53 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M1244.93 1537.81 Q1244.93 1531.44 1242.28 1527.94 Q1239.67 1524.44 1234.93 1524.44 Q1230.22 1524.44 1227.58 1527.94 Q1224.97 1531.44 1224.97 1537.81 Q1224.97 1544.14 1227.58 1547.64 Q1230.22 1551.14 1234.93 1551.14 Q1239.67 1551.14 1242.28 1547.64 Q1244.93 1544.14 1244.93 1537.81 M1250.78 1551.62 Q1250.78 1560.72 1246.74 1565.15 Q1242.7 1569.6 1234.36 1569.6 Q1231.27 1569.6 1228.53 1569.13 Q1225.8 1568.68 1223.22 1567.72 L1223.22 1562.03 Q1225.8 1563.43 1228.31 1564.1 Q1230.83 1564.76 1233.44 1564.76 Q1239.2 1564.76 1242.06 1561.74 Q1244.93 1558.75 1244.93 1552.67 L1244.93 1549.77 Q1243.11 1552.92 1240.28 1554.48 Q1237.45 1556.04 1233.5 1556.04 Q1226.94 1556.04 1222.93 1551.05 Q1218.92 1546.05 1218.92 1537.81 Q1218.92 1529.53 1222.93 1524.53 Q1226.94 1519.54 1233.5 1519.54 Q1237.45 1519.54 1240.28 1521.1 Q1243.11 1522.66 1244.93 1525.81 L1244.93 1520.4 L1250.78 1520.4 L1250.78 1551.62 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M1284.01 1566.87 L1284.01 1571.42 L1250.15 1571.42 L1250.15 1566.87 L1284.01 1566.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M1310.81 1525.87 Q1309.82 1525.3 1308.65 1525.04 Q1307.5 1524.76 1306.1 1524.76 Q1301.14 1524.76 1298.46 1528 Q1295.82 1531.22 1295.82 1537.27 L1295.82 1556.04 L1289.93 1556.04 L1289.93 1520.4 L1295.82 1520.4 L1295.82 1525.93 Q1297.67 1522.69 1300.63 1521.13 Q1303.59 1519.54 1307.82 1519.54 Q1308.42 1519.54 1309.16 1519.63 Q1309.89 1519.7 1310.78 1519.85 L1310.81 1525.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M1333.15 1538.12 Q1326.06 1538.12 1323.32 1539.75 Q1320.58 1541.37 1320.58 1545.29 Q1320.58 1548.4 1322.62 1550.25 Q1324.69 1552.07 1328.22 1552.07 Q1333.09 1552.07 1336.02 1548.63 Q1338.98 1545.16 1338.98 1539.43 L1338.98 1538.12 L1333.15 1538.12 M1344.84 1535.71 L1344.84 1556.04 L1338.98 1556.04 L1338.98 1550.63 Q1336.97 1553.88 1333.98 1555.44 Q1330.99 1556.97 1326.66 1556.97 Q1321.19 1556.97 1317.94 1553.91 Q1314.73 1550.82 1314.73 1545.67 Q1314.73 1539.65 1318.74 1536.6 Q1322.78 1533.54 1330.77 1533.54 L1338.98 1533.54 L1338.98 1532.97 Q1338.98 1528.93 1336.31 1526.73 Q1333.66 1524.5 1328.86 1524.5 Q1325.8 1524.5 1322.91 1525.23 Q1320.01 1525.97 1317.34 1527.43 L1317.34 1522.02 Q1320.55 1520.78 1323.57 1520.17 Q1326.6 1519.54 1329.46 1519.54 Q1337.2 1519.54 1341.02 1523.55 Q1344.84 1527.56 1344.84 1535.71 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M1356.77 1510.27 L1356.77 1520.4 L1368.83 1520.4 L1368.83 1524.95 L1356.77 1524.95 L1356.77 1544.3 Q1356.77 1548.66 1357.95 1549.9 Q1359.16 1551.14 1362.82 1551.14 L1368.83 1551.14 L1368.83 1556.04 L1362.82 1556.04 Q1356.04 1556.04 1353.46 1553.53 Q1350.88 1550.98 1350.88 1544.3 L1350.88 1524.95 L1346.59 1524.95 L1346.59 1520.4 L1350.88 1520.4 L1350.88 1510.27 L1356.77 1510.27 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M1405.47 1536.76 L1405.47 1539.62 L1378.54 1539.62 Q1378.92 1545.67 1382.17 1548.85 Q1385.45 1552 1391.27 1552 Q1394.65 1552 1397.8 1551.17 Q1400.98 1550.35 1404.1 1548.69 L1404.1 1554.23 Q1400.95 1555.57 1397.64 1556.27 Q1394.33 1556.97 1390.92 1556.97 Q1382.39 1556.97 1377.4 1552 Q1372.43 1547.04 1372.43 1538.57 Q1372.43 1529.82 1377.14 1524.69 Q1381.88 1519.54 1389.91 1519.54 Q1397.1 1519.54 1401.27 1524.18 Q1405.47 1528.8 1405.47 1536.76 M1399.61 1535.04 Q1399.55 1530.23 1396.91 1527.37 Q1394.3 1524.5 1389.97 1524.5 Q1385.07 1524.5 1382.11 1527.27 Q1379.18 1530.04 1378.73 1535.07 L1399.61 1535.04 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M66.4881 893.543 L88.0042 893.543 L88.0042 899.399 L66.679 899.399 Q61.6183 899.399 59.1038 901.373 Q56.5894 903.346 56.5894 907.293 Q56.5894 912.035 59.6131 914.773 Q62.6368 917.51 67.8567 917.51 L88.0042 917.51 L88.0042 923.398 L52.3562 923.398 L52.3562 917.51 L57.8944 917.51 Q54.6797 915.409 53.0883 912.576 Q51.4968 909.712 51.4968 905.988 Q51.4968 899.845 55.3163 896.694 Q59.1038 893.543 66.4881 893.543 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M98.8259 860.314 L103.377 860.314 L103.377 894.18 L98.8259 894.18 L98.8259 860.314 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M68.7161 823.679 L71.5806 823.679 L71.5806 850.606 Q77.6281 850.224 80.8109 846.978 Q83.9619 843.7 83.9619 837.875 Q83.9619 834.501 83.1344 831.35 Q82.3069 828.167 80.6518 825.048 L86.1899 825.048 Q87.5267 828.199 88.227 831.509 Q88.9272 834.819 88.9272 838.225 Q88.9272 846.755 83.9619 851.752 Q78.9967 856.717 70.5303 856.717 Q61.7774 856.717 56.6531 852.007 Q51.4968 847.264 51.4968 839.244 Q51.4968 832.05 56.1438 827.881 Q60.7589 823.679 68.7161 823.679 M66.9973 829.536 Q62.1912 829.599 59.3266 832.241 Q56.4621 834.851 56.4621 839.18 Q56.4621 844.081 59.2312 847.042 Q62.0002 849.97 67.0292 850.415 L66.9973 829.536 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M53.4065 794.811 L58.9447 794.811 Q57.6716 797.294 57.035 799.967 Q56.3984 802.641 56.3984 805.505 Q56.3984 809.866 57.7352 812.062 Q59.072 814.226 61.7456 814.226 Q63.7826 814.226 64.9603 812.667 Q66.1061 811.107 67.1565 806.396 L67.6021 804.391 Q68.9389 798.153 71.3897 795.543 Q73.8086 792.901 78.1691 792.901 Q83.1344 792.901 86.0308 796.848 Q88.9272 800.763 88.9272 807.638 Q88.9272 810.502 88.3543 813.622 Q87.8132 816.709 86.6992 820.146 L80.6518 820.146 Q82.3387 816.9 83.198 813.749 Q84.0256 810.598 84.0256 807.51 Q84.0256 803.373 82.6251 801.145 Q81.1929 798.917 78.6147 798.917 Q76.2276 798.917 74.9545 800.54 Q73.6813 802.131 72.5037 807.574 L72.0262 809.611 Q70.8804 815.054 68.5251 817.473 Q66.138 819.892 62.0002 819.892 Q56.9713 819.892 54.2341 816.327 Q51.4968 812.762 51.4968 806.206 Q51.4968 802.959 51.9743 800.094 Q52.4517 797.23 53.4065 794.811 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M42.2347 780.965 L52.3562 780.965 L52.3562 768.902 L56.9077 768.902 L56.9077 780.965 L76.2594 780.965 Q80.6199 780.965 81.8613 779.788 Q83.1026 778.578 83.1026 774.918 L83.1026 768.902 L88.0042 768.902 L88.0042 774.918 Q88.0042 781.698 85.4897 784.276 Q82.9434 786.854 76.2594 786.854 L56.9077 786.854 L56.9077 791.151 L52.3562 791.151 L52.3562 786.854 L42.2347 786.854 L42.2347 780.965 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M52.3562 762.76 L52.3562 756.903 L88.0042 756.903 L88.0042 762.76 L52.3562 762.76 M38.479 762.76 L38.479 756.903 L45.895 756.903 L45.895 762.76 L38.479 762.76 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M59.1993 723.006 Q55.2526 720.81 53.3747 717.754 Q51.4968 714.698 51.4968 710.561 Q51.4968 704.991 55.4117 701.967 Q59.2948 698.943 66.4881 698.943 L88.0042 698.943 L88.0042 704.832 L66.679 704.832 Q61.5546 704.832 59.072 706.646 Q56.5894 708.46 56.5894 712.184 Q56.5894 716.736 59.6131 719.377 Q62.6368 722.019 67.8567 722.019 L88.0042 722.019 L88.0042 727.907 L66.679 727.907 Q61.5228 727.907 59.072 729.722 Q56.5894 731.536 56.5894 735.323 Q56.5894 739.811 59.6449 742.453 Q62.6686 745.095 67.8567 745.095 L88.0042 745.095 L88.0042 750.983 L52.3562 750.983 L52.3562 745.095 L57.8944 745.095 Q54.616 743.09 53.0564 740.289 Q51.4968 737.488 51.4968 733.636 Q51.4968 729.753 53.4702 727.048 Q55.4436 724.311 59.1993 723.006 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M70.0847 676.6 Q70.0847 683.697 71.7079 686.435 Q73.3312 689.172 77.2461 689.172 Q80.3653 689.172 82.2114 687.135 Q84.0256 685.066 84.0256 681.533 Q84.0256 676.663 80.5881 673.735 Q77.1188 670.775 71.3897 670.775 L70.0847 670.775 L70.0847 676.6 M67.6657 664.919 L88.0042 664.919 L88.0042 670.775 L82.5933 670.775 Q85.8398 672.78 87.3994 675.772 Q88.9272 678.764 88.9272 683.093 Q88.9272 688.567 85.8716 691.814 Q82.7843 695.028 77.6281 695.028 Q71.6125 695.028 68.5569 691.018 Q65.5014 686.976 65.5014 678.987 L65.5014 670.775 L64.9285 670.775 Q60.8862 670.775 58.6901 673.449 Q56.4621 676.09 56.4621 680.897 Q56.4621 683.952 57.1941 686.849 Q57.9262 689.745 59.3903 692.419 L53.9795 692.419 Q52.7381 689.204 52.1334 686.18 Q51.4968 683.156 51.4968 680.292 Q51.4968 672.558 55.5072 668.738 Q59.5176 664.919 67.6657 664.919 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M42.2347 652.983 L52.3562 652.983 L52.3562 640.92 L56.9077 640.92 L56.9077 652.983 L76.2594 652.983 Q80.6199 652.983 81.8613 651.805 Q83.1026 650.596 83.1026 646.936 L83.1026 640.92 L88.0042 640.92 L88.0042 646.936 Q88.0042 653.715 85.4897 656.293 Q82.9434 658.871 76.2594 658.871 L56.9077 658.871 L56.9077 663.168 L52.3562 663.168 L52.3562 658.871 L42.2347 658.871 L42.2347 652.983 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M56.4621 620.963 Q56.4621 625.674 60.1542 628.411 Q63.8145 631.149 70.212 631.149 Q76.6095 631.149 80.3017 628.443 Q83.9619 625.706 83.9619 620.963 Q83.9619 616.285 80.2698 613.547 Q76.5777 610.81 70.212 610.81 Q63.8781 610.81 60.186 613.547 Q56.4621 616.285 56.4621 620.963 M51.4968 620.963 Q51.4968 613.325 56.4621 608.964 Q61.4273 604.604 70.212 604.604 Q78.9649 604.604 83.9619 608.964 Q88.9272 613.325 88.9272 620.963 Q88.9272 628.634 83.9619 632.995 Q78.9649 637.323 70.212 637.323 Q61.4273 637.323 56.4621 632.995 Q51.4968 628.634 51.4968 620.963 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M57.8307 577.804 Q57.2578 578.791 57.0032 579.968 Q56.7167 581.114 56.7167 582.515 Q56.7167 587.48 59.9632 590.153 Q63.1779 592.795 69.2253 592.795 L88.0042 592.795 L88.0042 598.683 L52.3562 598.683 L52.3562 592.795 L57.8944 592.795 Q54.6479 590.949 53.0883 587.989 Q51.4968 585.029 51.4968 580.796 Q51.4968 580.191 51.5923 579.459 Q51.656 578.727 51.8151 577.836 L57.8307 577.804 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M53.4065 548.935 L58.9447 548.935 Q57.6716 551.418 57.035 554.092 Q56.3984 556.765 56.3984 559.63 Q56.3984 563.99 57.7352 566.187 Q59.072 568.351 61.7456 568.351 Q63.7826 568.351 64.9603 566.791 Q66.1061 565.232 67.1565 560.521 L67.6021 558.516 Q68.9389 552.277 71.3897 549.668 Q73.8086 547.026 78.1691 547.026 Q83.1344 547.026 86.0308 550.973 Q88.9272 554.887 88.9272 561.762 Q88.9272 564.627 88.3543 567.746 Q87.8132 570.834 86.6992 574.271 L80.6518 574.271 Q82.3387 571.024 83.198 567.873 Q84.0256 564.722 84.0256 561.635 Q84.0256 557.497 82.6251 555.269 Q81.1929 553.041 78.6147 553.041 Q76.2276 553.041 74.9545 554.665 Q73.6813 556.256 72.5037 561.699 L72.0262 563.736 Q70.8804 569.178 68.5251 571.597 Q66.138 574.016 62.0002 574.016 Q56.9713 574.016 54.2341 570.452 Q51.4968 566.887 51.4968 560.33 Q51.4968 557.084 51.9743 554.219 Q52.4517 551.354 53.4065 548.935 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><circle clip-path=\"url(#clip952)\" cx=\"1874.41\" cy=\"86.1857\" r=\"61\" fill=\"#fbfea3\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"560.669\" cy=\"523.944\" r=\"27\" fill=\"#86216a\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1499.05\" cy=\"523.944\" r=\"44\" fill=\"#ed6924\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"748.346\" cy=\"374.157\" r=\"42\" fill=\"#e65d2e\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"2062.08\" cy=\"523.944\" r=\"42\" fill=\"#e55c2e\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1311.38\" cy=\"1236.33\" r=\"16\" fill=\"#3c0965\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1311.38\" cy=\"939.756\" r=\"23\" fill=\"#6c176e\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"748.346\" cy=\"1384.24\" r=\"11\" fill=\"#1f0c47\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1874.41\" cy=\"1384.24\" r=\"13\" fill=\"#290b54\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"560.669\" cy=\"662.128\" r=\"17\" fill=\"#470a69\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"560.669\" cy=\"374.157\" r=\"38\" fill=\"#d44841\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"372.992\" cy=\"86.1857\" r=\"42\" fill=\"#e65d2e\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1686.73\" cy=\"233.527\" r=\"55\" fill=\"#f8ca33\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1311.38\" cy=\"803.804\" r=\"27\" fill=\"#892269\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"560.669\" cy=\"939.756\" r=\"7\" fill=\"#090621\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"372.992\" cy=\"233.527\" r=\"33\" fill=\"#b53357\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1874.41\" cy=\"662.128\" r=\"36\" fill=\"#c53d4d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1686.73\" cy=\"939.756\" r=\"18\" fill=\"#4c0c6b\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"2062.08\" cy=\"939.756\" r=\"17\" fill=\"#480b6a\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"936.022\" cy=\"662.128\" r=\"30\" fill=\"#a02a62\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1499.05\" cy=\"1236.33\" r=\"23\" fill=\"#70196e\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"2062.08\" cy=\"1085.1\" r=\"14\" fill=\"#2f0a5a\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"372.992\" cy=\"523.944\" r=\"14\" fill=\"#34095f\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"936.022\" cy=\"1236.33\" r=\"15\" fill=\"#3a0963\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1686.73\" cy=\"86.1857\" r=\"56\" fill=\"#f5da4a\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1123.7\" cy=\"803.804\" r=\"25\" fill=\"#791c6d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1874.41\" cy=\"374.157\" r=\"52\" fill=\"#fbae12\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"560.669\" cy=\"233.527\" r=\"47\" fill=\"#f78310\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"748.346\" cy=\"662.128\" r=\"29\" fill=\"#952666\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1499.05\" cy=\"803.804\" r=\"32\" fill=\"#a82d5e\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"372.992\" cy=\"662.128\" r=\"8\" fill=\"#0f092c\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"748.346\" cy=\"86.1857\" r=\"58\" fill=\"#f1ec6f\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1499.05\" cy=\"86.1857\" r=\"60\" fill=\"#f6f994\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1499.05\" cy=\"233.527\" r=\"54\" fill=\"#f8ca33\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1311.38\" cy=\"1384.24\" r=\"20\" fill=\"#5b116e\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"936.022\" cy=\"1384.24\" r=\"21\" fill=\"#5f136e\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1686.73\" cy=\"1384.24\" r=\"11\" fill=\"#1c0c43\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"936.022\" cy=\"939.756\" r=\"13\" fill=\"#2c0a57\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1874.41\" cy=\"1085.1\" r=\"13\" fill=\"#270b52\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1311.38\" cy=\"374.157\" r=\"51\" fill=\"#fbab10\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1311.38\" cy=\"86.1857\" r=\"61\" fill=\"#fcfea4\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"2062.08\" cy=\"86.1857\" r=\"54\" fill=\"#f9c52c\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1123.7\" cy=\"1384.24\" r=\"14\" fill=\"#33095e\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"372.992\" cy=\"1085.1\" r=\"11\" fill=\"#1b0c41\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"560.669\" cy=\"1236.33\" r=\"12\" fill=\"#210c4a\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"936.022\" cy=\"233.527\" r=\"51\" fill=\"#fbaa0f\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"2062.08\" cy=\"803.804\" r=\"27\" fill=\"#8a2269\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1686.73\" cy=\"662.128\" r=\"33\" fill=\"#af315b\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1123.7\" cy=\"523.944\" r=\"41\" fill=\"#e05535\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"748.346\" cy=\"1085.1\" r=\"7\" fill=\"#090621\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1686.73\" cy=\"374.157\" r=\"47\" fill=\"#f8870d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1123.7\" cy=\"233.527\" r=\"53\" fill=\"#fbb71b\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1311.38\" cy=\"523.944\" r=\"43\" fill=\"#eb6527\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1311.38\" cy=\"233.527\" r=\"56\" fill=\"#f5da4b\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1499.05\" cy=\"1384.24\" r=\"24\" fill=\"#761b6d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1311.38\" cy=\"662.128\" r=\"36\" fill=\"#c43c4e\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1686.73\" cy=\"1236.33\" r=\"15\" fill=\"#350960\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"936.022\" cy=\"523.944\" r=\"35\" fill=\"#c23b4f\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1123.7\" cy=\"86.1857\" r=\"59\" fill=\"#f3f78c\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"936.022\" cy=\"1085.1\" r=\"13\" fill=\"#2c0a58\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"372.992\" cy=\"374.157\" r=\"23\" fill=\"#71196d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1686.73\" cy=\"803.804\" r=\"23\" fill=\"#6e186e\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"2062.08\" cy=\"662.128\" r=\"33\" fill=\"#b53358\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1311.38\" cy=\"1085.1\" r=\"19\" fill=\"#510d6c\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1123.7\" cy=\"939.756\" r=\"16\" fill=\"#420968\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1874.41\" cy=\"233.527\" r=\"56\" fill=\"#f4dc4d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1874.41\" cy=\"803.804\" r=\"27\" fill=\"#8a2269\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"936.022\" cy=\"803.804\" r=\"20\" fill=\"#5d126e\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1686.73\" cy=\"523.944\" r=\"39\" fill=\"#d64a3f\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"372.992\" cy=\"1384.24\" r=\"7\" fill=\"#07051e\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1123.7\" cy=\"1236.33\" r=\"10\" fill=\"#150b38\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"748.346\" cy=\"803.804\" r=\"20\" fill=\"#58106d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1123.7\" cy=\"374.157\" r=\"46\" fill=\"#f47a16\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"936.022\" cy=\"374.157\" r=\"44\" fill=\"#ee6c22\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"560.669\" cy=\"1384.24\" r=\"15\" fill=\"#360961\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"372.992\" cy=\"939.756\" r=\"8\" fill=\"#0c0726\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"2062.08\" cy=\"1384.24\" r=\"11\" fill=\"#1c0c43\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1686.73\" cy=\"1085.1\" r=\"15\" fill=\"#360960\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1123.7\" cy=\"662.128\" r=\"33\" fill=\"#b13259\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1123.7\" cy=\"1085.1\" r=\"12\" fill=\"#210b4b\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"372.992\" cy=\"1236.33\" r=\"7\" fill=\"#0a0622\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1874.41\" cy=\"939.756\" r=\"21\" fill=\"#5d126e\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"560.669\" cy=\"1085.1\" r=\"6\" fill=\"#06041a\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"2062.08\" cy=\"374.157\" r=\"50\" fill=\"#fb9a06\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"2062.08\" cy=\"233.527\" r=\"52\" fill=\"#fbb014\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1499.05\" cy=\"662.128\" r=\"39\" fill=\"#d84c3d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"748.346\" cy=\"1236.33\" r=\"6\" fill=\"#06041b\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"560.669\" cy=\"803.804\" r=\"7\" fill=\"#090621\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"936.022\" cy=\"86.1857\" r=\"58\" fill=\"#f1ee74\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"560.669\" cy=\"86.1857\" r=\"55\" fill=\"#f7ce38\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"748.346\" cy=\"523.944\" r=\"35\" fill=\"#bd3852\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1499.05\" cy=\"374.157\" r=\"48\" fill=\"#f99007\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1874.41\" cy=\"1236.33\" r=\"11\" fill=\"#1e0c46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"372.992\" cy=\"803.804\" r=\"3\" fill=\"#000003\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"748.346\" cy=\"939.756\" r=\"12\" fill=\"#270b52\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1499.05\" cy=\"939.756\" r=\"24\" fill=\"#72196d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1874.41\" cy=\"523.944\" r=\"44\" fill=\"#ed6924\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"2062.08\" cy=\"1236.33\" r=\"9\" fill=\"#120a32\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"1499.05\" cy=\"1085.1\" r=\"18\" fill=\"#4c0c6b\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip952)\" cx=\"748.346\" cy=\"233.527\" r=\"50\" fill=\"#fba309\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip953\">\n",
       "    <rect x=\"2160\" y=\"47\" width=\"73\" height=\"1377\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<g clip-path=\"url(#clip953)\">\n",
       "<image width=\"72\" height=\"1376\" xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAAEgAAAVgCAYAAADsKhu7AAAL6UlEQVR4nO3dwZEjNxBFQVBR/lsh\n",
       "L6UFZIHqHclDpgUTL35wCXTP7Off+/c7/K+/vv0D/DqBgkBBoCBQmPv+/fbP8NMsKAgUBAoChXnv\n",
       "z7d/hp9mQUGgIFAQKAgUHDWCBQWBgkBBoDDPh/TKgoJAQaAgUJh3fUhvLCgIFAQKAgWBgqNGsKAg\n",
       "UBAoCBR8SAcLCgIFgYJAwX1QsKAgUBAoCBQECnMcNVYWFAQKAgWBgvugYEFBoCBQECgIFOa4MFtZ\n",
       "UBAoCBQECnPuP9/+GX6aBQWBgkBBoODSPlhQECgIFAQKAgX3QcGCgkBBoCBQ8CEdLCgIFAQKAgX3\n",
       "QcGCgkBBoCBQECjMx1FjZUFBoCBQECjMuf5XhI0FBYGCQEGgIFBw1AgWFAQKAgWBgqNGsKAgUBAo\n",
       "CBS8HxQsKAgUBAoCBYHCfBw1VhYUBAoCBYGCt1yDBQWBgkBBoOCbdLCgIFAQKAgUBAoePQcLCgIF\n",
       "gYJAwVEjWFAQKAgUBAoCBUeNYEFBoCBQECg4agQLCgIFgYJAYc693/4ZfpoFBYGCQEGgIFBw1AgW\n",
       "FAQKAgWBgkv7YEFBoCBQECj4kA4WFAQKAgWBgkBhPp5qrCwoCBQECgIFR41gQUGgIFAQKAgUvEAV\n",
       "LCgIFAQKAgX3QcGCgkBBoCBQcB8ULCgIFAQKAgWBgvugYEFBoCBQECj4kA4WFAQKAgWBgl/qDRYU\n",
       "BAoCBYGCQMFRI1hQECgIFAQKPqSDBQWBgkBBoCBQ8K9YsKAgUBAoCBR8SAcLCgIFgYJAYc7zIb2x\n",
       "oCBQECgIFAQKjhrBgoJAQaAgUPAhHSwoCBQECgIFH9LBgoJAQaAgUBAozLnv2z/DT7OgIFAQKAgU\n",
       "HDWCBQWBgkBBoCBQcNQIFhQECgIFgYKjRrCgIFAQKAgUfJMOFhQECgIFgYJAYY6TxsqCgkBBoCBQ\n",
       "mPMcNTYWFAQKAgWBgm/SwYKCQEGgIFAQKPhXLFhQECgIFAQK44/g7SwoCBQECgIFgYKjRrCgIFAQ\n",
       "KAgUfEgHCwoCBYGCQGHO/Xz7Z/hpFhQECgIFgYJAYd7zr9jGgoJAQaAgUHAfFCwoCBQECgIF90HB\n",
       "goJAQaAgUBAozLsabdQJAgWBgkDBUSNYUBAoCBQECgKFOR49rywoCBQECgKFeY4aKwsKAgWBgkBh\n",
       "jkv7lTpBoCBQECgIFBw1ggUFgYJAQaDg0j5YUBAoCBQECl7iDOoEgYJAQaAgUPCWa7CgIFAQKAgU\n",
       "XNoHCwoCBYGCQEGgMO9ptFEnCBQECgIF90HBgoJAQaAgUHAfFCwoCBQECgIFgcIc90ErdYJAQaAg\n",
       "UHDUCBYUBAoCBYGCD+lgQUGgIFAQKAgU/NZzsKAgUBAoCBT81nNQJwgUBAoCBYHCPEeNlQUFgYJA\n",
       "QaDgqUawoCBQECgIFPyvCEGdIFAQKAgUBArug4IFBYGCQEGg4D4oWFAQKAgUBAq+SQcLCgIFgYJA\n",
       "QaDgLdegThAoCBQECo4awYKCQEGgIFAQKHiqESwoCBQECgIFR41gQUGgIFAQKPiva4IFBYGCQEGg\n",
       "IFDwv2QGdYJAQaAgUHAfFCwoCBQECgIFT1aDBQWBgkBBoCBQcNQIFhQECgIFgcJcH9IrCwoCBYGC\n",
       "QEGg4LeegzpBoCBQECi4DwoWFAQKAgWBgg/pYEFBoCBQECgIFLxAFSwoCBQECgIFR41gQUGgIFAQ\n",
       "KPiQDhYUBAoCBYGCQMGfpgjqBIGCQEGgMNel/cqCgkBBoCBQECi4MAsWFAQKAgWBgg/pYEFBoCBQ\n",
       "ECj4kA4WFAQKAgWBgkDBH1gKFhQECgIFgYKjRrCgIFAQKAgUfEgHCwoCBYGCQEGg4FcRgjpBoCBQ\n",
       "ECj4VYRgQUGgIFAQKAgUXJgFCwoCBYGCQMGHdLCgIFAQKAgUvMQZLCgIFAQKAgWBgqNGsKAgUBAo\n",
       "CBTmHR/SGwsKAgWBgkDBfVCwoCBQECgIFAQK7oOCBQWBgkBBoOCoESwoCBQECgIFgYKjRrCgIFAQ\n",
       "KAgUHDWCBQWBgkBBoOCbdLCgIFAQKAgUBAr+FQsWFAQKAgWBwly/irCyoCBQECgIFHyTDhYUBAoC\n",
       "BYGCQMGj52BBQaAgUBAozHvf/hF+mwUFgYJAQaAgUHDUCBYUBAoCBYGCv4IXLCgIFAQKAgXfpIMF\n",
       "BYGCQEGgIFDwAlWwoCBQECgIFPwqQrCgIFAQKAgUvB8ULCgIFAQKAgWBgqcawYKCQEGgIFBwaR8s\n",
       "KAgUBAoCBYGCpxrBgoJAQaAgUHAfFCwoCBQECgIFj56DBQWBgkBBoCBQcB8ULCgIFAQKAgWPnoMF\n",
       "BYGCQEGgMPfbP8GPs6AgUBAoCBQECo4awYKCQEGgIFDwflCwoCBQECgIFAQKLsyCBQWBgkBBoOA+\n",
       "KFhQECgIFAQKvkkHCwoCBYGCQEGg4KgRLCgIFAQKAgWPnoMFBYGCQEGgMP4yxc6CgkBBoCBQECg4\n",
       "agQLCgIFgYJAwaPnYEFBoCBQECgIFDx6DhYUBAoCBYGCo0awoCBQECgIFHyTDhYUBAoCBYGCQGGu\n",
       "N6hWFhQECgIFgYL7oGBBQaAgUBAouA8KFhQECgIFgYJAwVEjWFAQKAgUBArzXNqvLCgIFAQKAgWB\n",
       "wtzjwmxjQUGgIFAQKHg/KFhQECgIFAQK/gpesKAgUBAoCBQECv4KXrCgIFAQKAgUPHoOFhQECgIF\n",
       "gYKXOIMFBYGCQEGgIFDwC3XBgoJAQaAgUHDUCBYUBAoCBYGCQMFbrsGCgkBBoCBQ8JZrsKAgUBAo\n",
       "CBR8kw4WFAQKAgWBgkDBW67BgoJAQaAgUPD3g4IFBYGCQEGg4D4oWFAQKAgUBAoCBY+egwUFgYJA\n",
       "QaDgqBEsKAgUBAoCBYGCo0awoCBQECgIFBw1ggUFgYJAQaDgQzpYUBAoCBQECgIF90HBgoJAQaAg\n",
       "UHDUCBYUBAoCBYGCb9LBgoJAQaAgUBAoOGoECwoCBYGCQMHfDwoWFAQKAgWBgkDB/+0TLCgIFAQK\n",
       "AgX3QcGCgkBBoCBQmHd8Sm8sKAgUBAoCBYGCo0awoCBQECgIFDx6DhYUBAoCBYGCJ6vBgoJAQaAg\n",
       "UBAouA8KFhQECgIFgYJHz8GCgkBBoCBQECg4agQLCgIFgYJAwR9YChYUBAoCBYHCXC8IrSwoCBQE\n",
       "CgIFgYIXqIIFBYGCQEGgMM9RY2VBQaAgUBAo+CYdLCgIFAQKAgWBgqcawYKCQEGgIFDwflCwoCBQ\n",
       "ECgIFAQKc/1C3cqCgkBBoCBQcB8ULCgIFAQKAgV/miJYUBAoCBQECgIFL1AFCwoCBYGCQMGlfbCg\n",
       "IFAQKAgU3AcFCwoCBYGCQEGgMPe4EdpYUBAoCBQECu6DggUFgYJAQaAgUPCvWLCgIFAQKAgUPNUI\n",
       "FhQECgIFgYJL+2BBQaAgUBAoCBTmfhw1NhYUBAoCBYGCo0awoCBQECgIFOb5kF5ZUBAoCBQECgIF\n",
       "R41gQUGgIFAQKMz9+JDeWFAQKAgUBAoCBUeNYEFBoCBQECh4qhEsKAgUBAoCBd+kgwUFgYJAQaAg\n",
       "UPCvWLCgIFAQKAgUPHoOFhQECgIFgcK88+fbP8NPs6AgUBAoCBQECu6DggUFgYJAQaDg/aBgQUGg\n",
       "IFAQKAgU5j4XZhsLCgIFgYJAwVEjWFAQKAgUBApzPXpeWVAQKAgUBAoCBUeNYEFBoCBQECg4agQL\n",
       "CgIFgYJAYd7zTXpjQUGgIFAQKAgU3AcFCwoCBYGCQMFLnMGCgkBBoCBQECg4agQLCgIFgYJAYZ6j\n",
       "xsqCgkBBoCBQ8E06WFAQKAgUBAoChbleoFpZUBAoCBQECv7gdrCgIFAQKAgU/CpCsKAgUBAoCBQE\n",
       "Cp5qBAsKAgWBgkDBUSNYUBAoCBQECgIF/4oFCwoCBYGCQMGj52BBQaAgUBAo+CYdLCgIFAQKAgWB\n",
       "whyPnlcWFAQKAgWBgqNGsKAgUBAoCBS8xBksKAgUBAoCBYHCHEeNlQUFgYJAQaDg/aBgQUGgIFAQ\n",
       "KAgUPHoOFhQECgIFgYL7oGBBQaAgUBAozDvv2z/DT7OgIFAQKAgUBArug4IFBYGCQEGgMMdRY2VB\n",
       "QaAgUBAo/AdhU+3PqlcPeQAAAABJRU5ErkJggg==\n",
       "\" transform=\"translate(2161, 47)\"/>\n",
       "</g>\n",
       "<path clip-path=\"url(#clip950)\" d=\"M 0 0 M2280.7 1347.12 Q2277.09 1347.12 2275.26 1350.68 Q2273.45 1354.22 2273.45 1361.35 Q2273.45 1368.46 2275.26 1372.02 Q2277.09 1375.57 2280.7 1375.57 Q2284.33 1375.57 2286.14 1372.02 Q2287.97 1368.46 2287.97 1361.35 Q2287.97 1354.22 2286.14 1350.68 Q2284.33 1347.12 2280.7 1347.12 M2280.7 1343.41 Q2286.51 1343.41 2289.57 1348.02 Q2292.64 1352.6 2292.64 1361.35 Q2292.64 1370.08 2289.57 1374.69 Q2286.51 1379.27 2280.7 1379.27 Q2274.89 1379.27 2271.81 1374.69 Q2268.76 1370.08 2268.76 1361.35 Q2268.76 1352.6 2271.81 1348.02 Q2274.89 1343.41 2280.7 1343.41 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2297.71 1372.72 L2302.6 1372.72 L2302.6 1378.6 L2297.71 1378.6 L2297.71 1372.72 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2311.7 1374.66 L2328.01 1374.66 L2328.01 1378.6 L2306.07 1378.6 L2306.07 1374.66 Q2308.73 1371.91 2313.32 1367.28 Q2317.92 1362.63 2319.1 1361.28 Q2321.35 1358.76 2322.23 1357.02 Q2323.13 1355.26 2323.13 1353.57 Q2323.13 1350.82 2321.19 1349.08 Q2319.26 1347.35 2316.16 1347.35 Q2313.96 1347.35 2311.51 1348.11 Q2309.08 1348.88 2306.3 1350.43 L2306.3 1345.7 Q2309.13 1344.57 2311.58 1343.99 Q2314.03 1343.41 2316.07 1343.41 Q2321.44 1343.41 2324.64 1346.1 Q2327.83 1348.78 2327.83 1353.27 Q2327.83 1355.4 2327.02 1357.32 Q2326.23 1359.22 2324.13 1361.82 Q2323.55 1362.49 2320.45 1365.7 Q2317.34 1368.9 2311.7 1374.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2337.11 1374.66 L2353.43 1374.66 L2353.43 1378.6 L2331.49 1378.6 L2331.49 1374.66 Q2334.15 1371.91 2338.73 1367.28 Q2343.34 1362.63 2344.52 1361.28 Q2346.76 1358.76 2347.64 1357.02 Q2348.55 1355.26 2348.55 1353.57 Q2348.55 1350.82 2346.6 1349.08 Q2344.68 1347.35 2341.58 1347.35 Q2339.38 1347.35 2336.93 1348.11 Q2334.5 1348.88 2331.72 1350.43 L2331.72 1345.7 Q2334.54 1344.57 2337 1343.99 Q2339.45 1343.41 2341.49 1343.41 Q2346.86 1343.41 2350.05 1346.1 Q2353.25 1348.78 2353.25 1353.27 Q2353.25 1355.4 2352.44 1357.32 Q2351.65 1359.22 2349.54 1361.82 Q2348.96 1362.49 2345.86 1365.7 Q2342.76 1368.9 2337.11 1374.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2358.55 1344.04 L2376.9 1344.04 L2376.9 1347.97 L2362.83 1347.97 L2362.83 1356.45 Q2363.85 1356.1 2364.87 1355.94 Q2365.89 1355.75 2366.9 1355.75 Q2372.69 1355.75 2376.07 1358.92 Q2379.45 1362.09 2379.45 1367.51 Q2379.45 1373.09 2375.98 1376.19 Q2372.51 1379.27 2366.19 1379.27 Q2364.01 1379.27 2361.74 1378.9 Q2359.5 1378.53 2357.09 1377.79 L2357.09 1373.09 Q2359.17 1374.22 2361.39 1374.78 Q2363.62 1375.33 2366.09 1375.33 Q2370.1 1375.33 2372.44 1373.23 Q2374.77 1371.12 2374.77 1367.51 Q2374.77 1363.9 2372.44 1361.79 Q2370.1 1359.69 2366.09 1359.69 Q2364.22 1359.69 2362.34 1360.1 Q2360.49 1360.52 2358.55 1361.4 L2358.55 1344.04 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2280.7 1181.83 Q2277.09 1181.83 2275.26 1185.4 Q2273.45 1188.94 2273.45 1196.07 Q2273.45 1203.17 2275.26 1206.74 Q2277.09 1210.28 2280.7 1210.28 Q2284.33 1210.28 2286.14 1206.74 Q2287.97 1203.17 2287.97 1196.07 Q2287.97 1188.94 2286.14 1185.4 Q2284.33 1181.83 2280.7 1181.83 M2280.7 1178.13 Q2286.51 1178.13 2289.57 1182.73 Q2292.64 1187.32 2292.64 1196.07 Q2292.64 1204.79 2289.57 1209.4 Q2286.51 1213.98 2280.7 1213.98 Q2274.89 1213.98 2271.81 1209.4 Q2268.76 1204.79 2268.76 1196.07 Q2268.76 1187.32 2271.81 1182.73 Q2274.89 1178.13 2280.7 1178.13 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2297.71 1207.43 L2302.6 1207.43 L2302.6 1213.31 L2297.71 1213.31 L2297.71 1207.43 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2311.7 1209.38 L2328.01 1209.38 L2328.01 1213.31 L2306.07 1213.31 L2306.07 1209.38 Q2308.73 1206.62 2313.32 1201.99 Q2317.92 1197.34 2319.1 1196 Q2321.35 1193.47 2322.23 1191.74 Q2323.13 1189.98 2323.13 1188.29 Q2323.13 1185.54 2321.19 1183.8 Q2319.26 1182.06 2316.16 1182.06 Q2313.96 1182.06 2311.51 1182.83 Q2309.08 1183.59 2306.3 1185.14 L2306.3 1180.42 Q2309.13 1179.29 2311.58 1178.71 Q2314.03 1178.13 2316.07 1178.13 Q2321.44 1178.13 2324.64 1180.81 Q2327.83 1183.5 2327.83 1187.99 Q2327.83 1190.12 2327.02 1192.04 Q2326.23 1193.94 2324.13 1196.53 Q2323.55 1197.2 2320.45 1200.42 Q2317.34 1203.61 2311.7 1209.38 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2333.13 1178.75 L2351.49 1178.75 L2351.49 1182.69 L2337.41 1182.69 L2337.41 1191.16 Q2338.43 1190.81 2339.45 1190.65 Q2340.47 1190.47 2341.49 1190.47 Q2347.27 1190.47 2350.65 1193.64 Q2354.03 1196.81 2354.03 1202.22 Q2354.03 1207.8 2350.56 1210.91 Q2347.09 1213.98 2340.77 1213.98 Q2338.59 1213.98 2336.32 1213.61 Q2334.08 1213.24 2331.67 1212.5 L2331.67 1207.8 Q2333.76 1208.94 2335.98 1209.49 Q2338.2 1210.05 2340.68 1210.05 Q2344.68 1210.05 2347.02 1207.94 Q2349.36 1205.84 2349.36 1202.22 Q2349.36 1198.61 2347.02 1196.51 Q2344.68 1194.4 2340.68 1194.4 Q2338.8 1194.4 2336.93 1194.82 Q2335.07 1195.23 2333.13 1196.11 L2333.13 1178.75 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2369.1 1181.83 Q2365.49 1181.83 2363.66 1185.4 Q2361.86 1188.94 2361.86 1196.07 Q2361.86 1203.17 2363.66 1206.74 Q2365.49 1210.28 2369.1 1210.28 Q2372.74 1210.28 2374.54 1206.74 Q2376.37 1203.17 2376.37 1196.07 Q2376.37 1188.94 2374.54 1185.4 Q2372.74 1181.83 2369.1 1181.83 M2369.1 1178.13 Q2374.91 1178.13 2377.97 1182.73 Q2381.05 1187.32 2381.05 1196.07 Q2381.05 1204.79 2377.97 1209.4 Q2374.91 1213.98 2369.1 1213.98 Q2363.29 1213.98 2360.21 1209.4 Q2357.16 1204.79 2357.16 1196.07 Q2357.16 1187.32 2360.21 1182.73 Q2363.29 1178.13 2369.1 1178.13 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2280.7 1016.55 Q2277.09 1016.55 2275.26 1020.11 Q2273.45 1023.65 2273.45 1030.78 Q2273.45 1037.89 2275.26 1041.45 Q2277.09 1045 2280.7 1045 Q2284.33 1045 2286.14 1041.45 Q2287.97 1037.89 2287.97 1030.78 Q2287.97 1023.65 2286.14 1020.11 Q2284.33 1016.55 2280.7 1016.55 M2280.7 1012.84 Q2286.51 1012.84 2289.57 1017.45 Q2292.64 1022.03 2292.64 1030.78 Q2292.64 1039.51 2289.57 1044.12 Q2286.51 1048.7 2280.7 1048.7 Q2274.89 1048.7 2271.81 1044.12 Q2268.76 1039.51 2268.76 1030.78 Q2268.76 1022.03 2271.81 1017.45 Q2274.89 1012.84 2280.7 1012.84 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2297.71 1042.15 L2302.6 1042.15 L2302.6 1048.03 L2297.71 1048.03 L2297.71 1042.15 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2311.7 1044.09 L2328.01 1044.09 L2328.01 1048.03 L2306.07 1048.03 L2306.07 1044.09 Q2308.73 1041.34 2313.32 1036.71 Q2317.92 1032.06 2319.1 1030.71 Q2321.35 1028.19 2322.23 1026.45 Q2323.13 1024.69 2323.13 1023 Q2323.13 1020.25 2321.19 1018.51 Q2319.26 1016.78 2316.16 1016.78 Q2313.96 1016.78 2311.51 1017.54 Q2309.08 1018.31 2306.3 1019.86 L2306.3 1015.13 Q2309.13 1014 2311.58 1013.42 Q2314.03 1012.84 2316.07 1012.84 Q2321.44 1012.84 2324.64 1015.53 Q2327.83 1018.21 2327.83 1022.7 Q2327.83 1024.83 2327.02 1026.75 Q2326.23 1028.65 2324.13 1031.25 Q2323.55 1031.92 2320.45 1035.13 Q2317.34 1038.33 2311.7 1044.09 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2331.9 1013.47 L2354.13 1013.47 L2354.13 1015.46 L2341.58 1048.03 L2336.7 1048.03 L2348.5 1017.4 L2331.9 1017.4 L2331.9 1013.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2359.24 1013.47 L2377.6 1013.47 L2377.6 1017.4 L2363.52 1017.4 L2363.52 1025.87 Q2364.54 1025.53 2365.56 1025.37 Q2366.58 1025.18 2367.6 1025.18 Q2373.38 1025.18 2376.76 1028.35 Q2380.14 1031.52 2380.14 1036.94 Q2380.14 1042.52 2376.67 1045.62 Q2373.2 1048.7 2366.88 1048.7 Q2364.7 1048.7 2362.44 1048.33 Q2360.19 1047.96 2357.78 1047.22 L2357.78 1042.52 Q2359.87 1043.65 2362.09 1044.21 Q2364.31 1044.76 2366.79 1044.76 Q2370.79 1044.76 2373.13 1042.66 Q2375.47 1040.55 2375.47 1036.94 Q2375.47 1033.33 2373.13 1031.22 Q2370.79 1029.12 2366.79 1029.12 Q2364.91 1029.12 2363.04 1029.53 Q2361.19 1029.95 2359.24 1030.83 L2359.24 1013.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2280.7 851.261 Q2277.09 851.261 2275.26 854.826 Q2273.45 858.368 2273.45 865.497 Q2273.45 872.604 2275.26 876.168 Q2277.09 879.71 2280.7 879.71 Q2284.33 879.71 2286.14 876.168 Q2287.97 872.604 2287.97 865.497 Q2287.97 858.368 2286.14 854.826 Q2284.33 851.261 2280.7 851.261 M2280.7 847.557 Q2286.51 847.557 2289.57 852.164 Q2292.64 856.747 2292.64 865.497 Q2292.64 874.224 2289.57 878.83 Q2286.51 883.414 2280.7 883.414 Q2274.89 883.414 2271.81 878.83 Q2268.76 874.224 2268.76 865.497 Q2268.76 856.747 2271.81 852.164 Q2274.89 847.557 2280.7 847.557 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2297.71 876.863 L2302.6 876.863 L2302.6 882.742 L2297.71 882.742 L2297.71 876.863 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2321.83 864.108 Q2325.19 864.826 2327.07 867.094 Q2328.96 869.363 2328.96 872.696 Q2328.96 877.812 2325.45 880.613 Q2321.93 883.414 2315.45 883.414 Q2313.27 883.414 2310.95 882.974 Q2308.66 882.557 2306.21 881.701 L2306.21 877.187 Q2308.15 878.321 2310.47 878.9 Q2312.78 879.479 2315.31 879.479 Q2319.7 879.479 2322 877.742 Q2324.31 876.006 2324.31 872.696 Q2324.31 869.641 2322.16 867.928 Q2320.03 866.192 2316.21 866.192 L2312.18 866.192 L2312.18 862.349 L2316.39 862.349 Q2319.84 862.349 2321.67 860.983 Q2323.5 859.594 2323.5 857.002 Q2323.5 854.34 2321.6 852.928 Q2319.73 851.493 2316.21 851.493 Q2314.29 851.493 2312.09 851.909 Q2309.89 852.326 2307.25 853.206 L2307.25 849.039 Q2309.91 848.298 2312.23 847.928 Q2314.57 847.557 2316.63 847.557 Q2321.95 847.557 2325.05 849.988 Q2328.15 852.395 2328.15 856.516 Q2328.15 859.386 2326.51 861.377 Q2324.87 863.344 2321.83 864.108 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2344.03 851.261 Q2340.42 851.261 2338.59 854.826 Q2336.79 858.368 2336.79 865.497 Q2336.79 872.604 2338.59 876.168 Q2340.42 879.71 2344.03 879.71 Q2347.67 879.71 2349.47 876.168 Q2351.3 872.604 2351.3 865.497 Q2351.3 858.368 2349.47 854.826 Q2347.67 851.261 2344.03 851.261 M2344.03 847.557 Q2349.84 847.557 2352.9 852.164 Q2355.98 856.747 2355.98 865.497 Q2355.98 874.224 2352.9 878.83 Q2349.84 883.414 2344.03 883.414 Q2338.22 883.414 2335.14 878.83 Q2332.09 874.224 2332.09 865.497 Q2332.09 856.747 2335.14 852.164 Q2338.22 847.557 2344.03 847.557 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2371.05 851.261 Q2367.44 851.261 2365.61 854.826 Q2363.8 858.368 2363.8 865.497 Q2363.8 872.604 2365.61 876.168 Q2367.44 879.71 2371.05 879.71 Q2374.68 879.71 2376.49 876.168 Q2378.32 872.604 2378.32 865.497 Q2378.32 858.368 2376.49 854.826 Q2374.68 851.261 2371.05 851.261 M2371.05 847.557 Q2376.86 847.557 2379.91 852.164 Q2382.99 856.747 2382.99 865.497 Q2382.99 874.224 2379.91 878.83 Q2376.86 883.414 2371.05 883.414 Q2365.24 883.414 2362.16 878.83 Q2359.1 874.224 2359.1 865.497 Q2359.1 856.747 2362.16 852.164 Q2365.24 847.557 2371.05 847.557 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2280.7 685.976 Q2277.09 685.976 2275.26 689.541 Q2273.45 693.082 2273.45 700.212 Q2273.45 707.318 2275.26 710.883 Q2277.09 714.425 2280.7 714.425 Q2284.33 714.425 2286.14 710.883 Q2287.97 707.318 2287.97 700.212 Q2287.97 693.082 2286.14 689.541 Q2284.33 685.976 2280.7 685.976 M2280.7 682.272 Q2286.51 682.272 2289.57 686.879 Q2292.64 691.462 2292.64 700.212 Q2292.64 708.939 2289.57 713.545 Q2286.51 718.129 2280.7 718.129 Q2274.89 718.129 2271.81 713.545 Q2268.76 708.939 2268.76 700.212 Q2268.76 691.462 2271.81 686.879 Q2274.89 682.272 2280.7 682.272 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2297.71 711.578 L2302.6 711.578 L2302.6 717.457 L2297.71 717.457 L2297.71 711.578 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2321.83 698.823 Q2325.19 699.541 2327.07 701.809 Q2328.96 704.078 2328.96 707.411 Q2328.96 712.527 2325.45 715.328 Q2321.93 718.129 2315.45 718.129 Q2313.27 718.129 2310.95 717.689 Q2308.66 717.272 2306.21 716.416 L2306.21 711.902 Q2308.15 713.036 2310.47 713.615 Q2312.78 714.193 2315.31 714.193 Q2319.7 714.193 2322 712.457 Q2324.31 710.721 2324.31 707.411 Q2324.31 704.355 2322.16 702.642 Q2320.03 700.906 2316.21 700.906 L2312.18 700.906 L2312.18 697.064 L2316.39 697.064 Q2319.84 697.064 2321.67 695.698 Q2323.5 694.309 2323.5 691.717 Q2323.5 689.055 2321.6 687.643 Q2319.73 686.207 2316.21 686.207 Q2314.29 686.207 2312.09 686.624 Q2309.89 687.041 2307.25 687.92 L2307.25 683.754 Q2309.91 683.013 2312.23 682.643 Q2314.57 682.272 2316.63 682.272 Q2321.95 682.272 2325.05 684.703 Q2328.15 687.11 2328.15 691.231 Q2328.15 694.101 2326.51 696.092 Q2324.87 698.059 2321.83 698.823 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2338.06 713.522 L2354.38 713.522 L2354.38 717.457 L2332.44 717.457 L2332.44 713.522 Q2335.1 710.767 2339.68 706.138 Q2344.29 701.485 2345.47 700.143 Q2347.71 697.619 2348.59 695.883 Q2349.5 694.124 2349.5 692.434 Q2349.5 689.68 2347.55 687.944 Q2345.63 686.207 2342.53 686.207 Q2340.33 686.207 2337.88 686.971 Q2335.45 687.735 2332.67 689.286 L2332.67 684.564 Q2335.49 683.43 2337.95 682.851 Q2340.4 682.272 2342.44 682.272 Q2347.81 682.272 2351 684.957 Q2354.2 687.643 2354.2 692.133 Q2354.2 694.263 2353.39 696.184 Q2352.6 698.082 2350.49 700.675 Q2349.91 701.346 2346.81 704.564 Q2343.71 707.758 2338.06 713.522 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2359.5 682.897 L2377.85 682.897 L2377.85 686.832 L2363.78 686.832 L2363.78 695.305 Q2364.8 694.957 2365.82 694.795 Q2366.83 694.61 2367.85 694.61 Q2373.64 694.61 2377.02 697.781 Q2380.4 700.953 2380.4 706.369 Q2380.4 711.948 2376.93 715.05 Q2373.45 718.129 2367.14 718.129 Q2364.96 718.129 2362.69 717.758 Q2360.45 717.388 2358.04 716.647 L2358.04 711.948 Q2360.12 713.082 2362.34 713.638 Q2364.57 714.193 2367.04 714.193 Q2371.05 714.193 2373.38 712.087 Q2375.72 709.98 2375.72 706.369 Q2375.72 702.758 2373.38 700.652 Q2371.05 698.545 2367.04 698.545 Q2365.17 698.545 2363.29 698.962 Q2361.44 699.379 2359.5 700.258 L2359.5 682.897 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2280.7 520.691 Q2277.09 520.691 2275.26 524.256 Q2273.45 527.797 2273.45 534.927 Q2273.45 542.033 2275.26 545.598 Q2277.09 549.14 2280.7 549.14 Q2284.33 549.14 2286.14 545.598 Q2287.97 542.033 2287.97 534.927 Q2287.97 527.797 2286.14 524.256 Q2284.33 520.691 2280.7 520.691 M2280.7 516.987 Q2286.51 516.987 2289.57 521.594 Q2292.64 526.177 2292.64 534.927 Q2292.64 543.654 2289.57 548.26 Q2286.51 552.843 2280.7 552.843 Q2274.89 552.843 2271.81 548.26 Q2268.76 543.654 2268.76 534.927 Q2268.76 526.177 2271.81 521.594 Q2274.89 516.987 2280.7 516.987 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2297.71 546.292 L2302.6 546.292 L2302.6 552.172 L2297.71 552.172 L2297.71 546.292 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2321.83 533.538 Q2325.19 534.255 2327.07 536.524 Q2328.96 538.792 2328.96 542.126 Q2328.96 547.242 2325.45 550.042 Q2321.93 552.843 2315.45 552.843 Q2313.27 552.843 2310.95 552.404 Q2308.66 551.987 2306.21 551.13 L2306.21 546.617 Q2308.15 547.751 2310.47 548.329 Q2312.78 548.908 2315.31 548.908 Q2319.7 548.908 2322 547.172 Q2324.31 545.436 2324.31 542.126 Q2324.31 539.07 2322.16 537.357 Q2320.03 535.621 2316.21 535.621 L2312.18 535.621 L2312.18 531.779 L2316.39 531.779 Q2319.84 531.779 2321.67 530.413 Q2323.5 529.024 2323.5 526.431 Q2323.5 523.769 2321.6 522.357 Q2319.73 520.922 2316.21 520.922 Q2314.29 520.922 2312.09 521.339 Q2309.89 521.756 2307.25 522.635 L2307.25 518.469 Q2309.91 517.728 2312.23 517.357 Q2314.57 516.987 2316.63 516.987 Q2321.95 516.987 2325.05 519.418 Q2328.15 521.825 2328.15 525.945 Q2328.15 528.816 2326.51 530.806 Q2324.87 532.774 2321.83 533.538 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2334.08 517.612 L2352.44 517.612 L2352.44 521.547 L2338.36 521.547 L2338.36 530.019 Q2339.38 529.672 2340.4 529.51 Q2341.42 529.325 2342.44 529.325 Q2348.22 529.325 2351.6 532.496 Q2354.98 535.668 2354.98 541.084 Q2354.98 546.663 2351.51 549.765 Q2348.04 552.843 2341.72 552.843 Q2339.54 552.843 2337.27 552.473 Q2335.03 552.103 2332.62 551.362 L2332.62 546.663 Q2334.7 547.797 2336.93 548.353 Q2339.15 548.908 2341.63 548.908 Q2345.63 548.908 2347.97 546.802 Q2350.31 544.695 2350.31 541.084 Q2350.31 537.473 2347.97 535.367 Q2345.63 533.26 2341.63 533.26 Q2339.75 533.26 2337.88 533.677 Q2336.02 534.093 2334.08 534.973 L2334.08 517.612 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2370.05 520.691 Q2366.44 520.691 2364.61 524.256 Q2362.81 527.797 2362.81 534.927 Q2362.81 542.033 2364.61 545.598 Q2366.44 549.14 2370.05 549.14 Q2373.69 549.14 2375.49 545.598 Q2377.32 542.033 2377.32 534.927 Q2377.32 527.797 2375.49 524.256 Q2373.69 520.691 2370.05 520.691 M2370.05 516.987 Q2375.86 516.987 2378.92 521.594 Q2382 526.177 2382 534.927 Q2382 543.654 2378.92 548.26 Q2375.86 552.843 2370.05 552.843 Q2364.24 552.843 2361.16 548.26 Q2358.11 543.654 2358.11 534.927 Q2358.11 526.177 2361.16 521.594 Q2364.24 516.987 2370.05 516.987 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2280.7 355.406 Q2277.09 355.406 2275.26 358.97 Q2273.45 362.512 2273.45 369.642 Q2273.45 376.748 2275.26 380.313 Q2277.09 383.854 2280.7 383.854 Q2284.33 383.854 2286.14 380.313 Q2287.97 376.748 2287.97 369.642 Q2287.97 362.512 2286.14 358.97 Q2284.33 355.406 2280.7 355.406 M2280.7 351.702 Q2286.51 351.702 2289.57 356.308 Q2292.64 360.892 2292.64 369.642 Q2292.64 378.368 2289.57 382.975 Q2286.51 387.558 2280.7 387.558 Q2274.89 387.558 2271.81 382.975 Q2268.76 378.368 2268.76 369.642 Q2268.76 360.892 2271.81 356.308 Q2274.89 351.702 2280.7 351.702 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2297.71 381.007 L2302.6 381.007 L2302.6 386.887 L2297.71 386.887 L2297.71 381.007 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2321.83 368.253 Q2325.19 368.97 2327.07 371.239 Q2328.96 373.507 2328.96 376.841 Q2328.96 381.956 2325.45 384.757 Q2321.93 387.558 2315.45 387.558 Q2313.27 387.558 2310.95 387.118 Q2308.66 386.702 2306.21 385.845 L2306.21 381.331 Q2308.15 382.466 2310.47 383.044 Q2312.78 383.623 2315.31 383.623 Q2319.7 383.623 2322 381.887 Q2324.31 380.151 2324.31 376.841 Q2324.31 373.785 2322.16 372.072 Q2320.03 370.336 2316.21 370.336 L2312.18 370.336 L2312.18 366.493 L2316.39 366.493 Q2319.84 366.493 2321.67 365.128 Q2323.5 363.739 2323.5 361.146 Q2323.5 358.484 2321.6 357.072 Q2319.73 355.637 2316.21 355.637 Q2314.29 355.637 2312.09 356.054 Q2309.89 356.47 2307.25 357.35 L2307.25 353.183 Q2309.91 352.443 2312.23 352.072 Q2314.57 351.702 2316.63 351.702 Q2321.95 351.702 2325.05 354.132 Q2328.15 356.54 2328.15 360.66 Q2328.15 363.53 2326.51 365.521 Q2324.87 367.489 2321.83 368.253 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2332.85 352.327 L2355.07 352.327 L2355.07 354.318 L2342.53 386.887 L2337.64 386.887 L2349.45 356.262 L2332.85 356.262 L2332.85 352.327 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2360.19 352.327 L2378.55 352.327 L2378.55 356.262 L2364.47 356.262 L2364.47 364.734 Q2365.49 364.387 2366.51 364.225 Q2367.53 364.04 2368.55 364.04 Q2374.33 364.04 2377.71 367.211 Q2381.09 370.382 2381.09 375.799 Q2381.09 381.378 2377.62 384.479 Q2374.15 387.558 2367.83 387.558 Q2365.65 387.558 2363.39 387.188 Q2361.14 386.817 2358.73 386.077 L2358.73 381.378 Q2360.82 382.512 2363.04 383.067 Q2365.26 383.623 2367.74 383.623 Q2371.74 383.623 2374.08 381.517 Q2376.42 379.41 2376.42 375.799 Q2376.42 372.188 2374.08 370.081 Q2371.74 367.975 2367.74 367.975 Q2365.86 367.975 2363.99 368.392 Q2362.14 368.808 2360.19 369.688 L2360.19 352.327 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2280.7 190.12 Q2277.09 190.12 2275.26 193.685 Q2273.45 197.227 2273.45 204.356 Q2273.45 211.463 2275.26 215.028 Q2277.09 218.569 2280.7 218.569 Q2284.33 218.569 2286.14 215.028 Q2287.97 211.463 2287.97 204.356 Q2287.97 197.227 2286.14 193.685 Q2284.33 190.12 2280.7 190.12 M2280.7 186.417 Q2286.51 186.417 2289.57 191.023 Q2292.64 195.606 2292.64 204.356 Q2292.64 213.083 2289.57 217.69 Q2286.51 222.273 2280.7 222.273 Q2274.89 222.273 2271.81 217.69 Q2268.76 213.083 2268.76 204.356 Q2268.76 195.606 2271.81 191.023 Q2274.89 186.417 2280.7 186.417 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2297.71 215.722 L2302.6 215.722 L2302.6 221.602 L2297.71 221.602 L2297.71 215.722 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2320.51 191.116 L2308.71 209.565 L2320.51 209.565 L2320.51 191.116 M2319.29 187.042 L2325.17 187.042 L2325.17 209.565 L2330.1 209.565 L2330.1 213.454 L2325.17 213.454 L2325.17 221.602 L2320.51 221.602 L2320.51 213.454 L2304.91 213.454 L2304.91 208.94 L2319.29 187.042 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2345.17 190.12 Q2341.56 190.12 2339.73 193.685 Q2337.92 197.227 2337.92 204.356 Q2337.92 211.463 2339.73 215.028 Q2341.56 218.569 2345.17 218.569 Q2348.8 218.569 2350.61 215.028 Q2352.44 211.463 2352.44 204.356 Q2352.44 197.227 2350.61 193.685 Q2348.8 190.12 2345.17 190.12 M2345.17 186.417 Q2350.98 186.417 2354.03 191.023 Q2357.11 195.606 2357.11 204.356 Q2357.11 213.083 2354.03 217.69 Q2350.98 222.273 2345.17 222.273 Q2339.36 222.273 2336.28 217.69 Q2333.22 213.083 2333.22 204.356 Q2333.22 195.606 2336.28 191.023 Q2339.36 186.417 2345.17 186.417 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip950)\" d=\"M 0 0 M2372.18 190.12 Q2368.57 190.12 2366.74 193.685 Q2364.94 197.227 2364.94 204.356 Q2364.94 211.463 2366.74 215.028 Q2368.57 218.569 2372.18 218.569 Q2375.82 218.569 2377.62 215.028 Q2379.45 211.463 2379.45 204.356 Q2379.45 197.227 2377.62 193.685 Q2375.82 190.12 2372.18 190.12 M2372.18 186.417 Q2377.99 186.417 2381.05 191.023 Q2384.13 195.606 2384.13 204.356 Q2384.13 213.083 2381.05 217.69 Q2377.99 222.273 2372.18 222.273 Q2366.37 222.273 2363.29 217.69 Q2360.24 213.083 2360.24 204.356 Q2360.24 195.606 2363.29 191.023 Q2366.37 186.417 2372.18 186.417 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip950)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2232.76,1423.18 2232.76,1364.95 2256.76,1364.95 2232.76,1364.95 2232.76,1199.66 2256.76,1199.66 2232.76,1199.66 2232.76,1034.38 2256.76,1034.38 2232.76,1034.38 \n",
       "  2232.76,869.091 2256.76,869.091 2232.76,869.091 2232.76,703.806 2256.76,703.806 2232.76,703.806 2232.76,538.521 2256.76,538.521 2232.76,538.521 2232.76,373.236 \n",
       "  2256.76,373.236 2232.76,373.236 2232.76,207.95 2256.76,207.95 2232.76,207.95 2232.76,47.2441 \n",
       "  \"/>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(self_tuning_boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(best_model = \u001b[34mAdaBoostClassifier @180\u001b[39m,\n",
       " best_fitted_params = (estimators = PyCall.PyObject[PyObject DecisionTreeClassifier(max_depth=1, random_state=222236409), PyObject DecisionTreeClassifier(max_depth=1, random_state=1217850360), PyObject DecisionTreeClassifier(max_depth=1, random_state=23430956), PyObject DecisionTreeClassifier(max_depth=1, random_state=280062800), PyObject DecisionTreeClassifier(max_depth=1, random_state=262260212), PyObject DecisionTreeClassifier(max_depth=1, random_state=2087665186), PyObject DecisionTreeClassifier(max_depth=1, random_state=330899414), PyObject DecisionTreeClassifier(max_depth=1, random_state=2128092493), PyObject DecisionTreeClassifier(max_depth=1, random_state=2104983211), PyObject DecisionTreeClassifier(max_depth=1, random_state=856704578)    PyObject DecisionTreeClassifier(max_depth=1, random_state=253847527), PyObject DecisionTreeClassifier(max_depth=1, random_state=1524641325), PyObject DecisionTreeClassifier(max_depth=1, random_state=848158225), PyObject DecisionTreeClassifier(max_depth=1, random_state=794047550), PyObject DecisionTreeClassifier(max_depth=1, random_state=582500563), PyObject DecisionTreeClassifier(max_depth=1, random_state=1855428571), PyObject DecisionTreeClassifier(max_depth=1, random_state=295691262), PyObject DecisionTreeClassifier(max_depth=1, random_state=127350182), PyObject DecisionTreeClassifier(max_depth=1, random_state=695778622), PyObject DecisionTreeClassifier(max_depth=1, random_state=2073802162)],\n",
       "                       estimator_weights = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0    1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
       "                       estimator_errors = [0.07286432160804018, 0.08183998450370512, 0.09322719789280672, 0.10487154727552025, 0.12070526044865408, 0.12236629189987257, 0.13907285574141232, 0.1581952912743032, 0.16116949147050405, 0.16745040266404956    0.24745647532439857, 0.23322732800562593, 0.2936301120138729, 0.2268833574780739, 0.2399118901396155, 0.26185931073736735, 0.2622070053446888, 0.3248652716393529, 0.2965217042148114, 0.2800463300148376],\n",
       "                       classes = UInt32[0x00000001, 0x00000002],\n",
       "                       n_classes = 2,),)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = fitted_params(self_tuning_boost)\n",
    "best.best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21619"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_loss = round(z.report.best_result.measurement[1],digits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_n = best.best_model.n_estimators\n",
    "best_lr = best.best_model.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"Figures/LearningCurve_Boost_nestimators:$(best_n)_lr:$(best_lr)_loss:$(best_loss)\"\n",
    "png(replace(fn,'.' => ','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(\n",
       "    base_estimator = nothing,\n",
       "    n_estimators = 28,\n",
       "    learning_rate = 0.1,\n",
       "    algorithm = \"SAMME.R\",\n",
       "    random_state = nothing)\u001b[34m @180\u001b[39m"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_boost_model = best.best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{AdaBoostClassifier} @829\u001b[39m trained 0 times.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @478\u001b[39m  `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @626\u001b[39m  `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Boost = machine(final_boost_model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Info: Training \u001b[34mMachine{AdaBoostClassifier} @829\u001b[39m.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/machines.jl:322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{AdaBoostClassifier} @829\u001b[39m trained 1 time.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @478\u001b[39m  `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @626\u001b[39m  `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(Final_Boost, rows=train, verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = predict(Final_Boost, X[test,:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2557718718885153"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(y2, y[test]) |> mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(y2, y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
