{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using CSV\n",
    "using MLJ\n",
    "using DecisionTree: print_tree\n",
    "using Plots\n",
    "\n",
    "include(\"../../lib.jl\")\n",
    "\n",
    "ENV[\"LINES\"]=50;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread = 1 warning: only found 32 / 33 columns around data row: 2. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 3. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 4. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 5. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 6. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 7. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 8. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 9. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 10. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 11. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 12. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 13. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 14. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 15. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 16. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 17. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 18. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 19. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 20. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 21. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 22. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 23. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 24. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 25. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 26. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 27. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 28. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 29. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 30. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 31. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 32. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 33. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 34. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 35. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 36. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 37. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 38. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 39. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 40. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 41. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 42. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 43. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 44. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 45. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 46. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 47. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 48. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 49. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 50. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 51. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 52. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 53. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 54. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 55. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 56. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 57. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 58. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 59. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 60. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 61. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 62. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 63. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 64. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 65. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 66. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 67. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 68. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 69. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 70. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 71. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 72. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 73. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 74. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 75. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 76. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 77. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 78. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 79. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 80. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 81. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 82. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 83. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 84. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 85. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 86. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 87. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 88. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 89. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 90. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 91. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 92. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 93. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 94. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 95. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 96. Filling remaining columns with `missing`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread = 1 warning: only found 32 / 33 columns around data row: 97. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 98. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 99. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 100. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 101. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 102. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 103. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 104. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 105. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 106. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 107. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 108. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 109. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 110. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 111. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 112. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 113. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 114. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 115. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 116. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 117. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 118. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 119. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 120. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 121. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 122. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 123. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 124. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 125. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 126. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 127. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 128. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 129. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 130. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 131. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 132. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 133. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 134. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 135. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 136. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 137. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 138. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 139. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 140. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 141. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 142. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 143. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 144. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 145. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 146. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 147. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 148. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 149. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 150. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 151. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 152. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 153. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 154. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 155. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 156. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 157. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 158. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 159. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 160. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 161. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 162. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 163. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 164. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 165. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 166. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 167. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 168. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 169. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 170. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 171. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 172. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 173. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 174. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 175. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 176. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 177. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 178. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 179. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 180. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 181. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 182. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 183. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 184. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 185. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 186. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 187. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 188. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 189. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 190. Filling remaining columns with `missing`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread = 1 warning: only found 32 / 33 columns around data row: 191. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 192. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 193. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 194. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 195. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 196. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 197. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 198. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 199. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 200. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 201. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 202. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 203. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 204. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 205. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 206. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 207. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 208. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 209. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 210. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 211. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 212. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 213. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 214. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 215. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 216. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 217. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 218. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 219. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 220. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 221. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 222. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 223. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 224. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 225. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 226. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 227. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 228. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 229. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 230. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 231. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 232. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 233. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 234. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 235. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 236. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 237. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 238. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 239. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 240. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 241. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 242. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 243. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 244. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 245. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 246. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 247. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 248. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 249. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 250. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 251. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 252. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 253. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 254. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 255. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 256. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 257. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 258. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 259. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 260. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 261. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 262. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 263. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 264. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 265. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 266. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 267. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 268. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 269. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 270. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 271. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 272. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 273. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 274. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 275. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 276. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 277. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 278. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 279. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 280. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 281. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 282. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 283. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 284. Filling remaining columns with `missing`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread = 1 warning: only found 32 / 33 columns around data row: 285. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 286. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 287. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 288. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 289. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 290. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 291. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 292. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 293. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 294. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 295. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 296. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 297. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 298. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 299. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 300. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 301. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 302. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 303. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 304. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 305. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 306. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 307. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 308. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 309. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 310. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 311. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 312. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 313. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 314. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 315. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 316. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 317. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 318. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 319. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 320. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 321. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 322. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 323. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 324. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 325. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 326. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 327. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 328. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 329. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 330. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 331. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 332. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 333. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 334. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 335. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 336. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 337. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 338. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 339. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 340. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 341. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 342. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 343. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 344. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 345. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 346. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 347. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 348. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 349. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 350. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 351. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 352. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 353. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 354. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 355. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 356. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 357. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 358. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 359. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 360. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 361. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 362. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 363. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 364. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 365. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 366. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 367. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 368. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 369. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 370. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 371. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 372. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 373. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 374. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 375. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 376. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 377. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 378. Filling remaining columns with `missing`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread = 1 warning: only found 32 / 33 columns around data row: 379. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 380. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 381. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 382. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 383. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 384. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 385. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 386. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 387. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 388. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 389. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 390. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 391. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 392. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 393. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 394. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 395. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 396. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 397. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 398. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 399. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 400. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 401. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 402. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 403. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 404. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 405. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 406. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 407. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 408. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 409. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 410. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 411. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 412. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 413. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 414. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 415. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 416. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 417. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 418. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 419. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 420. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 421. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 422. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 423. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 424. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 425. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 426. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 427. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 428. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 429. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 430. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 431. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 432. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 433. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 434. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 435. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 436. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 437. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 438. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 439. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 440. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 441. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 442. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 443. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 444. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 445. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 446. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 447. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 448. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 449. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 450. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 451. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 452. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 453. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 454. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 455. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 456. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 457. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 458. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 459. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 460. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 461. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 462. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 463. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 464. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 465. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 466. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 467. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 468. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 469. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 470. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 471. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 472. Filling remaining columns with `missing`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread = 1 warning: only found 32 / 33 columns around data row: 473. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 474. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 475. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 476. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 477. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 478. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 479. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 480. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 481. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 482. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 483. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 484. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 485. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 486. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 487. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 488. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 489. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 490. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 491. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 492. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 493. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 494. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 495. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 496. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 497. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 498. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 499. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 500. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 501. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 502. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 503. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 504. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 505. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 506. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 507. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 508. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 509. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 510. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 511. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 512. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 513. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 514. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 515. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 516. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 517. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 518. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 519. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 520. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 521. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 522. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 523. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 524. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 525. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 526. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 527. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 528. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 529. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 530. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 531. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 532. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 533. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 534. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 535. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 536. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 537. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 538. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 539. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 540. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 541. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 542. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 543. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 544. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 545. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 546. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 547. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 548. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 549. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 550. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 551. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 552. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 553. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 554. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 555. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 556. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 557. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 558. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 559. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 560. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 561. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 562. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 563. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 564. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 565. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 566. Filling remaining columns with `missing`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread = 1 warning: only found 32 / 33 columns around data row: 567. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 568. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 569. Filling remaining columns with `missing`\n",
      "thread = 1 warning: only found 32 / 33 columns around data row: 570. Filling remaining columns with `missing`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>id</th><th>diagnosis</th><th>radius_mean</th><th>texture_mean</th><th>perimeter_mean</th><th>area_mean</th><th>smoothness_mean</th></tr><tr><th></th><th>Int64</th><th>String</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>569 rows  33 columns (omitted printing of 26 columns)</p><tr><th>1</th><td>842302</td><td>M</td><td>17.99</td><td>10.38</td><td>122.8</td><td>1001.0</td><td>0.1184</td></tr><tr><th>2</th><td>842517</td><td>M</td><td>20.57</td><td>17.77</td><td>132.9</td><td>1326.0</td><td>0.08474</td></tr><tr><th>3</th><td>84300903</td><td>M</td><td>19.69</td><td>21.25</td><td>130.0</td><td>1203.0</td><td>0.1096</td></tr><tr><th>4</th><td>84348301</td><td>M</td><td>11.42</td><td>20.38</td><td>77.58</td><td>386.1</td><td>0.1425</td></tr><tr><th>5</th><td>84358402</td><td>M</td><td>20.29</td><td>14.34</td><td>135.1</td><td>1297.0</td><td>0.1003</td></tr><tr><th>6</th><td>843786</td><td>M</td><td>12.45</td><td>15.7</td><td>82.57</td><td>477.1</td><td>0.1278</td></tr><tr><th>7</th><td>844359</td><td>M</td><td>18.25</td><td>19.98</td><td>119.6</td><td>1040.0</td><td>0.09463</td></tr><tr><th>8</th><td>84458202</td><td>M</td><td>13.71</td><td>20.83</td><td>90.2</td><td>577.9</td><td>0.1189</td></tr><tr><th>9</th><td>844981</td><td>M</td><td>13.0</td><td>21.82</td><td>87.5</td><td>519.8</td><td>0.1273</td></tr><tr><th>10</th><td>84501001</td><td>M</td><td>12.46</td><td>24.04</td><td>83.97</td><td>475.9</td><td>0.1186</td></tr><tr><th>11</th><td>845636</td><td>M</td><td>16.02</td><td>23.24</td><td>102.7</td><td>797.8</td><td>0.08206</td></tr><tr><th>12</th><td>84610002</td><td>M</td><td>15.78</td><td>17.89</td><td>103.6</td><td>781.0</td><td>0.0971</td></tr><tr><th>13</th><td>846226</td><td>M</td><td>19.17</td><td>24.8</td><td>132.4</td><td>1123.0</td><td>0.0974</td></tr><tr><th>14</th><td>846381</td><td>M</td><td>15.85</td><td>23.95</td><td>103.7</td><td>782.7</td><td>0.08401</td></tr><tr><th>15</th><td>84667401</td><td>M</td><td>13.73</td><td>22.61</td><td>93.6</td><td>578.3</td><td>0.1131</td></tr><tr><th>16</th><td>84799002</td><td>M</td><td>14.54</td><td>27.54</td><td>96.73</td><td>658.8</td><td>0.1139</td></tr><tr><th>17</th><td>848406</td><td>M</td><td>14.68</td><td>20.13</td><td>94.74</td><td>684.5</td><td>0.09867</td></tr><tr><th>18</th><td>84862001</td><td>M</td><td>16.13</td><td>20.68</td><td>108.1</td><td>798.8</td><td>0.117</td></tr><tr><th>19</th><td>849014</td><td>M</td><td>19.81</td><td>22.15</td><td>130.0</td><td>1260.0</td><td>0.09831</td></tr><tr><th>20</th><td>8510426</td><td>B</td><td>13.54</td><td>14.36</td><td>87.46</td><td>566.3</td><td>0.09779</td></tr><tr><th>21</th><td>8510653</td><td>B</td><td>13.08</td><td>15.71</td><td>85.63</td><td>520.0</td><td>0.1075</td></tr><tr><th>22</th><td>8510824</td><td>B</td><td>9.504</td><td>12.44</td><td>60.34</td><td>273.9</td><td>0.1024</td></tr><tr><th>23</th><td>8511133</td><td>M</td><td>15.34</td><td>14.26</td><td>102.5</td><td>704.4</td><td>0.1073</td></tr><tr><th>24</th><td>851509</td><td>M</td><td>21.16</td><td>23.04</td><td>137.2</td><td>1404.0</td><td>0.09428</td></tr><tr><th>25</th><td>852552</td><td>M</td><td>16.65</td><td>21.38</td><td>110.0</td><td>904.6</td><td>0.1121</td></tr><tr><th>26</th><td>852631</td><td>M</td><td>17.14</td><td>16.4</td><td>116.0</td><td>912.7</td><td>0.1186</td></tr><tr><th>27</th><td>852763</td><td>M</td><td>14.58</td><td>21.53</td><td>97.41</td><td>644.8</td><td>0.1054</td></tr><tr><th>28</th><td>852781</td><td>M</td><td>18.61</td><td>20.25</td><td>122.1</td><td>1094.0</td><td>0.0944</td></tr><tr><th>29</th><td>852973</td><td>M</td><td>15.3</td><td>25.27</td><td>102.4</td><td>732.4</td><td>0.1082</td></tr><tr><th>30</th><td>853201</td><td>M</td><td>17.57</td><td>15.05</td><td>115.0</td><td>955.1</td><td>0.09847</td></tr><tr><th>31</th><td>853401</td><td>M</td><td>18.63</td><td>25.11</td><td>124.8</td><td>1088.0</td><td>0.1064</td></tr><tr><th>32</th><td>853612</td><td>M</td><td>11.84</td><td>18.7</td><td>77.93</td><td>440.6</td><td>0.1109</td></tr><tr><th>33</th><td>85382601</td><td>M</td><td>17.02</td><td>23.98</td><td>112.8</td><td>899.3</td><td>0.1197</td></tr><tr><th>34</th><td>854002</td><td>M</td><td>19.27</td><td>26.47</td><td>127.9</td><td>1162.0</td><td>0.09401</td></tr><tr><th>35</th><td>854039</td><td>M</td><td>16.13</td><td>17.88</td><td>107.0</td><td>807.2</td><td>0.104</td></tr><tr><th>36</th><td>854253</td><td>M</td><td>16.74</td><td>21.59</td><td>110.1</td><td>869.5</td><td>0.0961</td></tr><tr><th>37</th><td>854268</td><td>M</td><td>14.25</td><td>21.72</td><td>93.63</td><td>633.0</td><td>0.09823</td></tr><tr><th>38</th><td>854941</td><td>B</td><td>13.03</td><td>18.42</td><td>82.61</td><td>523.8</td><td>0.08983</td></tr><tr><th>39</th><td>855133</td><td>M</td><td>14.99</td><td>25.2</td><td>95.54</td><td>698.8</td><td>0.09387</td></tr><tr><th>40</th><td>855138</td><td>M</td><td>13.48</td><td>20.82</td><td>88.4</td><td>559.2</td><td>0.1016</td></tr><tr><th>41</th><td>855167</td><td>M</td><td>13.44</td><td>21.58</td><td>86.18</td><td>563.0</td><td>0.08162</td></tr><tr><th>42</th><td>855563</td><td>M</td><td>10.95</td><td>21.35</td><td>71.9</td><td>371.1</td><td>0.1227</td></tr><tr><th>43</th><td>855625</td><td>M</td><td>19.07</td><td>24.81</td><td>128.3</td><td>1104.0</td><td>0.09081</td></tr><tr><th>44</th><td>856106</td><td>M</td><td>13.28</td><td>20.28</td><td>87.32</td><td>545.2</td><td>0.1041</td></tr><tr><th>45</th><td>85638502</td><td>M</td><td>13.17</td><td>21.81</td><td>85.42</td><td>531.5</td><td>0.09714</td></tr><tr><th>46</th><td>857010</td><td>M</td><td>18.65</td><td>17.6</td><td>123.7</td><td>1076.0</td><td>0.1099</td></tr><tr><th>47</th><td>85713702</td><td>B</td><td>8.196</td><td>16.84</td><td>51.71</td><td>201.9</td><td>0.086</td></tr><tr><th>48</th><td>85715</td><td>M</td><td>13.17</td><td>18.66</td><td>85.98</td><td>534.6</td><td>0.1158</td></tr><tr><th>49</th><td>857155</td><td>B</td><td>12.05</td><td>14.63</td><td>78.04</td><td>449.3</td><td>0.1031</td></tr><tr><th>50</th><td>857156</td><td>B</td><td>13.49</td><td>22.3</td><td>86.91</td><td>561.0</td><td>0.08752</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& id & diagnosis & radius\\_mean & texture\\_mean & perimeter\\_mean & area\\_mean & smoothness\\_mean & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 842302 & M & 17.99 & 10.38 & 122.8 & 1001.0 & 0.1184 & $\\dots$ \\\\\n",
       "\t2 & 842517 & M & 20.57 & 17.77 & 132.9 & 1326.0 & 0.08474 & $\\dots$ \\\\\n",
       "\t3 & 84300903 & M & 19.69 & 21.25 & 130.0 & 1203.0 & 0.1096 & $\\dots$ \\\\\n",
       "\t4 & 84348301 & M & 11.42 & 20.38 & 77.58 & 386.1 & 0.1425 & $\\dots$ \\\\\n",
       "\t5 & 84358402 & M & 20.29 & 14.34 & 135.1 & 1297.0 & 0.1003 & $\\dots$ \\\\\n",
       "\t6 & 843786 & M & 12.45 & 15.7 & 82.57 & 477.1 & 0.1278 & $\\dots$ \\\\\n",
       "\t7 & 844359 & M & 18.25 & 19.98 & 119.6 & 1040.0 & 0.09463 & $\\dots$ \\\\\n",
       "\t8 & 84458202 & M & 13.71 & 20.83 & 90.2 & 577.9 & 0.1189 & $\\dots$ \\\\\n",
       "\t9 & 844981 & M & 13.0 & 21.82 & 87.5 & 519.8 & 0.1273 & $\\dots$ \\\\\n",
       "\t10 & 84501001 & M & 12.46 & 24.04 & 83.97 & 475.9 & 0.1186 & $\\dots$ \\\\\n",
       "\t11 & 845636 & M & 16.02 & 23.24 & 102.7 & 797.8 & 0.08206 & $\\dots$ \\\\\n",
       "\t12 & 84610002 & M & 15.78 & 17.89 & 103.6 & 781.0 & 0.0971 & $\\dots$ \\\\\n",
       "\t13 & 846226 & M & 19.17 & 24.8 & 132.4 & 1123.0 & 0.0974 & $\\dots$ \\\\\n",
       "\t14 & 846381 & M & 15.85 & 23.95 & 103.7 & 782.7 & 0.08401 & $\\dots$ \\\\\n",
       "\t15 & 84667401 & M & 13.73 & 22.61 & 93.6 & 578.3 & 0.1131 & $\\dots$ \\\\\n",
       "\t16 & 84799002 & M & 14.54 & 27.54 & 96.73 & 658.8 & 0.1139 & $\\dots$ \\\\\n",
       "\t17 & 848406 & M & 14.68 & 20.13 & 94.74 & 684.5 & 0.09867 & $\\dots$ \\\\\n",
       "\t18 & 84862001 & M & 16.13 & 20.68 & 108.1 & 798.8 & 0.117 & $\\dots$ \\\\\n",
       "\t19 & 849014 & M & 19.81 & 22.15 & 130.0 & 1260.0 & 0.09831 & $\\dots$ \\\\\n",
       "\t20 & 8510426 & B & 13.54 & 14.36 & 87.46 & 566.3 & 0.09779 & $\\dots$ \\\\\n",
       "\t21 & 8510653 & B & 13.08 & 15.71 & 85.63 & 520.0 & 0.1075 & $\\dots$ \\\\\n",
       "\t22 & 8510824 & B & 9.504 & 12.44 & 60.34 & 273.9 & 0.1024 & $\\dots$ \\\\\n",
       "\t23 & 8511133 & M & 15.34 & 14.26 & 102.5 & 704.4 & 0.1073 & $\\dots$ \\\\\n",
       "\t24 & 851509 & M & 21.16 & 23.04 & 137.2 & 1404.0 & 0.09428 & $\\dots$ \\\\\n",
       "\t25 & 852552 & M & 16.65 & 21.38 & 110.0 & 904.6 & 0.1121 & $\\dots$ \\\\\n",
       "\t26 & 852631 & M & 17.14 & 16.4 & 116.0 & 912.7 & 0.1186 & $\\dots$ \\\\\n",
       "\t27 & 852763 & M & 14.58 & 21.53 & 97.41 & 644.8 & 0.1054 & $\\dots$ \\\\\n",
       "\t28 & 852781 & M & 18.61 & 20.25 & 122.1 & 1094.0 & 0.0944 & $\\dots$ \\\\\n",
       "\t29 & 852973 & M & 15.3 & 25.27 & 102.4 & 732.4 & 0.1082 & $\\dots$ \\\\\n",
       "\t30 & 853201 & M & 17.57 & 15.05 & 115.0 & 955.1 & 0.09847 & $\\dots$ \\\\\n",
       "\t31 & 853401 & M & 18.63 & 25.11 & 124.8 & 1088.0 & 0.1064 & $\\dots$ \\\\\n",
       "\t32 & 853612 & M & 11.84 & 18.7 & 77.93 & 440.6 & 0.1109 & $\\dots$ \\\\\n",
       "\t33 & 85382601 & M & 17.02 & 23.98 & 112.8 & 899.3 & 0.1197 & $\\dots$ \\\\\n",
       "\t34 & 854002 & M & 19.27 & 26.47 & 127.9 & 1162.0 & 0.09401 & $\\dots$ \\\\\n",
       "\t35 & 854039 & M & 16.13 & 17.88 & 107.0 & 807.2 & 0.104 & $\\dots$ \\\\\n",
       "\t36 & 854253 & M & 16.74 & 21.59 & 110.1 & 869.5 & 0.0961 & $\\dots$ \\\\\n",
       "\t37 & 854268 & M & 14.25 & 21.72 & 93.63 & 633.0 & 0.09823 & $\\dots$ \\\\\n",
       "\t38 & 854941 & B & 13.03 & 18.42 & 82.61 & 523.8 & 0.08983 & $\\dots$ \\\\\n",
       "\t39 & 855133 & M & 14.99 & 25.2 & 95.54 & 698.8 & 0.09387 & $\\dots$ \\\\\n",
       "\t40 & 855138 & M & 13.48 & 20.82 & 88.4 & 559.2 & 0.1016 & $\\dots$ \\\\\n",
       "\t41 & 855167 & M & 13.44 & 21.58 & 86.18 & 563.0 & 0.08162 & $\\dots$ \\\\\n",
       "\t42 & 855563 & M & 10.95 & 21.35 & 71.9 & 371.1 & 0.1227 & $\\dots$ \\\\\n",
       "\t43 & 855625 & M & 19.07 & 24.81 & 128.3 & 1104.0 & 0.09081 & $\\dots$ \\\\\n",
       "\t44 & 856106 & M & 13.28 & 20.28 & 87.32 & 545.2 & 0.1041 & $\\dots$ \\\\\n",
       "\t45 & 85638502 & M & 13.17 & 21.81 & 85.42 & 531.5 & 0.09714 & $\\dots$ \\\\\n",
       "\t46 & 857010 & M & 18.65 & 17.6 & 123.7 & 1076.0 & 0.1099 & $\\dots$ \\\\\n",
       "\t47 & 85713702 & B & 8.196 & 16.84 & 51.71 & 201.9 & 0.086 & $\\dots$ \\\\\n",
       "\t48 & 85715 & M & 13.17 & 18.66 & 85.98 & 534.6 & 0.1158 & $\\dots$ \\\\\n",
       "\t49 & 857155 & B & 12.05 & 14.63 & 78.04 & 449.3 & 0.1031 & $\\dots$ \\\\\n",
       "\t50 & 857156 & B & 13.49 & 22.3 & 86.91 & 561.0 & 0.08752 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "56933 DataFrame. Omitted printing of 28 columns\n",
       " Row  id        diagnosis  radius_mean  texture_mean  perimeter_mean \n",
       "      \u001b[90mInt64\u001b[39m     \u001b[90mString\u001b[39m     \u001b[90mFloat64\u001b[39m      \u001b[90mFloat64\u001b[39m       \u001b[90mFloat64\u001b[39m        \n",
       "\n",
       " 1    842302    M          17.99        10.38         122.8          \n",
       " 2    842517    M          20.57        17.77         132.9          \n",
       " 3    84300903  M          19.69        21.25         130.0          \n",
       " 4    84348301  M          11.42        20.38         77.58          \n",
       " 5    84358402  M          20.29        14.34         135.1          \n",
       " 6    843786    M          12.45        15.7          82.57          \n",
       " 7    844359    M          18.25        19.98         119.6          \n",
       " 8    84458202  M          13.71        20.83         90.2           \n",
       " 9    844981    M          13.0         21.82         87.5           \n",
       " 10   84501001  M          12.46        24.04         83.97          \n",
       " 11   845636    M          16.02        23.24         102.7          \n",
       " 12   84610002  M          15.78        17.89         103.6          \n",
       " 13   846226    M          19.17        24.8          132.4          \n",
       " 14   846381    M          15.85        23.95         103.7          \n",
       " 15   84667401  M          13.73        22.61         93.6           \n",
       " 16   84799002  M          14.54        27.54         96.73          \n",
       " 17   848406    M          14.68        20.13         94.74          \n",
       " 18   84862001  M          16.13        20.68         108.1          \n",
       " 19   849014    M          19.81        22.15         130.0          \n",
       " 20   8510426   B          13.54        14.36         87.46          \n",
       "\n",
       " 549  923169    B          9.683        19.34         61.05          \n",
       " 550  923465    B          10.82        24.21         68.89          \n",
       " 551  923748    B          10.86        21.48         68.51          \n",
       " 552  923780    B          11.13        22.44         71.49          \n",
       " 553  924084    B          12.77        29.43         81.35          \n",
       " 554  924342    B          9.333        21.94         59.01          \n",
       " 555  924632    B          12.88        28.92         82.5           \n",
       " 556  924934    B          10.29        27.61         65.67          \n",
       " 557  924964    B          10.16        19.59         64.73          \n",
       " 558  925236    B          9.423        27.88         59.26          \n",
       " 559  925277    B          14.59        22.68         96.39          \n",
       " 560  925291    B          11.51        23.93         74.52          \n",
       " 561  925292    B          14.05        27.15         91.38          \n",
       " 562  925311    B          11.2         29.37         70.67          \n",
       " 563  925622    M          15.22        30.62         103.4          \n",
       " 564  926125    M          20.92        25.09         143.0          \n",
       " 565  926424    M          21.56        22.39         142.0          \n",
       " 566  926682    M          20.13        28.25         131.2          \n",
       " 567  926954    M          16.6         28.08         108.3          \n",
       " 568  927241    M          20.6         29.33         140.1          \n",
       " 569  92751     B          7.76         24.54         47.92          "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = CSV.read(\"./data_cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th><th>nunique</th><th>nmissing</th></tr><tr><th></th><th>Symbol</th><th>Union</th><th>Any</th><th>Union</th><th>Any</th><th>Union</th><th>Nothing</th></tr></thead><tbody><p>31 rows  8 columns (omitted printing of 1 columns)</p><tr><th>1</th><td>diagnosis</td><td></td><td>B</td><td></td><td>M</td><td>2</td><td></td></tr><tr><th>2</th><td>radius_mean</td><td>14.1273</td><td>6.981</td><td>13.37</td><td>28.11</td><td></td><td></td></tr><tr><th>3</th><td>texture_mean</td><td>19.2896</td><td>9.71</td><td>18.84</td><td>39.28</td><td></td><td></td></tr><tr><th>4</th><td>perimeter_mean</td><td>91.969</td><td>43.79</td><td>86.24</td><td>188.5</td><td></td><td></td></tr><tr><th>5</th><td>area_mean</td><td>654.889</td><td>143.5</td><td>551.1</td><td>2501.0</td><td></td><td></td></tr><tr><th>6</th><td>smoothness_mean</td><td>0.0963603</td><td>0.05263</td><td>0.09587</td><td>0.1634</td><td></td><td></td></tr><tr><th>7</th><td>compactness_mean</td><td>0.104341</td><td>0.01938</td><td>0.09263</td><td>0.3454</td><td></td><td></td></tr><tr><th>8</th><td>concavity_mean</td><td>0.0887993</td><td>0.0</td><td>0.06154</td><td>0.4268</td><td></td><td></td></tr><tr><th>9</th><td>concave points_mean</td><td>0.0489191</td><td>0.0</td><td>0.0335</td><td>0.2012</td><td></td><td></td></tr><tr><th>10</th><td>symmetry_mean</td><td>0.181162</td><td>0.106</td><td>0.1792</td><td>0.304</td><td></td><td></td></tr><tr><th>11</th><td>fractal_dimension_mean</td><td>0.0627976</td><td>0.04996</td><td>0.06154</td><td>0.09744</td><td></td><td></td></tr><tr><th>12</th><td>radius_se</td><td>0.405172</td><td>0.1115</td><td>0.3242</td><td>2.873</td><td></td><td></td></tr><tr><th>13</th><td>texture_se</td><td>1.21685</td><td>0.3602</td><td>1.108</td><td>4.885</td><td></td><td></td></tr><tr><th>14</th><td>perimeter_se</td><td>2.86606</td><td>0.757</td><td>2.287</td><td>21.98</td><td></td><td></td></tr><tr><th>15</th><td>area_se</td><td>40.3371</td><td>6.802</td><td>24.53</td><td>542.2</td><td></td><td></td></tr><tr><th>16</th><td>smoothness_se</td><td>0.00704098</td><td>0.001713</td><td>0.00638</td><td>0.03113</td><td></td><td></td></tr><tr><th>17</th><td>compactness_se</td><td>0.0254781</td><td>0.002252</td><td>0.02045</td><td>0.1354</td><td></td><td></td></tr><tr><th>18</th><td>concavity_se</td><td>0.0318937</td><td>0.0</td><td>0.02589</td><td>0.396</td><td></td><td></td></tr><tr><th>19</th><td>concave points_se</td><td>0.0117961</td><td>0.0</td><td>0.01093</td><td>0.05279</td><td></td><td></td></tr><tr><th>20</th><td>symmetry_se</td><td>0.0205423</td><td>0.007882</td><td>0.01873</td><td>0.07895</td><td></td><td></td></tr><tr><th>21</th><td>fractal_dimension_se</td><td>0.0037949</td><td>0.0008948</td><td>0.003187</td><td>0.02984</td><td></td><td></td></tr><tr><th>22</th><td>radius_worst</td><td>16.2692</td><td>7.93</td><td>14.97</td><td>36.04</td><td></td><td></td></tr><tr><th>23</th><td>texture_worst</td><td>25.6772</td><td>12.02</td><td>25.41</td><td>49.54</td><td></td><td></td></tr><tr><th>24</th><td>perimeter_worst</td><td>107.261</td><td>50.41</td><td>97.66</td><td>251.2</td><td></td><td></td></tr><tr><th>25</th><td>area_worst</td><td>880.583</td><td>185.2</td><td>686.5</td><td>4254.0</td><td></td><td></td></tr><tr><th>26</th><td>smoothness_worst</td><td>0.132369</td><td>0.07117</td><td>0.1313</td><td>0.2226</td><td></td><td></td></tr><tr><th>27</th><td>compactness_worst</td><td>0.254265</td><td>0.02729</td><td>0.2119</td><td>1.058</td><td></td><td></td></tr><tr><th>28</th><td>concavity_worst</td><td>0.272188</td><td>0.0</td><td>0.2267</td><td>1.252</td><td></td><td></td></tr><tr><th>29</th><td>concave points_worst</td><td>0.114606</td><td>0.0</td><td>0.09993</td><td>0.291</td><td></td><td></td></tr><tr><th>30</th><td>symmetry_worst</td><td>0.290076</td><td>0.1565</td><td>0.2822</td><td>0.6638</td><td></td><td></td></tr><tr><th>31</th><td>fractal_dimension_worst</td><td>0.0839458</td><td>0.05504</td><td>0.08004</td><td>0.2075</td><td></td><td></td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& variable & mean & min & median & max & nunique & nmissing & \\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Union & Any & Union & Any & Union & Nothing & \\\\\n",
       "\t\\hline\n",
       "\t1 & diagnosis &  & B &  & M & 2 &  & $\\dots$ \\\\\n",
       "\t2 & radius\\_mean & 14.1273 & 6.981 & 13.37 & 28.11 &  &  & $\\dots$ \\\\\n",
       "\t3 & texture\\_mean & 19.2896 & 9.71 & 18.84 & 39.28 &  &  & $\\dots$ \\\\\n",
       "\t4 & perimeter\\_mean & 91.969 & 43.79 & 86.24 & 188.5 &  &  & $\\dots$ \\\\\n",
       "\t5 & area\\_mean & 654.889 & 143.5 & 551.1 & 2501.0 &  &  & $\\dots$ \\\\\n",
       "\t6 & smoothness\\_mean & 0.0963603 & 0.05263 & 0.09587 & 0.1634 &  &  & $\\dots$ \\\\\n",
       "\t7 & compactness\\_mean & 0.104341 & 0.01938 & 0.09263 & 0.3454 &  &  & $\\dots$ \\\\\n",
       "\t8 & concavity\\_mean & 0.0887993 & 0.0 & 0.06154 & 0.4268 &  &  & $\\dots$ \\\\\n",
       "\t9 & concave points\\_mean & 0.0489191 & 0.0 & 0.0335 & 0.2012 &  &  & $\\dots$ \\\\\n",
       "\t10 & symmetry\\_mean & 0.181162 & 0.106 & 0.1792 & 0.304 &  &  & $\\dots$ \\\\\n",
       "\t11 & fractal\\_dimension\\_mean & 0.0627976 & 0.04996 & 0.06154 & 0.09744 &  &  & $\\dots$ \\\\\n",
       "\t12 & radius\\_se & 0.405172 & 0.1115 & 0.3242 & 2.873 &  &  & $\\dots$ \\\\\n",
       "\t13 & texture\\_se & 1.21685 & 0.3602 & 1.108 & 4.885 &  &  & $\\dots$ \\\\\n",
       "\t14 & perimeter\\_se & 2.86606 & 0.757 & 2.287 & 21.98 &  &  & $\\dots$ \\\\\n",
       "\t15 & area\\_se & 40.3371 & 6.802 & 24.53 & 542.2 &  &  & $\\dots$ \\\\\n",
       "\t16 & smoothness\\_se & 0.00704098 & 0.001713 & 0.00638 & 0.03113 &  &  & $\\dots$ \\\\\n",
       "\t17 & compactness\\_se & 0.0254781 & 0.002252 & 0.02045 & 0.1354 &  &  & $\\dots$ \\\\\n",
       "\t18 & concavity\\_se & 0.0318937 & 0.0 & 0.02589 & 0.396 &  &  & $\\dots$ \\\\\n",
       "\t19 & concave points\\_se & 0.0117961 & 0.0 & 0.01093 & 0.05279 &  &  & $\\dots$ \\\\\n",
       "\t20 & symmetry\\_se & 0.0205423 & 0.007882 & 0.01873 & 0.07895 &  &  & $\\dots$ \\\\\n",
       "\t21 & fractal\\_dimension\\_se & 0.0037949 & 0.0008948 & 0.003187 & 0.02984 &  &  & $\\dots$ \\\\\n",
       "\t22 & radius\\_worst & 16.2692 & 7.93 & 14.97 & 36.04 &  &  & $\\dots$ \\\\\n",
       "\t23 & texture\\_worst & 25.6772 & 12.02 & 25.41 & 49.54 &  &  & $\\dots$ \\\\\n",
       "\t24 & perimeter\\_worst & 107.261 & 50.41 & 97.66 & 251.2 &  &  & $\\dots$ \\\\\n",
       "\t25 & area\\_worst & 880.583 & 185.2 & 686.5 & 4254.0 &  &  & $\\dots$ \\\\\n",
       "\t26 & smoothness\\_worst & 0.132369 & 0.07117 & 0.1313 & 0.2226 &  &  & $\\dots$ \\\\\n",
       "\t27 & compactness\\_worst & 0.254265 & 0.02729 & 0.2119 & 1.058 &  &  & $\\dots$ \\\\\n",
       "\t28 & concavity\\_worst & 0.272188 & 0.0 & 0.2267 & 1.252 &  &  & $\\dots$ \\\\\n",
       "\t29 & concave points\\_worst & 0.114606 & 0.0 & 0.09993 & 0.291 &  &  & $\\dots$ \\\\\n",
       "\t30 & symmetry\\_worst & 0.290076 & 0.1565 & 0.2822 & 0.6638 &  &  & $\\dots$ \\\\\n",
       "\t31 & fractal\\_dimension\\_worst & 0.0839458 & 0.05504 & 0.08004 & 0.2075 &  &  & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "318 DataFrame. Omitted printing of 3 columns\n",
       " Row  variable                 mean        min        median    max     \n",
       "      \u001b[90mSymbol\u001b[39m                   \u001b[90mUnion\u001b[39m      \u001b[90mAny\u001b[39m        \u001b[90mUnion\u001b[39m    \u001b[90mAny\u001b[39m     \n",
       "\n",
       " 1    diagnosis                            B                    M       \n",
       " 2    radius_mean              14.1273     6.981      13.37     28.11   \n",
       " 3    texture_mean             19.2896     9.71       18.84     39.28   \n",
       " 4    perimeter_mean           91.969      43.79      86.24     188.5   \n",
       " 5    area_mean                654.889     143.5      551.1     2501.0  \n",
       " 6    smoothness_mean          0.0963603   0.05263    0.09587   0.1634  \n",
       " 7    compactness_mean         0.104341    0.01938    0.09263   0.3454  \n",
       " 8    concavity_mean           0.0887993   0.0        0.06154   0.4268  \n",
       " 9    concave points_mean      0.0489191   0.0        0.0335    0.2012  \n",
       " 10   symmetry_mean            0.181162    0.106      0.1792    0.304   \n",
       " 11   fractal_dimension_mean   0.0627976   0.04996    0.06154   0.09744 \n",
       " 12   radius_se                0.405172    0.1115     0.3242    2.873   \n",
       " 13   texture_se               1.21685     0.3602     1.108     4.885   \n",
       " 14   perimeter_se             2.86606     0.757      2.287     21.98   \n",
       " 15   area_se                  40.3371     6.802      24.53     542.2   \n",
       " 16   smoothness_se            0.00704098  0.001713   0.00638   0.03113 \n",
       " 17   compactness_se           0.0254781   0.002252   0.02045   0.1354  \n",
       " 18   concavity_se             0.0318937   0.0        0.02589   0.396   \n",
       " 19   concave points_se        0.0117961   0.0        0.01093   0.05279 \n",
       " 20   symmetry_se              0.0205423   0.007882   0.01873   0.07895 \n",
       " 21   fractal_dimension_se     0.0037949   0.0008948  0.003187  0.02984 \n",
       " 22   radius_worst             16.2692     7.93       14.97     36.04   \n",
       " 23   texture_worst            25.6772     12.02      25.41     49.54   \n",
       " 24   perimeter_worst          107.261     50.41      97.66     251.2   \n",
       " 25   area_worst               880.583     185.2      686.5     4254.0  \n",
       " 26   smoothness_worst         0.132369    0.07117    0.1313    0.2226  \n",
       " 27   compactness_worst        0.254265    0.02729    0.2119    1.058   \n",
       " 28   concavity_worst          0.272188    0.0        0.2267    1.252   \n",
       " 29   concave points_worst     0.114606    0.0        0.09993   0.291   \n",
       " 30   symmetry_worst           0.290076    0.1565     0.2822    0.6638  \n",
       " 31   fractal_dimension_worst  0.0839458   0.05504    0.08004   0.2075  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[:, Not([33, 1])]\n",
    "describe(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[22m _.names                 \u001b[0m\u001b[0m\u001b[22m _.types                         \u001b[0m\u001b[0m\u001b[22m _.scitypes    \u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "\u001b[0m diagnosis               \u001b[0m\u001b[0m CategoricalValue{String,UInt32} \u001b[0m\u001b[0m Multiclass{2} \u001b[0m\u001b[0m\n",
       "\u001b[0m radius_mean             \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m texture_mean            \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m perimeter_mean          \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m area_mean               \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m smoothness_mean         \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m compactness_mean        \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m concavity_mean          \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m concave points_mean     \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m symmetry_mean           \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m fractal_dimension_mean  \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m radius_se               \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m texture_se              \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m perimeter_se            \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m area_se                 \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m smoothness_se           \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m compactness_se          \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m concavity_se            \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m concave points_se       \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m symmetry_se             \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m fractal_dimension_se    \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m radius_worst            \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m texture_worst           \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m perimeter_worst         \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m area_worst              \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m smoothness_worst        \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m compactness_worst       \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m concavity_worst         \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m concave points_worst    \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m symmetry_worst          \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m fractal_dimension_worst \u001b[0m\u001b[0m Float64                         \u001b[0m\u001b[0m Continuous    \u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "_.nrows = 569\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coerce!(data, :diagnosis=>Multiclass)\n",
    "schema(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CategoricalValue{String,UInt32}[\"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\"    \"B\", \"B\", \"B\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"B\"], 56930 DataFrame. Omitted printing of 26 columns\n",
       " Row  radius_mean  texture_mean  perimeter_mean  area_mean \n",
       "      \u001b[90mFloat64\u001b[39m      \u001b[90mFloat64\u001b[39m       \u001b[90mFloat64\u001b[39m         \u001b[90mFloat64\u001b[39m   \n",
       "\n",
       " 1    17.99        10.38         122.8           1001.0    \n",
       " 2    20.57        17.77         132.9           1326.0    \n",
       " 3    19.69        21.25         130.0           1203.0    \n",
       " 4    11.42        20.38         77.58           386.1     \n",
       " 5    20.29        14.34         135.1           1297.0    \n",
       " 6    12.45        15.7          82.57           477.1     \n",
       " 7    18.25        19.98         119.6           1040.0    \n",
       " 8    13.71        20.83         90.2            577.9     \n",
       " 9    13.0         21.82         87.5            519.8     \n",
       " 10   12.46        24.04         83.97           475.9     \n",
       " 11   16.02        23.24         102.7           797.8     \n",
       " 12   15.78        17.89         103.6           781.0     \n",
       " 13   19.17        24.8          132.4           1123.0    \n",
       " 14   15.85        23.95         103.7           782.7     \n",
       " 15   13.73        22.61         93.6            578.3     \n",
       " 16   14.54        27.54         96.73           658.8     \n",
       " 17   14.68        20.13         94.74           684.5     \n",
       " 18   16.13        20.68         108.1           798.8     \n",
       " 19   19.81        22.15         130.0           1260.0    \n",
       " 20   13.54        14.36         87.46           566.3     \n",
       "\n",
       " 549  9.683        19.34         61.05           285.7     \n",
       " 550  10.82        24.21         68.89           361.6     \n",
       " 551  10.86        21.48         68.51           360.5     \n",
       " 552  11.13        22.44         71.49           378.4     \n",
       " 553  12.77        29.43         81.35           507.9     \n",
       " 554  9.333        21.94         59.01           264.0     \n",
       " 555  12.88        28.92         82.5            514.3     \n",
       " 556  10.29        27.61         65.67           321.4     \n",
       " 557  10.16        19.59         64.73           311.7     \n",
       " 558  9.423        27.88         59.26           271.3     \n",
       " 559  14.59        22.68         96.39           657.1     \n",
       " 560  11.51        23.93         74.52           403.5     \n",
       " 561  14.05        27.15         91.38           600.4     \n",
       " 562  11.2         29.37         70.67           386.0     \n",
       " 563  15.22        30.62         103.4           716.9     \n",
       " 564  20.92        25.09         143.0           1347.0    \n",
       " 565  21.56        22.39         142.0           1479.0    \n",
       " 566  20.13        28.25         131.2           1261.0    \n",
       " 567  16.6         28.08         108.3           858.1     \n",
       " 568  20.6         29.33         140.1           1265.0    \n",
       " 569  7.76         24.54         47.92           181.0     )"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, X = unpack(data, ==(:diagnosis), colname->true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([479, 495, 486, 419, 541, 331, 189, 394, 172, 548    431, 367, 288, 254, 198, 162, 228, 271, 534, 373], [120, 324, 449, 444, 54, 25, 498, 184, 480, 442    284, 240, 210, 511, 23, 388, 383, 199, 104, 425])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data to use when trying to fit a single validation set\n",
    "train, test = partition(eachindex(y), 0.7, shuffle=true) # gives 70:30 split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Five Learning Algorithms\n",
    "\n",
    "* Decision trees with some form of pruning\n",
    "* Neural networks\n",
    "* Boosting\n",
    "* Support Vector Machines\n",
    "* k-nearest neighbors\n",
    "\n",
    "\n",
    "##### Testing\n",
    "* Implement the algorithms\n",
    "* Design two *interesting* classification problems. For the purposes of this assignment, a classification problem is just a set of training examples and a set of test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43-element Array{NamedTuple{(:name, :package_name, :is_supervised, :docstring, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :is_pure_julia, :is_wrapper, :load_path, :package_license, :package_url, :package_uuid, :prediction_type, :supports_online, :supports_weights, :input_scitype, :target_scitype, :output_scitype),T} where T<:Tuple,1}:\n",
       " (name = AdaBoostClassifier, package_name = ScikitLearn, ... )\n",
       " (name = AdaBoostStumpClassifier, package_name = DecisionTree, ... )\n",
       " (name = BaggingClassifier, package_name = ScikitLearn, ... )\n",
       " (name = BayesianLDA, package_name = MultivariateStats, ... )\n",
       " (name = BayesianLDA, package_name = ScikitLearn, ... )\n",
       " (name = BayesianQDA, package_name = ScikitLearn, ... )\n",
       " (name = BayesianSubspaceLDA, package_name = MultivariateStats, ... )\n",
       " (name = ConstantClassifier, package_name = MLJModels, ... )\n",
       " (name = DecisionTreeClassifier, package_name = DecisionTree, ... )\n",
       " (name = DeterministicConstantClassifier, package_name = MLJModels, ... )\n",
       " (name = DummyClassifier, package_name = ScikitLearn, ... )\n",
       " (name = EvoTreeClassifier, package_name = EvoTrees, ... )\n",
       " (name = ExtraTreesClassifier, package_name = ScikitLearn, ... )\n",
       " (name = GaussianNBClassifier, package_name = NaiveBayes, ... )\n",
       " (name = GaussianNBClassifier, package_name = ScikitLearn, ... )\n",
       " (name = GaussianProcessClassifier, package_name = ScikitLearn, ... )\n",
       " (name = GradientBoostingClassifier, package_name = ScikitLearn, ... )\n",
       " (name = KNNClassifier, package_name = NearestNeighbors, ... )\n",
       " (name = KNeighborsClassifier, package_name = ScikitLearn, ... )\n",
       " (name = LDA, package_name = MultivariateStats, ... )\n",
       " (name = LGBMClassifier, package_name = LightGBM, ... )\n",
       " (name = LinearBinaryClassifier, package_name = GLM, ... )\n",
       " (name = LinearSVC, package_name = LIBSVM, ... )\n",
       " (name = LogisticCVClassifier, package_name = ScikitLearn, ... )\n",
       " (name = LogisticClassifier, package_name = MLJLinearModels, ... )\n",
       " (name = LogisticClassifier, package_name = ScikitLearn, ... )\n",
       " (name = MultinomialClassifier, package_name = MLJLinearModels, ... )\n",
       " (name = NeuralNetworkClassifier, package_name = MLJFlux, ... )\n",
       " (name = NuSVC, package_name = LIBSVM, ... )\n",
       " (name = PassiveAggressiveClassifier, package_name = ScikitLearn, ... )\n",
       " (name = PerceptronClassifier, package_name = ScikitLearn, ... )\n",
       " (name = ProbabilisticSGDClassifier, package_name = ScikitLearn, ... )\n",
       " (name = RandomForestClassifier, package_name = DecisionTree, ... )\n",
       " (name = RandomForestClassifier, package_name = ScikitLearn, ... )\n",
       " (name = RidgeCVClassifier, package_name = ScikitLearn, ... )\n",
       " (name = RidgeClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SGDClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SVC, package_name = LIBSVM, ... )\n",
       " (name = SVMClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SVMLinearClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SVMNuClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SubspaceLDA, package_name = MultivariateStats, ... )\n",
       " (name = XGBoostClassifier, package_name = XGBoost, ... )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models(matching(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJModels \n",
      "import DecisionTree \n",
      "import MLJModels.DecisionTree_ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Info: Loading into module \"Main\": \n",
      " @ MLJModels /home/andrew/.julia/packages/MLJModels/5DFoi/src/loading.jl:70\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(\n",
       "    max_depth = -1,\n",
       "    min_samples_leaf = 1,\n",
       "    min_samples_split = 2,\n",
       "    min_purity_increase = 0.0,\n",
       "    n_subfeatures = 0,\n",
       "    post_prune = false,\n",
       "    merge_purity_threshold = 1.0,\n",
       "    pdf_smoothing = 0.0,\n",
       "    display_depth = 5)\u001b[34m @536\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@load DecisionTreeClassifier verbosity=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees\n",
    "* Be sure to use some form of pruning. \n",
    "* You are not required to use information gain (for example, there is something called the GINI index that is sometimes used) to split attributes, but you should describe whatever it is that you do use.\n",
    "\n",
    "1. https://alan-turing-institute.github.io/MLJ.jl/dev/transformers/#MLJModels.UnivariateDiscretizer\n",
    "1. https://alan-turing-institute.github.io/MLJ.jl/dev/getting_started/#Getting-Started-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No post-pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(\n",
       "    max_depth = -1,\n",
       "    min_samples_leaf = 1,\n",
       "    min_samples_split = 2,\n",
       "    min_purity_increase = 0.0,\n",
       "    n_subfeatures = 0,\n",
       "    post_prune = false,\n",
       "    merge_purity_threshold = 1.0,\n",
       "    pdf_smoothing = 0.0,\n",
       "    display_depth = 8)\u001b[34m @978\u001b[39m"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(post_prune=false, display_depth=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @608\u001b[39m trained 0 times.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @740\u001b[39m  `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @040\u001b[39m  `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tree = machine(dt, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 21, Threshold 16.795\n",
      "L-> Feature 28, Threshold 0.13595\n",
      "    L-> Feature 2, Threshold 21.435000000000002\n",
      "        L-> 1 : 185/185\n",
      "        R-> Feature 14, Threshold 37.0\n",
      "            L-> Feature 25, Threshold 0.14015\n",
      "                L-> 1 : 36/36\n",
      "                R-> Feature 25, Threshold 0.14355\n",
      "                    L-> 2 : 1/1\n",
      "                    R-> 1 : 4/4\n",
      "            R-> Feature 2, Threshold 26.67\n",
      "                L-> 2 : 2/2\n",
      "                R-> 1 : 1/1\n",
      "    R-> Feature 2, Threshold 20.299999999999997\n",
      "        L-> Feature 25, Threshold 0.13985\n",
      "            L-> 1 : 7/7\n",
      "            R-> Feature 23, Threshold 99.72999999999999\n",
      "                L-> 1 : 3/3\n",
      "                R-> 2 : 6/6\n",
      "        R-> 2 : 14/14\n",
      "R-> Feature 2, Threshold 14.99\n",
      "    L-> Feature 29, Threshold 0.29695\n",
      "        L-> 1 : 4/4\n",
      "        R-> 2 : 2/2\n",
      "    R-> Feature 27, Threshold 0.17975000000000002\n",
      "        L-> Feature 11, Threshold 0.35919999999999996\n",
      "            L-> 1 : 1/1\n",
      "            R-> 2 : 3/3\n",
      "        R-> 2 : 129/129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Info: Training \u001b[34mMachine{DecisionTreeClassifier} @608\u001b[39m.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/machines.jl:322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @608\u001b[39m trained 1 time.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @740\u001b[39m  `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @040\u001b[39m  `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(Tree, rows=train, verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = predict(Tree, X[test,:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7401607839679705"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(y, y[test]) |> mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9239766081871345"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(y, y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 6 folds: 100%[=========================] Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[22m _.measure     \u001b[0m\u001b[0m\u001b[22m _.measurement \u001b[0m\u001b[0m\u001b[22m _.per_fold                                 \u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "\u001b[0m cross_entropy \u001b[0m\u001b[0m 2.22          \u001b[0m\u001b[0m [2.28, 2.66, 2.28, 2.28, 1.9, 1.92]        \u001b[0m\u001b[0m\n",
       "\u001b[0m acc           \u001b[0m\u001b[0m 0.939         \u001b[0m\u001b[0m [0.937, 0.926, 0.937, 0.937, 0.947, 0.947] \u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "_.per_observation = [[[2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 36.0, ..., 2.22e-16]], missing]\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_acc = evaluate!(Tree, resampling=CV(shuffle=true), measure=[cross_entropy, acc], verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tree = Decision Tree\n",
       "Leaves: 16\n",
       "Depth:  7,\n",
       " encoding = Dict{CategoricalValue{String,UInt32},UInt32}(\"B\" => 0x00000001,\"M\" => 0x00000002),)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_params(Tree) \n",
    "# print_tree(Tree.fitresult[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(classes_seen = CategoricalValue{String,UInt32}[\"B\", \"M\"],\n",
       " print_tree = TreePrinter object (call with display depth),)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report(Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Post-pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(\n",
       "    max_depth = -1,\n",
       "    min_samples_leaf = 1,\n",
       "    min_samples_split = 2,\n",
       "    min_purity_increase = 0.0,\n",
       "    n_subfeatures = 0,\n",
       "    post_prune = true,\n",
       "    merge_purity_threshold = 1.0,\n",
       "    pdf_smoothing = 0.0,\n",
       "    display_depth = 5)\u001b[34m @702\u001b[39m"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt2 = DecisionTreeClassifier(post_prune=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @645\u001b[39m trained 0 times.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @979\u001b[39m  `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @553\u001b[39m  `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tree2 = machine(dt2, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 21, Threshold 16.795\n",
      "L-> Feature 28, Threshold 0.13595\n",
      "    L-> Feature 2, Threshold 21.435000000000002\n",
      "        L-> 1 : 185/185\n",
      "        R-> Feature 18, Threshold 0.017410000000000002\n",
      "            L-> Feature 25, Threshold 0.14015\n",
      "                L-> 1 : 37/37\n",
      "                R-> \n",
      "            R-> Feature 25, Threshold 0.1537\n",
      "                L-> 2 : 2/2\n",
      "                R-> 1 : 1/1\n",
      "    R-> Feature 2, Threshold 20.299999999999997\n",
      "        L-> Feature 25, Threshold 0.13985\n",
      "            L-> 1 : 7/7\n",
      "            R-> Feature 23, Threshold 99.72999999999999\n",
      "                L-> 1 : 3/3\n",
      "                R-> 2 : 6/6\n",
      "        R-> 2 : 14/14\n",
      "R-> Feature 2, Threshold 14.99\n",
      "    L-> Feature 19, Threshold 0.017305\n",
      "        L-> 1 : 4/4\n",
      "        R-> 2 : 2/2\n",
      "    R-> Feature 9, Threshold 0.15\n",
      "        L-> Feature 30, Threshold 0.066435\n",
      "            L-> 1 : 1/1\n",
      "            R-> 2 : 3/3\n",
      "        R-> 2 : 129/129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Info: Training \u001b[34mMachine{DecisionTreeClassifier} @645\u001b[39m.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/machines.jl:322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @645\u001b[39m trained 1 time.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @979\u001b[39m  `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @553\u001b[39m  `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(Tree2, rows=train, verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = predict(Tree2, X[test,:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.318597586434437"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(y2, y[test]) |> mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.935672514619883"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(y2, y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 6 folds: 100%[=========================] Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[22m _.measure     \u001b[0m\u001b[0m\u001b[22m _.measurement \u001b[0m\u001b[0m\u001b[22m _.per_fold                                 \u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "\u001b[0m cross_entropy \u001b[0m\u001b[0m 2.28          \u001b[0m\u001b[0m [3.04, 3.79, 0.759, 1.52, 1.9, 2.68]       \u001b[0m\u001b[0m\n",
       "\u001b[0m acc           \u001b[0m\u001b[0m 0.937         \u001b[0m\u001b[0m [0.916, 0.895, 0.979, 0.958, 0.947, 0.926] \u001b[0m\u001b[0m\n",
       "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
       "_.per_observation = [[[2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16]], missing]\n"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_acc = evaluate!(Tree, resampling=CV(shuffle=true), measure=[cross_entropy, acc], verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tree = Decision Tree\n",
       "Leaves: 15\n",
       "Depth:  6,\n",
       " encoding = Dict{CategoricalValue{String,UInt32},UInt32}(\"B\" => 0x00000001,\"M\" => 0x00000002),)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_params(Tree2) \n",
    "# print_tree(Tree.fitresult[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(classes_seen = CategoricalValue{String,UInt32}[\"B\", \"M\"],\n",
       " print_tree = TreePrinter object (call with display depth),)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report(Tree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Info: Training \u001b[34mMachine{ProbabilisticTunedModel{Grid,}} @657\u001b[39m.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/machines.jl:322\n",
      " Info: Attempting to evaluate 101 models.\n",
      " @ MLJTuning /home/andrew/.julia/packages/MLJTuning/nuvTc/src/tuned_models.jl:501\n",
      "\u001b[33mEvaluating over 101 metamodels: 100%[=========================] Time: 0:00:04\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(parameter_name = \"merge_purity_threshold\",\n",
       " parameter_scale = :none,\n",
       " parameter_values = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09    0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.0],\n",
       " measurements = [0.6856475609566427, 0.6856475609566427, 0.6856475609566427, 0.6856475609566427, 0.6856475609566427, 0.6856475609566427, 0.6856475609566427, 0.6856475609566427, 0.6856475609566427, 0.6856475609566427    2.2115973502779296, 2.0198757896975192, 2.2647551854830437, 2.009799145272603, 2.189452545349039, 2.254705146669389, 2.1907979598092524, 2.5708775448195396, 2.4444085855594797, 2.471526363412027],)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = collect(0:.01:1)\n",
    "r = range(dt2, :merge_purity_threshold, values=values)\n",
    "# r = range(nn2, :epochs, lower=0, upper=max_epochs)\n",
    "curve = learning_curve(Tree2, \n",
    "                        range=r, \n",
    "#                         resampling=Holdout(fraction_train=0.7), \n",
    "                        resampling=CV(), \n",
    "                        measure=cross_entropy, \n",
    "                        acceleration=CPUThreads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip580\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip580)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip581\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip580)\" d=\"\n",
       "M210.121 1423.18 L2352.76 1423.18 L2352.76 47.2441 L210.121 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip582\">\n",
       "    <rect x=\"210\" y=\"47\" width=\"2144\" height=\"1377\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  270.762,1423.18 270.762,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  776.1,1423.18 776.1,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1281.44,1423.18 1281.44,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1786.78,1423.18 1786.78,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2292.12,1423.18 2292.12,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  210.121,1315.4 2352.76,1315.4 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  210.121,1018.62 2352.76,1018.62 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  210.121,721.831 2352.76,721.831 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  210.121,425.044 2352.76,425.044 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip582)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  210.121,128.257 2352.76,128.257 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  210.121,1423.18 2352.76,1423.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  210.121,1423.18 210.121,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  270.762,1423.18 270.762,1406.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  776.1,1423.18 776.1,1406.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1281.44,1423.18 1281.44,1406.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1786.78,1423.18 1786.78,1406.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2292.12,1423.18 2292.12,1406.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  210.121,1315.4 235.833,1315.4 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  210.121,1018.62 235.833,1018.62 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  210.121,721.831 235.833,721.831 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  210.121,425.044 235.833,425.044 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  210.121,128.257 235.833,128.257 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip580)\" d=\"M 0 0 M238.771 1445.17 Q235.16 1445.17 233.331 1448.74 Q231.526 1452.28 231.526 1459.41 Q231.526 1466.51 233.331 1470.08 Q235.16 1473.62 238.771 1473.62 Q242.405 1473.62 244.211 1470.08 Q246.039 1466.51 246.039 1459.41 Q246.039 1452.28 244.211 1448.74 Q242.405 1445.17 238.771 1445.17 M238.771 1441.47 Q244.581 1441.47 247.637 1446.07 Q250.715 1450.66 250.715 1459.41 Q250.715 1468.13 247.637 1472.74 Q244.581 1477.32 238.771 1477.32 Q232.961 1477.32 229.882 1472.74 Q226.827 1468.13 226.827 1459.41 Q226.827 1450.66 229.882 1446.07 Q232.961 1441.47 238.771 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M255.785 1470.77 L260.669 1470.77 L260.669 1476.65 L255.785 1476.65 L255.785 1470.77 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M275.738 1445.17 Q272.127 1445.17 270.299 1448.74 Q268.493 1452.28 268.493 1459.41 Q268.493 1466.51 270.299 1470.08 Q272.127 1473.62 275.738 1473.62 Q279.373 1473.62 281.178 1470.08 Q283.007 1466.51 283.007 1459.41 Q283.007 1452.28 281.178 1448.74 Q279.373 1445.17 275.738 1445.17 M275.738 1441.47 Q281.549 1441.47 284.604 1446.07 Q287.683 1450.66 287.683 1459.41 Q287.683 1468.13 284.604 1472.74 Q281.549 1477.32 275.738 1477.32 Q269.928 1477.32 266.85 1472.74 Q263.794 1468.13 263.794 1459.41 Q263.794 1450.66 266.85 1446.07 Q269.928 1441.47 275.738 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M302.752 1445.17 Q299.141 1445.17 297.312 1448.74 Q295.507 1452.28 295.507 1459.41 Q295.507 1466.51 297.312 1470.08 Q299.141 1473.62 302.752 1473.62 Q306.386 1473.62 308.192 1470.08 Q310.021 1466.51 310.021 1459.41 Q310.021 1452.28 308.192 1448.74 Q306.386 1445.17 302.752 1445.17 M302.752 1441.47 Q308.562 1441.47 311.618 1446.07 Q314.697 1450.66 314.697 1459.41 Q314.697 1468.13 311.618 1472.74 Q308.562 1477.32 302.752 1477.32 Q296.942 1477.32 293.863 1472.74 Q290.808 1468.13 290.808 1459.41 Q290.808 1450.66 293.863 1446.07 Q296.942 1441.47 302.752 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M745.406 1445.17 Q741.795 1445.17 739.966 1448.74 Q738.16 1452.28 738.16 1459.41 Q738.16 1466.51 739.966 1470.08 Q741.795 1473.62 745.406 1473.62 Q749.04 1473.62 750.845 1470.08 Q752.674 1466.51 752.674 1459.41 Q752.674 1452.28 750.845 1448.74 Q749.04 1445.17 745.406 1445.17 M745.406 1441.47 Q751.216 1441.47 754.271 1446.07 Q757.35 1450.66 757.35 1459.41 Q757.35 1468.13 754.271 1472.74 Q751.216 1477.32 745.406 1477.32 Q739.596 1477.32 736.517 1472.74 Q733.461 1468.13 733.461 1459.41 Q733.461 1450.66 736.517 1446.07 Q739.596 1441.47 745.406 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M762.42 1470.77 L767.304 1470.77 L767.304 1476.65 L762.42 1476.65 L762.42 1470.77 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M776.401 1472.72 L792.72 1472.72 L792.72 1476.65 L770.776 1476.65 L770.776 1472.72 Q773.438 1469.96 778.021 1465.33 Q782.628 1460.68 783.808 1459.34 Q786.054 1456.81 786.933 1455.08 Q787.836 1453.32 787.836 1451.63 Q787.836 1448.87 785.892 1447.14 Q783.97 1445.4 780.868 1445.4 Q778.669 1445.4 776.216 1446.17 Q773.785 1446.93 771.007 1448.48 L771.007 1443.76 Q773.831 1442.62 776.285 1442.05 Q778.739 1441.47 780.776 1441.47 Q786.146 1441.47 789.341 1444.15 Q792.535 1446.84 792.535 1451.33 Q792.535 1453.46 791.725 1455.38 Q790.938 1457.28 788.831 1459.87 Q788.253 1460.54 785.151 1463.76 Q782.049 1466.95 776.401 1472.72 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M797.836 1442.09 L816.192 1442.09 L816.192 1446.03 L802.118 1446.03 L802.118 1454.5 Q803.137 1454.15 804.155 1453.99 Q805.174 1453.8 806.192 1453.8 Q811.979 1453.8 815.359 1456.98 Q818.739 1460.15 818.739 1465.56 Q818.739 1471.14 815.266 1474.24 Q811.794 1477.32 805.475 1477.32 Q803.299 1477.32 801.03 1476.95 Q798.785 1476.58 796.378 1475.84 L796.378 1471.14 Q798.461 1472.28 800.683 1472.83 Q802.905 1473.39 805.382 1473.39 Q809.387 1473.39 811.725 1471.28 Q814.063 1469.18 814.063 1465.56 Q814.063 1461.95 811.725 1459.85 Q809.387 1457.74 805.382 1457.74 Q803.507 1457.74 801.632 1458.16 Q799.78 1458.57 797.836 1459.45 L797.836 1442.09 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1249.95 1445.17 Q1246.33 1445.17 1244.51 1448.74 Q1242.7 1452.28 1242.7 1459.41 Q1242.7 1466.51 1244.51 1470.08 Q1246.33 1473.62 1249.95 1473.62 Q1253.58 1473.62 1255.39 1470.08 Q1257.21 1466.51 1257.21 1459.41 Q1257.21 1452.28 1255.39 1448.74 Q1253.58 1445.17 1249.95 1445.17 M1249.95 1441.47 Q1255.76 1441.47 1258.81 1446.07 Q1261.89 1450.66 1261.89 1459.41 Q1261.89 1468.13 1258.81 1472.74 Q1255.76 1477.32 1249.95 1477.32 Q1244.14 1477.32 1241.06 1472.74 Q1238 1468.13 1238 1459.41 Q1238 1450.66 1241.06 1446.07 Q1244.14 1441.47 1249.95 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1266.96 1470.77 L1271.84 1470.77 L1271.84 1476.65 L1266.96 1476.65 L1266.96 1470.77 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1276.96 1442.09 L1295.32 1442.09 L1295.32 1446.03 L1281.24 1446.03 L1281.24 1454.5 Q1282.26 1454.15 1283.28 1453.99 Q1284.3 1453.8 1285.32 1453.8 Q1291.1 1453.8 1294.48 1456.98 Q1297.86 1460.15 1297.86 1465.56 Q1297.86 1471.14 1294.39 1474.24 Q1290.92 1477.32 1284.6 1477.32 Q1282.42 1477.32 1280.15 1476.95 Q1277.91 1476.58 1275.5 1475.84 L1275.5 1471.14 Q1277.58 1472.28 1279.81 1472.83 Q1282.03 1473.39 1284.51 1473.39 Q1288.51 1473.39 1290.85 1471.28 Q1293.19 1469.18 1293.19 1465.56 Q1293.19 1461.95 1290.85 1459.85 Q1288.51 1457.74 1284.51 1457.74 Q1282.63 1457.74 1280.76 1458.16 Q1278.9 1458.57 1276.96 1459.45 L1276.96 1442.09 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1312.93 1445.17 Q1309.32 1445.17 1307.49 1448.74 Q1305.69 1452.28 1305.69 1459.41 Q1305.69 1466.51 1307.49 1470.08 Q1309.32 1473.62 1312.93 1473.62 Q1316.57 1473.62 1318.37 1470.08 Q1320.2 1466.51 1320.2 1459.41 Q1320.2 1452.28 1318.37 1448.74 Q1316.57 1445.17 1312.93 1445.17 M1312.93 1441.47 Q1318.74 1441.47 1321.8 1446.07 Q1324.88 1450.66 1324.88 1459.41 Q1324.88 1468.13 1321.8 1472.74 Q1318.74 1477.32 1312.93 1477.32 Q1307.12 1477.32 1304.04 1472.74 Q1300.99 1468.13 1300.99 1459.41 Q1300.99 1450.66 1304.04 1446.07 Q1307.12 1441.47 1312.93 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1755.74 1445.17 Q1752.12 1445.17 1750.3 1448.74 Q1748.49 1452.28 1748.49 1459.41 Q1748.49 1466.51 1750.3 1470.08 Q1752.12 1473.62 1755.74 1473.62 Q1759.37 1473.62 1761.18 1470.08 Q1763 1466.51 1763 1459.41 Q1763 1452.28 1761.18 1448.74 Q1759.37 1445.17 1755.74 1445.17 M1755.74 1441.47 Q1761.55 1441.47 1764.6 1446.07 Q1767.68 1450.66 1767.68 1459.41 Q1767.68 1468.13 1764.6 1472.74 Q1761.55 1477.32 1755.74 1477.32 Q1749.93 1477.32 1746.85 1472.74 Q1743.79 1468.13 1743.79 1459.41 Q1743.79 1450.66 1746.85 1446.07 Q1749.93 1441.47 1755.74 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1772.75 1470.77 L1777.63 1470.77 L1777.63 1476.65 L1772.75 1476.65 L1772.75 1470.77 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1781.52 1442.09 L1803.74 1442.09 L1803.74 1444.08 L1791.2 1476.65 L1786.31 1476.65 L1798.12 1446.03 L1781.52 1446.03 L1781.52 1442.09 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1808.86 1442.09 L1827.22 1442.09 L1827.22 1446.03 L1813.14 1446.03 L1813.14 1454.5 Q1814.16 1454.15 1815.18 1453.99 Q1816.2 1453.8 1817.22 1453.8 Q1823 1453.8 1826.38 1456.98 Q1829.76 1460.15 1829.76 1465.56 Q1829.76 1471.14 1826.29 1474.24 Q1822.82 1477.32 1816.5 1477.32 Q1814.32 1477.32 1812.05 1476.95 Q1809.81 1476.58 1807.4 1475.84 L1807.4 1471.14 Q1809.49 1472.28 1811.71 1472.83 Q1813.93 1473.39 1816.41 1473.39 Q1820.41 1473.39 1822.75 1471.28 Q1825.09 1469.18 1825.09 1465.56 Q1825.09 1461.95 1822.75 1459.85 Q1820.41 1457.74 1816.41 1457.74 Q1814.53 1457.74 1812.66 1458.16 Q1810.8 1458.57 1808.86 1459.45 L1808.86 1442.09 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M2250.51 1472.72 L2258.15 1472.72 L2258.15 1446.35 L2249.84 1448.02 L2249.84 1443.76 L2258.1 1442.09 L2262.78 1442.09 L2262.78 1472.72 L2270.41 1472.72 L2270.41 1476.65 L2250.51 1476.65 L2250.51 1472.72 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M2275.48 1470.77 L2280.37 1470.77 L2280.37 1476.65 L2275.48 1476.65 L2275.48 1470.77 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M2295.44 1445.17 Q2291.83 1445.17 2290 1448.74 Q2288.19 1452.28 2288.19 1459.41 Q2288.19 1466.51 2290 1470.08 Q2291.83 1473.62 2295.44 1473.62 Q2299.07 1473.62 2300.88 1470.08 Q2302.71 1466.51 2302.71 1459.41 Q2302.71 1452.28 2300.88 1448.74 Q2299.07 1445.17 2295.44 1445.17 M2295.44 1441.47 Q2301.25 1441.47 2304.3 1446.07 Q2307.38 1450.66 2307.38 1459.41 Q2307.38 1468.13 2304.3 1472.74 Q2301.25 1477.32 2295.44 1477.32 Q2289.63 1477.32 2286.55 1472.74 Q2283.49 1468.13 2283.49 1459.41 Q2283.49 1450.66 2286.55 1446.07 Q2289.63 1441.47 2295.44 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M2322.45 1445.17 Q2318.84 1445.17 2317.01 1448.74 Q2315.21 1452.28 2315.21 1459.41 Q2315.21 1466.51 2317.01 1470.08 Q2318.84 1473.62 2322.45 1473.62 Q2326.09 1473.62 2327.89 1470.08 Q2329.72 1466.51 2329.72 1459.41 Q2329.72 1452.28 2327.89 1448.74 Q2326.09 1445.17 2322.45 1445.17 M2322.45 1441.47 Q2328.26 1441.47 2331.32 1446.07 Q2334.4 1450.66 2334.4 1459.41 Q2334.4 1468.13 2331.32 1472.74 Q2328.26 1477.32 2322.45 1477.32 Q2316.64 1477.32 2313.56 1472.74 Q2310.51 1468.13 2310.51 1459.41 Q2310.51 1450.66 2313.56 1446.07 Q2316.64 1441.47 2322.45 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M138.205 1301.2 Q134.593 1301.2 132.765 1304.77 Q130.959 1308.31 130.959 1315.44 Q130.959 1322.55 132.765 1326.11 Q134.593 1329.65 138.205 1329.65 Q141.839 1329.65 143.644 1326.11 Q145.473 1322.55 145.473 1315.44 Q145.473 1308.31 143.644 1304.77 Q141.839 1301.2 138.205 1301.2 M138.205 1297.5 Q144.015 1297.5 147.07 1302.11 Q150.149 1306.69 150.149 1315.44 Q150.149 1324.17 147.07 1328.77 Q144.015 1333.36 138.205 1333.36 Q132.394 1333.36 129.316 1328.77 Q126.26 1324.17 126.26 1315.44 Q126.26 1306.69 129.316 1302.11 Q132.394 1297.5 138.205 1297.5 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M155.218 1326.8 L160.103 1326.8 L160.103 1332.68 L155.218 1332.68 L155.218 1326.8 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M165.218 1298.12 L183.575 1298.12 L183.575 1302.06 L169.501 1302.06 L169.501 1310.53 Q170.519 1310.18 171.538 1310.02 Q172.556 1309.84 173.575 1309.84 Q179.362 1309.84 182.741 1313.01 Q186.121 1316.18 186.121 1321.6 Q186.121 1327.18 182.649 1330.28 Q179.177 1333.36 172.857 1333.36 Q170.681 1333.36 168.413 1332.99 Q166.167 1332.61 163.76 1331.87 L163.76 1327.18 Q165.843 1328.31 168.065 1328.86 Q170.288 1329.42 172.765 1329.42 Q176.769 1329.42 179.107 1327.31 Q181.445 1325.21 181.445 1321.6 Q181.445 1317.99 179.107 1315.88 Q176.769 1313.77 172.765 1313.77 Q170.89 1313.77 169.015 1314.19 Q167.163 1314.61 165.218 1315.49 L165.218 1298.12 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M129.246 1031.96 L136.885 1031.96 L136.885 1005.6 L128.575 1007.26 L128.575 1003 L136.839 1001.34 L141.515 1001.34 L141.515 1031.96 L149.154 1031.96 L149.154 1035.9 L129.246 1035.9 L129.246 1031.96 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M154.223 1030.02 L159.107 1030.02 L159.107 1035.9 L154.223 1035.9 L154.223 1030.02 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M174.177 1004.42 Q170.565 1004.42 168.737 1007.98 Q166.931 1011.52 166.931 1018.65 Q166.931 1025.76 168.737 1029.32 Q170.565 1032.87 174.177 1032.87 Q177.811 1032.87 179.616 1029.32 Q181.445 1025.76 181.445 1018.65 Q181.445 1011.52 179.616 1007.98 Q177.811 1004.42 174.177 1004.42 M174.177 1000.71 Q179.987 1000.71 183.042 1005.32 Q186.121 1009.9 186.121 1018.65 Q186.121 1027.38 183.042 1031.99 Q179.987 1036.57 174.177 1036.57 Q168.366 1036.57 165.288 1031.99 Q162.232 1027.38 162.232 1018.65 Q162.232 1009.9 165.288 1005.32 Q168.366 1000.71 174.177 1000.71 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M130.242 735.175 L137.88 735.175 L137.88 708.81 L129.57 710.476 L129.57 706.217 L137.834 704.551 L142.51 704.551 L142.51 735.175 L150.149 735.175 L150.149 739.111 L130.242 739.111 L130.242 735.175 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M155.218 733.231 L160.103 733.231 L160.103 739.111 L155.218 739.111 L155.218 733.231 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M165.218 704.551 L183.575 704.551 L183.575 708.486 L169.501 708.486 L169.501 716.958 Q170.519 716.611 171.538 716.449 Q172.556 716.263 173.575 716.263 Q179.362 716.263 182.741 719.435 Q186.121 722.606 186.121 728.023 Q186.121 733.601 182.649 736.703 Q179.177 739.782 172.857 739.782 Q170.681 739.782 168.413 739.411 Q166.167 739.041 163.76 738.3 L163.76 733.601 Q165.843 734.736 168.065 735.291 Q170.288 735.847 172.765 735.847 Q176.769 735.847 179.107 733.74 Q181.445 731.634 181.445 728.023 Q181.445 724.412 179.107 722.305 Q176.769 720.199 172.765 720.199 Q170.89 720.199 169.015 720.615 Q167.163 721.032 165.218 721.912 L165.218 704.551 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M132.834 438.388 L149.154 438.388 L149.154 442.324 L127.209 442.324 L127.209 438.388 Q129.871 435.634 134.455 431.004 Q139.061 426.351 140.242 425.009 Q142.487 422.486 143.367 420.75 Q144.269 418.99 144.269 417.301 Q144.269 414.546 142.325 412.81 Q140.404 411.074 137.302 411.074 Q135.103 411.074 132.649 411.838 Q130.218 412.602 127.441 414.152 L127.441 409.43 Q130.265 408.296 132.718 407.717 Q135.172 407.139 137.209 407.139 Q142.58 407.139 145.774 409.824 Q148.968 412.509 148.968 417 Q148.968 419.129 148.158 421.051 Q147.371 422.949 145.265 425.541 Q144.686 426.213 141.584 429.43 Q138.482 432.625 132.834 438.388 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M154.223 436.444 L159.107 436.444 L159.107 442.324 L154.223 442.324 L154.223 436.444 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M174.177 410.842 Q170.565 410.842 168.737 414.407 Q166.931 417.949 166.931 425.078 Q166.931 432.185 168.737 435.75 Q170.565 439.291 174.177 439.291 Q177.811 439.291 179.616 435.75 Q181.445 432.185 181.445 425.078 Q181.445 417.949 179.616 414.407 Q177.811 410.842 174.177 410.842 M174.177 407.139 Q179.987 407.139 183.042 411.745 Q186.121 416.328 186.121 425.078 Q186.121 433.805 183.042 438.412 Q179.987 442.995 174.177 442.995 Q168.366 442.995 165.288 438.412 Q162.232 433.805 162.232 425.078 Q162.232 416.328 165.288 411.745 Q168.366 407.139 174.177 407.139 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M133.83 141.602 L150.149 141.602 L150.149 145.537 L128.205 145.537 L128.205 141.602 Q130.867 138.847 135.45 134.217 Q140.056 129.565 141.237 128.222 Q143.482 125.699 144.362 123.963 Q145.265 122.204 145.265 120.514 Q145.265 117.759 143.32 116.023 Q141.399 114.287 138.297 114.287 Q136.098 114.287 133.644 115.051 Q131.214 115.815 128.436 117.366 L128.436 112.643 Q131.26 111.509 133.714 110.93 Q136.168 110.352 138.205 110.352 Q143.575 110.352 146.769 113.037 Q149.964 115.722 149.964 120.213 Q149.964 122.342 149.154 124.264 Q148.367 126.162 146.26 128.754 Q145.681 129.426 142.58 132.643 Q139.478 135.838 133.83 141.602 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M155.218 139.657 L160.103 139.657 L160.103 145.537 L155.218 145.537 L155.218 139.657 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M165.218 110.977 L183.575 110.977 L183.575 114.912 L169.501 114.912 L169.501 123.384 Q170.519 123.037 171.538 122.875 Q172.556 122.69 173.575 122.69 Q179.362 122.69 182.741 125.861 Q186.121 129.032 186.121 134.449 Q186.121 140.027 182.649 143.129 Q179.177 146.208 172.857 146.208 Q170.681 146.208 168.413 145.838 Q166.167 145.467 163.76 144.727 L163.76 140.027 Q165.843 141.162 168.065 141.717 Q170.288 142.273 172.765 142.273 Q176.769 142.273 179.107 140.166 Q181.445 138.06 181.445 134.449 Q181.445 130.838 179.107 128.731 Q176.769 126.625 172.765 126.625 Q170.89 126.625 169.015 127.041 Q167.163 127.458 165.218 128.338 L165.218 110.977 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M960.607 1527.24 Q962.803 1523.29 965.859 1521.41 Q968.914 1519.54 973.052 1519.54 Q978.622 1519.54 981.645 1523.45 Q984.669 1527.33 984.669 1534.53 L984.669 1556.04 L978.781 1556.04 L978.781 1534.72 Q978.781 1529.59 976.967 1527.11 Q975.152 1524.63 971.429 1524.63 Q966.877 1524.63 964.235 1527.65 Q961.593 1530.68 961.593 1535.9 L961.593 1556.04 L955.705 1556.04 L955.705 1534.72 Q955.705 1529.56 953.891 1527.11 Q952.077 1524.63 948.289 1524.63 Q943.801 1524.63 941.16 1527.68 Q938.518 1530.71 938.518 1535.9 L938.518 1556.04 L932.63 1556.04 L932.63 1520.4 L938.518 1520.4 L938.518 1525.93 Q940.523 1522.66 943.324 1521.1 Q946.125 1519.54 949.976 1519.54 Q953.859 1519.54 956.565 1521.51 Q959.302 1523.48 960.607 1527.24 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1021.3 1536.76 L1021.3 1539.62 L994.377 1539.62 Q994.759 1545.67 998.005 1548.85 Q1001.28 1552 1007.11 1552 Q1010.48 1552 1013.63 1551.17 Q1016.82 1550.35 1019.94 1548.69 L1019.94 1554.23 Q1016.78 1555.57 1013.47 1556.27 Q1010.16 1556.97 1006.76 1556.97 Q998.228 1556.97 993.231 1552 Q988.266 1547.04 988.266 1538.57 Q988.266 1529.82 992.976 1524.69 Q997.719 1519.54 1005.74 1519.54 Q1012.93 1519.54 1017.1 1524.18 Q1021.3 1528.8 1021.3 1536.76 M1015.45 1535.04 Q1015.38 1530.23 1012.74 1527.37 Q1010.13 1524.5 1005.8 1524.5 Q1000.9 1524.5 997.942 1527.27 Q995.013 1530.04 994.568 1535.07 L1015.45 1535.04 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1048.1 1525.87 Q1047.12 1525.3 1045.94 1525.04 Q1044.79 1524.76 1043.39 1524.76 Q1038.43 1524.76 1035.75 1528 Q1033.11 1531.22 1033.11 1537.27 L1033.11 1556.04 L1027.22 1556.04 L1027.22 1520.4 L1033.11 1520.4 L1033.11 1525.93 Q1034.96 1522.69 1037.92 1521.13 Q1040.88 1519.54 1045.11 1519.54 Q1045.72 1519.54 1046.45 1519.63 Q1047.18 1519.7 1048.07 1519.85 L1048.1 1525.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1076.56 1537.81 Q1076.56 1531.44 1073.92 1527.94 Q1071.31 1524.44 1066.56 1524.44 Q1061.85 1524.44 1059.21 1527.94 Q1056.6 1531.44 1056.6 1537.81 Q1056.6 1544.14 1059.21 1547.64 Q1061.85 1551.14 1066.56 1551.14 Q1071.31 1551.14 1073.92 1547.64 Q1076.56 1544.14 1076.56 1537.81 M1082.41 1551.62 Q1082.41 1560.72 1078.37 1565.15 Q1074.33 1569.6 1065.99 1569.6 Q1062.9 1569.6 1060.17 1569.13 Q1057.43 1568.68 1054.85 1567.72 L1054.85 1562.03 Q1057.43 1563.43 1059.94 1564.1 Q1062.46 1564.76 1065.07 1564.76 Q1070.83 1564.76 1073.69 1561.74 Q1076.56 1558.75 1076.56 1552.67 L1076.56 1549.77 Q1074.74 1552.92 1071.91 1554.48 Q1069.08 1556.04 1065.13 1556.04 Q1058.58 1556.04 1054.56 1551.05 Q1050.55 1546.05 1050.55 1537.81 Q1050.55 1529.53 1054.56 1524.53 Q1058.58 1519.54 1065.13 1519.54 Q1069.08 1519.54 1071.91 1521.1 Q1074.74 1522.66 1076.56 1525.81 L1076.56 1520.4 L1082.41 1520.4 L1082.41 1551.62 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1119.05 1536.76 L1119.05 1539.62 L1092.12 1539.62 Q1092.5 1545.67 1095.75 1548.85 Q1099.03 1552 1104.85 1552 Q1108.23 1552 1111.38 1551.17 Q1114.56 1550.35 1117.68 1548.69 L1117.68 1554.23 Q1114.53 1555.57 1111.22 1556.27 Q1107.91 1556.97 1104.5 1556.97 Q1095.97 1556.97 1090.98 1552 Q1086.01 1547.04 1086.01 1538.57 Q1086.01 1529.82 1090.72 1524.69 Q1095.46 1519.54 1103.49 1519.54 Q1110.68 1519.54 1114.85 1524.18 Q1119.05 1528.8 1119.05 1536.76 M1113.19 1535.04 Q1113.13 1530.23 1110.49 1527.37 Q1107.88 1524.5 1103.55 1524.5 Q1098.65 1524.5 1095.69 1527.27 Q1092.76 1530.04 1092.31 1535.07 L1113.19 1535.04 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1152.28 1566.87 L1152.28 1571.42 L1118.41 1571.42 L1118.41 1566.87 L1152.28 1566.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1164.09 1550.7 L1164.09 1569.6 L1158.2 1569.6 L1158.2 1520.4 L1164.09 1520.4 L1164.09 1525.81 Q1165.93 1522.62 1168.73 1521.1 Q1171.57 1519.54 1175.48 1519.54 Q1181.97 1519.54 1186.02 1524.69 Q1190.09 1529.85 1190.09 1538.25 Q1190.09 1546.65 1186.02 1551.81 Q1181.97 1556.97 1175.48 1556.97 Q1171.57 1556.97 1168.73 1555.44 Q1165.93 1553.88 1164.09 1550.7 M1184.01 1538.25 Q1184.01 1531.79 1181.34 1528.13 Q1178.7 1524.44 1174.05 1524.44 Q1169.4 1524.44 1166.73 1528.13 Q1164.09 1531.79 1164.09 1538.25 Q1164.09 1544.71 1166.73 1548.4 Q1169.4 1552.07 1174.05 1552.07 Q1178.7 1552.07 1181.34 1548.4 Q1184.01 1544.71 1184.01 1538.25 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1195.63 1541.98 L1195.63 1520.4 L1201.49 1520.4 L1201.49 1541.75 Q1201.49 1546.81 1203.46 1549.36 Q1205.43 1551.87 1209.38 1551.87 Q1214.12 1551.87 1216.86 1548.85 Q1219.63 1545.83 1219.63 1540.61 L1219.63 1520.4 L1225.48 1520.4 L1225.48 1556.04 L1219.63 1556.04 L1219.63 1550.57 Q1217.49 1553.82 1214.66 1555.41 Q1211.86 1556.97 1208.14 1556.97 Q1201.99 1556.97 1198.81 1553.15 Q1195.63 1549.33 1195.63 1541.98 M1210.37 1519.54 L1210.37 1519.54 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1252.28 1525.87 Q1251.3 1525.3 1250.12 1525.04 Q1248.97 1524.76 1247.57 1524.76 Q1242.61 1524.76 1239.93 1528 Q1237.29 1531.22 1237.29 1537.27 L1237.29 1556.04 L1231.4 1556.04 L1231.4 1520.4 L1237.29 1520.4 L1237.29 1525.93 Q1239.14 1522.69 1242.1 1521.13 Q1245.06 1519.54 1249.29 1519.54 Q1249.9 1519.54 1250.63 1519.63 Q1251.36 1519.7 1252.25 1519.85 L1252.28 1525.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1258.43 1520.4 L1264.28 1520.4 L1264.28 1556.04 L1258.43 1556.04 L1258.43 1520.4 M1258.43 1506.52 L1264.28 1506.52 L1264.28 1513.93 L1258.43 1513.93 L1258.43 1506.52 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1276.22 1510.27 L1276.22 1520.4 L1288.28 1520.4 L1288.28 1524.95 L1276.22 1524.95 L1276.22 1544.3 Q1276.22 1548.66 1277.4 1549.9 Q1278.61 1551.14 1282.27 1551.14 L1288.28 1551.14 L1288.28 1556.04 L1282.27 1556.04 Q1275.49 1556.04 1272.91 1553.53 Q1270.33 1550.98 1270.33 1544.3 L1270.33 1524.95 L1266.03 1524.95 L1266.03 1520.4 L1270.33 1520.4 L1270.33 1510.27 L1276.22 1510.27 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1309.26 1559.35 Q1306.77 1565.72 1304.42 1567.66 Q1302.06 1569.6 1298.12 1569.6 L1293.44 1569.6 L1293.44 1564.7 L1296.88 1564.7 Q1299.29 1564.7 1300.63 1563.56 Q1301.97 1562.41 1303.59 1558.14 L1304.64 1555.47 L1290.22 1520.4 L1296.43 1520.4 L1307.57 1548.28 L1318.71 1520.4 L1324.92 1520.4 L1309.26 1559.35 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1358.15 1566.87 L1358.15 1571.42 L1324.28 1571.42 L1324.28 1566.87 L1358.15 1566.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1370.08 1510.27 L1370.08 1520.4 L1382.14 1520.4 L1382.14 1524.95 L1370.08 1524.95 L1370.08 1544.3 Q1370.08 1548.66 1371.26 1549.9 Q1372.47 1551.14 1376.13 1551.14 L1382.14 1551.14 L1382.14 1556.04 L1376.13 1556.04 Q1369.35 1556.04 1366.77 1553.53 Q1364.19 1550.98 1364.19 1544.3 L1364.19 1524.95 L1359.9 1524.95 L1359.9 1520.4 L1364.19 1520.4 L1364.19 1510.27 L1370.08 1510.27 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1417.92 1534.53 L1417.92 1556.04 L1412.06 1556.04 L1412.06 1534.72 Q1412.06 1529.66 1410.09 1527.14 Q1408.12 1524.63 1404.17 1524.63 Q1399.43 1524.63 1396.69 1527.65 Q1393.95 1530.68 1393.95 1535.9 L1393.95 1556.04 L1388.06 1556.04 L1388.06 1506.52 L1393.95 1506.52 L1393.95 1525.93 Q1396.05 1522.72 1398.89 1521.13 Q1401.75 1519.54 1405.47 1519.54 Q1411.62 1519.54 1414.77 1523.36 Q1417.92 1527.14 1417.92 1534.53 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1444.72 1525.87 Q1443.73 1525.3 1442.55 1525.04 Q1441.41 1524.76 1440.01 1524.76 Q1435.04 1524.76 1432.37 1528 Q1429.73 1531.22 1429.73 1537.27 L1429.73 1556.04 L1423.84 1556.04 L1423.84 1520.4 L1429.73 1520.4 L1429.73 1525.93 Q1431.57 1522.69 1434.53 1521.13 Q1437.49 1519.54 1441.73 1519.54 Q1442.33 1519.54 1443.06 1519.63 Q1443.8 1519.7 1444.69 1519.85 L1444.72 1525.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1479.92 1536.76 L1479.92 1539.62 L1452.99 1539.62 Q1453.38 1545.67 1456.62 1548.85 Q1459.9 1552 1465.73 1552 Q1469.1 1552 1472.25 1551.17 Q1475.43 1550.35 1478.55 1548.69 L1478.55 1554.23 Q1475.4 1555.57 1472.09 1556.27 Q1468.78 1556.97 1465.38 1556.97 Q1456.85 1556.97 1451.85 1552 Q1446.88 1547.04 1446.88 1538.57 Q1446.88 1529.82 1451.59 1524.69 Q1456.34 1519.54 1464.36 1519.54 Q1471.55 1519.54 1475.72 1524.18 Q1479.92 1528.8 1479.92 1536.76 M1474.06 1535.04 Q1474 1530.23 1471.36 1527.37 Q1468.75 1524.5 1464.42 1524.5 Q1459.52 1524.5 1456.56 1527.27 Q1453.63 1530.04 1453.19 1535.07 L1474.06 1535.04 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1508.79 1521.45 L1508.79 1526.98 Q1506.31 1525.71 1503.63 1525.07 Q1500.96 1524.44 1498.1 1524.44 Q1493.73 1524.44 1491.54 1525.77 Q1489.37 1527.11 1489.37 1529.79 Q1489.37 1531.82 1490.93 1533 Q1492.49 1534.15 1497.2 1535.2 L1499.21 1535.64 Q1505.45 1536.98 1508.06 1539.43 Q1510.7 1541.85 1510.7 1546.21 Q1510.7 1551.17 1506.75 1554.07 Q1502.84 1556.97 1495.96 1556.97 Q1493.1 1556.97 1489.98 1556.39 Q1486.89 1555.85 1483.45 1554.74 L1483.45 1548.69 Q1486.7 1550.38 1489.85 1551.24 Q1493 1552.07 1496.09 1552.07 Q1500.23 1552.07 1502.46 1550.66 Q1504.68 1549.23 1504.68 1546.65 Q1504.68 1544.27 1503.06 1542.99 Q1501.47 1541.72 1496.03 1540.54 L1493.99 1540.07 Q1488.55 1538.92 1486.13 1536.56 Q1483.71 1534.18 1483.71 1530.04 Q1483.71 1525.01 1487.27 1522.27 Q1490.84 1519.54 1497.4 1519.54 Q1500.64 1519.54 1503.51 1520.01 Q1506.37 1520.49 1508.79 1521.45 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1546.47 1534.53 L1546.47 1556.04 L1540.62 1556.04 L1540.62 1534.72 Q1540.62 1529.66 1538.64 1527.14 Q1536.67 1524.63 1532.72 1524.63 Q1527.98 1524.63 1525.24 1527.65 Q1522.51 1530.68 1522.51 1535.9 L1522.51 1556.04 L1516.62 1556.04 L1516.62 1506.52 L1522.51 1506.52 L1522.51 1525.93 Q1524.61 1522.72 1527.44 1521.13 Q1530.31 1519.54 1534.03 1519.54 Q1540.17 1519.54 1543.32 1523.36 Q1546.47 1527.14 1546.47 1534.53 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1566.43 1524.5 Q1561.72 1524.5 1558.98 1528.19 Q1556.25 1531.85 1556.25 1538.25 Q1556.25 1544.65 1558.95 1548.34 Q1561.69 1552 1566.43 1552 Q1571.11 1552 1573.85 1548.31 Q1576.58 1544.62 1576.58 1538.25 Q1576.58 1531.92 1573.85 1528.23 Q1571.11 1524.5 1566.43 1524.5 M1566.43 1519.54 Q1574.07 1519.54 1578.43 1524.5 Q1582.79 1529.47 1582.79 1538.25 Q1582.79 1547 1578.43 1552 Q1574.07 1556.97 1566.43 1556.97 Q1558.76 1556.97 1554.4 1552 Q1550.07 1547 1550.07 1538.25 Q1550.07 1529.47 1554.4 1524.5 Q1558.76 1519.54 1566.43 1519.54 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1588.93 1506.52 L1594.79 1506.52 L1594.79 1556.04 L1588.93 1556.04 L1588.93 1506.52 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M1624.39 1525.81 L1624.39 1506.52 L1630.25 1506.52 L1630.25 1556.04 L1624.39 1556.04 L1624.39 1550.7 Q1622.54 1553.88 1619.71 1555.44 Q1616.91 1556.97 1612.96 1556.97 Q1606.5 1556.97 1602.43 1551.81 Q1598.39 1546.65 1598.39 1538.25 Q1598.39 1529.85 1602.43 1524.69 Q1606.5 1519.54 1612.96 1519.54 Q1616.91 1519.54 1619.71 1521.1 Q1622.54 1522.62 1624.39 1525.81 M1604.43 1538.25 Q1604.43 1544.71 1607.08 1548.4 Q1609.75 1552.07 1614.4 1552.07 Q1619.04 1552.07 1621.72 1548.4 Q1624.39 1544.71 1624.39 1538.25 Q1624.39 1531.79 1621.72 1528.13 Q1619.04 1524.44 1614.4 1524.44 Q1609.75 1524.44 1607.08 1528.13 Q1604.43 1531.79 1604.43 1538.25 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M44.1444 904.492 L50.9239 904.492 Q47.9002 907.739 46.4043 911.431 Q44.9083 915.091 44.9083 919.229 Q44.9083 927.377 49.9054 931.705 Q54.8707 936.034 64.2919 936.034 Q73.6813 936.034 78.6784 931.705 Q83.6436 927.377 83.6436 919.229 Q83.6436 915.091 82.1477 911.431 Q80.6518 907.739 77.6281 904.492 L84.3439 904.492 Q86.6355 907.866 87.7814 911.653 Q88.9272 915.409 88.9272 919.611 Q88.9272 930.4 82.3387 936.607 Q75.7183 942.814 64.2919 942.814 Q52.8336 942.814 46.2451 936.607 Q39.6248 930.4 39.6248 919.611 Q39.6248 915.346 40.7706 911.59 Q41.8846 907.802 44.1444 904.492 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M57.8307 877.692 Q57.2578 878.679 57.0032 879.857 Q56.7167 881.003 56.7167 882.403 Q56.7167 887.368 59.9632 890.042 Q63.1779 892.684 69.2253 892.684 L88.0042 892.684 L88.0042 898.572 L52.3562 898.572 L52.3562 892.684 L57.8944 892.684 Q54.6479 890.838 53.0883 887.878 Q51.4968 884.917 51.4968 880.684 Q51.4968 880.08 51.5923 879.347 Q51.656 878.615 51.8151 877.724 L57.8307 877.692 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M56.4621 859.168 Q56.4621 863.879 60.1542 866.616 Q63.8145 869.353 70.212 869.353 Q76.6095 869.353 80.3017 866.648 Q83.9619 863.911 83.9619 859.168 Q83.9619 854.489 80.2698 851.752 Q76.5777 849.015 70.212 849.015 Q63.8781 849.015 60.186 851.752 Q56.4621 854.489 56.4621 859.168 M51.4968 859.168 Q51.4968 851.529 56.4621 847.169 Q61.4273 842.808 70.212 842.808 Q78.9649 842.808 83.9619 847.169 Q88.9272 851.529 88.9272 859.168 Q88.9272 866.839 83.9619 871.199 Q78.9649 875.528 70.212 875.528 Q61.4273 875.528 56.4621 871.199 Q51.4968 866.839 51.4968 859.168 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M53.4065 813.94 L58.9447 813.94 Q57.6716 816.422 57.035 819.096 Q56.3984 821.77 56.3984 824.634 Q56.3984 828.995 57.7352 831.191 Q59.072 833.355 61.7456 833.355 Q63.7826 833.355 64.9603 831.796 Q66.1061 830.236 67.1565 825.525 L67.6021 823.52 Q68.9389 817.282 71.3897 814.672 Q73.8086 812.03 78.1691 812.03 Q83.1344 812.03 86.0308 815.977 Q88.9272 819.892 88.9272 826.767 Q88.9272 829.631 88.3543 832.751 Q87.8132 835.838 86.6992 839.275 L80.6518 839.275 Q82.3387 836.029 83.198 832.878 Q84.0256 829.727 84.0256 826.639 Q84.0256 822.502 82.6251 820.274 Q81.1929 818.046 78.6147 818.046 Q76.2276 818.046 74.9545 819.669 Q73.6813 821.26 72.5037 826.703 L72.0262 828.74 Q70.8804 834.183 68.5251 836.602 Q66.138 839.021 62.0002 839.021 Q56.9713 839.021 54.2341 835.456 Q51.4968 831.891 51.4968 825.334 Q51.4968 822.088 51.9743 819.223 Q52.4517 816.359 53.4065 813.94 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M53.4065 783.162 L58.9447 783.162 Q57.6716 785.644 57.035 788.318 Q56.3984 790.991 56.3984 793.856 Q56.3984 798.217 57.7352 800.413 Q59.072 802.577 61.7456 802.577 Q63.7826 802.577 64.9603 801.017 Q66.1061 799.458 67.1565 794.747 L67.6021 792.742 Q68.9389 786.504 71.3897 783.894 Q73.8086 781.252 78.1691 781.252 Q83.1344 781.252 86.0308 785.199 Q88.9272 789.114 88.9272 795.989 Q88.9272 798.853 88.3543 801.972 Q87.8132 805.06 86.6992 808.497 L80.6518 808.497 Q82.3387 805.251 83.198 802.1 Q84.0256 798.949 84.0256 795.861 Q84.0256 791.724 82.6251 789.496 Q81.1929 787.268 78.6147 787.268 Q76.2276 787.268 74.9545 788.891 Q73.6813 790.482 72.5037 795.925 L72.0262 797.962 Q70.8804 803.405 68.5251 805.824 Q66.138 808.243 62.0002 808.243 Q56.9713 808.243 54.2341 804.678 Q51.4968 801.113 51.4968 794.556 Q51.4968 791.31 51.9743 788.445 Q52.4517 785.581 53.4065 783.162 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M40.4842 754.134 L40.4842 724.088 L45.895 724.088 L45.895 747.705 L59.9632 747.705 L59.9632 725.075 L65.3741 725.075 L65.3741 747.705 L82.5933 747.705 L82.5933 723.515 L88.0042 723.515 L88.0042 754.134 L40.4842 754.134 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M66.4881 687.74 L88.0042 687.74 L88.0042 693.596 L66.679 693.596 Q61.6183 693.596 59.1038 695.57 Q56.5894 697.543 56.5894 701.49 Q56.5894 706.232 59.6131 708.969 Q62.6368 711.707 67.8567 711.707 L88.0042 711.707 L88.0042 717.595 L52.3562 717.595 L52.3562 711.707 L57.8944 711.707 Q54.6797 709.606 53.0883 706.773 Q51.4968 703.909 51.4968 700.185 Q51.4968 694.042 55.3163 690.891 Q59.1038 687.74 66.4881 687.74 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M42.2347 675.804 L52.3562 675.804 L52.3562 663.741 L56.9077 663.741 L56.9077 675.804 L76.2594 675.804 Q80.6199 675.804 81.8613 674.626 Q83.1026 673.417 83.1026 669.757 L83.1026 663.741 L88.0042 663.741 L88.0042 669.757 Q88.0042 676.536 85.4897 679.114 Q82.9434 681.692 76.2594 681.692 L56.9077 681.692 L56.9077 685.989 L52.3562 685.989 L52.3562 681.692 L42.2347 681.692 L42.2347 675.804 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M57.8307 636.941 Q57.2578 637.928 57.0032 639.106 Q56.7167 640.252 56.7167 641.652 Q56.7167 646.617 59.9632 649.291 Q63.1779 651.933 69.2253 651.933 L88.0042 651.933 L88.0042 657.821 L52.3562 657.821 L52.3562 651.933 L57.8944 651.933 Q54.6479 650.087 53.0883 647.127 Q51.4968 644.166 51.4968 639.933 Q51.4968 639.329 51.5923 638.596 Q51.656 637.864 51.8151 636.973 L57.8307 636.941 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M56.4621 618.417 Q56.4621 623.128 60.1542 625.865 Q63.8145 628.602 70.212 628.602 Q76.6095 628.602 80.3017 625.897 Q83.9619 623.16 83.9619 618.417 Q83.9619 613.738 80.2698 611.001 Q76.5777 608.264 70.212 608.264 Q63.8781 608.264 60.186 611.001 Q56.4621 613.738 56.4621 618.417 M51.4968 618.417 Q51.4968 610.778 56.4621 606.418 Q61.4273 602.057 70.212 602.057 Q78.9649 602.057 83.9619 606.418 Q88.9272 610.778 88.9272 618.417 Q88.9272 626.088 83.9619 630.448 Q78.9649 634.777 70.212 634.777 Q61.4273 634.777 56.4621 630.448 Q51.4968 626.088 51.4968 618.417 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M82.657 590.249 L101.563 590.249 L101.563 596.137 L52.3562 596.137 L52.3562 590.249 L57.7671 590.249 Q54.5842 588.403 53.0564 585.602 Q51.4968 582.769 51.4968 578.854 Q51.4968 572.361 56.6531 568.319 Q61.8093 564.245 70.212 564.245 Q78.6147 564.245 83.771 568.319 Q88.9272 572.361 88.9272 578.854 Q88.9272 582.769 87.3994 585.602 Q85.8398 588.403 82.657 590.249 M70.212 570.324 Q63.7508 570.324 60.0905 572.998 Q56.3984 575.64 56.3984 580.287 Q56.3984 584.934 60.0905 587.607 Q63.7508 590.249 70.212 590.249 Q76.6732 590.249 80.3653 587.607 Q84.0256 584.934 84.0256 580.287 Q84.0256 575.64 80.3653 572.998 Q76.6732 570.324 70.212 570.324 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M91.3143 543.27 Q97.68 545.753 99.6216 548.108 Q101.563 550.463 101.563 554.41 L101.563 559.089 L96.6615 559.089 L96.6615 555.651 Q96.6615 553.232 95.5157 551.896 Q94.3699 550.559 90.1048 548.935 L87.4312 547.885 L52.3562 562.303 L52.3562 556.097 L80.238 544.957 L52.3562 533.817 L52.3562 527.61 L91.3143 543.27 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip582)\" style=\"stroke:#009af9; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  270.762,1205.21 290.975,1205.21 311.189,1205.21 331.402,1205.21 351.616,1205.21 371.829,1205.21 392.043,1205.21 412.256,1205.21 432.47,1205.21 452.683,1205.21 \n",
       "  472.897,1205.21 493.11,1205.21 513.324,1205.21 533.538,1205.21 553.751,1205.21 573.965,1205.21 594.178,1205.21 614.392,1205.21 634.605,1205.21 654.819,1205.21 \n",
       "  675.032,1205.21 695.246,1205.21 715.459,1205.21 735.673,1205.21 755.886,1205.21 776.1,1205.21 796.314,1205.21 816.527,1205.21 836.741,1205.21 856.954,1205.21 \n",
       "  877.168,1205.21 897.381,1205.21 917.595,1205.21 937.808,1205.21 958.022,1205.21 978.235,1205.21 998.449,1205.21 1018.66,1205.21 1038.88,1205.21 1059.09,1205.21 \n",
       "  1079.3,1205.21 1099.52,1205.21 1119.73,1205.21 1139.94,1205.21 1160.16,1205.21 1180.37,1205.21 1200.58,1205.21 1220.8,1205.21 1241.01,1205.21 1261.22,1205.21 \n",
       "  1281.44,1205.21 1301.65,1264.01 1321.87,1325.17 1342.08,1366.11 1362.29,1336.98 1382.51,1378.27 1402.72,1345.65 1422.93,1384.24 1443.15,1376.7 1463.36,1338.11 \n",
       "  1483.57,1338.11 1503.79,1235.82 1524,1235.82 1544.21,1162.75 1564.43,1073.09 1584.64,1034.5 1604.86,1073.09 1625.07,759.479 1645.28,759.479 1665.5,721.545 \n",
       "  1685.71,800.252 1705.92,501.542 1726.14,731.034 1746.35,616.121 1766.56,616.611 1786.78,655.083 1806.99,583.541 1827.2,513.499 1847.42,591.699 1867.63,477.898 \n",
       "  1887.84,589.905 1908.06,513.899 1928.27,552.371 1948.49,552.232 1968.7,552.232 1988.91,475.965 2009.13,444.973 2029.34,369.905 2049.55,300.643 2069.77,374.913 \n",
       "  2089.98,375.712 2110.19,299.445 2130.41,413.246 2150.62,267.892 2170.83,419.227 2191.05,312.59 2211.26,273.857 2231.47,311.791 2251.69,86.1857 2271.9,161.254 \n",
       "  2292.12,145.158 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip580)\" d=\"\n",
       "M1843.94 214.069 L2281.33 214.069 L2281.33 93.1086 L1843.94 93.1086  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1843.94,214.069 2281.33,214.069 2281.33,93.1086 1843.94,93.1086 1843.94,214.069 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip580)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1867.74,153.589 2010.59,153.589 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip580)\" d=\"M 0 0 M2047.59 170.869 L2034.39 136.309 L2039.28 136.309 L2050.23 165.406 L2061.2 136.309 L2066.06 136.309 L2052.89 170.869 L2047.59 170.869 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M2078.63 157.836 Q2073.47 157.836 2071.48 159.017 Q2069.49 160.197 2069.49 163.045 Q2069.49 165.313 2070.97 166.656 Q2072.47 167.975 2075.04 167.975 Q2078.58 167.975 2080.71 165.475 Q2082.86 162.952 2082.86 158.785 L2082.86 157.836 L2078.63 157.836 M2087.12 156.077 L2087.12 170.869 L2082.86 170.869 L2082.86 166.933 Q2081.41 169.295 2079.23 170.429 Q2077.05 171.54 2073.91 171.54 Q2069.93 171.54 2067.56 169.318 Q2065.23 167.072 2065.23 163.322 Q2065.23 158.947 2068.14 156.725 Q2071.08 154.503 2076.89 154.503 L2082.86 154.503 L2082.86 154.086 Q2082.86 151.147 2080.92 149.549 Q2079 147.929 2075.5 147.929 Q2073.28 147.929 2071.18 148.461 Q2069.07 148.994 2067.12 150.059 L2067.12 146.123 Q2069.46 145.221 2071.66 144.781 Q2073.86 144.318 2075.94 144.318 Q2081.57 144.318 2084.35 147.234 Q2087.12 150.151 2087.12 156.077 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M2091.59 134.85 L2095.85 134.85 L2095.85 170.869 L2091.59 170.869 L2091.59 134.85 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M2100.32 144.943 L2104.58 144.943 L2104.58 170.869 L2100.32 170.869 L2100.32 144.943 M2100.32 134.85 L2104.58 134.85 L2104.58 140.244 L2100.32 140.244 L2100.32 134.85 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M2126.11 148.878 L2126.11 134.85 L2130.36 134.85 L2130.36 170.869 L2126.11 170.869 L2126.11 166.98 Q2124.76 169.295 2122.7 170.429 Q2120.67 171.54 2117.8 171.54 Q2113.1 171.54 2110.13 167.79 Q2107.19 164.04 2107.19 157.929 Q2107.19 151.818 2110.13 148.068 Q2113.1 144.318 2117.8 144.318 Q2120.67 144.318 2122.7 145.452 Q2124.76 146.563 2126.11 148.878 M2111.59 157.929 Q2111.59 162.628 2113.51 165.313 Q2115.46 167.975 2118.84 167.975 Q2122.22 167.975 2124.16 165.313 Q2126.11 162.628 2126.11 157.929 Q2126.11 153.23 2124.16 150.568 Q2122.22 147.883 2118.84 147.883 Q2115.46 147.883 2113.51 150.568 Q2111.59 153.23 2111.59 157.929 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M2146.61 157.836 Q2141.45 157.836 2139.46 159.017 Q2137.47 160.197 2137.47 163.045 Q2137.47 165.313 2138.95 166.656 Q2140.46 167.975 2143.03 167.975 Q2146.57 167.975 2148.7 165.475 Q2150.85 162.952 2150.85 158.785 L2150.85 157.836 L2146.61 157.836 M2155.11 156.077 L2155.11 170.869 L2150.85 170.869 L2150.85 166.933 Q2149.39 169.295 2147.22 170.429 Q2145.04 171.54 2141.89 171.54 Q2137.91 171.54 2135.55 169.318 Q2133.21 167.072 2133.21 163.322 Q2133.21 158.947 2136.13 156.725 Q2139.07 154.503 2144.88 154.503 L2150.85 154.503 L2150.85 154.086 Q2150.85 151.147 2148.91 149.549 Q2146.98 147.929 2143.49 147.929 Q2141.27 147.929 2139.16 148.461 Q2137.05 148.994 2135.11 150.059 L2135.11 146.123 Q2137.45 145.221 2139.65 144.781 Q2141.85 144.318 2143.93 144.318 Q2149.55 144.318 2152.33 147.234 Q2155.11 150.151 2155.11 156.077 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M2163.79 137.582 L2163.79 144.943 L2172.56 144.943 L2172.56 148.253 L2163.79 148.253 L2163.79 162.327 Q2163.79 165.498 2164.65 166.401 Q2165.53 167.304 2168.19 167.304 L2172.56 167.304 L2172.56 170.869 L2168.19 170.869 Q2163.26 170.869 2161.38 169.04 Q2159.51 167.188 2159.51 162.327 L2159.51 148.253 L2156.38 148.253 L2156.38 144.943 L2159.51 144.943 L2159.51 137.582 L2163.79 137.582 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M2177.03 144.943 L2181.29 144.943 L2181.29 170.869 L2177.03 170.869 L2177.03 144.943 M2177.03 134.85 L2181.29 134.85 L2181.29 140.244 L2177.03 140.244 L2177.03 134.85 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M2195.8 147.929 Q2192.38 147.929 2190.39 150.614 Q2188.4 153.276 2188.4 157.929 Q2188.4 162.582 2190.36 165.267 Q2192.36 167.929 2195.8 167.929 Q2199.21 167.929 2201.2 165.244 Q2203.19 162.558 2203.19 157.929 Q2203.19 153.322 2201.2 150.637 Q2199.21 147.929 2195.8 147.929 M2195.8 144.318 Q2201.36 144.318 2204.53 147.929 Q2207.7 151.54 2207.7 157.929 Q2207.7 164.295 2204.53 167.929 Q2201.36 171.54 2195.8 171.54 Q2190.23 171.54 2187.05 167.929 Q2183.91 164.295 2183.91 157.929 Q2183.91 151.54 2187.05 147.929 Q2190.23 144.318 2195.8 144.318 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip580)\" d=\"M 0 0 M2233.72 155.221 L2233.72 170.869 L2229.46 170.869 L2229.46 155.359 Q2229.46 151.679 2228.03 149.85 Q2226.59 148.022 2223.72 148.022 Q2220.27 148.022 2218.28 150.221 Q2216.29 152.42 2216.29 156.216 L2216.29 170.869 L2212.01 170.869 L2212.01 144.943 L2216.29 144.943 L2216.29 148.971 Q2217.82 146.633 2219.88 145.475 Q2221.96 144.318 2224.67 144.318 Q2229.14 144.318 2231.43 147.096 Q2233.72 149.85 2233.72 155.221 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(curve.parameter_values,\n",
    "     curve.measurements,\n",
    "     xlab=curve.parameter_name,\n",
    "     ylab=\"Cross Entropy\",\n",
    "     label=\"Validation\", lw=2)\n",
    "# plot!(Net2.report.training_losses, label=\"Training\", lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38403"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = round(minimum(curve.measurements), digits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch / RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[35mCART decision tree classifier.\u001b[39m\n",
       "\u001b[35m based on [DecisionTree](https://github.com/bensadeghi/DecisionTree.jl).\u001b[39m\n",
       "\u001b[35m do `@load DecisionTreeClassifier pkg=\"DecisionTree\"` to use the model.\u001b[39m\n",
       "\u001b[35m do `?DecisionTreeClassifier` for documentation.\u001b[39m\n",
       "(name = \"DecisionTreeClassifier\",\n",
       " package_name = \"DecisionTree\",\n",
       " is_supervised = true,\n",
       " docstring = \"CART decision tree classifier.\\n based on [DecisionTree](https://github.com/bensadeghi/DecisionTree.jl).\\n do `@load DecisionTreeClassifier pkg=\\\"DecisionTree\\\"` to use the model.\\n do `?DecisionTreeClassifier` for documentation.\",\n",
       " hyperparameter_ranges = (nothing, nothing, nothing, nothing, nothing, nothing, nothing, nothing, nothing),\n",
       " hyperparameter_types = (\"Int64\", \"Int64\", \"Int64\", \"Float64\", \"Int64\", \"Bool\", \"Float64\", \"Float64\", \"Int64\"),\n",
       " hyperparameters = (:max_depth, :min_samples_leaf, :min_samples_split, :min_purity_increase, :n_subfeatures, :post_prune, :merge_purity_threshold, :pdf_smoothing, :display_depth),\n",
       " implemented_methods = [:fitted_params, :predict, :clean!, :fit],\n",
       " is_pure_julia = true,\n",
       " is_wrapper = false,\n",
       " load_path = \"MLJModels.DecisionTree_.DecisionTreeClassifier\",\n",
       " package_license = \"MIT\",\n",
       " package_url = \"https://github.com/bensadeghi/DecisionTree.jl\",\n",
       " package_uuid = \"7806a523-6efd-50cb-b5f6-3fa6f1930dbb\",\n",
       " prediction_type = :probabilistic,\n",
       " supports_online = false,\n",
       " supports_weights = false,\n",
       " input_scitype = Table{var\"#s13\"} where var\"#s13\"<:Union{AbstractArray{var\"#s45\",1} where var\"#s45\"<:Continuous, AbstractArray{var\"#s45\",1} where var\"#s45\"<:Count, AbstractArray{var\"#s45\",1} where var\"#s45\"<:OrderedFactor},\n",
       " target_scitype = AbstractArray{var\"#s419\",1} where var\"#s419\"<:Finite,\n",
       " output_scitype = Unknown,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info(dt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLJBase.NumericRange(Float64, :merge_purity_threshold, ... )"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param1 = :merge_purity_threshold\n",
    "\n",
    "r1 = range(dt2, param1, lower=1, upper=50, scale=:linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProbabilisticTunedModel(\n",
       "    model = DecisionTreeClassifier(\n",
       "            max_depth = -1,\n",
       "            min_samples_leaf = 1,\n",
       "            min_samples_split = 2,\n",
       "            min_purity_increase = 0.0,\n",
       "            n_subfeatures = 0,\n",
       "            post_prune = true,\n",
       "            merge_purity_threshold = 1.0,\n",
       "            pdf_smoothing = 0.0,\n",
       "            display_depth = 5),\n",
       "    tuning = Grid(\n",
       "            goal = 50,\n",
       "            resolution = 10,\n",
       "            shuffle = true,\n",
       "            rng = Random._GLOBAL_RNG()),\n",
       "    resampling = CV(\n",
       "            nfolds = 6,\n",
       "            shuffle = false,\n",
       "            rng = Random._GLOBAL_RNG()),\n",
       "    measure = cross_entropy(\n",
       "            eps = 2.220446049250313e-16),\n",
       "    weights = nothing,\n",
       "    operation = MLJModelInterface.predict,\n",
       "    range = MLJBase.NumericRange{Float64,MLJBase.Bounded,Symbol}[\u001b[34mNumericRange{Float64,} @278\u001b[39m],\n",
       "    train_best = true,\n",
       "    repeats = 1,\n",
       "    n = nothing,\n",
       "    acceleration = CPUThreads{Int64}(1),\n",
       "    acceleration_resampling = CPU1{Nothing}(nothing),\n",
       "    check_measure = true)\u001b[34m @931\u001b[39m"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_tuning_dt_model = TunedModel(model=dt2,\n",
    "                                    tuning=Grid(goal=50),\n",
    "                                    resampling=CV(), \n",
    "                                    measure=cross_entropy,\n",
    "                                    acceleration=CPUThreads(),\n",
    "                                    range=[r1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{ProbabilisticTunedModel{Grid,}} @773\u001b[39m trained 0 times.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @059\u001b[39m  `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @398\u001b[39m  `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_tuning_dt = machine(self_tuning_dt_model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Info: Training \u001b[34mMachine{ProbabilisticTunedModel{Grid,}} @773\u001b[39m.\n",
      " @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/machines.jl:322\n",
      " Info: Attempting to evaluate 50 models.\n",
      " @ MLJTuning /home/andrew/.julia/packages/MLJTuning/nuvTc/src/tuned_models.jl:501\n",
      "\u001b[33mEvaluating over 50 metamodels: 100%[=========================] Time: 0:00:01\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{ProbabilisticTunedModel{Grid,}} @773\u001b[39m trained 1 time.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @059\u001b[39m  `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @398\u001b[39m  `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = fit!(self_tuning_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "BoundsError: attempt to access 501 Array{Any,2} at index [1:50, 2]",
     "output_type": "error",
     "traceback": [
      "BoundsError: attempt to access 501 Array{Any,2} at index [1:50, 2]",
      "",
      "Stacktrace:",
      " [1] throw_boundserror(::Array{Any,2}, ::Tuple{Base.Slice{Base.OneTo{Int64}},Int64}) at ./abstractarray.jl:541",
      " [2] checkbounds at ./abstractarray.jl:506 [inlined]",
      " [3] _getindex at ./multidimensional.jl:742 [inlined]",
      " [4] getindex(::Array{Any,2}, ::Function, ::Int64) at ./abstractarray.jl:1060",
      " [5] macro expansion at /home/andrew/.julia/packages/MLJTuning/nuvTc/src/plotrecipes.jl:5 [inlined]",
      " [6] apply_recipe(::Dict{Symbol,Any}, ::Machine{MLJTuning.ProbabilisticTunedModel{Grid,MLJModels.DecisionTree_.DecisionTreeClassifier}}) at /home/andrew/.julia/packages/RecipesBase/AN696/src/RecipesBase.jl:282",
      " [7] _process_userrecipes!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Machine{MLJTuning.ProbabilisticTunedModel{Grid,MLJModels.DecisionTree_.DecisionTreeClassifier}}}) at /home/andrew/.julia/packages/RecipesPipeline/qM4Ea/src/user_recipe.jl:35",
      " [8] recipe_pipeline!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Machine{MLJTuning.ProbabilisticTunedModel{Grid,MLJModels.DecisionTree_.DecisionTreeClassifier}}}) at /home/andrew/.julia/packages/RecipesPipeline/qM4Ea/src/RecipesPipeline.jl:69",
      " [9] _plot!(::Plots.Plot{Plots.GRBackend}, ::Dict{Symbol,Any}, ::Tuple{Machine{MLJTuning.ProbabilisticTunedModel{Grid,MLJModels.DecisionTree_.DecisionTreeClassifier}}}) at /home/andrew/.julia/packages/Plots/6RLiv/src/plot.jl:167",
      " [10] plot(::Machine{MLJTuning.ProbabilisticTunedModel{Grid,MLJModels.DecisionTree_.DecisionTreeClassifier}}; kw::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/andrew/.julia/packages/Plots/6RLiv/src/plot.jl:57",
      " [11] plot(::Machine{MLJTuning.ProbabilisticTunedModel{Grid,MLJModels.DecisionTree_.DecisionTreeClassifier}}) at /home/andrew/.julia/packages/Plots/6RLiv/src/plot.jl:51",
      " [12] top-level scope at In[62]:1",
      " [13] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "plot(self_tuning_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = fitted_params(self_tuning_dt)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best.best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = z.report.best_result.measurement[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = best.best_model.builder.n1\n",
    "a = best.best_model.epochs\n",
    "c = round(best.best_model.optimiser.eta, digits=5)\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"Figures/Grid_NN_$(param1):$(a)_x_$(param2):$(b)_bestloss:$(best_loss)_lr:$c\"\n",
    "png(replace(fn,'.' => ','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\n",
    "    \"Decision Tree:       \",dt_acc.measurement[2], \"\\n\",\n",
    "    \"Neural Net:          \",nn_acc.measurement[2], \"\\n\",\n",
    "    \"K Nearest Neighbors: \",knn_acc.measurement[2], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
