{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using CSV\n",
    "using MLJ\n",
    "using Flux\n",
    "using Plots\n",
    "using StatsBase\n",
    "using MLJ: confusion_matrix\n",
    "\n",
    "include(\"../../lib.jl\")\n",
    "\n",
    "ENV[\"LINES\"]=30;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "IOError: mkdir: file already exists (EEXIST)",
     "output_type": "error",
     "traceback": [
      "IOError: mkdir: file already exists (EEXIST)",
      "",
      "Stacktrace:",
      " [1] uv_error at ./libuv.jl:97 [inlined]",
      " [2] mkdir(::String; mode::UInt16) at ./file.jl:177",
      " [3] mkdir(::String) at ./file.jl:170",
      " [4] top-level scope at In[2]:1",
      " [5] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "mkdir(\"./Figures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CSV.read(\"data.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th><th>nunique</th><th>nmissing</th><th>eltype</th></tr><tr><th></th><th>Symbol</th><th>Union…</th><th>Any</th><th>Union…</th><th>Any</th><th>Union…</th><th>Nothing</th><th>DataType</th></tr></thead><tbody><p>5 rows × 8 columns</p><tr><th>1</th><td>Class_Name</td><td></td><td>B</td><td></td><td>R</td><td>3</td><td></td><td>String</td></tr><tr><th>2</th><td>Left_Weight</td><td>3.0</td><td>1</td><td>3.0</td><td>5</td><td></td><td></td><td>Int64</td></tr><tr><th>3</th><td>Left_Distance</td><td>3.0</td><td>1</td><td>3.0</td><td>5</td><td></td><td></td><td>Int64</td></tr><tr><th>4</th><td>Right_Weight</td><td>3.0</td><td>1</td><td>3.0</td><td>5</td><td></td><td></td><td>Int64</td></tr><tr><th>5</th><td>Right_Distance</td><td>3.0</td><td>1</td><td>3.0</td><td>5</td><td></td><td></td><td>Int64</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& variable & mean & min & median & max & nunique & nmissing & eltype\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Union… & Any & Union… & Any & Union… & Nothing & DataType\\\\\n",
       "\t\\hline\n",
       "\t1 & Class\\_Name &  & B &  & R & 3 &  & String \\\\\n",
       "\t2 & Left\\_Weight & 3.0 & 1 & 3.0 & 5 &  &  & Int64 \\\\\n",
       "\t3 & Left\\_Distance & 3.0 & 1 & 3.0 & 5 &  &  & Int64 \\\\\n",
       "\t4 & Right\\_Weight & 3.0 & 1 & 3.0 & 5 &  &  & Int64 \\\\\n",
       "\t5 & Right\\_Distance & 3.0 & 1 & 3.0 & 5 &  &  & Int64 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×8 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ variable       │ mean   │ min │ median │ max │ nunique │ nmissing │\n",
       "│     │ \u001b[90mSymbol\u001b[39m         │ \u001b[90mUnion…\u001b[39m │ \u001b[90mAny\u001b[39m │ \u001b[90mUnion…\u001b[39m │ \u001b[90mAny\u001b[39m │ \u001b[90mUnion…\u001b[39m  │ \u001b[90mNothing\u001b[39m  │\n",
       "├─────┼────────────────┼────────┼─────┼────────┼─────┼─────────┼──────────┤\n",
       "│ 1   │ Class_Name     │        │ B   │        │ R   │ 3       │          │\n",
       "│ 2   │ Left_Weight    │ 3.0    │ 1   │ 3.0    │ 5   │         │          │\n",
       "│ 3   │ Left_Distance  │ 3.0    │ 1   │ 3.0    │ 5   │         │          │\n",
       "│ 4   │ Right_Weight   │ 3.0    │ 1   │ 3.0    │ 5   │         │          │\n",
       "│ 5   │ Right_Distance │ 3.0    │ 1   │ 3.0    │ 5   │         │          │"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at class labels to see if dataset is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Int64} with 3 entries:\n",
       "  \"B\" => 49\n",
       "  \"L\" => 288\n",
       "  \"R\" => 288"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = countmap(data[:Class_Name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " 0.0784\n",
       " 0.4608\n",
       " 0.4608"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect(label_counts[i] / size(data)[1] for i in keys(label_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data ready for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌\u001b[0m────────────────\u001b[0m┬\u001b[0m─────────────────────────────────\u001b[0m┬\u001b[0m───────────────\u001b[0m┐\u001b[0m\n",
       "│\u001b[0m\u001b[22m _.names        \u001b[0m│\u001b[0m\u001b[22m _.types                         \u001b[0m│\u001b[0m\u001b[22m _.scitypes    \u001b[0m│\u001b[0m\n",
       "├\u001b[0m────────────────\u001b[0m┼\u001b[0m─────────────────────────────────\u001b[0m┼\u001b[0m───────────────\u001b[0m┤\u001b[0m\n",
       "│\u001b[0m Class_Name     \u001b[0m│\u001b[0m CategoricalValue{String,UInt32} \u001b[0m│\u001b[0m Multiclass{3} \u001b[0m│\u001b[0m\n",
       "│\u001b[0m Left_Weight    \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m Left_Distance  \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m Right_Weight   \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m Right_Distance \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "└\u001b[0m────────────────\u001b[0m┴\u001b[0m─────────────────────────────────\u001b[0m┴\u001b[0m───────────────\u001b[0m┘\u001b[0m\n",
       "_.nrows = 625\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coerce!(data, :Class_Name=>Multiclass,\n",
    "              :Left_Weight=>Continuous,\n",
    "              :Right_Weight=>Continuous,\n",
    "              :Left_Distance=>Continuous,\n",
    "              :Right_Distance=>Continuous)\n",
    "schema(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CategoricalValue{String,UInt32}[\"B\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\"  …  \"L\", \"L\", \"L\", \"L\", \"L\", \"L\", \"L\", \"L\", \"L\", \"B\"], 625×4 DataFrame\n",
       "│ Row │ Left_Weight │ Left_Distance │ Right_Weight │ Right_Distance │\n",
       "│     │ \u001b[90mFloat64\u001b[39m     │ \u001b[90mFloat64\u001b[39m       │ \u001b[90mFloat64\u001b[39m      │ \u001b[90mFloat64\u001b[39m        │\n",
       "├─────┼─────────────┼───────────────┼──────────────┼────────────────┤\n",
       "│ 1   │ 1.0         │ 1.0           │ 1.0          │ 1.0            │\n",
       "│ 2   │ 1.0         │ 1.0           │ 1.0          │ 2.0            │\n",
       "│ 3   │ 1.0         │ 1.0           │ 1.0          │ 3.0            │\n",
       "│ 4   │ 1.0         │ 1.0           │ 1.0          │ 4.0            │\n",
       "│ 5   │ 1.0         │ 1.0           │ 1.0          │ 5.0            │\n",
       "│ 6   │ 1.0         │ 1.0           │ 2.0          │ 1.0            │\n",
       "│ 7   │ 1.0         │ 1.0           │ 2.0          │ 2.0            │\n",
       "│ 8   │ 1.0         │ 1.0           │ 2.0          │ 3.0            │\n",
       "│ 9   │ 1.0         │ 1.0           │ 2.0          │ 4.0            │\n",
       "│ 10  │ 1.0         │ 1.0           │ 2.0          │ 5.0            │\n",
       "⋮\n",
       "│ 615 │ 5.0         │ 5.0           │ 3.0          │ 5.0            │\n",
       "│ 616 │ 5.0         │ 5.0           │ 4.0          │ 1.0            │\n",
       "│ 617 │ 5.0         │ 5.0           │ 4.0          │ 2.0            │\n",
       "│ 618 │ 5.0         │ 5.0           │ 4.0          │ 3.0            │\n",
       "│ 619 │ 5.0         │ 5.0           │ 4.0          │ 4.0            │\n",
       "│ 620 │ 5.0         │ 5.0           │ 4.0          │ 5.0            │\n",
       "│ 621 │ 5.0         │ 5.0           │ 5.0          │ 1.0            │\n",
       "│ 622 │ 5.0         │ 5.0           │ 5.0          │ 2.0            │\n",
       "│ 623 │ 5.0         │ 5.0           │ 5.0          │ 3.0            │\n",
       "│ 624 │ 5.0         │ 5.0           │ 5.0          │ 4.0            │\n",
       "│ 625 │ 5.0         │ 5.0           │ 5.0          │ 5.0            │)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, X = unpack(data, ==(:Class_Name), colname->true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition train and test data accoring to class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([595, 102, 55, 568, 425, 389, 146, 63, 372, 250  …  195, 500, 571, 533, 112, 396, 297, 106, 303, 261], [444, 144, 546, 43, 19, 173, 365, 423, 27, 218  …  293, 614, 90, 471, 13, 134, 296, 79, 395, 415])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data to use when trying to fit a single validation set\n",
    "train, test = partition(eachindex(y), 0.7, shuffle=true, rng=123, stratify=values(data[:Class_Name])) # gives 70:30 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " 0.0776255707762557\n",
       " 0.4611872146118721\n",
       " 0.4611872146118721"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_counts = countmap(data[train,:Class_Name])\n",
    "collect(train_counts[i] / size(train)[1] for i in keys(train_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " 0.08021390374331551\n",
       " 0.45989304812834225\n",
       " 0.45989304812834225"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_counts = countmap(data[test,:Class_Name])\n",
    "collect(test_counts[i] / size(test)[1] for i in keys(test_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Five Learning Algorithms\n",
    "\n",
    "* Decision trees with some form of pruning\n",
    "* Neural networks\n",
    "* Boosting\n",
    "* Support Vector Machines\n",
    "* k-nearest neighbors\n",
    "\n",
    "\n",
    "##### Testing\n",
    "* Implement the algorithms\n",
    "* Design two *interesting* classification problems. For the purposes of this assignment, a classification problem is just a set of training examples and a set of test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42-element Array{NamedTuple{(:name, :package_name, :is_supervised, :docstring, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :is_pure_julia, :is_wrapper, :load_path, :package_license, :package_url, :package_uuid, :prediction_type, :supports_online, :supports_weights, :input_scitype, :target_scitype, :output_scitype),T} where T<:Tuple,1}:\n",
       " (name = AdaBoostClassifier, package_name = ScikitLearn, ... )\n",
       " (name = AdaBoostStumpClassifier, package_name = DecisionTree, ... )\n",
       " (name = BaggingClassifier, package_name = ScikitLearn, ... )\n",
       " (name = BayesianLDA, package_name = MultivariateStats, ... )\n",
       " (name = BayesianLDA, package_name = ScikitLearn, ... )\n",
       " (name = BayesianQDA, package_name = ScikitLearn, ... )\n",
       " (name = BayesianSubspaceLDA, package_name = MultivariateStats, ... )\n",
       " (name = ConstantClassifier, package_name = MLJModels, ... )\n",
       " (name = DecisionTreeClassifier, package_name = DecisionTree, ... )\n",
       " (name = DeterministicConstantClassifier, package_name = MLJModels, ... )\n",
       " (name = DummyClassifier, package_name = ScikitLearn, ... )\n",
       " (name = EvoTreeClassifier, package_name = EvoTrees, ... )\n",
       " (name = ExtraTreesClassifier, package_name = ScikitLearn, ... )\n",
       " ⋮\n",
       " (name = ProbabilisticSGDClassifier, package_name = ScikitLearn, ... )\n",
       " (name = RandomForestClassifier, package_name = DecisionTree, ... )\n",
       " (name = RandomForestClassifier, package_name = ScikitLearn, ... )\n",
       " (name = RidgeCVClassifier, package_name = ScikitLearn, ... )\n",
       " (name = RidgeClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SGDClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SVC, package_name = LIBSVM, ... )\n",
       " (name = SVMClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SVMLinearClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SVMNuClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SubspaceLDA, package_name = MultivariateStats, ... )\n",
       " (name = XGBoostClassifier, package_name = XGBoost, ... )"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models(matching(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJFlux ✔\n",
      "import "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Loading into module \"Main\": \n",
      "└ @ MLJModels /home/andrew/.julia/packages/MLJModels/mUBFt/src/loading.jl:70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLJFlux ✔\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNetworkClassifier(\n",
       "    builder = Short(\n",
       "            n_hidden = 0,\n",
       "            dropout = 0.5,\n",
       "            σ = NNlib.σ),\n",
       "    finaliser = NNlib.softmax,\n",
       "    optimiser = ADAM(0.001, (0.9, 0.999), IdDict{Any,Any}()),\n",
       "    loss = Flux.crossentropy,\n",
       "    epochs = 10,\n",
       "    batch_size = 1,\n",
       "    lambda = 0.0,\n",
       "    alpha = 0.0,\n",
       "    optimiser_changes_trigger_retraining = false)\u001b[34m @981\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@load NeuralNetworkClassifier verbosity=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks\n",
    "* Use favorite kind of network and training algorithm. \n",
    "* You may use networks of nodes with as many layers as you like and any activation function you see fit.\n",
    "\n",
    "1. https://github.com/alan-turing-institute/MLJFlux.jl/blob/master/examples/boston.ipynb\n",
    "1. https://github.com/alan-turing-institute/MLJFlux.jl\n",
    "1. https://alan-turing-institute.github.io/MLJ.jl/dev/transformers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom network\n",
    "mutable struct CustomNN <:MLJFlux.Builder\n",
    "    n1 ::Int\n",
    "    n2 ::Int\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "function MLJFlux.build(nn::CustomNN, n_in, n_out)\n",
    "    return Chain(\n",
    "        Flux.Dense(n_in, nn.n1, σ),\n",
    "        Flux.Dense(nn.n1, nn.n2, σ),\n",
    "        Flux.Dense(nn.n2, n_out, σ),\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1 = 80\n",
    "layer2 = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 16;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 4000;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No-preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetworkClassifier(\n",
       "    builder = CustomNN(\n",
       "            n1 = 80,\n",
       "            n2 = 40),\n",
       "    finaliser = NNlib.softmax,\n",
       "    optimiser = ADAM(0.001, (0.9, 0.999), IdDict{Any,Any}()),\n",
       "    loss = Flux.crossentropy,\n",
       "    epochs = 10,\n",
       "    batch_size = 1,\n",
       "    lambda = 0.0,\n",
       "    alpha = 0.0,\n",
       "    optimiser_changes_trigger_retraining = false)\u001b[34m @935\u001b[39m"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NeuralNetworkClassifier(builder=CustomNN(layer1,layer2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{NeuralNetworkClassifier{CustomNN,…}} @518\u001b[39m trained 0 times.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @885\u001b[39m ⏎ `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @853\u001b[39m ⏎ `AbstractArray{Multiclass{3},1}`\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net = machine(nn, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.optimiser.eta = 0.001\n",
    "nn.epochs = 60\n",
    "nn.batch_size = batch_sz\n",
    "nn.lambda = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{NeuralNetworkClassifier{CustomNN,…}} @518\u001b[39m.\n",
      "└ @ MLJBase /home/andrew/.julia/packages/MLJBase/uKzAz/src/machines.jl:319\n",
      "┌ Info: Loss is 0.9775\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.957\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.9498\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.9453\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.9407\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.9341\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.9207\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.8923\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.853\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.815\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.7844\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.7614\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.7442\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.7313\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.7213\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.7134\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.707\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.7018\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6975\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6939\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6907\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.688\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6856\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6836\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6817\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.68\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6785\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6771\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6758\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6746\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6735\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6725\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6716\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6707\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6699\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6691\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6683\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6676\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.667\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6663\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6657\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6651\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6646\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6641\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6636\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6631\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6626\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6622\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6617\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6613\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6609\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6605\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6601\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6598\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6594\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6591\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6587\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6584\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6581\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6578\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{NeuralNetworkClassifier{CustomNN,…}} @518\u001b[39m trained 1 time.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @885\u001b[39m ⏎ `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @853\u001b[39m ⏎ `AbstractArray{Multiclass{3},1}`\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(Net, rows=train, verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.optimiser.eta = nn.optimiser.eta / 3\n",
    "nn.epochs = nn.epochs + 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Updating \u001b[34mMachine{NeuralNetworkClassifier{CustomNN,…}} @518\u001b[39m.\n",
      "└ @ MLJBase /home/andrew/.julia/packages/MLJBase/uKzAz/src/machines.jl:320\n",
      "┌ Info: Loss is 0.6575\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6573\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6572\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.657\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6569\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6567\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6566\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6564\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6563\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6562\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6561\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6559\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6558\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6557\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6556\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6555\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6554\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6553\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6551\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.655\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6549\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6548\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6547\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6546\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6545\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6544\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6544\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6543\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6542\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6541\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.654\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6539\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6538\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6537\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6537\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6536\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6535\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6534\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6533\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n",
      "┌ Info: Loss is 0.6533\n",
      "└ @ MLJFlux /home/andrew/.julia/packages/MLJFlux/rYILg/src/core.jl:95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{NeuralNetworkClassifier{CustomNN,…}} @518\u001b[39m trained 2 times.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @885\u001b[39m ⏎ `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @853\u001b[39m ⏎ `AbstractArray{Multiclass{3},1}`\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(Net, rows=train, verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 6 folds: 100%[=========================] Time: 0:00:08\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "┌\u001b[0m───────────────\u001b[0m┬\u001b[0m───────────────\u001b[0m┬\u001b[0m───────────────────────────────────────────────────\u001b[0m┐\u001b[0m\n",
       "│\u001b[0m\u001b[22m _.measure     \u001b[0m│\u001b[0m\u001b[22m _.measurement \u001b[0m│\u001b[0m\u001b[22m _.per_fold                                        \u001b[0m│\u001b[0m\n",
       "├\u001b[0m───────────────\u001b[0m┼\u001b[0m───────────────\u001b[0m┼\u001b[0m───────────────────────────────────────────────────\u001b[0m┤\u001b[0m\n",
       "│\u001b[0m cross_entropy \u001b[0m│\u001b[0m 0.664         \u001b[0m│\u001b[0m Float32[0.682, 0.686, 0.627, 0.655, 0.659, 0.677] \u001b[0m│\u001b[0m\n",
       "│\u001b[0m acc           \u001b[0m│\u001b[0m 0.867         \u001b[0m│\u001b[0m [0.857, 0.846, 0.904, 0.875, 0.875, 0.846]        \u001b[0m│\u001b[0m\n",
       "└\u001b[0m───────────────\u001b[0m┴\u001b[0m───────────────\u001b[0m┴\u001b[0m───────────────────────────────────────────────────\u001b[0m┘\u001b[0m\n",
       "_.per_observation = [[[0.556, 0.556, ..., 0.583], [1.03, 0.553, ..., 0.553], [0.553, 0.554, ..., 0.554], [0.558, 1.15, ..., 0.556], [0.587, 0.585, ..., 0.553], [0.576, 0.556, ..., 1.28]], missing]\n",
       "_.fitted_params_per_fold = [ … ]\n",
       "_.report_per_fold = [ … ]\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_acc = evaluate!(Net, resampling=CV(shuffle=true), measure=[cross_entropy, acc], verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(chain = Chain(Chain(Dense(4, 80, σ), Dense(80, 40, σ), Dense(40, 3, σ)), softmax),)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_params(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(training_losses = Any[1.030618f0, 0.9969693f0, 0.97918415f0, 0.9686325f0, 0.96174383f0, 0.95690876f0, 0.95330346f0, 0.95046276f0, 0.9481032f0, 0.9460374f0  …  0.6602216f0, 0.65992695f0, 0.65963894f0, 0.6593573f0, 0.65908164f0, 0.65881205f0, 0.658548f0, 0.65828955f0, 0.6580363f0, 0.6577881f0],)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report(Net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing Inputs makes a huge difference.\n",
    "Before, I could only barely break below 0.4 training loss, but by standardizing inputs, I can easily get near 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{Standardizer} @559\u001b[39m.\n",
      "└ @ MLJBase /home/andrew/.julia/packages/MLJBase/uKzAz/src/machines.jl:319\n"
     ]
    }
   ],
   "source": [
    "standardizer = Standardizer()\n",
    "stand = machine(standardizer, X[train,:]) #only want to standardize on training distribution\n",
    "fit!(stand)\n",
    "X_stand = MLJ.transform(stand, X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{NeuralNetworkClassifier{CustomNN,…}} @394\u001b[39m trained 0 times.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @298\u001b[39m ⏎ `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @656\u001b[39m ⏎ `AbstractArray{Multiclass{3},1}`\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net = machine(nn, X_stand, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{NeuralNetworkClassifier{CustomNN,…}} @394\u001b[39m.\n",
      "└ @ MLJBase /home/andrew/.julia/packages/MLJBase/uKzAz/src/machines.jl:319\n",
      "\u001b[33mOptimising neural net:100%[=========================] Time: 0:00:26\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{NeuralNetworkClassifier{CustomNN,…}} @394\u001b[39m trained 1 time.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @298\u001b[39m ⏎ `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @656\u001b[39m ⏎ `AbstractArray{Multiclass{3},1}`\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net.model.epochs = max_epochs\n",
    "fit!(Net, rows=train, verbosity=1, force=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 6 folds:  83%[====================>    ]  ETA: 0:00:29\u001b[39m"
     ]
    }
   ],
   "source": [
    "nn_acc = evaluate!(Net, resampling=CV(shuffle=true), measure=[cross_entropy, acc], verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vals = collect(0:5:max_epochs)\n",
    "r = range(nn, :epochs, values=vals)\n",
    "# r = range(nn, :epochs, lower=0, upper=max_epochs)\n",
    "curve = learning_curve(Net, \n",
    "                        range=r, \n",
    "                        resampling=Holdout(fraction_train=0.7), \n",
    "#                         resampling=CV(nfolds=4), \n",
    "                        measure=cross_entropy, \n",
    "                        acceleration=CPUThreads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(curve.parameter_values,\n",
    "     curve.measurements,\n",
    "     xlab=curve.parameter_name,\n",
    "     ylab=\"Cross Entropy\",\n",
    "     label=\"Validation\", lw=2)\n",
    "plot!(Net.report.training_losses, label=\"Training\", lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = round(nn.optimiser.eta, digits=5)\n",
    "b = round(minimum(curve.measurements), digits=5)\n",
    "best_epochs = curve.parameter_values[argmin(curve.measurements)]\n",
    "a,b, best_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"Figures/LearningCurve_NN_hidden:$(layer1)x$(layer2)_epochs:$(nn.epochs)_lr:$(a)_loss:$(b)_labmda:$(nn.lambda)\"\n",
    "png(replace(fn,'.' => ','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch for Hidden Layer Size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net = machine(nn, X_stand, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param1 = :epochs\n",
    "param2 = :(builder.n1)\n",
    "# param2 = :(builder.n2)\n",
    "\n",
    "r1 = range(nn, param1, lower=10, upper=4000, scale=:log10)\n",
    "# r1 = range(nn, param1, lower=1, upper=100, scale=:linear)\n",
    "r2 = range(nn, param2, lower=5, upper=100, scale=:linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "self_tuning_nn_model = TunedModel(model=nn,\n",
    "                                    tuning=Grid(goal=64),\n",
    "                                    resampling=Holdout(fraction_train=0.7), \n",
    "                                    measure=cross_entropy,\n",
    "                                    acceleration=CPUThreads(),\n",
    "                                    range=[r1, r2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_tuning_nn = machine(self_tuning_nn_model, X_stand, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = fit!(self_tuning_nn, rows=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(self_tuning_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = fitted_params(self_tuning_nn)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best.best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_loss = z.report.best_result.measurement[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n1 = best.best_model.builder.n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"Figures/Grid_NN_$(param1):$(best.best_model.epochs)_x_$(param2):$(best_n1)_bestloss:$(best_loss)\"\n",
    "f = replace(fn,'.' => ',')\n",
    "png(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch for Hidden Layer Size 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetworkClassifier(builder=CustomNN(best_n1,layer2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.optimiser.eta = 0.001\n",
    "nn.epochs = 60\n",
    "nn.batch_size = batch_sz\n",
    "nn.lambda = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net = machine(nn, X_stand, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param1 = :epochs\n",
    "# param1 = :(builder.n1)\n",
    "param2 = :(builder.n2)\n",
    "\n",
    "r1 = range(nn, param1, lower=10, upper=4000, scale=:log10)\n",
    "# r1 = range(nn, param1, lower=1, upper=100, scale=:linear)\n",
    "r2 = range(nn, param2, lower=5, upper=100, scale=:linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "self_tuning_nn_model = TunedModel(model=nn,\n",
    "                                    tuning=Grid(goal=64),\n",
    "                                    resampling=Holdout(fraction_train=0.7), \n",
    "                                    measure=cross_entropy,\n",
    "                                    acceleration=CPUThreads(),\n",
    "                                    range=[r1, r2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_tuning_nn = machine(self_tuning_nn_model, X_stand, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = fit!(self_tuning_nn, rows=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(self_tuning_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = fitted_params(self_tuning_nn)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best.best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_loss = z.report.best_result.measurement[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n2 = best.best_model.builder.n2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"Figures/Grid_NN_$(param1):$(best.best_model.epochs)_x_$(param2):$(best_n2)_bestloss:$(best_loss)\"\n",
    "png(replace(fn,'.' => ','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch for Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetworkClassifier(builder=CustomNN(best_n1,best_n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.optimiser.eta = 0.001\n",
    "nn.epochs = 60\n",
    "nn.batch_size = batch_sz\n",
    "nn.lambda = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net = machine(nn, X_stand, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit!(Net, rows=train, verbosity=1, force=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param1 = :epochs\n",
    "param2 = :(optimiser.eta)\n",
    "\n",
    "r1 = range(nn, param1, lower=10, upper=4000, scale=:linear)\n",
    "r2 = range(nn, param2, lower=0.0001, upper=0.1, scale=:log10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "self_tuning_nn_model = TunedModel(model=nn,\n",
    "                                    tuning=Grid(goal=50),\n",
    "                                    resampling=Holdout(fraction_train=0.7), \n",
    "                                    measure=cross_entropy,\n",
    "                                    acceleration=CPUThreads(),\n",
    "                                    range=[r1, r2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_tuning_nn = machine(self_tuning_nn_model, X_stand, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = fit!(self_tuning_nn, rows=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(self_tuning_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = fitted_params(self_tuning_nn)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best.best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_loss = z.report.best_result.measurement[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_eta = round(best.best_model.optimiser.eta, digits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"Figures/Grid_NN_$(param1):$(best.best_model.epochs)_x_$(param2):$(best_eta)_bestloss:$(best_loss)_hidden:$b\"\n",
    "png(replace(fn,'.' => ','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch for Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetworkClassifier(builder=CustomNN(best_n1,best_n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.optimiser.eta = best_eta\n",
    "nn.epochs = 60\n",
    "nn.batch_size = batch_sz\n",
    "nn.lambda = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net = machine(nn, X_stand, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param1 = :epochs\n",
    "param2 = :lambda\n",
    "\n",
    "r1 = range(nn, param1, lower=100, upper=4000, scale=:linear)\n",
    "r2 = range(nn, param2, lower=0.0001, upper=10, scale=:log10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "self_tuning_nn_model = TunedModel(model=nn,\n",
    "                                    tuning=Grid(goal=50),\n",
    "                                    resampling=Holdout(fraction_train=0.7), \n",
    "                                    measure=cross_entropy,\n",
    "                                    acceleration=CPUThreads(),\n",
    "                                    range=[r1, r2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_tuning_nn = machine(self_tuning_nn_model, X_stand, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = fit!(self_tuning_nn, rows=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(self_tuning_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = fitted_params(self_tuning_nn)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best.best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_loss = z.report.best_result.measurement[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lambda = best.best_model.lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"Figures/Grid_NN_$(param1):$(best.best_model.epochs)_x_$(param2):$(best_lambda)_bestloss:$(best_loss)\"\n",
    "png(replace(fn,'.' => ','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_model = NeuralNetworkClassifier(builder=CustomNN(best_n1,best_n2))\n",
    "lc_model.optimiser.eta = best_eta;\n",
    "lc_model.lambda = best_lambda\n",
    "lc_model.epochs = 4000\n",
    "lc_model.batch_size = batch_sz\n",
    "lc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lc_model = NeuralNetworkClassifier(builder=CustomNN(80,80))\n",
    "# lc_model.optimiser.eta = 0.001;\n",
    "# lc_model.lambda = best_lambda\n",
    "# lc_model.epochs = 3000\n",
    "# lc_model.batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_schedule, training_losses, valid_losses = learn_curve(lc_model, X[train,:], y[train], acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(data_schedule, training_losses)\n",
    "plot!(data_schedule, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png(\"learning_curve_nn_3000epochs_balance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_model = NeuralNetworkClassifier(builder=CustomNN(best_n1,best_n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.optimiser.eta = lc_model.optimiser.eta = best_eta;\n",
    "final_model.batch_size = batch_sz\n",
    "final_model.lambda = best_lambda\n",
    "final_model.epochs = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = NeuralNetworkClassifier(builder=CustomNN(80,80))\n",
    "final_model.optimiser.eta = 0.01;\n",
    "final_model.lambda = 0.1\n",
    "final_model.epochs = 3000\n",
    "final_model.batch_size = batch_sz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Net = machine(final_model, X_stand, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fit!(Final_Net, rows=train, force=true, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vals = collect(0:5:max_epochs)\n",
    "r = range(final_model, :epochs, values=vals)\n",
    "# r = range(nn, :epochs, lower=0, upper=max_epochs)\n",
    "curve = learning_curve(Final_Net, \n",
    "                        range=r, \n",
    "                        resampling=Holdout(fraction_train=0.7), \n",
    "#                         resampling=CV(nfolds=4), \n",
    "                        measure=cross_entropy, \n",
    "                        acceleration=CPUThreads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(curve.parameter_values,\n",
    "     curve.measurements,\n",
    "     xlab=curve.parameter_name,\n",
    "     ylab=\"Cross Entropy\",\n",
    "     label=\"Validation\", lw=2)\n",
    "plot!(Final_Net.report.training_losses, label=\"Training\", lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_acc = evaluate!(Final_Net, resampling=CV(shuffle=true), measure=[cross_entropy, acc], verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ŷ = MLJ.predict(Final_Net, X_stand[test,:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy(ŷ, y[test]) |> mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc(ŷ, y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(mode.(ŷ), y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_params(Final_Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report(Final_Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot slower than Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self_tuning_nn_model = TunedModel(model=nn,\n",
    "#                                     tuning=Grid(goal=50),\n",
    "#                                     resampling=CV(), \n",
    "#                                     measure=cross_entropy,\n",
    "#                                     acceleration=CPUThreads(),\n",
    "#                                     range=[r_its, r_lr])\n",
    "\n",
    "# self_tuning_nn = machine(self_tuning_nn_model, X_stand, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit!(self_tuning_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(self_tuning_nn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
