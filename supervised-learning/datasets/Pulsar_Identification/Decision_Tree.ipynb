{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using CSV\n",
    "using MLJ\n",
    "using DecisionTree: print_tree\n",
    "using Plots\n",
    "using StatsBase\n",
    "\n",
    "include(\"../../lib.jl\")\n",
    "\n",
    "ENV[\"LINES\"]=30;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "IOError: mkdir: file already exists (EEXIST)",
     "output_type": "error",
     "traceback": [
      "IOError: mkdir: file already exists (EEXIST)",
      "",
      "Stacktrace:",
      " [1] uv_error at ./libuv.jl:97 [inlined]",
      " [2] mkdir(::String; mode::UInt16) at ./file.jl:177",
      " [3] mkdir(::String) at ./file.jl:170",
      " [4] top-level scope at In[2]:1",
      " [5] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "mkdir(\"./Figures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th> Mean of the integrated profile</th><th> Standard deviation of the integrated profile</th></tr><tr><th></th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>17,898 rows × 9 columns (omitted printing of 7 columns)</p><tr><th>1</th><td>140.562</td><td>55.6838</td></tr><tr><th>2</th><td>102.508</td><td>58.8824</td></tr><tr><th>3</th><td>103.016</td><td>39.3416</td></tr><tr><th>4</th><td>136.75</td><td>57.1784</td></tr><tr><th>5</th><td>88.7266</td><td>40.6722</td></tr><tr><th>6</th><td>93.5703</td><td>46.6981</td></tr><tr><th>7</th><td>119.484</td><td>48.7651</td></tr><tr><th>8</th><td>130.383</td><td>39.8441</td></tr><tr><th>9</th><td>107.25</td><td>52.6271</td></tr><tr><th>10</th><td>107.258</td><td>39.4965</td></tr><tr><th>11</th><td>142.078</td><td>45.2881</td></tr><tr><th>12</th><td>133.258</td><td>44.0582</td></tr><tr><th>13</th><td>134.961</td><td>49.5543</td></tr><tr><th>14</th><td>117.945</td><td>45.5066</td></tr><tr><th>15</th><td>138.18</td><td>51.5245</td></tr><tr><th>16</th><td>114.367</td><td>51.9457</td></tr><tr><th>17</th><td>109.641</td><td>49.0177</td></tr><tr><th>18</th><td>100.852</td><td>51.7435</td></tr><tr><th>19</th><td>136.094</td><td>51.691</td></tr><tr><th>20</th><td>99.3672</td><td>41.5722</td></tr><tr><th>21</th><td>100.891</td><td>51.8904</td></tr><tr><th>22</th><td>105.445</td><td>41.14</td></tr><tr><th>23</th><td>95.8672</td><td>42.0599</td></tr><tr><th>24</th><td>117.367</td><td>53.9086</td></tr><tr><th>25</th><td>106.648</td><td>56.3672</td></tr><tr><th>26</th><td>112.719</td><td>50.3013</td></tr><tr><th>27</th><td>130.852</td><td>52.4329</td></tr><tr><th>28</th><td>119.438</td><td>52.8748</td></tr><tr><th>29</th><td>123.211</td><td>51.078</td></tr><tr><th>30</th><td>102.617</td><td>49.6924</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t&  Mean of the integrated profile &  Standard deviation of the integrated profile & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 140.562 & 55.6838 & $\\dots$ \\\\\n",
       "\t2 & 102.508 & 58.8824 & $\\dots$ \\\\\n",
       "\t3 & 103.016 & 39.3416 & $\\dots$ \\\\\n",
       "\t4 & 136.75 & 57.1784 & $\\dots$ \\\\\n",
       "\t5 & 88.7266 & 40.6722 & $\\dots$ \\\\\n",
       "\t6 & 93.5703 & 46.6981 & $\\dots$ \\\\\n",
       "\t7 & 119.484 & 48.7651 & $\\dots$ \\\\\n",
       "\t8 & 130.383 & 39.8441 & $\\dots$ \\\\\n",
       "\t9 & 107.25 & 52.6271 & $\\dots$ \\\\\n",
       "\t10 & 107.258 & 39.4965 & $\\dots$ \\\\\n",
       "\t11 & 142.078 & 45.2881 & $\\dots$ \\\\\n",
       "\t12 & 133.258 & 44.0582 & $\\dots$ \\\\\n",
       "\t13 & 134.961 & 49.5543 & $\\dots$ \\\\\n",
       "\t14 & 117.945 & 45.5066 & $\\dots$ \\\\\n",
       "\t15 & 138.18 & 51.5245 & $\\dots$ \\\\\n",
       "\t16 & 114.367 & 51.9457 & $\\dots$ \\\\\n",
       "\t17 & 109.641 & 49.0177 & $\\dots$ \\\\\n",
       "\t18 & 100.852 & 51.7435 & $\\dots$ \\\\\n",
       "\t19 & 136.094 & 51.691 & $\\dots$ \\\\\n",
       "\t20 & 99.3672 & 41.5722 & $\\dots$ \\\\\n",
       "\t21 & 100.891 & 51.8904 & $\\dots$ \\\\\n",
       "\t22 & 105.445 & 41.14 & $\\dots$ \\\\\n",
       "\t23 & 95.8672 & 42.0599 & $\\dots$ \\\\\n",
       "\t24 & 117.367 & 53.9086 & $\\dots$ \\\\\n",
       "\t25 & 106.648 & 56.3672 & $\\dots$ \\\\\n",
       "\t26 & 112.719 & 50.3013 & $\\dots$ \\\\\n",
       "\t27 & 130.852 & 52.4329 & $\\dots$ \\\\\n",
       "\t28 & 119.438 & 52.8748 & $\\dots$ \\\\\n",
       "\t29 & 123.211 & 51.078 & $\\dots$ \\\\\n",
       "\t30 & 102.617 & 49.6924 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "17898×9 DataFrame. Omitted printing of 8 columns\n",
       "│ Row   │  Mean of the integrated profile │\n",
       "│       │ \u001b[90mFloat64\u001b[39m                         │\n",
       "├───────┼─────────────────────────────────┤\n",
       "│ 1     │ 140.562                         │\n",
       "│ 2     │ 102.508                         │\n",
       "│ 3     │ 103.016                         │\n",
       "│ 4     │ 136.75                          │\n",
       "│ 5     │ 88.7266                         │\n",
       "│ 6     │ 93.5703                         │\n",
       "│ 7     │ 119.484                         │\n",
       "│ 8     │ 130.383                         │\n",
       "│ 9     │ 107.25                          │\n",
       "│ 10    │ 107.258                         │\n",
       "⋮\n",
       "│ 17888 │ 121.375                         │\n",
       "│ 17889 │ 98.7266                         │\n",
       "│ 17890 │ 126.625                         │\n",
       "│ 17891 │ 143.672                         │\n",
       "│ 17892 │ 118.484                         │\n",
       "│ 17893 │ 96.0                            │\n",
       "│ 17894 │ 136.43                          │\n",
       "│ 17895 │ 122.555                         │\n",
       "│ 17896 │ 119.336                         │\n",
       "│ 17897 │ 114.508                         │\n",
       "│ 17898 │ 57.0625                         │"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = CSV.read(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th></tr><tr><th></th><th>Symbol</th><th>Float64</th><th>Real</th><th>Float64</th><th>Real</th></tr></thead><tbody><p>9 rows × 8 columns (omitted printing of 3 columns)</p><tr><th>1</th><td> Mean of the integrated profile</td><td>111.08</td><td>5.8125</td><td>115.078</td><td>192.617</td></tr><tr><th>2</th><td> Standard deviation of the integrated profile</td><td>46.5495</td><td>24.772</td><td>46.9475</td><td>98.7789</td></tr><tr><th>3</th><td> Excess kurtosis of the integrated profile</td><td>0.477857</td><td>-1.87601</td><td>0.22324</td><td>8.06952</td></tr><tr><th>4</th><td> Skewness of the integrated profile</td><td>1.77028</td><td>-1.79189</td><td>0.19871</td><td>68.1016</td></tr><tr><th>5</th><td> Mean of the DM-SNR curve</td><td>12.6144</td><td>0.213211</td><td>2.80184</td><td>223.392</td></tr><tr><th>6</th><td> Standard deviation of the DM-SNR curve</td><td>26.3265</td><td>7.37043</td><td>18.4613</td><td>110.642</td></tr><tr><th>7</th><td> Excess kurtosis of the DM-SNR curve</td><td>8.30356</td><td>-3.13927</td><td>8.43351</td><td>34.5398</td></tr><tr><th>8</th><td> Skewness of the DM-SNR curve</td><td>104.858</td><td>-1.97698</td><td>83.0646</td><td>1191.0</td></tr><tr><th>9</th><td>target_class</td><td>0.0915745</td><td>0</td><td>0.0</td><td>1</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& variable & mean & min & median & max & \\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Float64 & Real & Float64 & Real & \\\\\n",
       "\t\\hline\n",
       "\t1 &  Mean of the integrated profile & 111.08 & 5.8125 & 115.078 & 192.617 & $\\dots$ \\\\\n",
       "\t2 &  Standard deviation of the integrated profile & 46.5495 & 24.772 & 46.9475 & 98.7789 & $\\dots$ \\\\\n",
       "\t3 &  Excess kurtosis of the integrated profile & 0.477857 & -1.87601 & 0.22324 & 8.06952 & $\\dots$ \\\\\n",
       "\t4 &  Skewness of the integrated profile & 1.77028 & -1.79189 & 0.19871 & 68.1016 & $\\dots$ \\\\\n",
       "\t5 &  Mean of the DM-SNR curve & 12.6144 & 0.213211 & 2.80184 & 223.392 & $\\dots$ \\\\\n",
       "\t6 &  Standard deviation of the DM-SNR curve & 26.3265 & 7.37043 & 18.4613 & 110.642 & $\\dots$ \\\\\n",
       "\t7 &  Excess kurtosis of the DM-SNR curve & 8.30356 & -3.13927 & 8.43351 & 34.5398 & $\\dots$ \\\\\n",
       "\t8 &  Skewness of the DM-SNR curve & 104.858 & -1.97698 & 83.0646 & 1191.0 & $\\dots$ \\\\\n",
       "\t9 & target\\_class & 0.0915745 & 0 & 0.0 & 1 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "9×8 DataFrame. Omitted printing of 5 columns\n",
       "│ Row │ variable                                      │ mean      │ min      │\n",
       "│     │ \u001b[90mSymbol\u001b[39m                                        │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mReal\u001b[39m     │\n",
       "├─────┼───────────────────────────────────────────────┼───────────┼──────────┤\n",
       "│ 1   │  Mean of the integrated profile               │ 111.08    │ 5.8125   │\n",
       "│ 2   │  Standard deviation of the integrated profile │ 46.5495   │ 24.772   │\n",
       "│ 3   │  Excess kurtosis of the integrated profile    │ 0.477857  │ -1.87601 │\n",
       "│ 4   │  Skewness of the integrated profile           │ 1.77028   │ -1.79189 │\n",
       "│ 5   │  Mean of the DM-SNR curve                     │ 12.6144   │ 0.213211 │\n",
       "│ 6   │  Standard deviation of the DM-SNR curve       │ 26.3265   │ 7.37043  │\n",
       "│ 7   │  Excess kurtosis of the DM-SNR curve          │ 8.30356   │ -3.13927 │\n",
       "│ 8   │  Skewness of the DM-SNR curve                 │ 104.858   │ -1.97698 │\n",
       "│ 9   │ target_class                                  │ 0.0915745 │ 0        │"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(data, cols=:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at class labels to see if dataset is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64,Int64} with 2 entries:\n",
       "  0 => 16259\n",
       "  1 => 1639"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = countmap(data[:(target_class)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 0.908425522404738\n",
       " 0.09157447759526204"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect(label_counts[i] / size(data)[1] for i in keys(label_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data ready for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌\u001b[0m───────────────────────────────────────────────\u001b[0m┬\u001b[0m────────────────────────────────\u001b[0m┬\u001b[0m───────────────\u001b[0m┐\u001b[0m\n",
       "│\u001b[0m\u001b[22m _.names                                       \u001b[0m│\u001b[0m\u001b[22m _.types                        \u001b[0m│\u001b[0m\u001b[22m _.scitypes    \u001b[0m│\u001b[0m\n",
       "├\u001b[0m───────────────────────────────────────────────\u001b[0m┼\u001b[0m────────────────────────────────\u001b[0m┼\u001b[0m───────────────\u001b[0m┤\u001b[0m\n",
       "│\u001b[0m  Mean of the integrated profile               \u001b[0m│\u001b[0m Float64                        \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m  Standard deviation of the integrated profile \u001b[0m│\u001b[0m Float64                        \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m  Excess kurtosis of the integrated profile    \u001b[0m│\u001b[0m Float64                        \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m  Skewness of the integrated profile           \u001b[0m│\u001b[0m Float64                        \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m  Mean of the DM-SNR curve                     \u001b[0m│\u001b[0m Float64                        \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m  Standard deviation of the DM-SNR curve       \u001b[0m│\u001b[0m Float64                        \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m  Excess kurtosis of the DM-SNR curve          \u001b[0m│\u001b[0m Float64                        \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m  Skewness of the DM-SNR curve                 \u001b[0m│\u001b[0m Float64                        \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m target_class                                  \u001b[0m│\u001b[0m CategoricalValue{Int64,UInt32} \u001b[0m│\u001b[0m Multiclass{2} \u001b[0m│\u001b[0m\n",
       "└\u001b[0m───────────────────────────────────────────────\u001b[0m┴\u001b[0m────────────────────────────────\u001b[0m┴\u001b[0m───────────────\u001b[0m┘\u001b[0m\n",
       "_.nrows = 17898\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coerce!(data, :target_class=>Multiclass)\n",
    "schema(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CategoricalValue{Int64,UInt32}[0, 0, 0, 0, 0, 0, 0, 0, 0, 0  …  0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 17898×8 DataFrame. Omitted printing of 7 columns\n",
       "│ Row   │  Mean of the integrated profile │\n",
       "│       │ \u001b[90mFloat64\u001b[39m                         │\n",
       "├───────┼─────────────────────────────────┤\n",
       "│ 1     │ 140.562                         │\n",
       "│ 2     │ 102.508                         │\n",
       "│ 3     │ 103.016                         │\n",
       "│ 4     │ 136.75                          │\n",
       "│ 5     │ 88.7266                         │\n",
       "│ 6     │ 93.5703                         │\n",
       "│ 7     │ 119.484                         │\n",
       "│ 8     │ 130.383                         │\n",
       "│ 9     │ 107.25                          │\n",
       "│ 10    │ 107.258                         │\n",
       "⋮\n",
       "│ 17888 │ 121.375                         │\n",
       "│ 17889 │ 98.7266                         │\n",
       "│ 17890 │ 126.625                         │\n",
       "│ 17891 │ 143.672                         │\n",
       "│ 17892 │ 118.484                         │\n",
       "│ 17893 │ 96.0                            │\n",
       "│ 17894 │ 136.43                          │\n",
       "│ 17895 │ 122.555                         │\n",
       "│ 17896 │ 119.336                         │\n",
       "│ 17897 │ 114.508                         │\n",
       "│ 17898 │ 57.0625                         │)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, X = unpack(data, ==(:target_class), colname->true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition train and test data accoring to class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2859, 3242, 436, 12919, 3279, 17651, 16341, 14975, 16060, 730  …  805, 13608, 9896, 11042, 13883, 3467, 112, 9612, 2792, 261], [1078, 16815, 4553, 12452, 10187, 17806, 8156, 16807, 2688, 1554  …  4126, 15656, 16102, 15077, 13659, 13276, 13241, 8204, 5417, 415])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data to use when trying to fit a single validation set\n",
    "train, test = partition(eachindex(y), 0.7, shuffle=true, rng=123, stratify=values(data[:target_class])) # gives 70:30 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 0.9084450830140486\n",
       " 0.09155491698595147"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_counts = countmap(data[train,:target_class])\n",
    "collect(train_counts[i] / size(train)[1] for i in keys(train_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 0.9083798882681564\n",
       " 0.09162011173184358"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_counts = countmap(data[test,:target_class])\n",
    "collect(test_counts[i] / size(test)[1] for i in keys(test_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Five Learning Algorithms\n",
    "\n",
    "* Decision trees with some form of pruning\n",
    "* Neural networks\n",
    "* Boosting\n",
    "* Support Vector Machines\n",
    "* k-nearest neighbors\n",
    "\n",
    "\n",
    "##### Testing\n",
    "* Implement the algorithms\n",
    "* Design two *interesting* classification problems. For the purposes of this assignment, a classification problem is just a set of training examples and a set of test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43-element Array{NamedTuple{(:name, :package_name, :is_supervised, :docstring, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :is_pure_julia, :is_wrapper, :load_path, :package_license, :package_url, :package_uuid, :prediction_type, :supports_online, :supports_weights, :input_scitype, :target_scitype, :output_scitype),T} where T<:Tuple,1}:\n",
       " (name = AdaBoostClassifier, package_name = ScikitLearn, ... )\n",
       " (name = AdaBoostStumpClassifier, package_name = DecisionTree, ... )\n",
       " (name = BaggingClassifier, package_name = ScikitLearn, ... )\n",
       " (name = BayesianLDA, package_name = MultivariateStats, ... )\n",
       " (name = BayesianLDA, package_name = ScikitLearn, ... )\n",
       " (name = BayesianQDA, package_name = ScikitLearn, ... )\n",
       " (name = BayesianSubspaceLDA, package_name = MultivariateStats, ... )\n",
       " (name = ConstantClassifier, package_name = MLJModels, ... )\n",
       " (name = DecisionTreeClassifier, package_name = DecisionTree, ... )\n",
       " (name = DeterministicConstantClassifier, package_name = MLJModels, ... )\n",
       " (name = DummyClassifier, package_name = ScikitLearn, ... )\n",
       " (name = EvoTreeClassifier, package_name = EvoTrees, ... )\n",
       " (name = ExtraTreesClassifier, package_name = ScikitLearn, ... )\n",
       " ⋮\n",
       " (name = ProbabilisticSGDClassifier, package_name = ScikitLearn, ... )\n",
       " (name = RandomForestClassifier, package_name = DecisionTree, ... )\n",
       " (name = RandomForestClassifier, package_name = ScikitLearn, ... )\n",
       " (name = RidgeCVClassifier, package_name = ScikitLearn, ... )\n",
       " (name = RidgeClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SGDClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SVC, package_name = LIBSVM, ... )\n",
       " (name = SVMClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SVMLinearClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SVMNuClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SubspaceLDA, package_name = MultivariateStats, ... )\n",
       " (name = XGBoostClassifier, package_name = XGBoost, ... )"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models(matching(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Model code for DecisionTreeClassifier already loaded\n",
      "└ @ MLJModels /home/andrew/.julia/packages/MLJModels/5DFoi/src/loading.jl:54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(\n",
       "    max_depth = -1,\n",
       "    min_samples_leaf = 1,\n",
       "    min_samples_split = 2,\n",
       "    min_purity_increase = 0.0,\n",
       "    n_subfeatures = 0,\n",
       "    post_prune = false,\n",
       "    merge_purity_threshold = 1.0,\n",
       "    pdf_smoothing = 0.0,\n",
       "    display_depth = 5)\u001b[34m @181\u001b[39m"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@load DecisionTreeClassifier verbosity=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees\n",
    "* Be sure to use some form of pruning. \n",
    "* You are not required to use information gain (for example, there is something called the GINI index that is sometimes used) to split attributes, but you should describe whatever it is that you do use.\n",
    "\n",
    "1. https://alan-turing-institute.github.io/MLJ.jl/dev/transformers/#MLJModels.UnivariateDiscretizer\n",
    "1. https://alan-turing-institute.github.io/MLJ.jl/dev/getting_started/#Getting-Started-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No post-pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(\n",
       "    max_depth = -1,\n",
       "    min_samples_leaf = 1,\n",
       "    min_samples_split = 2,\n",
       "    min_purity_increase = 0.0,\n",
       "    n_subfeatures = 0,\n",
       "    post_prune = false,\n",
       "    merge_purity_threshold = 1.0,\n",
       "    pdf_smoothing = 0.0,\n",
       "    display_depth = 8)\u001b[34m @418\u001b[39m"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(post_prune=false, display_depth=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @049\u001b[39m trained 0 times.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @855\u001b[39m ⏎ `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @115\u001b[39m ⏎ `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tree = machine(dt, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{DecisionTreeClassifier} @049\u001b[39m.\n",
      "└ @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/machines.jl:322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 3, Threshold 1.0845743415\n",
      "L-> Feature 3, Threshold 0.3457475635\n",
      "    L-> Feature 3, Threshold 0.163776564\n",
      "        L-> Feature 3, Threshold -0.09493500099999999\n",
      "            L-> 1 : 1594/1594\n",
      "            R-> Feature 3, Threshold -0.0948241945\n",
      "                L-> 2 : 1/1\n",
      "                R-> Feature 1, Threshold 127.2421875\n",
      "                    L-> Feature 3, Threshold -0.018585328499999998\n",
      "                        L-> Feature 3, Threshold -0.0189379425\n",
      "                            L-> 1 : 330/330\n",
      "                            R-> 2 : 1/1\n",
      "                        R-> 1 : 1884/1884\n",
      "                    R-> Feature 1, Threshold 127.59765625\n",
      "                        L-> Feature 1, Threshold 127.56640625\n",
      "                            L-> \n",
      "                            R-> \n",
      "                        R-> Feature 3, Threshold 0.088706859\n",
      "                            L-> 1 : 1147/1147\n",
      "                            R-> \n",
      "        R-> Feature 2, Threshold 45.557603549999996\n",
      "            L-> Feature 2, Threshold 45.54981163\n",
      "                L-> Feature 6, Threshold 28.53321501\n",
      "                    L-> Feature 1, Threshold 112.43359375\n",
      "                        L-> Feature 1, Threshold 112.29296875\n",
      "                            L-> \n",
      "                            R-> \n",
      "                        R-> 1 : 410/410\n",
      "                    R-> Feature 6, Threshold 28.705881390000002\n",
      "                        L-> 2 : 1/1\n",
      "                        R-> Feature 2, Threshold 43.876804175000004\n",
      "                            L-> \n",
      "                            R-> \n",
      "                R-> 2 : 1/1\n",
      "            R-> Feature 3, Threshold 0.1639058065\n",
      "                L-> 2 : 1/1\n",
      "                R-> Feature 3, Threshold 0.315473087\n",
      "                    L-> Feature 6, Threshold 44.807853315\n",
      "                        L-> 1 : 1440/1440\n",
      "                        R-> Feature 8, Threshold 8.698306435\n",
      "                            L-> 1 : 95/95\n",
      "                            R-> \n",
      "                    R-> Feature 3, Threshold 0.31558551599999995\n",
      "                        L-> 2 : 1/1\n",
      "                        R-> Feature 6, Threshold 9.3468125205\n",
      "                            L-> 2 : 1/1\n",
      "                            R-> \n",
      "    R-> Feature 6, Threshold 27.994632285\n",
      "        L-> Feature 3, Threshold 0.7677057494999999\n",
      "            L-> Feature 2, Threshold 37.455441855000004\n",
      "                L-> 1 : 351/351\n",
      "                R-> Feature 2, Threshold 37.458133335\n",
      "                    L-> 2 : 1/1\n",
      "                    R-> Feature 1, Threshold 88.43359375\n",
      "                        L-> 1 : 242/242\n",
      "                        R-> Feature 1, Threshold 88.4609375\n",
      "                            L-> 2 : 1/1\n",
      "                            R-> \n",
      "            R-> Feature 2, Threshold 42.859770995000005\n",
      "                L-> Feature 1, Threshold 81.390625\n",
      "                    L-> 1 : 110/110\n",
      "                    R-> Feature 1, Threshold 81.49609375\n",
      "                        L-> 2 : 1/1\n",
      "                        R-> Feature 3, Threshold 0.837425487\n",
      "                            L-> \n",
      "                            R-> 1 : 66/66\n",
      "                R-> Feature 6, Threshold 16.14153513\n",
      "                    L-> Feature 3, Threshold 1.0054088865\n",
      "                        L-> 1 : 28/28\n",
      "                        R-> Feature 2, Threshold 47.667693255\n",
      "                            L-> 2 : 1/1\n",
      "                            R-> 1 : 1/1\n",
      "                    R-> Feature 6, Threshold 16.303167545\n",
      "                        L-> 2 : 2/2\n",
      "                        R-> Feature 3, Threshold 0.9449931\n",
      "                            L-> \n",
      "                            R-> \n",
      "        R-> Feature 3, Threshold 0.817397867\n",
      "            L-> Feature 7, Threshold 3.1218967575\n",
      "                L-> Feature 3, Threshold 0.4405811355\n",
      "                    L-> Feature 3, Threshold 0.346074066\n",
      "                        L-> 2 : 1/1\n",
      "                        R-> Feature 2, Threshold 51.41982951999999\n",
      "                            L-> 1 : 32/32\n",
      "                            R-> \n",
      "                    R-> Feature 7, Threshold 0.194754234\n",
      "                        L-> Feature 6, Threshold 97.365132055\n",
      "                            L-> 1 : 27/27\n",
      "                            R-> \n",
      "                        R-> Feature 1, Threshold 100.86328125\n",
      "                            L-> \n",
      "                            R-> \n",
      "                R-> Feature 1, Threshold 96.58984375\n",
      "                    L-> Feature 2, Threshold 47.200996875\n",
      "                        L-> 1 : 80/80\n",
      "                        R-> Feature 2, Threshold 47.37835523\n",
      "                            L-> 2 : 1/1\n",
      "                            R-> 1 : 10/10\n",
      "                    R-> Feature 3, Threshold 0.5265485685\n",
      "                        L-> Feature 7, Threshold 5.9363769315\n",
      "                            L-> \n",
      "                            R-> \n",
      "                        R-> Feature 3, Threshold 0.5354819230000001\n",
      "                            L-> \n",
      "                            R-> \n",
      "            R-> Feature 4, Threshold 2.2153734335\n",
      "                L-> Feature 7, Threshold 1.1199327585\n",
      "                    L-> Feature 3, Threshold 1.0045686075\n",
      "                        L-> Feature 3, Threshold 0.938122637\n",
      "                            L-> \n",
      "                            R-> 1 : 6/6\n",
      "                        R-> Feature 5, Threshold 133.82859530000002\n",
      "                            L-> \n",
      "                            R-> 2 : 4/4\n",
      "                    R-> Feature 3, Threshold 1.0632489155\n",
      "                        L-> Feature 6, Threshold 41.479049950000004\n",
      "                            L-> \n",
      "                            R-> 2 : 16/16\n",
      "                        R-> 1 : 2/2\n",
      "                R-> Feature 1, Threshold 88.25390625\n",
      "                    L-> 1 : 21/21\n",
      "                    R-> Feature 1, Threshold 92.203125\n",
      "                        L-> 2 : 1/1\n",
      "                        R-> 1 : 2/2\n",
      "R-> Feature 3, Threshold 1.5225476735\n",
      "    L-> Feature 6, Threshold 23.409673395\n",
      "        L-> Feature 1, Threshold 89.4140625\n",
      "            L-> Feature 3, Threshold 1.3639256185000002\n",
      "                L-> Feature 3, Threshold 1.0945411225\n",
      "                    L-> 2 : 1/1\n",
      "                    R-> Feature 4, Threshold 2.414257165\n",
      "                        L-> Feature 2, Threshold 48.05141729\n",
      "                            L-> 2 : 1/1\n",
      "                            R-> 1 : 5/5\n",
      "                        R-> 1 : 31/31\n",
      "                R-> 2 : 2/2\n",
      "            R-> 2 : 3/3\n",
      "        R-> Feature 7, Threshold 1.618563661\n",
      "            L-> Feature 1, Threshold 69.51953125\n",
      "                L-> 1 : 8/8\n",
      "                R-> Feature 2, Threshold 58.403731745\n",
      "                    L-> Feature 8, Threshold -1.705776148\n",
      "                        L-> 1 : 4/4\n",
      "                        R-> Feature 5, Threshold 41.14005017\n",
      "                            L-> 1 : 4/4\n",
      "                            R-> \n",
      "                    R-> 2 : 5/5\n",
      "            R-> Feature 3, Threshold 1.1187952934999998\n",
      "                L-> Feature 2, Threshold 37.332282465000006\n",
      "                    L-> 1 : 3/3\n",
      "                    R-> Feature 3, Threshold 1.092505854\n",
      "                        L-> 1 : 1/1\n",
      "                        R-> 2 : 3/3\n",
      "                R-> Feature 1, Threshold 73.53125\n",
      "                    L-> 1 : 2/2\n",
      "                    R-> Feature 4, Threshold 1.9265600615\n",
      "                        L-> Feature 4, Threshold 1.7753003575\n",
      "                            L-> \n",
      "                            R-> 1 : 1/1\n",
      "                        R-> 2 : 58/58\n",
      "    R-> Feature 3, Threshold 2.670348647\n",
      "        L-> Feature 7, Threshold 0.37629415499999996\n",
      "            L-> Feature 7, Threshold 0.171747004\n",
      "                L-> Feature 1, Threshold 76.44921875\n",
      "                    L-> Feature 8, Threshold -1.7381392385\n",
      "                        L-> 1 : 3/3\n",
      "                        R-> Feature 5, Threshold 137.16429764999998\n",
      "                            L-> 2 : 8/8\n",
      "                            R-> \n",
      "                    R-> 2 : 8/8\n",
      "                R-> Feature 6, Threshold 83.91434226999999\n",
      "                    L-> 1 : 5/5\n",
      "                    R-> 2 : 1/1\n",
      "            R-> Feature 1, Threshold 66.484375\n",
      "                L-> Feature 7, Threshold 9.2829436665\n",
      "                    L-> Feature 2, Threshold 30.132134999999998\n",
      "                        L-> 1 : 1/1\n",
      "                        R-> Feature 8, Threshold 23.25387886\n",
      "                            L-> \n",
      "                            R-> 2 : 22/22\n",
      "                    R-> 1 : 2/2\n",
      "                R-> Feature 2, Threshold 31.51382543\n",
      "                    L-> 1 : 1/1\n",
      "                    R-> Feature 2, Threshold 46.50677293\n",
      "                        L-> Feature 3, Threshold 2.184274963\n",
      "                            L-> 2 : 98/98\n",
      "                            R-> \n",
      "                        R-> Feature 4, Threshold 4.0603601860000005\n",
      "                            L-> 2 : 15/15\n",
      "                            R-> \n",
      "        R-> Feature 2, Threshold 39.136276145\n",
      "            L-> 2 : 511/511\n",
      "            R-> Feature 2, Threshold 40.376768165\n",
      "                L-> Feature 6, Threshold 24.297348195\n",
      "                    L-> 1 : 1/1\n",
      "                    R-> Feature 5, Threshold 176.12876254999998\n",
      "                        L-> Feature 4, Threshold 20.45177787\n",
      "                            L-> 2 : 19/19\n",
      "                            R-> \n",
      "                        R-> 1 : 1/1\n",
      "                R-> 2 : 84/84\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @049\u001b[39m trained 1 time.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @855\u001b[39m ⏎ `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @115\u001b[39m ⏎ `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(Tree, rows=train, verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 6 folds: 100%[=========================] Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "┌\u001b[0m───────────────\u001b[0m┬\u001b[0m───────────────\u001b[0m┬\u001b[0m────────────────────────────────────────────\u001b[0m┐\u001b[0m\n",
       "│\u001b[0m\u001b[22m _.measure     \u001b[0m│\u001b[0m\u001b[22m _.measurement \u001b[0m│\u001b[0m\u001b[22m _.per_fold                                 \u001b[0m│\u001b[0m\n",
       "├\u001b[0m───────────────\u001b[0m┼\u001b[0m───────────────\u001b[0m┼\u001b[0m────────────────────────────────────────────\u001b[0m┤\u001b[0m\n",
       "│\u001b[0m cross_entropy \u001b[0m│\u001b[0m 1.2           \u001b[0m│\u001b[0m [1.04, 1.35, 1.24, 1.21, 1.14, 1.24]       \u001b[0m│\u001b[0m\n",
       "│\u001b[0m acc           \u001b[0m│\u001b[0m 0.967         \u001b[0m│\u001b[0m [0.971, 0.962, 0.965, 0.966, 0.968, 0.965] \u001b[0m│\u001b[0m\n",
       "└\u001b[0m───────────────\u001b[0m┴\u001b[0m───────────────\u001b[0m┴\u001b[0m────────────────────────────────────────────\u001b[0m┘\u001b[0m\n",
       "_.per_observation = [[[2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16]], missing]\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_acc = evaluate!(Tree, resampling=CV(shuffle=true), measure=[cross_entropy, acc], verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tree = Decision Tree\n",
       "Leaves: 324\n",
       "Depth:  20,\n",
       " encoding = Dict{CategoricalValue{Int64,UInt32},UInt32}(0 => 0x00000001,1 => 0x00000002),)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_params(Tree) \n",
    "# print_tree(Tree.fitresult[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(classes_seen = CategoricalValue{Int64,UInt32}[0, 1],\n",
       " print_tree = TreePrinter object (call with display depth),)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report(Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Post-pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(\n",
       "    max_depth = -1,\n",
       "    min_samples_leaf = 1,\n",
       "    min_samples_split = 2,\n",
       "    min_purity_increase = 0.0,\n",
       "    n_subfeatures = 0,\n",
       "    post_prune = true,\n",
       "    merge_purity_threshold = 1.0,\n",
       "    pdf_smoothing = 0.0,\n",
       "    display_depth = 5)\u001b[34m @822\u001b[39m"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt2 = DecisionTreeClassifier(post_prune=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @697\u001b[39m trained 0 times.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @999\u001b[39m ⏎ `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @976\u001b[39m ⏎ `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tree2 = machine(dt2, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{DecisionTreeClassifier} @697\u001b[39m.\n",
      "└ @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/machines.jl:322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 3, Threshold 1.125419075\n",
      "L-> Feature 3, Threshold 0.3315821845\n",
      "    L-> Feature 3, Threshold 0.08878459899999999\n",
      "        L-> Feature 1, Threshold 127.59375\n",
      "            L-> Feature 1, Threshold 127.56640625\n",
      "                L-> 1 : 1545/1545\n",
      "                R-> \n",
      "            R-> 1 : 2525/2525\n",
      "        R-> Feature 2, Threshold 45.713650945\n",
      "            L-> Feature 6, Threshold 28.437492499999998\n",
      "                L-> \n",
      "                R-> \n",
      "            R-> Feature 3, Threshold 0.089089753\n",
      "                L-> 2 : 1/1\n",
      "                R-> \n",
      "    R-> Feature 6, Threshold 26.103903135000003\n",
      "        L-> Feature 6, Threshold 15.81663735\n",
      "            L-> Feature 5, Threshold 0.959866221\n",
      "                L-> \n",
      "                R-> \n",
      "            R-> Feature 3, Threshold 0.7677057494999999\n",
      "                L-> \n",
      "                R-> \n",
      "        R-> Feature 3, Threshold 0.9116480495\n",
      "            L-> Feature 2, Threshold 42.575829035\n",
      "                L-> \n",
      "                R-> \n",
      "            R-> Feature 2, Threshold 36.830941845\n",
      "                L-> \n",
      "                R-> \n",
      "R-> Feature 3, Threshold 1.716443635\n",
      "    L-> Feature 6, Threshold 23.65988604\n",
      "        L-> Feature 3, Threshold 1.2014623995\n",
      "            L-> 1 : 15/15\n",
      "            R-> Feature 1, Threshold 85.171875\n",
      "                L-> \n",
      "                R-> 2 : 3/3\n",
      "        R-> Feature 7, Threshold 1.618563661\n",
      "            L-> Feature 3, Threshold 1.3826888455000002\n",
      "                L-> \n",
      "                R-> \n",
      "            R-> Feature 2, Threshold 34.193070899999995\n",
      "                L-> 1 : 4/4\n",
      "                R-> \n",
      "    R-> Feature 3, Threshold 2.5660046515\n",
      "        L-> Feature 7, Threshold 1.2944660314999998\n",
      "            L-> Feature 8, Threshold 0.6456529520000001\n",
      "                L-> \n",
      "                R-> 1 : 3/3\n",
      "            R-> Feature 3, Threshold 2.551815212\n",
      "                L-> \n",
      "                R-> 1 : 2/2\n",
      "        R-> Feature 4, Threshold 24.91313546\n",
      "            L-> Feature 4, Threshold 24.86836714\n",
      "                L-> \n",
      "                R-> 1 : 1/1\n",
      "            R-> 2 : 283/283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @697\u001b[39m trained 1 time.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @999\u001b[39m ⏎ `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @976\u001b[39m ⏎ `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(Tree2, rows=train, verbosity=2, force=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 6 folds: 100%[=========================] Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "┌\u001b[0m───────────────\u001b[0m┬\u001b[0m───────────────\u001b[0m┬\u001b[0m───────────────────────────────────────────\u001b[0m┐\u001b[0m\n",
       "│\u001b[0m\u001b[22m _.measure     \u001b[0m│\u001b[0m\u001b[22m _.measurement \u001b[0m│\u001b[0m\u001b[22m _.per_fold                                \u001b[0m│\u001b[0m\n",
       "├\u001b[0m───────────────\u001b[0m┼\u001b[0m───────────────\u001b[0m┼\u001b[0m───────────────────────────────────────────\u001b[0m┤\u001b[0m\n",
       "│\u001b[0m cross_entropy \u001b[0m│\u001b[0m 1.13          \u001b[0m│\u001b[0m [0.906, 1.28, 1.06, 1.17, 1.1, 1.27]      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m acc           \u001b[0m│\u001b[0m 0.969         \u001b[0m│\u001b[0m [0.975, 0.964, 0.97, 0.967, 0.969, 0.965] \u001b[0m│\u001b[0m\n",
       "└\u001b[0m───────────────\u001b[0m┴\u001b[0m───────────────\u001b[0m┴\u001b[0m───────────────────────────────────────────\u001b[0m┘\u001b[0m\n",
       "_.per_observation = [[[2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [36.0, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [36.0, 2.22e-16, ..., 2.22e-16]], missing]\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_acc = evaluate!(Tree2, resampling=CV(shuffle=true), measure=[cross_entropy, acc], verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate!(Tree2, resampling=CV(shuffle=true), measure=[tnr,tpr,fnr,fpr], verbosity=1, operation=predict_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tree = Decision Tree\n",
       "Leaves: 317\n",
       "Depth:  29,\n",
       " encoding = Dict{CategoricalValue{Int64,UInt32},UInt32}(0 => 0x00000001,1 => 0x00000002),)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_params(Tree2) \n",
    "# print_tree(Tree.fitresult[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(classes_seen = CategoricalValue{Int64,UInt32}[0, 1],\n",
       " print_tree = TreePrinter object (call with display depth),)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report(Tree2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch / RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{ProbabilisticTunedModel{Grid,…}} @051\u001b[39m.\n",
      "└ @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/machines.jl:322\n",
      "┌ Info: Attempting to evaluate 101 models.\n",
      "└ @ MLJTuning /home/andrew/.julia/packages/MLJTuning/nuvTc/src/tuned_models.jl:501\n",
      "\u001b[33mEvaluating over 101 metamodels: 100%[=========================] Time: 0:03:40\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(parameter_name = \"merge_purity_threshold\",\n",
       " parameter_scale = :none,\n",
       " parameter_values = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09  …  0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.0],\n",
       " measurements = [0.31734618337388115, 0.31734618337388115, 0.31734618337388115, 0.31734618337388115, 0.31734618337388115, 0.31734618337388115, 0.31734618337388115, 0.31734618337388115, 0.31734618337388115, 0.31734618337388115  …  1.052846031257589, 1.061957280663215, 1.0805719658850375, 1.0878862555230084, 1.1175505997516766, 1.1335571841402483, 1.1530839889656255, 1.1558495503041937, 1.1380860083490822, 1.1438593767470413],)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = range(dt2, :merge_purity_threshold, lower=0, upper=1, scale=:linear)\n",
    "curve = learning_curve(Tree2, \n",
    "                        range=r, \n",
    "#                         resampling=Holdout(fraction_train=0.7), \n",
    "                        resampling=CV(), \n",
    "                        measure=cross_entropy, \n",
    "                        acceleration=CPUThreads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip100\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip100)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip101\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip100)\" d=\"\n",
       "M211.602 1423.18 L2352.76 1423.18 L2352.76 47.2441 L211.602 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip102\">\n",
       "    <rect x=\"211\" y=\"47\" width=\"2142\" height=\"1377\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip102)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  272.201,1423.18 272.201,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip102)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  777.19,1423.18 777.19,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip102)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1282.18,1423.18 1282.18,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip102)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1787.17,1423.18 1787.17,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip102)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2292.16,1423.18 2292.16,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip102)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  211.602,1256.29 2352.76,1256.29 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip102)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  211.602,946.674 2352.76,946.674 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip102)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  211.602,637.062 2352.76,637.062 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip102)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  211.602,327.45 2352.76,327.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  211.602,1423.18 2352.76,1423.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  211.602,1423.18 211.602,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  272.201,1423.18 272.201,1406.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  777.19,1423.18 777.19,1406.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1282.18,1423.18 1282.18,1406.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1787.17,1423.18 1787.17,1406.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2292.16,1423.18 2292.16,1406.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  211.602,1256.29 237.296,1256.29 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  211.602,946.674 237.296,946.674 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  211.602,637.062 237.296,637.062 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  211.602,327.45 237.296,327.45 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip100)\" d=\"M 0 0 M240.211 1445.17 Q236.599 1445.17 234.771 1448.74 Q232.965 1452.28 232.965 1459.41 Q232.965 1466.51 234.771 1470.08 Q236.599 1473.62 240.211 1473.62 Q243.845 1473.62 245.65 1470.08 Q247.479 1466.51 247.479 1459.41 Q247.479 1452.28 245.65 1448.74 Q243.845 1445.17 240.211 1445.17 M240.211 1441.47 Q246.021 1441.47 249.076 1446.07 Q252.155 1450.66 252.155 1459.41 Q252.155 1468.13 249.076 1472.74 Q246.021 1477.32 240.211 1477.32 Q234.4 1477.32 231.322 1472.74 Q228.266 1468.13 228.266 1459.41 Q228.266 1450.66 231.322 1446.07 Q234.4 1441.47 240.211 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M257.224 1470.77 L262.109 1470.77 L262.109 1476.65 L257.224 1476.65 L257.224 1470.77 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M277.178 1445.17 Q273.567 1445.17 271.738 1448.74 Q269.933 1452.28 269.933 1459.41 Q269.933 1466.51 271.738 1470.08 Q273.567 1473.62 277.178 1473.62 Q280.812 1473.62 282.618 1470.08 Q284.446 1466.51 284.446 1459.41 Q284.446 1452.28 282.618 1448.74 Q280.812 1445.17 277.178 1445.17 M277.178 1441.47 Q282.988 1441.47 286.044 1446.07 Q289.122 1450.66 289.122 1459.41 Q289.122 1468.13 286.044 1472.74 Q282.988 1477.32 277.178 1477.32 Q271.368 1477.32 268.289 1472.74 Q265.234 1468.13 265.234 1459.41 Q265.234 1450.66 268.289 1446.07 Q271.368 1441.47 277.178 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M304.192 1445.17 Q300.581 1445.17 298.752 1448.74 Q296.946 1452.28 296.946 1459.41 Q296.946 1466.51 298.752 1470.08 Q300.581 1473.62 304.192 1473.62 Q307.826 1473.62 309.631 1470.08 Q311.46 1466.51 311.46 1459.41 Q311.46 1452.28 309.631 1448.74 Q307.826 1445.17 304.192 1445.17 M304.192 1441.47 Q310.002 1441.47 313.057 1446.07 Q316.136 1450.66 316.136 1459.41 Q316.136 1468.13 313.057 1472.74 Q310.002 1477.32 304.192 1477.32 Q298.382 1477.32 295.303 1472.74 Q292.247 1468.13 292.247 1459.41 Q292.247 1450.66 295.303 1446.07 Q298.382 1441.47 304.192 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M746.496 1445.17 Q742.885 1445.17 741.056 1448.74 Q739.251 1452.28 739.251 1459.41 Q739.251 1466.51 741.056 1470.08 Q742.885 1473.62 746.496 1473.62 Q750.13 1473.62 751.936 1470.08 Q753.764 1466.51 753.764 1459.41 Q753.764 1452.28 751.936 1448.74 Q750.13 1445.17 746.496 1445.17 M746.496 1441.47 Q752.306 1441.47 755.362 1446.07 Q758.44 1450.66 758.44 1459.41 Q758.44 1468.13 755.362 1472.74 Q752.306 1477.32 746.496 1477.32 Q740.686 1477.32 737.607 1472.74 Q734.551 1468.13 734.551 1459.41 Q734.551 1450.66 737.607 1446.07 Q740.686 1441.47 746.496 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M763.51 1470.77 L768.394 1470.77 L768.394 1476.65 L763.51 1476.65 L763.51 1470.77 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M777.491 1472.72 L793.81 1472.72 L793.81 1476.65 L771.866 1476.65 L771.866 1472.72 Q774.528 1469.96 779.111 1465.33 Q783.718 1460.68 784.898 1459.34 Q787.144 1456.81 788.023 1455.08 Q788.926 1453.32 788.926 1451.63 Q788.926 1448.87 786.982 1447.14 Q785.06 1445.4 781.959 1445.4 Q779.76 1445.4 777.306 1446.17 Q774.875 1446.93 772.098 1448.48 L772.098 1443.76 Q774.922 1442.62 777.375 1442.05 Q779.829 1441.47 781.866 1441.47 Q787.236 1441.47 790.431 1444.15 Q793.625 1446.84 793.625 1451.33 Q793.625 1453.46 792.815 1455.38 Q792.028 1457.28 789.922 1459.87 Q789.343 1460.54 786.241 1463.76 Q783.139 1466.95 777.491 1472.72 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M798.926 1442.09 L817.283 1442.09 L817.283 1446.03 L803.209 1446.03 L803.209 1454.5 Q804.227 1454.15 805.246 1453.99 Q806.264 1453.8 807.283 1453.8 Q813.07 1453.8 816.449 1456.98 Q819.829 1460.15 819.829 1465.56 Q819.829 1471.14 816.357 1474.24 Q812.884 1477.32 806.565 1477.32 Q804.389 1477.32 802.121 1476.95 Q799.875 1476.58 797.468 1475.84 L797.468 1471.14 Q799.551 1472.28 801.773 1472.83 Q803.996 1473.39 806.472 1473.39 Q810.477 1473.39 812.815 1471.28 Q815.153 1469.18 815.153 1465.56 Q815.153 1461.95 812.815 1459.85 Q810.477 1457.74 806.472 1457.74 Q804.597 1457.74 802.722 1458.16 Q800.871 1458.57 798.926 1459.45 L798.926 1442.09 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1250.69 1445.17 Q1247.08 1445.17 1245.25 1448.74 Q1243.44 1452.28 1243.44 1459.41 Q1243.44 1466.51 1245.25 1470.08 Q1247.08 1473.62 1250.69 1473.62 Q1254.32 1473.62 1256.13 1470.08 Q1257.95 1466.51 1257.95 1459.41 Q1257.95 1452.28 1256.13 1448.74 Q1254.32 1445.17 1250.69 1445.17 M1250.69 1441.47 Q1256.5 1441.47 1259.55 1446.07 Q1262.63 1450.66 1262.63 1459.41 Q1262.63 1468.13 1259.55 1472.74 Q1256.5 1477.32 1250.69 1477.32 Q1244.88 1477.32 1241.8 1472.74 Q1238.74 1468.13 1238.74 1459.41 Q1238.74 1450.66 1241.8 1446.07 Q1244.88 1441.47 1250.69 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1267.7 1470.77 L1272.58 1470.77 L1272.58 1476.65 L1267.7 1476.65 L1267.7 1470.77 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1277.7 1442.09 L1296.06 1442.09 L1296.06 1446.03 L1281.98 1446.03 L1281.98 1454.5 Q1283 1454.15 1284.02 1453.99 Q1285.04 1453.8 1286.06 1453.8 Q1291.84 1453.8 1295.22 1456.98 Q1298.6 1460.15 1298.6 1465.56 Q1298.6 1471.14 1295.13 1474.24 Q1291.66 1477.32 1285.34 1477.32 Q1283.16 1477.32 1280.89 1476.95 Q1278.65 1476.58 1276.24 1475.84 L1276.24 1471.14 Q1278.33 1472.28 1280.55 1472.83 Q1282.77 1473.39 1285.25 1473.39 Q1289.25 1473.39 1291.59 1471.28 Q1293.93 1469.18 1293.93 1465.56 Q1293.93 1461.95 1291.59 1459.85 Q1289.25 1457.74 1285.25 1457.74 Q1283.37 1457.74 1281.5 1458.16 Q1279.64 1458.57 1277.7 1459.45 L1277.7 1442.09 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1313.67 1445.17 Q1310.06 1445.17 1308.23 1448.74 Q1306.43 1452.28 1306.43 1459.41 Q1306.43 1466.51 1308.23 1470.08 Q1310.06 1473.62 1313.67 1473.62 Q1317.31 1473.62 1319.11 1470.08 Q1320.94 1466.51 1320.94 1459.41 Q1320.94 1452.28 1319.11 1448.74 Q1317.31 1445.17 1313.67 1445.17 M1313.67 1441.47 Q1319.48 1441.47 1322.54 1446.07 Q1325.62 1450.66 1325.62 1459.41 Q1325.62 1468.13 1322.54 1472.74 Q1319.48 1477.32 1313.67 1477.32 Q1307.86 1477.32 1304.78 1472.74 Q1301.73 1468.13 1301.73 1459.41 Q1301.73 1450.66 1304.78 1446.07 Q1307.86 1441.47 1313.67 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1756.13 1445.17 Q1752.52 1445.17 1750.69 1448.74 Q1748.88 1452.28 1748.88 1459.41 Q1748.88 1466.51 1750.69 1470.08 Q1752.52 1473.62 1756.13 1473.62 Q1759.76 1473.62 1761.57 1470.08 Q1763.4 1466.51 1763.4 1459.41 Q1763.4 1452.28 1761.57 1448.74 Q1759.76 1445.17 1756.13 1445.17 M1756.13 1441.47 Q1761.94 1441.47 1764.99 1446.07 Q1768.07 1450.66 1768.07 1459.41 Q1768.07 1468.13 1764.99 1472.74 Q1761.94 1477.32 1756.13 1477.32 Q1750.32 1477.32 1747.24 1472.74 Q1744.18 1468.13 1744.18 1459.41 Q1744.18 1450.66 1747.24 1446.07 Q1750.32 1441.47 1756.13 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1773.14 1470.77 L1778.02 1470.77 L1778.02 1476.65 L1773.14 1476.65 L1773.14 1470.77 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1781.91 1442.09 L1804.14 1442.09 L1804.14 1444.08 L1791.59 1476.65 L1786.71 1476.65 L1798.51 1446.03 L1781.91 1446.03 L1781.91 1442.09 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1809.25 1442.09 L1827.61 1442.09 L1827.61 1446.03 L1813.53 1446.03 L1813.53 1454.5 Q1814.55 1454.15 1815.57 1453.99 Q1816.59 1453.8 1817.61 1453.8 Q1823.39 1453.8 1826.77 1456.98 Q1830.15 1460.15 1830.15 1465.56 Q1830.15 1471.14 1826.68 1474.24 Q1823.21 1477.32 1816.89 1477.32 Q1814.71 1477.32 1812.45 1476.95 Q1810.2 1476.58 1807.79 1475.84 L1807.79 1471.14 Q1809.88 1472.28 1812.1 1472.83 Q1814.32 1473.39 1816.8 1473.39 Q1820.8 1473.39 1823.14 1471.28 Q1825.48 1469.18 1825.48 1465.56 Q1825.48 1461.95 1823.14 1459.85 Q1820.8 1457.74 1816.8 1457.74 Q1814.92 1457.74 1813.05 1458.16 Q1811.2 1458.57 1809.25 1459.45 L1809.25 1442.09 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2250.55 1472.72 L2258.19 1472.72 L2258.19 1446.35 L2249.88 1448.02 L2249.88 1443.76 L2258.14 1442.09 L2262.82 1442.09 L2262.82 1472.72 L2270.46 1472.72 L2270.46 1476.65 L2250.55 1476.65 L2250.55 1472.72 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2275.53 1470.77 L2280.41 1470.77 L2280.41 1476.65 L2275.53 1476.65 L2275.53 1470.77 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2295.48 1445.17 Q2291.87 1445.17 2290.04 1448.74 Q2288.23 1452.28 2288.23 1459.41 Q2288.23 1466.51 2290.04 1470.08 Q2291.87 1473.62 2295.48 1473.62 Q2299.11 1473.62 2300.92 1470.08 Q2302.75 1466.51 2302.75 1459.41 Q2302.75 1452.28 2300.92 1448.74 Q2299.11 1445.17 2295.48 1445.17 M2295.48 1441.47 Q2301.29 1441.47 2304.34 1446.07 Q2307.42 1450.66 2307.42 1459.41 Q2307.42 1468.13 2304.34 1472.74 Q2301.29 1477.32 2295.48 1477.32 Q2289.67 1477.32 2286.59 1472.74 Q2283.53 1468.13 2283.53 1459.41 Q2283.53 1450.66 2286.59 1446.07 Q2289.67 1441.47 2295.48 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2322.49 1445.17 Q2318.88 1445.17 2317.05 1448.74 Q2315.25 1452.28 2315.25 1459.41 Q2315.25 1466.51 2317.05 1470.08 Q2318.88 1473.62 2322.49 1473.62 Q2326.13 1473.62 2327.93 1470.08 Q2329.76 1466.51 2329.76 1459.41 Q2329.76 1452.28 2327.93 1448.74 Q2326.13 1445.17 2322.49 1445.17 M2322.49 1441.47 Q2328.3 1441.47 2331.36 1446.07 Q2334.44 1450.66 2334.44 1459.41 Q2334.44 1468.13 2331.36 1472.74 Q2328.3 1477.32 2322.49 1477.32 Q2316.68 1477.32 2313.6 1472.74 Q2310.55 1468.13 2310.55 1459.41 Q2310.55 1450.66 2313.6 1446.07 Q2316.68 1441.47 2322.49 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M138.205 1242.08 Q134.593 1242.08 132.765 1245.65 Q130.959 1249.19 130.959 1256.32 Q130.959 1263.43 132.765 1266.99 Q134.593 1270.53 138.205 1270.53 Q141.839 1270.53 143.644 1266.99 Q145.473 1263.43 145.473 1256.32 Q145.473 1249.19 143.644 1245.65 Q141.839 1242.08 138.205 1242.08 M138.205 1238.38 Q144.015 1238.38 147.07 1242.99 Q150.149 1247.57 150.149 1256.32 Q150.149 1265.05 147.07 1269.65 Q144.015 1274.24 138.205 1274.24 Q132.394 1274.24 129.316 1269.65 Q126.26 1265.05 126.26 1256.32 Q126.26 1247.57 129.316 1242.99 Q132.394 1238.38 138.205 1238.38 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M155.218 1267.69 L160.103 1267.69 L160.103 1273.57 L155.218 1273.57 L155.218 1267.69 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M178.019 1243.08 L166.214 1261.53 L178.019 1261.53 L178.019 1243.08 M176.792 1239.01 L182.672 1239.01 L182.672 1261.53 L187.602 1261.53 L187.602 1265.42 L182.672 1265.42 L182.672 1273.57 L178.019 1273.57 L178.019 1265.42 L162.417 1265.42 L162.417 1260.9 L176.792 1239.01 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M138.529 932.472 Q134.918 932.472 133.089 936.037 Q131.283 939.579 131.283 946.708 Q131.283 953.815 133.089 957.379 Q134.918 960.921 138.529 960.921 Q142.163 960.921 143.968 957.379 Q145.797 953.815 145.797 946.708 Q145.797 939.579 143.968 936.037 Q142.163 932.472 138.529 932.472 M138.529 928.769 Q144.339 928.769 147.394 933.375 Q150.473 937.958 150.473 946.708 Q150.473 955.435 147.394 960.041 Q144.339 964.625 138.529 964.625 Q132.718 964.625 129.64 960.041 Q126.584 955.435 126.584 946.708 Q126.584 937.958 129.64 933.375 Q132.718 928.769 138.529 928.769 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M155.542 958.074 L160.427 958.074 L160.427 963.954 L155.542 963.954 L155.542 958.074 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M176.075 944.81 Q172.927 944.81 171.075 946.963 Q169.246 949.116 169.246 952.866 Q169.246 956.592 171.075 958.768 Q172.927 960.921 176.075 960.921 Q179.223 960.921 181.052 958.768 Q182.903 956.592 182.903 952.866 Q182.903 949.116 181.052 946.963 Q179.223 944.81 176.075 944.81 M185.357 930.157 L185.357 934.417 Q183.598 933.583 181.792 933.143 Q180.01 932.704 178.251 932.704 Q173.621 932.704 171.167 935.829 Q168.737 938.954 168.39 945.273 Q169.755 943.259 171.815 942.194 Q173.876 941.106 176.352 941.106 Q181.561 941.106 184.57 944.278 Q187.602 947.426 187.602 952.866 Q187.602 958.19 184.454 961.407 Q181.306 964.625 176.075 964.625 Q170.079 964.625 166.908 960.041 Q163.737 955.435 163.737 946.708 Q163.737 938.514 167.626 933.653 Q171.515 928.769 178.065 928.769 Q179.825 928.769 181.607 929.116 Q183.413 929.463 185.357 930.157 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M138.783 622.86 Q135.172 622.86 133.343 626.425 Q131.538 629.967 131.538 637.096 Q131.538 644.203 133.343 647.768 Q135.172 651.309 138.783 651.309 Q142.417 651.309 144.223 647.768 Q146.052 644.203 146.052 637.096 Q146.052 629.967 144.223 626.425 Q142.417 622.86 138.783 622.86 M138.783 619.157 Q144.593 619.157 147.649 623.763 Q150.728 628.347 150.728 637.096 Q150.728 645.823 147.649 650.43 Q144.593 655.013 138.783 655.013 Q132.973 655.013 129.894 650.43 Q126.839 645.823 126.839 637.096 Q126.839 628.347 129.894 623.763 Q132.973 619.157 138.783 619.157 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M155.797 648.462 L160.681 648.462 L160.681 654.342 L155.797 654.342 L155.797 648.462 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M175.751 637.93 Q172.417 637.93 170.496 639.712 Q168.598 641.495 168.598 644.62 Q168.598 647.745 170.496 649.527 Q172.417 651.309 175.751 651.309 Q179.084 651.309 181.005 649.527 Q182.927 647.721 182.927 644.62 Q182.927 641.495 181.005 639.712 Q179.107 637.93 175.751 637.93 M171.075 635.939 Q168.065 635.198 166.376 633.138 Q164.709 631.078 164.709 628.115 Q164.709 623.972 167.649 621.564 Q170.612 619.157 175.751 619.157 Q180.913 619.157 183.852 621.564 Q186.792 623.972 186.792 628.115 Q186.792 631.078 185.102 633.138 Q183.436 635.198 180.45 635.939 Q183.829 636.726 185.704 639.018 Q187.602 641.309 187.602 644.62 Q187.602 649.643 184.524 652.328 Q181.468 655.013 175.751 655.013 Q170.033 655.013 166.954 652.328 Q163.899 649.643 163.899 644.62 Q163.899 641.309 165.797 639.018 Q167.695 636.726 171.075 635.939 M169.362 628.555 Q169.362 631.24 171.028 632.745 Q172.718 634.249 175.751 634.249 Q178.76 634.249 180.45 632.745 Q182.163 631.24 182.163 628.555 Q182.163 625.87 180.45 624.365 Q178.76 622.86 175.751 622.86 Q172.718 622.86 171.028 624.365 Q169.362 625.87 169.362 628.555 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M130.728 340.795 L138.367 340.795 L138.367 314.429 L130.056 316.096 L130.056 311.837 L138.32 310.17 L142.996 310.17 L142.996 340.795 L150.635 340.795 L150.635 344.73 L130.728 344.73 L130.728 340.795 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M155.704 338.85 L160.589 338.85 L160.589 344.73 L155.704 344.73 L155.704 338.85 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M175.658 313.249 Q172.047 313.249 170.218 316.813 Q168.413 320.355 168.413 327.485 Q168.413 334.591 170.218 338.156 Q172.047 341.698 175.658 341.698 Q179.292 341.698 181.098 338.156 Q182.927 334.591 182.927 327.485 Q182.927 320.355 181.098 316.813 Q179.292 313.249 175.658 313.249 M175.658 309.545 Q181.468 309.545 184.524 314.151 Q187.602 318.735 187.602 327.485 Q187.602 336.211 184.524 340.818 Q181.468 345.401 175.658 345.401 Q169.848 345.401 166.769 340.818 Q163.714 336.211 163.714 327.485 Q163.714 318.735 166.769 314.151 Q169.848 309.545 175.658 309.545 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M961.348 1527.24 Q963.544 1523.29 966.599 1521.41 Q969.655 1519.54 973.793 1519.54 Q979.362 1519.54 982.386 1523.45 Q985.41 1527.33 985.41 1534.53 L985.41 1556.04 L979.522 1556.04 L979.522 1534.72 Q979.522 1529.59 977.707 1527.11 Q975.893 1524.63 972.169 1524.63 Q967.618 1524.63 964.976 1527.65 Q962.334 1530.68 962.334 1535.9 L962.334 1556.04 L956.446 1556.04 L956.446 1534.72 Q956.446 1529.56 954.632 1527.11 Q952.818 1524.63 949.03 1524.63 Q944.542 1524.63 941.9 1527.68 Q939.259 1530.71 939.259 1535.9 L939.259 1556.04 L933.37 1556.04 L933.37 1520.4 L939.259 1520.4 L939.259 1525.93 Q941.264 1522.66 944.065 1521.1 Q946.866 1519.54 950.717 1519.54 Q954.6 1519.54 957.305 1521.51 Q960.043 1523.48 961.348 1527.24 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1022.04 1536.76 L1022.04 1539.62 L995.118 1539.62 Q995.5 1545.67 998.746 1548.85 Q1002.02 1552 1007.85 1552 Q1011.22 1552 1014.37 1551.17 Q1017.56 1550.35 1020.68 1548.69 L1020.68 1554.23 Q1017.52 1555.57 1014.21 1556.27 Q1010.9 1556.97 1007.5 1556.97 Q998.969 1556.97 993.972 1552 Q989.007 1547.04 989.007 1538.57 Q989.007 1529.82 993.717 1524.69 Q998.46 1519.54 1006.48 1519.54 Q1013.67 1519.54 1017.84 1524.18 Q1022.04 1528.8 1022.04 1536.76 M1016.19 1535.04 Q1016.12 1530.23 1013.48 1527.37 Q1010.87 1524.5 1006.54 1524.5 Q1001.64 1524.5 998.682 1527.27 Q995.754 1530.04 995.309 1535.07 L1016.19 1535.04 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1048.84 1525.87 Q1047.86 1525.3 1046.68 1525.04 Q1045.53 1524.76 1044.13 1524.76 Q1039.17 1524.76 1036.49 1528 Q1033.85 1531.22 1033.85 1537.27 L1033.85 1556.04 L1027.96 1556.04 L1027.96 1520.4 L1033.85 1520.4 L1033.85 1525.93 Q1035.7 1522.69 1038.66 1521.13 Q1041.62 1519.54 1045.85 1519.54 Q1046.46 1519.54 1047.19 1519.63 Q1047.92 1519.7 1048.81 1519.85 L1048.84 1525.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1077.3 1537.81 Q1077.3 1531.44 1074.66 1527.94 Q1072.05 1524.44 1067.3 1524.44 Q1062.59 1524.44 1059.95 1527.94 Q1057.34 1531.44 1057.34 1537.81 Q1057.34 1544.14 1059.95 1547.64 Q1062.59 1551.14 1067.3 1551.14 Q1072.05 1551.14 1074.66 1547.64 Q1077.3 1544.14 1077.3 1537.81 M1083.16 1551.62 Q1083.16 1560.72 1079.11 1565.15 Q1075.07 1569.6 1066.73 1569.6 Q1063.64 1569.6 1060.91 1569.13 Q1058.17 1568.68 1055.59 1567.72 L1055.59 1562.03 Q1058.17 1563.43 1060.68 1564.1 Q1063.2 1564.76 1065.81 1564.76 Q1071.57 1564.76 1074.43 1561.74 Q1077.3 1558.75 1077.3 1552.67 L1077.3 1549.77 Q1075.48 1552.92 1072.65 1554.48 Q1069.82 1556.04 1065.87 1556.04 Q1059.32 1556.04 1055.31 1551.05 Q1051.29 1546.05 1051.29 1537.81 Q1051.29 1529.53 1055.31 1524.53 Q1059.32 1519.54 1065.87 1519.54 Q1069.82 1519.54 1072.65 1521.1 Q1075.48 1522.66 1077.3 1525.81 L1077.3 1520.4 L1083.16 1520.4 L1083.16 1551.62 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1119.79 1536.76 L1119.79 1539.62 L1092.86 1539.62 Q1093.24 1545.67 1096.49 1548.85 Q1099.77 1552 1105.59 1552 Q1108.97 1552 1112.12 1551.17 Q1115.3 1550.35 1118.42 1548.69 L1118.42 1554.23 Q1115.27 1555.57 1111.96 1556.27 Q1108.65 1556.97 1105.24 1556.97 Q1096.71 1556.97 1091.72 1552 Q1086.75 1547.04 1086.75 1538.57 Q1086.75 1529.82 1091.46 1524.69 Q1096.21 1519.54 1104.23 1519.54 Q1111.42 1519.54 1115.59 1524.18 Q1119.79 1528.8 1119.79 1536.76 M1113.93 1535.04 Q1113.87 1530.23 1111.23 1527.37 Q1108.62 1524.5 1104.29 1524.5 Q1099.39 1524.5 1096.43 1527.27 Q1093.5 1530.04 1093.05 1535.07 L1113.93 1535.04 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1153.02 1566.87 L1153.02 1571.42 L1119.15 1571.42 L1119.15 1566.87 L1153.02 1566.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1164.83 1550.7 L1164.83 1569.6 L1158.94 1569.6 L1158.94 1520.4 L1164.83 1520.4 L1164.83 1525.81 Q1166.67 1522.62 1169.47 1521.1 Q1172.31 1519.54 1176.22 1519.54 Q1182.71 1519.54 1186.76 1524.69 Q1190.83 1529.85 1190.83 1538.25 Q1190.83 1546.65 1186.76 1551.81 Q1182.71 1556.97 1176.22 1556.97 Q1172.31 1556.97 1169.47 1555.44 Q1166.67 1553.88 1164.83 1550.7 M1184.75 1538.25 Q1184.75 1531.79 1182.08 1528.13 Q1179.44 1524.44 1174.79 1524.44 Q1170.14 1524.44 1167.47 1528.13 Q1164.83 1531.79 1164.83 1538.25 Q1164.83 1544.71 1167.47 1548.4 Q1170.14 1552.07 1174.79 1552.07 Q1179.44 1552.07 1182.08 1548.4 Q1184.75 1544.71 1184.75 1538.25 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1196.37 1541.98 L1196.37 1520.4 L1202.23 1520.4 L1202.23 1541.75 Q1202.23 1546.81 1204.2 1549.36 Q1206.17 1551.87 1210.12 1551.87 Q1214.86 1551.87 1217.6 1548.85 Q1220.37 1545.83 1220.37 1540.61 L1220.37 1520.4 L1226.22 1520.4 L1226.22 1556.04 L1220.37 1556.04 L1220.37 1550.57 Q1218.24 1553.82 1215.4 1555.41 Q1212.6 1556.97 1208.88 1556.97 Q1202.74 1556.97 1199.55 1553.15 Q1196.37 1549.33 1196.37 1541.98 M1211.11 1519.54 L1211.11 1519.54 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1253.02 1525.87 Q1252.04 1525.3 1250.86 1525.04 Q1249.71 1524.76 1248.31 1524.76 Q1243.35 1524.76 1240.67 1528 Q1238.03 1531.22 1238.03 1537.27 L1238.03 1556.04 L1232.14 1556.04 L1232.14 1520.4 L1238.03 1520.4 L1238.03 1525.93 Q1239.88 1522.69 1242.84 1521.13 Q1245.8 1519.54 1250.03 1519.54 Q1250.64 1519.54 1251.37 1519.63 Q1252.1 1519.7 1252.99 1519.85 L1253.02 1525.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1259.17 1520.4 L1265.02 1520.4 L1265.02 1556.04 L1259.17 1556.04 L1259.17 1520.4 M1259.17 1506.52 L1265.02 1506.52 L1265.02 1513.93 L1259.17 1513.93 L1259.17 1506.52 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1276.96 1510.27 L1276.96 1520.4 L1289.02 1520.4 L1289.02 1524.95 L1276.96 1524.95 L1276.96 1544.3 Q1276.96 1548.66 1278.14 1549.9 Q1279.35 1551.14 1283.01 1551.14 L1289.02 1551.14 L1289.02 1556.04 L1283.01 1556.04 Q1276.23 1556.04 1273.65 1553.53 Q1271.07 1550.98 1271.07 1544.3 L1271.07 1524.95 L1266.77 1524.95 L1266.77 1520.4 L1271.07 1520.4 L1271.07 1510.27 L1276.96 1510.27 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1310 1559.35 Q1307.51 1565.72 1305.16 1567.66 Q1302.8 1569.6 1298.86 1569.6 L1294.18 1569.6 L1294.18 1564.7 L1297.62 1564.7 Q1300.03 1564.7 1301.37 1563.56 Q1302.71 1562.41 1304.33 1558.14 L1305.38 1555.47 L1290.96 1520.4 L1297.17 1520.4 L1308.31 1548.28 L1319.45 1520.4 L1325.66 1520.4 L1310 1559.35 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1358.89 1566.87 L1358.89 1571.42 L1325.02 1571.42 L1325.02 1566.87 L1358.89 1566.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1370.82 1510.27 L1370.82 1520.4 L1382.88 1520.4 L1382.88 1524.95 L1370.82 1524.95 L1370.82 1544.3 Q1370.82 1548.66 1372 1549.9 Q1373.21 1551.14 1376.87 1551.14 L1382.88 1551.14 L1382.88 1556.04 L1376.87 1556.04 Q1370.09 1556.04 1367.51 1553.53 Q1364.93 1550.98 1364.93 1544.3 L1364.93 1524.95 L1360.64 1524.95 L1360.64 1520.4 L1364.93 1520.4 L1364.93 1510.27 L1370.82 1510.27 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1418.66 1534.53 L1418.66 1556.04 L1412.8 1556.04 L1412.8 1534.72 Q1412.8 1529.66 1410.83 1527.14 Q1408.86 1524.63 1404.91 1524.63 Q1400.17 1524.63 1397.43 1527.65 Q1394.69 1530.68 1394.69 1535.9 L1394.69 1556.04 L1388.8 1556.04 L1388.8 1506.52 L1394.69 1506.52 L1394.69 1525.93 Q1396.79 1522.72 1399.63 1521.13 Q1402.49 1519.54 1406.21 1519.54 Q1412.36 1519.54 1415.51 1523.36 Q1418.66 1527.14 1418.66 1534.53 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1445.46 1525.87 Q1444.47 1525.3 1443.3 1525.04 Q1442.15 1524.76 1440.75 1524.76 Q1435.78 1524.76 1433.11 1528 Q1430.47 1531.22 1430.47 1537.27 L1430.47 1556.04 L1424.58 1556.04 L1424.58 1520.4 L1430.47 1520.4 L1430.47 1525.93 Q1432.31 1522.69 1435.27 1521.13 Q1438.23 1519.54 1442.47 1519.54 Q1443.07 1519.54 1443.8 1519.63 Q1444.54 1519.7 1445.43 1519.85 L1445.46 1525.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1480.66 1536.76 L1480.66 1539.62 L1453.73 1539.62 Q1454.12 1545.67 1457.36 1548.85 Q1460.64 1552 1466.47 1552 Q1469.84 1552 1472.99 1551.17 Q1476.17 1550.35 1479.29 1548.69 L1479.29 1554.23 Q1476.14 1555.57 1472.83 1556.27 Q1469.52 1556.97 1466.12 1556.97 Q1457.59 1556.97 1452.59 1552 Q1447.62 1547.04 1447.62 1538.57 Q1447.62 1529.82 1452.33 1524.69 Q1457.08 1519.54 1465.1 1519.54 Q1472.29 1519.54 1476.46 1524.18 Q1480.66 1528.8 1480.66 1536.76 M1474.81 1535.04 Q1474.74 1530.23 1472.1 1527.37 Q1469.49 1524.5 1465.16 1524.5 Q1460.26 1524.5 1457.3 1527.27 Q1454.37 1530.04 1453.93 1535.07 L1474.81 1535.04 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1509.53 1521.45 L1509.53 1526.98 Q1507.05 1525.71 1504.37 1525.07 Q1501.7 1524.44 1498.84 1524.44 Q1494.48 1524.44 1492.28 1525.77 Q1490.11 1527.11 1490.11 1529.79 Q1490.11 1531.82 1491.67 1533 Q1493.23 1534.15 1497.94 1535.2 L1499.95 1535.64 Q1506.19 1536.98 1508.8 1539.43 Q1511.44 1541.85 1511.44 1546.21 Q1511.44 1551.17 1507.49 1554.07 Q1503.58 1556.97 1496.7 1556.97 Q1493.84 1556.97 1490.72 1556.39 Q1487.63 1555.85 1484.19 1554.74 L1484.19 1548.69 Q1487.44 1550.38 1490.59 1551.24 Q1493.74 1552.07 1496.83 1552.07 Q1500.97 1552.07 1503.2 1550.66 Q1505.42 1549.23 1505.42 1546.65 Q1505.42 1544.27 1503.8 1542.99 Q1502.21 1541.72 1496.77 1540.54 L1494.73 1540.07 Q1489.29 1538.92 1486.87 1536.56 Q1484.45 1534.18 1484.45 1530.04 Q1484.45 1525.01 1488.01 1522.27 Q1491.58 1519.54 1498.14 1519.54 Q1501.38 1519.54 1504.25 1520.01 Q1507.11 1520.49 1509.53 1521.45 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1547.22 1534.53 L1547.22 1556.04 L1541.36 1556.04 L1541.36 1534.72 Q1541.36 1529.66 1539.39 1527.14 Q1537.41 1524.63 1533.47 1524.63 Q1528.72 1524.63 1525.99 1527.65 Q1523.25 1530.68 1523.25 1535.9 L1523.25 1556.04 L1517.36 1556.04 L1517.36 1506.52 L1523.25 1506.52 L1523.25 1525.93 Q1525.35 1522.72 1528.18 1521.13 Q1531.05 1519.54 1534.77 1519.54 Q1540.91 1519.54 1544.06 1523.36 Q1547.22 1527.14 1547.22 1534.53 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1567.17 1524.5 Q1562.46 1524.5 1559.72 1528.19 Q1556.99 1531.85 1556.99 1538.25 Q1556.99 1544.65 1559.69 1548.34 Q1562.43 1552 1567.17 1552 Q1571.85 1552 1574.59 1548.31 Q1577.33 1544.62 1577.33 1538.25 Q1577.33 1531.92 1574.59 1528.23 Q1571.85 1524.5 1567.17 1524.5 M1567.17 1519.54 Q1574.81 1519.54 1579.17 1524.5 Q1583.53 1529.47 1583.53 1538.25 Q1583.53 1547 1579.17 1552 Q1574.81 1556.97 1567.17 1556.97 Q1559.5 1556.97 1555.14 1552 Q1550.81 1547 1550.81 1538.25 Q1550.81 1529.47 1555.14 1524.5 Q1559.5 1519.54 1567.17 1519.54 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1589.67 1506.52 L1595.53 1506.52 L1595.53 1556.04 L1589.67 1556.04 L1589.67 1506.52 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M1625.13 1525.81 L1625.13 1506.52 L1630.99 1506.52 L1630.99 1556.04 L1625.13 1556.04 L1625.13 1550.7 Q1623.29 1553.88 1620.45 1555.44 Q1617.65 1556.97 1613.71 1556.97 Q1607.24 1556.97 1603.17 1551.81 Q1599.13 1546.65 1599.13 1538.25 Q1599.13 1529.85 1603.17 1524.69 Q1607.24 1519.54 1613.71 1519.54 Q1617.65 1519.54 1620.45 1521.1 Q1623.29 1522.62 1625.13 1525.81 M1605.18 1538.25 Q1605.18 1544.71 1607.82 1548.4 Q1610.49 1552.07 1615.14 1552.07 Q1619.78 1552.07 1622.46 1548.4 Q1625.13 1544.71 1625.13 1538.25 Q1625.13 1531.79 1622.46 1528.13 Q1619.78 1524.44 1615.14 1524.44 Q1610.49 1524.44 1607.82 1528.13 Q1605.18 1531.79 1605.18 1538.25 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M44.1444 904.492 L50.9239 904.492 Q47.9002 907.739 46.4043 911.431 Q44.9083 915.091 44.9083 919.229 Q44.9083 927.377 49.9054 931.705 Q54.8707 936.034 64.2919 936.034 Q73.6813 936.034 78.6784 931.705 Q83.6436 927.377 83.6436 919.229 Q83.6436 915.091 82.1477 911.431 Q80.6518 907.739 77.6281 904.492 L84.3439 904.492 Q86.6355 907.866 87.7814 911.653 Q88.9272 915.409 88.9272 919.611 Q88.9272 930.4 82.3387 936.607 Q75.7183 942.814 64.2919 942.814 Q52.8336 942.814 46.2451 936.607 Q39.6248 930.4 39.6248 919.611 Q39.6248 915.346 40.7706 911.59 Q41.8846 907.802 44.1444 904.492 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M57.8307 877.692 Q57.2578 878.679 57.0032 879.857 Q56.7167 881.003 56.7167 882.403 Q56.7167 887.368 59.9632 890.042 Q63.1779 892.684 69.2253 892.684 L88.0042 892.684 L88.0042 898.572 L52.3562 898.572 L52.3562 892.684 L57.8944 892.684 Q54.6479 890.838 53.0883 887.878 Q51.4968 884.917 51.4968 880.684 Q51.4968 880.08 51.5923 879.347 Q51.656 878.615 51.8151 877.724 L57.8307 877.692 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M56.4621 859.168 Q56.4621 863.879 60.1542 866.616 Q63.8145 869.353 70.212 869.353 Q76.6095 869.353 80.3017 866.648 Q83.9619 863.911 83.9619 859.168 Q83.9619 854.489 80.2698 851.752 Q76.5777 849.015 70.212 849.015 Q63.8781 849.015 60.186 851.752 Q56.4621 854.489 56.4621 859.168 M51.4968 859.168 Q51.4968 851.529 56.4621 847.169 Q61.4273 842.808 70.212 842.808 Q78.9649 842.808 83.9619 847.169 Q88.9272 851.529 88.9272 859.168 Q88.9272 866.839 83.9619 871.199 Q78.9649 875.528 70.212 875.528 Q61.4273 875.528 56.4621 871.199 Q51.4968 866.839 51.4968 859.168 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M53.4065 813.94 L58.9447 813.94 Q57.6716 816.422 57.035 819.096 Q56.3984 821.77 56.3984 824.634 Q56.3984 828.995 57.7352 831.191 Q59.072 833.355 61.7456 833.355 Q63.7826 833.355 64.9603 831.796 Q66.1061 830.236 67.1565 825.525 L67.6021 823.52 Q68.9389 817.282 71.3897 814.672 Q73.8086 812.03 78.1691 812.03 Q83.1344 812.03 86.0308 815.977 Q88.9272 819.892 88.9272 826.767 Q88.9272 829.631 88.3543 832.751 Q87.8132 835.838 86.6992 839.275 L80.6518 839.275 Q82.3387 836.029 83.198 832.878 Q84.0256 829.727 84.0256 826.639 Q84.0256 822.502 82.6251 820.274 Q81.1929 818.046 78.6147 818.046 Q76.2276 818.046 74.9545 819.669 Q73.6813 821.26 72.5037 826.703 L72.0262 828.74 Q70.8804 834.183 68.5251 836.602 Q66.138 839.021 62.0002 839.021 Q56.9713 839.021 54.2341 835.456 Q51.4968 831.891 51.4968 825.334 Q51.4968 822.088 51.9743 819.223 Q52.4517 816.359 53.4065 813.94 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M53.4065 783.162 L58.9447 783.162 Q57.6716 785.644 57.035 788.318 Q56.3984 790.991 56.3984 793.856 Q56.3984 798.217 57.7352 800.413 Q59.072 802.577 61.7456 802.577 Q63.7826 802.577 64.9603 801.017 Q66.1061 799.458 67.1565 794.747 L67.6021 792.742 Q68.9389 786.504 71.3897 783.894 Q73.8086 781.252 78.1691 781.252 Q83.1344 781.252 86.0308 785.199 Q88.9272 789.114 88.9272 795.989 Q88.9272 798.853 88.3543 801.972 Q87.8132 805.06 86.6992 808.497 L80.6518 808.497 Q82.3387 805.251 83.198 802.1 Q84.0256 798.949 84.0256 795.861 Q84.0256 791.724 82.6251 789.496 Q81.1929 787.268 78.6147 787.268 Q76.2276 787.268 74.9545 788.891 Q73.6813 790.482 72.5037 795.925 L72.0262 797.962 Q70.8804 803.405 68.5251 805.824 Q66.138 808.243 62.0002 808.243 Q56.9713 808.243 54.2341 804.678 Q51.4968 801.113 51.4968 794.556 Q51.4968 791.31 51.9743 788.445 Q52.4517 785.581 53.4065 783.162 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M40.4842 754.134 L40.4842 724.088 L45.895 724.088 L45.895 747.705 L59.9632 747.705 L59.9632 725.075 L65.3741 725.075 L65.3741 747.705 L82.5933 747.705 L82.5933 723.515 L88.0042 723.515 L88.0042 754.134 L40.4842 754.134 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M66.4881 687.74 L88.0042 687.74 L88.0042 693.596 L66.679 693.596 Q61.6183 693.596 59.1038 695.57 Q56.5894 697.543 56.5894 701.49 Q56.5894 706.232 59.6131 708.969 Q62.6368 711.707 67.8567 711.707 L88.0042 711.707 L88.0042 717.595 L52.3562 717.595 L52.3562 711.707 L57.8944 711.707 Q54.6797 709.606 53.0883 706.773 Q51.4968 703.909 51.4968 700.185 Q51.4968 694.042 55.3163 690.891 Q59.1038 687.74 66.4881 687.74 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M42.2347 675.804 L52.3562 675.804 L52.3562 663.741 L56.9077 663.741 L56.9077 675.804 L76.2594 675.804 Q80.6199 675.804 81.8613 674.626 Q83.1026 673.417 83.1026 669.757 L83.1026 663.741 L88.0042 663.741 L88.0042 669.757 Q88.0042 676.536 85.4897 679.114 Q82.9434 681.692 76.2594 681.692 L56.9077 681.692 L56.9077 685.989 L52.3562 685.989 L52.3562 681.692 L42.2347 681.692 L42.2347 675.804 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M57.8307 636.941 Q57.2578 637.928 57.0032 639.106 Q56.7167 640.252 56.7167 641.652 Q56.7167 646.617 59.9632 649.291 Q63.1779 651.933 69.2253 651.933 L88.0042 651.933 L88.0042 657.821 L52.3562 657.821 L52.3562 651.933 L57.8944 651.933 Q54.6479 650.087 53.0883 647.127 Q51.4968 644.166 51.4968 639.933 Q51.4968 639.329 51.5923 638.596 Q51.656 637.864 51.8151 636.973 L57.8307 636.941 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M56.4621 618.417 Q56.4621 623.128 60.1542 625.865 Q63.8145 628.602 70.212 628.602 Q76.6095 628.602 80.3017 625.897 Q83.9619 623.16 83.9619 618.417 Q83.9619 613.738 80.2698 611.001 Q76.5777 608.264 70.212 608.264 Q63.8781 608.264 60.186 611.001 Q56.4621 613.738 56.4621 618.417 M51.4968 618.417 Q51.4968 610.778 56.4621 606.418 Q61.4273 602.057 70.212 602.057 Q78.9649 602.057 83.9619 606.418 Q88.9272 610.778 88.9272 618.417 Q88.9272 626.088 83.9619 630.448 Q78.9649 634.777 70.212 634.777 Q61.4273 634.777 56.4621 630.448 Q51.4968 626.088 51.4968 618.417 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M82.657 590.249 L101.563 590.249 L101.563 596.137 L52.3562 596.137 L52.3562 590.249 L57.7671 590.249 Q54.5842 588.403 53.0564 585.602 Q51.4968 582.769 51.4968 578.854 Q51.4968 572.361 56.6531 568.319 Q61.8093 564.245 70.212 564.245 Q78.6147 564.245 83.771 568.319 Q88.9272 572.361 88.9272 578.854 Q88.9272 582.769 87.3994 585.602 Q85.8398 588.403 82.657 590.249 M70.212 570.324 Q63.7508 570.324 60.0905 572.998 Q56.3984 575.64 56.3984 580.287 Q56.3984 584.934 60.0905 587.607 Q63.7508 590.249 70.212 590.249 Q76.6732 590.249 80.3653 587.607 Q84.0256 584.934 84.0256 580.287 Q84.0256 575.64 80.3653 572.998 Q76.6732 570.324 70.212 570.324 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M91.3143 543.27 Q97.68 545.753 99.6216 548.108 Q101.563 550.463 101.563 554.41 L101.563 559.089 L96.6615 559.089 L96.6615 555.651 Q96.6615 553.232 95.5157 551.896 Q94.3699 550.559 90.1048 548.935 L87.4312 547.885 L52.3562 562.303 L52.3562 556.097 L80.238 544.957 L52.3562 533.817 L52.3562 527.61 L91.3143 543.27 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip102)\" style=\"stroke:#009af9; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  272.201,1384.24 292.401,1384.24 312.6,1384.24 332.8,1384.24 352.999,1384.24 373.199,1384.24 393.398,1384.24 413.598,1384.24 433.798,1384.24 453.997,1384.24 \n",
       "  474.197,1384.24 494.396,1384.24 514.596,1384.24 534.795,1384.24 554.995,1384.24 575.195,1384.24 595.394,1384.24 615.594,1384.24 635.793,1384.24 655.993,1384.24 \n",
       "  676.192,1384.24 696.392,1384.24 716.591,1384.24 736.791,1384.24 756.991,1384.24 777.19,1384.24 797.39,1384.24 817.589,1384.24 837.789,1384.24 857.988,1384.24 \n",
       "  878.188,1384.24 898.388,1384.24 918.587,1384.24 938.787,1384.24 958.986,1384.24 979.186,1384.24 999.385,1384.24 1019.58,1384.24 1039.78,1384.24 1059.98,1384.24 \n",
       "  1080.18,1384.24 1100.38,1384.24 1120.58,1384.24 1140.78,1384.24 1160.98,1384.24 1181.18,1384.24 1201.38,1384.24 1221.58,1384.24 1241.78,1384.24 1261.98,1384.24 \n",
       "  1282.18,1384.24 1302.38,1305.25 1322.58,1281.94 1342.78,1240.47 1362.98,1313.95 1383.18,1272.01 1403.38,1210.77 1423.58,1224.96 1443.78,1193.44 1463.98,1172.28 \n",
       "  1484.17,1148.39 1504.37,1072 1524.57,1136.17 1544.77,1027.24 1564.97,1028.1 1585.17,997.386 1605.37,993.486 1625.57,710.186 1645.77,766.267 1665.97,752.317 \n",
       "  1686.17,739.495 1706.37,739.488 1726.57,749.773 1746.77,699.509 1766.97,724.682 1787.17,666.895 1807.37,524.323 1827.57,598.143 1847.77,480.835 1867.97,534.134 \n",
       "  1888.17,472.502 1908.37,436.565 1928.57,405.599 1948.76,415.429 1968.96,344.391 1989.16,365.843 2009.36,332.824 2029.56,347.785 2049.76,303.193 2069.96,243.887 \n",
       "  2090.16,235.104 2110.36,245.641 2130.56,231.536 2150.76,202.72 2170.96,191.397 2191.16,145.475 2211.36,120.696 2231.56,90.4669 2251.76,86.1857 2271.96,113.685 \n",
       "  2292.16,104.747 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip100)\" d=\"\n",
       "M1844.15 214.069 L2281.38 214.069 L2281.38 93.1086 L1844.15 93.1086  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1844.15,214.069 2281.38,214.069 2281.38,93.1086 1844.15,93.1086 1844.15,214.069 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip100)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1867.94,153.589 2010.68,153.589 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip100)\" d=\"M 0 0 M2047.67 170.869 L2034.48 136.309 L2039.36 136.309 L2050.31 165.406 L2061.28 136.309 L2066.14 136.309 L2052.97 170.869 L2047.67 170.869 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2078.71 157.836 Q2073.55 157.836 2071.56 159.017 Q2069.57 160.197 2069.57 163.045 Q2069.57 165.313 2071.05 166.656 Q2072.55 167.975 2075.12 167.975 Q2078.66 167.975 2080.79 165.475 Q2082.95 162.952 2082.95 158.785 L2082.95 157.836 L2078.71 157.836 M2087.21 156.077 L2087.21 170.869 L2082.95 170.869 L2082.95 166.933 Q2081.49 169.295 2079.31 170.429 Q2077.14 171.54 2073.99 171.54 Q2070.01 171.54 2067.65 169.318 Q2065.31 167.072 2065.31 163.322 Q2065.31 158.947 2068.23 156.725 Q2071.16 154.503 2076.98 154.503 L2082.95 154.503 L2082.95 154.086 Q2082.95 151.147 2081 149.549 Q2079.08 147.929 2075.59 147.929 Q2073.36 147.929 2071.26 148.461 Q2069.15 148.994 2067.21 150.059 L2067.21 146.123 Q2069.54 145.221 2071.74 144.781 Q2073.94 144.318 2076.03 144.318 Q2081.65 144.318 2084.43 147.234 Q2087.21 150.151 2087.21 156.077 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2091.67 134.85 L2095.93 134.85 L2095.93 170.869 L2091.67 170.869 L2091.67 134.85 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2100.4 144.943 L2104.66 144.943 L2104.66 170.869 L2100.4 170.869 L2100.4 144.943 M2100.4 134.85 L2104.66 134.85 L2104.66 140.244 L2100.4 140.244 L2100.4 134.85 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2126.19 148.878 L2126.19 134.85 L2130.45 134.85 L2130.45 170.869 L2126.19 170.869 L2126.19 166.98 Q2124.85 169.295 2122.79 170.429 Q2120.75 171.54 2117.88 171.54 Q2113.18 171.54 2110.22 167.79 Q2107.28 164.04 2107.28 157.929 Q2107.28 151.818 2110.22 148.068 Q2113.18 144.318 2117.88 144.318 Q2120.75 144.318 2122.79 145.452 Q2124.85 146.563 2126.19 148.878 M2111.67 157.929 Q2111.67 162.628 2113.6 165.313 Q2115.54 167.975 2118.92 167.975 Q2122.3 167.975 2124.24 165.313 Q2126.19 162.628 2126.19 157.929 Q2126.19 153.23 2124.24 150.568 Q2122.3 147.883 2118.92 147.883 Q2115.54 147.883 2113.6 150.568 Q2111.67 153.23 2111.67 157.929 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2146.7 157.836 Q2141.53 157.836 2139.54 159.017 Q2137.55 160.197 2137.55 163.045 Q2137.55 165.313 2139.03 166.656 Q2140.54 167.975 2143.11 167.975 Q2146.65 167.975 2148.78 165.475 Q2150.93 162.952 2150.93 158.785 L2150.93 157.836 L2146.7 157.836 M2155.19 156.077 L2155.19 170.869 L2150.93 170.869 L2150.93 166.933 Q2149.47 169.295 2147.3 170.429 Q2145.12 171.54 2141.97 171.54 Q2137.99 171.54 2135.63 169.318 Q2133.29 167.072 2133.29 163.322 Q2133.29 158.947 2136.21 156.725 Q2139.15 154.503 2144.96 154.503 L2150.93 154.503 L2150.93 154.086 Q2150.93 151.147 2148.99 149.549 Q2147.07 147.929 2143.57 147.929 Q2141.35 147.929 2139.24 148.461 Q2137.14 148.994 2135.19 150.059 L2135.19 146.123 Q2137.53 145.221 2139.73 144.781 Q2141.93 144.318 2144.01 144.318 Q2149.64 144.318 2152.41 147.234 Q2155.19 150.151 2155.19 156.077 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2163.87 137.582 L2163.87 144.943 L2172.65 144.943 L2172.65 148.253 L2163.87 148.253 L2163.87 162.327 Q2163.87 165.498 2164.73 166.401 Q2165.61 167.304 2168.27 167.304 L2172.65 167.304 L2172.65 170.869 L2168.27 170.869 Q2163.34 170.869 2161.47 169.04 Q2159.59 167.188 2159.59 162.327 L2159.59 148.253 L2156.47 148.253 L2156.47 144.943 L2159.59 144.943 L2159.59 137.582 L2163.87 137.582 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2177.11 144.943 L2181.37 144.943 L2181.37 170.869 L2177.11 170.869 L2177.11 144.943 M2177.11 134.85 L2181.37 134.85 L2181.37 140.244 L2177.11 140.244 L2177.11 134.85 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2195.89 147.929 Q2192.46 147.929 2190.47 150.614 Q2188.48 153.276 2188.48 157.929 Q2188.48 162.582 2190.45 165.267 Q2192.44 167.929 2195.89 167.929 Q2199.29 167.929 2201.28 165.244 Q2203.27 162.558 2203.27 157.929 Q2203.27 153.322 2201.28 150.637 Q2199.29 147.929 2195.89 147.929 M2195.89 144.318 Q2201.44 144.318 2204.61 147.929 Q2207.78 151.54 2207.78 157.929 Q2207.78 164.295 2204.61 167.929 Q2201.44 171.54 2195.89 171.54 Q2190.31 171.54 2187.14 167.929 Q2183.99 164.295 2183.99 157.929 Q2183.99 151.54 2187.14 147.929 Q2190.31 144.318 2195.89 144.318 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip100)\" d=\"M 0 0 M2233.8 155.221 L2233.8 170.869 L2229.54 170.869 L2229.54 155.359 Q2229.54 151.679 2228.11 149.85 Q2226.67 148.022 2223.8 148.022 Q2220.35 148.022 2218.36 150.221 Q2216.37 152.42 2216.37 156.216 L2216.37 170.869 L2212.09 170.869 L2212.09 144.943 L2216.37 144.943 L2216.37 148.971 Q2217.9 146.633 2219.96 145.475 Q2222.04 144.318 2224.75 144.318 Q2229.22 144.318 2231.51 147.096 Q2233.8 149.85 2233.8 155.221 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(curve.parameter_values,\n",
    "     curve.measurements,\n",
    "     xlab=curve.parameter_name,\n",
    "     ylab=\"Cross Entropy\",\n",
    "     label=\"Validation\", lw=2)\n",
    "# plot!(Net2.report.training_losses, label=\"Training\", lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31735"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = round(minimum(curve.measurements), digits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curve.parameter_values[argmin(curve.measurements)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLJBase.NumericRange(Float64, :merge_purity_threshold, ... )"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param1 = :merge_purity_threshold\n",
    "\n",
    "r1 = range(dt2, param1, lower=0, upper=0.5, scale=:linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProbabilisticTunedModel(\n",
       "    model = DecisionTreeClassifier(\n",
       "            max_depth = -1,\n",
       "            min_samples_leaf = 1,\n",
       "            min_samples_split = 2,\n",
       "            min_purity_increase = 0.0,\n",
       "            n_subfeatures = 0,\n",
       "            post_prune = true,\n",
       "            merge_purity_threshold = 1.0,\n",
       "            pdf_smoothing = 0.0,\n",
       "            display_depth = 5),\n",
       "    tuning = Grid(\n",
       "            goal = 100,\n",
       "            resolution = 10,\n",
       "            shuffle = true,\n",
       "            rng = Random._GLOBAL_RNG()),\n",
       "    resampling = CV(\n",
       "            nfolds = 6,\n",
       "            shuffle = false,\n",
       "            rng = Random._GLOBAL_RNG()),\n",
       "    measure = cross_entropy(\n",
       "            eps = 2.220446049250313e-16),\n",
       "    weights = nothing,\n",
       "    operation = MLJModelInterface.predict,\n",
       "    range = MLJBase.NumericRange{Float64,MLJBase.Bounded,Symbol}[\u001b[34mNumericRange{Float64,…} @140\u001b[39m],\n",
       "    train_best = true,\n",
       "    repeats = 1,\n",
       "    n = nothing,\n",
       "    acceleration = CPUThreads{Int64}(1),\n",
       "    acceleration_resampling = CPU1{Nothing}(nothing),\n",
       "    check_measure = true)\u001b[34m @601\u001b[39m"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_tuning_dt_model = TunedModel(model=dt2,\n",
    "                                    tuning=Grid(goal=100),\n",
    "                                    resampling=CV(), \n",
    "                                    measure=cross_entropy,\n",
    "                                    acceleration=CPUThreads(),\n",
    "                                    range=[r1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{ProbabilisticTunedModel{Grid,…}} @151\u001b[39m trained 0 times.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @446\u001b[39m ⏎ `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @328\u001b[39m ⏎ `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_tuning_dt = machine(self_tuning_dt_model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{ProbabilisticTunedModel{Grid,…}} @151\u001b[39m.\n",
      "└ @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/machines.jl:322\n",
      "┌ Info: Attempting to evaluate 100 models.\n",
      "└ @ MLJTuning /home/andrew/.julia/packages/MLJTuning/nuvTc/src/tuned_models.jl:501\n",
      "\u001b[33mEvaluating over 100 metamodels: 100%[=========================] Time: 0:02:51\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{ProbabilisticTunedModel{Grid,…}} @151\u001b[39m trained 1 time.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @446\u001b[39m ⏎ `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @328\u001b[39m ⏎ `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = fit!(self_tuning_dt, rows=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(best_model = \u001b[34mDecisionTreeClassifier @688\u001b[39m,\n",
       " best_fitted_params = (tree = Decision Leaf\n",
       "Majority: 1\n",
       "Samples:  12528,\n",
       "                       encoding = Dict{CategoricalValue{Int64,UInt32},UInt32}(0 => 0x00000001,1 => 0x00000002),),)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = fitted_params(self_tuning_dt)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(\n",
       "    max_depth = -1,\n",
       "    min_samples_leaf = 1,\n",
       "    min_samples_split = 2,\n",
       "    min_purity_increase = 0.0,\n",
       "    n_subfeatures = 0,\n",
       "    post_prune = true,\n",
       "    merge_purity_threshold = 0.09595959595959595,\n",
       "    pdf_smoothing = 0.0,\n",
       "    display_depth = 5)\u001b[34m @688\u001b[39m"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30623"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_loss = round(z.report.best_result.measurement[1],digits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09596"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mpt = round(best.best_model.merge_purity_threshold,digits=5)\n",
    "# best_mpt = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"Figures/LearningCurve_DT_merge_purity_thresh:$(best_mpt)_loss:$(best_loss)\"\n",
    "png(replace(fn,'.' => ','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(d, train_metric, valid_metric) = (10, 1.0, 0.8918595371109338)\n",
      "(d, train_metric, valid_metric) = (60, 1.0, 0.9577015163607342)\n",
      "(d, train_metric, valid_metric) = (110, 1.0, 0.9692737430167597)\n",
      "(d, train_metric, valid_metric) = (160, 1.0, 0.9505187549880287)\n",
      "(d, train_metric, valid_metric) = (210, 1.0, 0.9704708699122107)\n",
      "(d, train_metric, valid_metric) = (260, 1.0, 0.9724660814046289)\n",
      "(d, train_metric, valid_metric) = (310, 1.0, 0.9676775738228253)\n",
      "(d, train_metric, valid_metric) = (360, 1.0, 0.9772545889864326)\n",
      "(d, train_metric, valid_metric) = (410, 1.0, 0.9720670391061452)\n",
      "(d, train_metric, valid_metric) = (460, 1.0, 0.9712689545091779)\n",
      "(d, train_metric, valid_metric) = (510, 1.0, 0.9672785315243416)\n",
      "(d, train_metric, valid_metric) = (560, 1.0, 0.9652833200319234)\n",
      "(d, train_metric, valid_metric) = (610, 1.0, 0.9768555466879489)\n",
      "(d, train_metric, valid_metric) = (660, 1.0, 0.9760574620909817)\n",
      "(d, train_metric, valid_metric) = (710, 1.0, 0.9696727853152434)\n",
      "(d, train_metric, valid_metric) = (760, 1.0, 0.9724660814046289)\n",
      "(d, train_metric, valid_metric) = (810, 1.0, 0.9708699122106943)\n",
      "(d, train_metric, valid_metric) = (860, 1.0, 0.9732641660015962)\n",
      "(d, train_metric, valid_metric) = (910, 1.0, 0.9636871508379888)\n",
      "(d, train_metric, valid_metric) = (960, 1.0, 0.9720670391061452)\n",
      "(d, train_metric, valid_metric) = (1010, 1.0, 0.9724660814046289)\n",
      "(d, train_metric, valid_metric) = (1060, 1.0, 0.9724660814046289)\n",
      "(d, train_metric, valid_metric) = (1110, 1.0, 0.9728651237031125)\n",
      "(d, train_metric, valid_metric) = (1160, 1.0, 0.9704708699122107)\n",
      "(d, train_metric, valid_metric) = (1210, 1.0, 0.9788507581803672)\n",
      "(d, train_metric, valid_metric) = (1260, 1.0, 0.9740622505985634)\n",
      "(d, train_metric, valid_metric) = (1310, 1.0, 0.9736632083000798)\n",
      "(d, train_metric, valid_metric) = (1360, 1.0, 0.9736632083000798)\n",
      "(d, train_metric, valid_metric) = (1410, 1.0, 0.9744612928970471)\n",
      "(d, train_metric, valid_metric) = (1460, 1.0, 0.9748603351955307)\n",
      "(d, train_metric, valid_metric) = (1510, 1.0, 0.9736632083000798)\n",
      "(d, train_metric, valid_metric) = (1560, 1.0, 0.9744612928970471)\n",
      "(d, train_metric, valid_metric) = (1610, 1.0, 0.965682362330407)\n",
      "(d, train_metric, valid_metric) = (1660, 1.0, 0.9664804469273743)\n",
      "(d, train_metric, valid_metric) = (1710, 1.0, 0.9672785315243416)\n",
      "(d, train_metric, valid_metric) = (1760, 1.0, 0.9736632083000798)\n",
      "(d, train_metric, valid_metric) = (1810, 1.0, 0.9704708699122107)\n",
      "(d, train_metric, valid_metric) = (1860, 1.0, 0.9692737430167597)\n",
      "(d, train_metric, valid_metric) = (1910, 1.0, 0.9676775738228253)\n",
      "(d, train_metric, valid_metric) = (1960, 1.0, 0.966879489225858)\n",
      "(d, train_metric, valid_metric) = (2010, 1.0, 0.9664804469273743)\n",
      "(d, train_metric, valid_metric) = (2060, 1.0, 0.9712689545091779)\n",
      "(d, train_metric, valid_metric) = (2110, 1.0, 0.9696727853152434)\n",
      "(d, train_metric, valid_metric) = (2160, 1.0, 0.970071827613727)\n",
      "(d, train_metric, valid_metric) = (2210, 1.0, 0.9652833200319234)\n",
      "(d, train_metric, valid_metric) = (2260, 1.0, 0.965682362330407)\n",
      "(d, train_metric, valid_metric) = (2310, 1.0, 0.9676775738228253)\n",
      "(d, train_metric, valid_metric) = (2360, 1.0, 0.9684756584197926)\n",
      "(d, train_metric, valid_metric) = (2410, 1.0, 0.9680766161213089)\n",
      "(d, train_metric, valid_metric) = (2460, 1.0, 0.9664804469273743)\n",
      "(d, train_metric, valid_metric) = (2510, 1.0, 0.966879489225858)\n",
      "(d, train_metric, valid_metric) = (2560, 1.0, 0.9716679968076616)\n",
      "(d, train_metric, valid_metric) = (2610, 1.0, 0.9708699122106943)\n",
      "(d, train_metric, valid_metric) = (2660, 1.0, 0.9692737430167597)\n",
      "(d, train_metric, valid_metric) = (2710, 1.0, 0.9676775738228253)\n",
      "(d, train_metric, valid_metric) = (2760, 1.0, 0.9692737430167597)\n",
      "(d, train_metric, valid_metric) = (2810, 1.0, 0.9692737430167597)\n",
      "(d, train_metric, valid_metric) = (2860, 1.0, 0.9688747007182761)\n",
      "(d, train_metric, valid_metric) = (2910, 1.0, 0.9684756584197926)\n",
      "(d, train_metric, valid_metric) = (2960, 1.0, 0.970071827613727)\n",
      "(d, train_metric, valid_metric) = (3010, 1.0, 0.9696727853152434)\n",
      "(d, train_metric, valid_metric) = (3060, 1.0, 0.9696727853152434)\n",
      "(d, train_metric, valid_metric) = (3110, 1.0, 0.9732641660015962)\n",
      "(d, train_metric, valid_metric) = (3160, 1.0, 0.9740622505985634)\n",
      "(d, train_metric, valid_metric) = (3210, 1.0, 0.9744612928970471)\n",
      "(d, train_metric, valid_metric) = (3260, 1.0, 0.9760574620909817)\n",
      "(d, train_metric, valid_metric) = (3310, 1.0, 0.9740622505985634)\n",
      "(d, train_metric, valid_metric) = (3360, 1.0, 0.9748603351955307)\n",
      "(d, train_metric, valid_metric) = (3410, 1.0, 0.9740622505985634)\n",
      "(d, train_metric, valid_metric) = (3460, 1.0, 0.9748603351955307)\n",
      "(d, train_metric, valid_metric) = (3510, 1.0, 0.9764565043894653)\n",
      "(d, train_metric, valid_metric) = (3560, 1.0, 0.9728651237031125)\n",
      "(d, train_metric, valid_metric) = (3610, 1.0, 0.9692737430167597)\n",
      "(d, train_metric, valid_metric) = (3660, 1.0, 0.970071827613727)\n",
      "(d, train_metric, valid_metric) = (3710, 1.0, 0.9716679968076616)\n",
      "(d, train_metric, valid_metric) = (3760, 1.0, 0.9716679968076616)\n",
      "(d, train_metric, valid_metric) = (3810, 1.0, 0.9712689545091779)\n",
      "(d, train_metric, valid_metric) = (3860, 1.0, 0.9708699122106943)\n",
      "(d, train_metric, valid_metric) = (3910, 1.0, 0.970071827613727)\n",
      "(d, train_metric, valid_metric) = (3960, 1.0, 0.9736632083000798)\n",
      "(d, train_metric, valid_metric) = (4010, 1.0, 0.9748603351955307)\n",
      "(d, train_metric, valid_metric) = (4060, 1.0, 0.9724660814046289)\n",
      "(d, train_metric, valid_metric) = (4110, 1.0, 0.970071827613727)\n",
      "(d, train_metric, valid_metric) = (4160, 1.0, 0.9696727853152434)\n",
      "(d, train_metric, valid_metric) = (4210, 1.0, 0.9708699122106943)\n",
      "(d, train_metric, valid_metric) = (4260, 1.0, 0.966879489225858)\n",
      "(d, train_metric, valid_metric) = (4310, 1.0, 0.9696727853152434)\n",
      "(d, train_metric, valid_metric) = (4360, 1.0, 0.9688747007182761)\n",
      "(d, train_metric, valid_metric) = (4410, 1.0, 0.9728651237031125)\n",
      "(d, train_metric, valid_metric) = (4460, 1.0, 0.970071827613727)\n",
      "(d, train_metric, valid_metric) = (4510, 1.0, 0.9728651237031125)\n",
      "(d, train_metric, valid_metric) = (4560, 1.0, 0.9732641660015962)\n",
      "(d, train_metric, valid_metric) = (4610, 1.0, 0.9712689545091779)\n",
      "(d, train_metric, valid_metric) = (4660, 1.0, 0.9712689545091779)\n",
      "(d, train_metric, valid_metric) = (4710, 1.0, 0.9732641660015962)\n",
      "(d, train_metric, valid_metric) = (4760, 1.0, 0.970071827613727)\n",
      "(d, train_metric, valid_metric) = (4810, 1.0, 0.9680766161213089)\n",
      "(d, train_metric, valid_metric) = (4860, 1.0, 0.9664804469273743)\n",
      "(d, train_metric, valid_metric) = (4910, 1.0, 0.9708699122106943)\n",
      "(d, train_metric, valid_metric) = (4960, 1.0, 0.970071827613727)\n",
      "(d, train_metric, valid_metric) = (5010, 1.0, 0.9684756584197926)\n",
      "(d, train_metric, valid_metric) = (5060, 1.0, 0.9708699122106943)\n",
      "(d, train_metric, valid_metric) = (5110, 1.0, 0.9716679968076616)\n",
      "(d, train_metric, valid_metric) = (5160, 1.0, 0.9684756584197926)\n",
      "(d, train_metric, valid_metric) = (5210, 1.0, 0.9680766161213089)\n",
      "(d, train_metric, valid_metric) = (5260, 1.0, 0.9712689545091779)\n",
      "(d, train_metric, valid_metric) = (5310, 1.0, 0.9688747007182761)\n",
      "(d, train_metric, valid_metric) = (5360, 1.0, 0.970071827613727)\n",
      "(d, train_metric, valid_metric) = (5410, 1.0, 0.9708699122106943)\n",
      "(d, train_metric, valid_metric) = (5460, 1.0, 0.9724660814046289)\n",
      "(d, train_metric, valid_metric) = (5510, 1.0, 0.9692737430167597)\n",
      "(d, train_metric, valid_metric) = (5560, 1.0, 0.9696727853152434)\n",
      "(d, train_metric, valid_metric) = (5610, 1.0, 0.9704708699122107)\n",
      "(d, train_metric, valid_metric) = (5660, 1.0, 0.9688747007182761)\n",
      "(d, train_metric, valid_metric) = (5710, 1.0, 0.970071827613727)\n",
      "(d, train_metric, valid_metric) = (5760, 1.0, 0.9648842777334398)\n",
      "(d, train_metric, valid_metric) = (5810, 1.0, 0.9676775738228253)\n",
      "(d, train_metric, valid_metric) = (5860, 1.0, 0.9696727853152434)\n",
      "(d, train_metric, valid_metric) = (5910, 1.0, 0.965682362330407)\n",
      "(d, train_metric, valid_metric) = (5960, 1.0, 0.9692737430167597)\n",
      "(d, train_metric, valid_metric) = (6010, 1.0, 0.9660814046288907)\n",
      "(d, train_metric, valid_metric) = (6060, 1.0, 0.9704708699122107)\n",
      "(d, train_metric, valid_metric) = (6110, 1.0, 0.9680766161213089)\n",
      "(d, train_metric, valid_metric) = (6160, 1.0, 0.9664804469273743)\n",
      "(d, train_metric, valid_metric) = (6210, 1.0, 0.9712689545091779)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(d, train_metric, valid_metric) = (6260, 1.0, 0.9680766161213089)\n",
      "(d, train_metric, valid_metric) = (6310, 1.0, 0.9676775738228253)\n",
      "(d, train_metric, valid_metric) = (6360, 1.0, 0.9672785315243416)\n",
      "(d, train_metric, valid_metric) = (6410, 1.0, 0.9684756584197926)\n",
      "(d, train_metric, valid_metric) = (6460, 1.0, 0.9676775738228253)\n",
      "(d, train_metric, valid_metric) = (6510, 1.0, 0.966879489225858)\n",
      "(d, train_metric, valid_metric) = (6560, 1.0, 0.9704708699122107)\n",
      "(d, train_metric, valid_metric) = (6610, 1.0, 0.9712689545091779)\n",
      "(d, train_metric, valid_metric) = (6660, 1.0, 0.9704708699122107)\n",
      "(d, train_metric, valid_metric) = (6710, 1.0, 0.9680766161213089)\n",
      "(d, train_metric, valid_metric) = (6760, 1.0, 0.9640861931364725)\n",
      "(d, train_metric, valid_metric) = (6810, 1.0, 0.9648842777334398)\n",
      "(d, train_metric, valid_metric) = (6860, 1.0, 0.9708699122106943)\n",
      "(d, train_metric, valid_metric) = (6910, 1.0, 0.9664804469273743)\n",
      "(d, train_metric, valid_metric) = (6960, 1.0, 0.966879489225858)\n",
      "(d, train_metric, valid_metric) = (7010, 1.0, 0.9676775738228253)\n",
      "(d, train_metric, valid_metric) = (7060, 1.0, 0.9680766161213089)\n",
      "(d, train_metric, valid_metric) = (7110, 1.0, 0.9672785315243416)\n",
      "(d, train_metric, valid_metric) = (7160, 1.0, 0.9672785315243416)\n",
      "(d, train_metric, valid_metric) = (7210, 1.0, 0.9676775738228253)\n",
      "(d, train_metric, valid_metric) = (7260, 1.0, 0.9680766161213089)\n",
      "(d, train_metric, valid_metric) = (7310, 1.0, 0.9640861931364725)\n",
      "(d, train_metric, valid_metric) = (7360, 1.0, 0.9664804469273743)\n",
      "(d, train_metric, valid_metric) = (7410, 1.0, 0.9652833200319234)\n",
      "(d, train_metric, valid_metric) = (7460, 1.0, 0.9636871508379888)\n",
      "(d, train_metric, valid_metric) = (7510, 1.0, 0.9652833200319234)\n",
      "(d, train_metric, valid_metric) = (7560, 1.0, 0.966879489225858)\n",
      "(d, train_metric, valid_metric) = (7610, 1.0, 0.9596967278531524)\n",
      "(d, train_metric, valid_metric) = (7660, 1.0, 0.9608938547486033)\n",
      "(d, train_metric, valid_metric) = (7710, 1.0, 0.960095770151636)\n",
      "(d, train_metric, valid_metric) = (7760, 1.0, 0.9616919393455706)\n",
      "(d, train_metric, valid_metric) = (7810, 1.0, 0.9636871508379888)\n",
      "(d, train_metric, valid_metric) = (7860, 1.0, 0.9628890662410216)\n",
      "(d, train_metric, valid_metric) = (7910, 1.0, 0.966879489225858)\n",
      "(d, train_metric, valid_metric) = (7960, 1.0, 0.9624900239425379)\n",
      "(d, train_metric, valid_metric) = (8010, 1.0, 0.9624900239425379)\n",
      "(d, train_metric, valid_metric) = (8060, 1.0, 0.9636871508379888)\n",
      "(d, train_metric, valid_metric) = (8110, 1.0, 0.9640861931364725)\n",
      "(d, train_metric, valid_metric) = (8160, 1.0, 0.966879489225858)\n",
      "(d, train_metric, valid_metric) = (8210, 1.0, 0.9680766161213089)\n",
      "(d, train_metric, valid_metric) = (8260, 1.0, 0.9664804469273743)\n",
      "(d, train_metric, valid_metric) = (8310, 1.0, 0.9712689545091779)\n",
      "(d, train_metric, valid_metric) = (8360, 1.0, 0.9664804469273743)\n",
      "(d, train_metric, valid_metric) = (8410, 1.0, 0.966879489225858)\n",
      "(d, train_metric, valid_metric) = (8460, 1.0, 0.9696727853152434)\n",
      "(d, train_metric, valid_metric) = (8510, 1.0, 0.9680766161213089)\n",
      "(d, train_metric, valid_metric) = (8560, 1.0, 0.9676775738228253)\n",
      "(d, train_metric, valid_metric) = (8610, 1.0, 0.9696727853152434)\n",
      "(d, train_metric, valid_metric) = (8660, 1.0, 0.9680766161213089)\n",
      "(d, train_metric, valid_metric) = (8710, 1.0, 0.966879489225858)\n",
      "(d, train_metric, valid_metric) = (8760, 1.0, 0.9660814046288907)\n",
      "(d, train_metric, valid_metric) = (8810, 1.0, 0.9660814046288907)\n",
      "(d, train_metric, valid_metric) = (8860, 1.0, 0.9696727853152434)\n",
      "(d, train_metric, valid_metric) = (8910, 1.0, 0.9688747007182761)\n",
      "(d, train_metric, valid_metric) = (8960, 1.0, 0.9696727853152434)\n",
      "(d, train_metric, valid_metric) = (9010, 1.0, 0.965682362330407)\n",
      "(d, train_metric, valid_metric) = (9060, 1.0, 0.9688747007182761)\n",
      "(d, train_metric, valid_metric) = (9110, 1.0, 0.9716679968076616)\n",
      "(d, train_metric, valid_metric) = (9160, 1.0, 0.9692737430167597)\n",
      "(d, train_metric, valid_metric) = (9210, 1.0, 0.9688747007182761)\n",
      "(d, train_metric, valid_metric) = (9260, 1.0, 0.9696727853152434)\n",
      "(d, train_metric, valid_metric) = (9310, 1.0, 0.9676775738228253)\n",
      "(d, train_metric, valid_metric) = (9360, 1.0, 0.9628890662410216)\n",
      "(d, train_metric, valid_metric) = (9410, 1.0, 0.9708699122106943)\n",
      "(d, train_metric, valid_metric) = (9460, 1.0, 0.9704708699122107)\n",
      "(d, train_metric, valid_metric) = (9510, 1.0, 0.9688747007182761)\n",
      "(d, train_metric, valid_metric) = (9560, 1.0, 0.9680766161213089)\n",
      "(d, train_metric, valid_metric) = (9610, 1.0, 0.9680766161213089)\n",
      "(d, train_metric, valid_metric) = (9660, 1.0, 0.9692737430167597)\n",
      "(d, train_metric, valid_metric) = (9710, 1.0, 0.9708699122106943)\n",
      "(d, train_metric, valid_metric) = (9760, 1.0, 0.9712689545091779)\n",
      "(d, train_metric, valid_metric) = (9810, 1.0, 0.9708699122106943)\n",
      "(d, train_metric, valid_metric) = (9860, 1.0, 0.9684756584197926)\n",
      "(d, train_metric, valid_metric) = (9910, 1.0, 0.970071827613727)\n",
      "(d, train_metric, valid_metric) = (9960, 1.0, 0.9720670391061452)\n",
      "(d, train_metric, valid_metric) = (10010, 1.0, 0.9728651237031125)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10:50:10010, Any[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], Any[0.8918595371109338, 0.9577015163607342, 0.9692737430167597, 0.9505187549880287, 0.9704708699122107, 0.9724660814046289, 0.9676775738228253, 0.9772545889864326, 0.9720670391061452, 0.9712689545091779  …  0.9680766161213089, 0.9680766161213089, 0.9692737430167597, 0.9708699122106943, 0.9712689545091779, 0.9708699122106943, 0.9684756584197926, 0.970071827613727, 0.9720670391061452, 0.9728651237031125])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(merge_purity_threshold=best_mpt)\n",
    "data_schedule, training_losses, valid_losses = learn_curve(dt, X[train,:], y[train], acc, step=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip240\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip240)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip241\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip240)\" d=\"\n",
       "M201.691 1486.45 L2352.76 1486.45 L2352.76 47.2441 L201.691 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip242\">\n",
       "    <rect x=\"201\" y=\"47\" width=\"2152\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip242)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  260.54,1486.45 260.54,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip242)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  767.867,1486.45 767.867,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip242)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1275.19,1486.45 1275.19,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip242)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1782.52,1486.45 1782.52,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip242)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2289.85,1486.45 2289.85,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip242)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  201.691,1343.51 2352.76,1343.51 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip242)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  201.691,1029.63 2352.76,1029.63 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip242)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  201.691,715.743 2352.76,715.743 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip242)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  201.691,401.86 2352.76,401.86 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip242)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  201.691,87.9763 2352.76,87.9763 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip240)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  201.691,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip240)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  201.691,1486.45 201.691,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip240)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  260.54,1486.45 260.54,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip240)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  767.867,1486.45 767.867,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip240)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1275.19,1486.45 1275.19,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip240)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1782.52,1486.45 1782.52,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip240)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2289.85,1486.45 2289.85,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip240)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  201.691,1343.51 227.503,1343.51 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip240)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  201.691,1029.63 227.503,1029.63 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip240)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  201.691,715.743 227.503,715.743 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip240)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  201.691,401.86 227.503,401.86 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip240)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  201.691,87.9763 227.503,87.9763 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip240)\" d=\"M 0 0 M260.54 1508.44 Q256.929 1508.44 255.101 1512 Q253.295 1515.55 253.295 1522.67 Q253.295 1529.78 255.101 1533.35 Q256.929 1536.89 260.54 1536.89 Q264.175 1536.89 265.98 1533.35 Q267.809 1529.78 267.809 1522.67 Q267.809 1515.55 265.98 1512 Q264.175 1508.44 260.54 1508.44 M260.54 1504.73 Q266.351 1504.73 269.406 1509.34 Q272.485 1513.92 272.485 1522.67 Q272.485 1531.4 269.406 1536.01 Q266.351 1540.59 260.54 1540.59 Q254.73 1540.59 251.652 1536.01 Q248.596 1531.4 248.596 1522.67 Q248.596 1513.92 251.652 1509.34 Q254.73 1504.73 260.54 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M722.497 1535.98 L738.816 1535.98 L738.816 1539.92 L716.872 1539.92 L716.872 1535.98 Q719.534 1533.23 724.117 1528.6 Q728.724 1523.95 729.904 1522.61 Q732.15 1520.08 733.029 1518.35 Q733.932 1516.59 733.932 1514.9 Q733.932 1512.14 731.988 1510.41 Q730.066 1508.67 726.965 1508.67 Q724.766 1508.67 722.312 1509.43 Q719.881 1510.2 717.104 1511.75 L717.104 1507.03 Q719.928 1505.89 722.381 1505.31 Q724.835 1504.73 726.872 1504.73 Q732.242 1504.73 735.437 1507.42 Q738.631 1510.11 738.631 1514.6 Q738.631 1516.73 737.821 1518.65 Q737.034 1520.54 734.928 1523.14 Q734.349 1523.81 731.247 1527.03 Q728.145 1530.22 722.497 1535.98 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M743.932 1505.36 L762.289 1505.36 L762.289 1509.3 L748.215 1509.3 L748.215 1517.77 Q749.233 1517.42 750.252 1517.26 Q751.27 1517.07 752.289 1517.07 Q758.076 1517.07 761.455 1520.24 Q764.835 1523.42 764.835 1528.83 Q764.835 1534.41 761.363 1537.51 Q757.89 1540.59 751.571 1540.59 Q749.395 1540.59 747.127 1540.22 Q744.881 1539.85 742.474 1539.11 L742.474 1534.41 Q744.557 1535.54 746.779 1536.1 Q749.002 1536.66 751.478 1536.66 Q755.483 1536.66 757.821 1534.55 Q760.159 1532.44 760.159 1528.83 Q760.159 1525.22 757.821 1523.11 Q755.483 1521.01 751.478 1521.01 Q749.603 1521.01 747.728 1521.42 Q745.877 1521.84 743.932 1522.72 L743.932 1505.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M779.904 1508.44 Q776.293 1508.44 774.464 1512 Q772.659 1515.55 772.659 1522.67 Q772.659 1529.78 774.464 1533.35 Q776.293 1536.89 779.904 1536.89 Q783.538 1536.89 785.344 1533.35 Q787.173 1529.78 787.173 1522.67 Q787.173 1515.55 785.344 1512 Q783.538 1508.44 779.904 1508.44 M779.904 1504.73 Q785.714 1504.73 788.77 1509.34 Q791.849 1513.92 791.849 1522.67 Q791.849 1531.4 788.77 1536.01 Q785.714 1540.59 779.904 1540.59 Q774.094 1540.59 771.015 1536.01 Q767.96 1531.4 767.96 1522.67 Q767.96 1513.92 771.015 1509.34 Q774.094 1504.73 779.904 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M806.918 1508.44 Q803.307 1508.44 801.478 1512 Q799.673 1515.55 799.673 1522.67 Q799.673 1529.78 801.478 1533.35 Q803.307 1536.89 806.918 1536.89 Q810.552 1536.89 812.358 1533.35 Q814.186 1529.78 814.186 1522.67 Q814.186 1515.55 812.358 1512 Q810.552 1508.44 806.918 1508.44 M806.918 1504.73 Q812.728 1504.73 815.784 1509.34 Q818.862 1513.92 818.862 1522.67 Q818.862 1531.4 815.784 1536.01 Q812.728 1540.59 806.918 1540.59 Q801.108 1540.59 798.029 1536.01 Q794.974 1531.4 794.974 1522.67 Q794.974 1513.92 798.029 1509.34 Q801.108 1504.73 806.918 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M1224.95 1505.36 L1243.31 1505.36 L1243.31 1509.3 L1229.23 1509.3 L1229.23 1517.77 Q1230.25 1517.42 1231.27 1517.26 Q1232.29 1517.07 1233.31 1517.07 Q1239.09 1517.07 1242.47 1520.24 Q1245.85 1523.42 1245.85 1528.83 Q1245.85 1534.41 1242.38 1537.51 Q1238.91 1540.59 1232.59 1540.59 Q1230.41 1540.59 1228.15 1540.22 Q1225.9 1539.85 1223.49 1539.11 L1223.49 1534.41 Q1225.58 1535.54 1227.8 1536.1 Q1230.02 1536.66 1232.5 1536.66 Q1236.5 1536.66 1238.84 1534.55 Q1241.18 1532.44 1241.18 1528.83 Q1241.18 1525.22 1238.84 1523.11 Q1236.5 1521.01 1232.5 1521.01 Q1230.62 1521.01 1228.75 1521.42 Q1226.9 1521.84 1224.95 1522.72 L1224.95 1505.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M1260.92 1508.44 Q1257.31 1508.44 1255.48 1512 Q1253.68 1515.55 1253.68 1522.67 Q1253.68 1529.78 1255.48 1533.35 Q1257.31 1536.89 1260.92 1536.89 Q1264.56 1536.89 1266.36 1533.35 Q1268.19 1529.78 1268.19 1522.67 Q1268.19 1515.55 1266.36 1512 Q1264.56 1508.44 1260.92 1508.44 M1260.92 1504.73 Q1266.73 1504.73 1269.79 1509.34 Q1272.87 1513.92 1272.87 1522.67 Q1272.87 1531.4 1269.79 1536.01 Q1266.73 1540.59 1260.92 1540.59 Q1255.11 1540.59 1252.03 1536.01 Q1248.98 1531.4 1248.98 1522.67 Q1248.98 1513.92 1252.03 1509.34 Q1255.11 1504.73 1260.92 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M1287.94 1508.44 Q1284.33 1508.44 1282.5 1512 Q1280.69 1515.55 1280.69 1522.67 Q1280.69 1529.78 1282.5 1533.35 Q1284.33 1536.89 1287.94 1536.89 Q1291.57 1536.89 1293.38 1533.35 Q1295.21 1529.78 1295.21 1522.67 Q1295.21 1515.55 1293.38 1512 Q1291.57 1508.44 1287.94 1508.44 M1287.94 1504.73 Q1293.75 1504.73 1296.8 1509.34 Q1299.88 1513.92 1299.88 1522.67 Q1299.88 1531.4 1296.8 1536.01 Q1293.75 1540.59 1287.94 1540.59 Q1282.13 1540.59 1279.05 1536.01 Q1275.99 1531.4 1275.99 1522.67 Q1275.99 1513.92 1279.05 1509.34 Q1282.13 1504.73 1287.94 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M1314.95 1508.44 Q1311.34 1508.44 1309.51 1512 Q1307.71 1515.55 1307.71 1522.67 Q1307.71 1529.78 1309.51 1533.35 Q1311.34 1536.89 1314.95 1536.89 Q1318.58 1536.89 1320.39 1533.35 Q1322.22 1529.78 1322.22 1522.67 Q1322.22 1515.55 1320.39 1512 Q1318.58 1508.44 1314.95 1508.44 M1314.95 1504.73 Q1320.76 1504.73 1323.82 1509.34 Q1326.9 1513.92 1326.9 1522.67 Q1326.9 1531.4 1323.82 1536.01 Q1320.76 1540.59 1314.95 1540.59 Q1309.14 1540.59 1306.06 1536.01 Q1303.01 1531.4 1303.01 1522.67 Q1303.01 1513.92 1306.06 1509.34 Q1309.14 1504.73 1314.95 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M1731.39 1505.36 L1753.61 1505.36 L1753.61 1507.35 L1741.06 1539.92 L1736.18 1539.92 L1747.98 1509.3 L1731.39 1509.3 L1731.39 1505.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M1758.72 1505.36 L1777.08 1505.36 L1777.08 1509.3 L1763.01 1509.3 L1763.01 1517.77 Q1764.03 1517.42 1765.04 1517.26 Q1766.06 1517.07 1767.08 1517.07 Q1772.87 1517.07 1776.25 1520.24 Q1779.63 1523.42 1779.63 1528.83 Q1779.63 1534.41 1776.15 1537.51 Q1772.68 1540.59 1766.36 1540.59 Q1764.19 1540.59 1761.92 1540.22 Q1759.67 1539.85 1757.27 1539.11 L1757.27 1534.41 Q1759.35 1535.54 1761.57 1536.1 Q1763.79 1536.66 1766.27 1536.66 Q1770.28 1536.66 1772.61 1534.55 Q1774.95 1532.44 1774.95 1528.83 Q1774.95 1525.22 1772.61 1523.11 Q1770.28 1521.01 1766.27 1521.01 Q1764.4 1521.01 1762.52 1521.42 Q1760.67 1521.84 1758.72 1522.72 L1758.72 1505.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M1794.7 1508.44 Q1791.09 1508.44 1789.26 1512 Q1787.45 1515.55 1787.45 1522.67 Q1787.45 1529.78 1789.26 1533.35 Q1791.09 1536.89 1794.7 1536.89 Q1798.33 1536.89 1800.14 1533.35 Q1801.97 1529.78 1801.97 1522.67 Q1801.97 1515.55 1800.14 1512 Q1798.33 1508.44 1794.7 1508.44 M1794.7 1504.73 Q1800.51 1504.73 1803.56 1509.34 Q1806.64 1513.92 1806.64 1522.67 Q1806.64 1531.4 1803.56 1536.01 Q1800.51 1540.59 1794.7 1540.59 Q1788.89 1540.59 1785.81 1536.01 Q1782.75 1531.4 1782.75 1522.67 Q1782.75 1513.92 1785.81 1509.34 Q1788.89 1504.73 1794.7 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M1821.71 1508.44 Q1818.1 1508.44 1816.27 1512 Q1814.46 1515.55 1814.46 1522.67 Q1814.46 1529.78 1816.27 1533.35 Q1818.1 1536.89 1821.71 1536.89 Q1825.34 1536.89 1827.15 1533.35 Q1828.98 1529.78 1828.98 1522.67 Q1828.98 1515.55 1827.15 1512 Q1825.34 1508.44 1821.71 1508.44 M1821.71 1504.73 Q1827.52 1504.73 1830.58 1509.34 Q1833.65 1513.92 1833.65 1522.67 Q1833.65 1531.4 1830.58 1536.01 Q1827.52 1540.59 1821.71 1540.59 Q1815.9 1540.59 1812.82 1536.01 Q1809.77 1531.4 1809.77 1522.67 Q1809.77 1513.92 1812.82 1509.34 Q1815.9 1504.73 1821.71 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M2226.2 1535.98 L2233.84 1535.98 L2233.84 1509.62 L2225.53 1511.29 L2225.53 1507.03 L2233.79 1505.36 L2238.47 1505.36 L2238.47 1535.98 L2246.11 1535.98 L2246.11 1539.92 L2226.2 1539.92 L2226.2 1535.98 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M2261.18 1508.44 Q2257.57 1508.44 2255.74 1512 Q2253.93 1515.55 2253.93 1522.67 Q2253.93 1529.78 2255.74 1533.35 Q2257.57 1536.89 2261.18 1536.89 Q2264.81 1536.89 2266.62 1533.35 Q2268.45 1529.78 2268.45 1522.67 Q2268.45 1515.55 2266.62 1512 Q2264.81 1508.44 2261.18 1508.44 M2261.18 1504.73 Q2266.99 1504.73 2270.04 1509.34 Q2273.12 1513.92 2273.12 1522.67 Q2273.12 1531.4 2270.04 1536.01 Q2266.99 1540.59 2261.18 1540.59 Q2255.37 1540.59 2252.29 1536.01 Q2249.23 1531.4 2249.23 1522.67 Q2249.23 1513.92 2252.29 1509.34 Q2255.37 1504.73 2261.18 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M2288.19 1508.44 Q2284.58 1508.44 2282.75 1512 Q2280.95 1515.55 2280.95 1522.67 Q2280.95 1529.78 2282.75 1533.35 Q2284.58 1536.89 2288.19 1536.89 Q2291.83 1536.89 2293.63 1533.35 Q2295.46 1529.78 2295.46 1522.67 Q2295.46 1515.55 2293.63 1512 Q2291.83 1508.44 2288.19 1508.44 M2288.19 1504.73 Q2294 1504.73 2297.06 1509.34 Q2300.14 1513.92 2300.14 1522.67 Q2300.14 1531.4 2297.06 1536.01 Q2294 1540.59 2288.19 1540.59 Q2282.38 1540.59 2279.3 1536.01 Q2276.25 1531.4 2276.25 1522.67 Q2276.25 1513.92 2279.3 1509.34 Q2282.38 1504.73 2288.19 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M2315.21 1508.44 Q2311.59 1508.44 2309.77 1512 Q2307.96 1515.55 2307.96 1522.67 Q2307.96 1529.78 2309.77 1533.35 Q2311.59 1536.89 2315.21 1536.89 Q2318.84 1536.89 2320.65 1533.35 Q2322.47 1529.78 2322.47 1522.67 Q2322.47 1515.55 2320.65 1512 Q2318.84 1508.44 2315.21 1508.44 M2315.21 1504.73 Q2321.02 1504.73 2324.07 1509.34 Q2327.15 1513.92 2327.15 1522.67 Q2327.15 1531.4 2324.07 1536.01 Q2321.02 1540.59 2315.21 1540.59 Q2309.4 1540.59 2306.32 1536.01 Q2303.26 1531.4 2303.26 1522.67 Q2303.26 1513.92 2306.32 1509.34 Q2309.4 1504.73 2315.21 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M2342.22 1508.44 Q2338.61 1508.44 2336.78 1512 Q2334.97 1515.55 2334.97 1522.67 Q2334.97 1529.78 2336.78 1533.35 Q2338.61 1536.89 2342.22 1536.89 Q2345.85 1536.89 2347.66 1533.35 Q2349.49 1529.78 2349.49 1522.67 Q2349.49 1515.55 2347.66 1512 Q2345.85 1508.44 2342.22 1508.44 M2342.22 1504.73 Q2348.03 1504.73 2351.09 1509.34 Q2354.16 1513.92 2354.16 1522.67 Q2354.16 1531.4 2351.09 1536.01 Q2348.03 1540.59 2342.22 1540.59 Q2336.41 1540.59 2333.33 1536.01 Q2330.28 1531.4 2330.28 1522.67 Q2330.28 1513.92 2333.33 1509.34 Q2336.41 1504.73 2342.22 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M74.9365 1329.31 Q71.3254 1329.31 69.4967 1332.87 Q67.6912 1336.41 67.6912 1343.54 Q67.6912 1350.65 69.4967 1354.22 Q71.3254 1357.76 74.9365 1357.76 Q78.5707 1357.76 80.3763 1354.22 Q82.205 1350.65 82.205 1343.54 Q82.205 1336.41 80.3763 1332.87 Q78.5707 1329.31 74.9365 1329.31 M74.9365 1325.6 Q80.7467 1325.6 83.8022 1330.21 Q86.8809 1334.79 86.8809 1343.54 Q86.8809 1352.27 83.8022 1356.88 Q80.7467 1361.46 74.9365 1361.46 Q69.1264 1361.46 66.0477 1356.88 Q62.9921 1352.27 62.9921 1343.54 Q62.9921 1334.79 66.0477 1330.21 Q69.1264 1325.6 74.9365 1325.6 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M91.9503 1354.91 L96.8345 1354.91 L96.8345 1360.79 L91.9503 1360.79 L91.9503 1354.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M102.043 1360.07 L102.043 1355.81 Q103.802 1356.65 105.608 1357.09 Q107.413 1357.53 109.149 1357.53 Q113.779 1357.53 116.209 1354.42 Q118.663 1351.3 119.01 1344.96 Q117.668 1346.95 115.608 1348.01 Q113.547 1349.08 111.047 1349.08 Q105.862 1349.08 102.83 1345.95 Q99.8206 1342.8 99.8206 1337.36 Q99.8206 1332.04 102.969 1328.82 Q106.117 1325.6 111.348 1325.6 Q117.344 1325.6 120.492 1330.21 Q123.663 1334.79 123.663 1343.54 Q123.663 1351.72 119.774 1356.6 Q115.909 1361.46 109.358 1361.46 Q107.598 1361.46 105.793 1361.11 Q103.987 1360.77 102.043 1360.07 M111.348 1345.42 Q114.496 1345.42 116.325 1343.27 Q118.177 1341.11 118.177 1337.36 Q118.177 1333.64 116.325 1331.48 Q114.496 1329.31 111.348 1329.31 Q108.2 1329.31 106.348 1331.48 Q104.52 1333.64 104.52 1337.36 Q104.52 1341.11 106.348 1343.27 Q108.2 1345.42 111.348 1345.42 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M138.732 1329.31 Q135.121 1329.31 133.293 1332.87 Q131.487 1336.41 131.487 1343.54 Q131.487 1350.65 133.293 1354.22 Q135.121 1357.76 138.732 1357.76 Q142.367 1357.76 144.172 1354.22 Q146.001 1350.65 146.001 1343.54 Q146.001 1336.41 144.172 1332.87 Q142.367 1329.31 138.732 1329.31 M138.732 1325.6 Q144.543 1325.6 147.598 1330.21 Q150.677 1334.79 150.677 1343.54 Q150.677 1352.27 147.598 1356.88 Q144.543 1361.46 138.732 1361.46 Q132.922 1361.46 129.844 1356.88 Q126.788 1352.27 126.788 1343.54 Q126.788 1334.79 129.844 1330.21 Q132.922 1325.6 138.732 1325.6 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M165.746 1329.31 Q162.135 1329.31 160.306 1332.87 Q158.501 1336.41 158.501 1343.54 Q158.501 1350.65 160.306 1354.22 Q162.135 1357.76 165.746 1357.76 Q169.38 1357.76 171.186 1354.22 Q173.015 1350.65 173.015 1343.54 Q173.015 1336.41 171.186 1332.87 Q169.38 1329.31 165.746 1329.31 M165.746 1325.6 Q171.556 1325.6 174.612 1330.21 Q177.691 1334.79 177.691 1343.54 Q177.691 1352.27 174.612 1356.88 Q171.556 1361.46 165.746 1361.46 Q159.936 1361.46 156.857 1356.88 Q153.802 1352.27 153.802 1343.54 Q153.802 1334.79 156.857 1330.21 Q159.936 1325.6 165.746 1325.6 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M77.5291 1015.42 Q73.918 1015.42 72.0893 1018.99 Q70.2838 1022.53 70.2838 1029.66 Q70.2838 1036.77 72.0893 1040.33 Q73.918 1043.87 77.5291 1043.87 Q81.1633 1043.87 82.9689 1040.33 Q84.7976 1036.77 84.7976 1029.66 Q84.7976 1022.53 82.9689 1018.99 Q81.1633 1015.42 77.5291 1015.42 M77.5291 1011.72 Q83.3392 1011.72 86.3948 1016.33 Q89.4735 1020.91 89.4735 1029.66 Q89.4735 1038.39 86.3948 1042.99 Q83.3392 1047.58 77.5291 1047.58 Q71.7189 1047.58 68.6402 1042.99 Q65.5847 1038.39 65.5847 1029.66 Q65.5847 1020.91 68.6402 1016.33 Q71.7189 1011.72 77.5291 1011.72 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M94.5429 1041.03 L99.4271 1041.03 L99.4271 1046.91 L94.5429 1046.91 L94.5429 1041.03 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M104.635 1046.19 L104.635 1041.93 Q106.395 1042.76 108.2 1043.2 Q110.006 1043.64 111.742 1043.64 Q116.371 1043.64 118.802 1040.54 Q121.256 1037.42 121.603 1031.07 Q120.26 1033.06 118.2 1034.13 Q116.14 1035.19 113.64 1035.19 Q108.455 1035.19 105.422 1032.07 Q102.413 1028.92 102.413 1023.48 Q102.413 1018.16 105.561 1014.94 Q108.709 1011.72 113.941 1011.72 Q119.936 1011.72 123.084 1016.33 Q126.256 1020.91 126.256 1029.66 Q126.256 1037.83 122.367 1042.72 Q118.501 1047.58 111.95 1047.58 Q110.191 1047.58 108.385 1047.23 Q106.58 1046.88 104.635 1046.19 M113.941 1031.54 Q117.089 1031.54 118.918 1029.38 Q120.77 1027.23 120.77 1023.48 Q120.77 1019.75 118.918 1017.6 Q117.089 1015.42 113.941 1015.42 Q110.793 1015.42 108.941 1017.6 Q107.112 1019.75 107.112 1023.48 Q107.112 1027.23 108.941 1029.38 Q110.793 1031.54 113.941 1031.54 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M135.353 1042.97 L151.672 1042.97 L151.672 1046.91 L129.728 1046.91 L129.728 1042.97 Q132.39 1040.22 136.973 1035.59 Q141.58 1030.93 142.76 1029.59 Q145.006 1027.07 145.885 1025.33 Q146.788 1023.57 146.788 1021.88 Q146.788 1019.13 144.844 1017.39 Q142.922 1015.66 139.82 1015.66 Q137.621 1015.66 135.168 1016.42 Q132.737 1017.18 129.959 1018.74 L129.959 1014.01 Q132.783 1012.88 135.237 1012.3 Q137.691 1011.72 139.728 1011.72 Q145.098 1011.72 148.293 1014.41 Q151.487 1017.09 151.487 1021.58 Q151.487 1023.71 150.677 1025.63 Q149.89 1027.53 147.783 1030.12 Q147.205 1030.8 144.103 1034.01 Q141.001 1037.21 135.353 1042.97 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M156.788 1012.35 L175.144 1012.35 L175.144 1016.28 L161.07 1016.28 L161.07 1024.75 Q162.089 1024.41 163.107 1024.24 Q164.126 1024.06 165.144 1024.06 Q170.931 1024.06 174.311 1027.23 Q177.691 1030.4 177.691 1035.82 Q177.691 1041.4 174.218 1044.5 Q170.746 1047.58 164.427 1047.58 Q162.251 1047.58 159.982 1047.21 Q157.737 1046.84 155.33 1046.1 L155.33 1041.4 Q157.413 1042.53 159.635 1043.09 Q161.857 1043.64 164.334 1043.64 Q168.339 1043.64 170.677 1041.54 Q173.015 1039.43 173.015 1035.82 Q173.015 1032.21 170.677 1030.1 Q168.339 1027.99 164.334 1027.99 Q162.459 1027.99 160.584 1028.41 Q158.732 1028.83 156.788 1029.71 L156.788 1012.35 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M75.9319 701.542 Q72.3208 701.542 70.4921 705.106 Q68.6865 708.648 68.6865 715.778 Q68.6865 722.884 70.4921 726.449 Q72.3208 729.99 75.9319 729.99 Q79.5661 729.99 81.3717 726.449 Q83.2004 722.884 83.2004 715.778 Q83.2004 708.648 81.3717 705.106 Q79.5661 701.542 75.9319 701.542 M75.9319 697.838 Q81.742 697.838 84.7976 702.444 Q87.8763 707.028 87.8763 715.778 Q87.8763 724.504 84.7976 729.111 Q81.742 733.694 75.9319 733.694 Q70.1217 733.694 67.043 729.111 Q63.9875 724.504 63.9875 715.778 Q63.9875 707.028 67.043 702.444 Q70.1217 697.838 75.9319 697.838 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M92.9457 727.143 L97.8299 727.143 L97.8299 733.023 L92.9457 733.023 L92.9457 727.143 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M103.038 732.305 L103.038 728.046 Q104.797 728.879 106.603 729.319 Q108.409 729.759 110.145 729.759 Q114.774 729.759 117.205 726.657 Q119.658 723.532 120.006 717.19 Q118.663 719.18 116.603 720.245 Q114.543 721.31 112.043 721.31 Q106.858 721.31 103.825 718.185 Q100.816 715.037 100.816 709.597 Q100.816 704.273 103.964 701.055 Q107.112 697.838 112.344 697.838 Q118.339 697.838 121.487 702.444 Q124.658 707.028 124.658 715.778 Q124.658 723.949 120.77 728.833 Q116.904 733.694 110.353 733.694 Q108.594 733.694 106.788 733.347 Q104.983 733 103.038 732.305 M112.344 717.653 Q115.492 717.653 117.321 715.5 Q119.172 713.347 119.172 709.597 Q119.172 705.87 117.321 703.717 Q115.492 701.542 112.344 701.542 Q109.196 701.542 107.344 703.717 Q105.515 705.87 105.515 709.597 Q105.515 713.347 107.344 715.5 Q109.196 717.653 112.344 717.653 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M129.774 698.463 L148.131 698.463 L148.131 702.398 L134.057 702.398 L134.057 710.87 Q135.075 710.523 136.094 710.361 Q137.112 710.176 138.131 710.176 Q143.918 710.176 147.297 713.347 Q150.677 716.518 150.677 721.935 Q150.677 727.514 147.205 730.615 Q143.732 733.694 137.413 733.694 Q135.237 733.694 132.969 733.324 Q130.723 732.953 128.316 732.213 L128.316 727.514 Q130.399 728.648 132.621 729.203 Q134.844 729.759 137.32 729.759 Q141.325 729.759 143.663 727.653 Q146.001 725.546 146.001 721.935 Q146.001 718.324 143.663 716.217 Q141.325 714.111 137.32 714.111 Q135.445 714.111 133.57 714.528 Q131.719 714.944 129.774 715.824 L129.774 698.463 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M165.746 701.542 Q162.135 701.542 160.306 705.106 Q158.501 708.648 158.501 715.778 Q158.501 722.884 160.306 726.449 Q162.135 729.99 165.746 729.99 Q169.38 729.99 171.186 726.449 Q173.015 722.884 173.015 715.778 Q173.015 708.648 171.186 705.106 Q169.38 701.542 165.746 701.542 M165.746 697.838 Q171.556 697.838 174.612 702.444 Q177.691 707.028 177.691 715.778 Q177.691 724.504 174.612 729.111 Q171.556 733.694 165.746 733.694 Q159.936 733.694 156.857 729.111 Q153.802 724.504 153.802 715.778 Q153.802 707.028 156.857 702.444 Q159.936 697.838 165.746 697.838 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M76.8346 387.658 Q73.2236 387.658 71.3949 391.223 Q69.5893 394.765 69.5893 401.894 Q69.5893 409.001 71.3949 412.566 Q73.2236 416.107 76.8346 416.107 Q80.4689 416.107 82.2744 412.566 Q84.1031 409.001 84.1031 401.894 Q84.1031 394.765 82.2744 391.223 Q80.4689 387.658 76.8346 387.658 M76.8346 383.955 Q82.6448 383.955 85.7003 388.561 Q88.779 393.144 88.779 401.894 Q88.779 410.621 85.7003 415.228 Q82.6448 419.811 76.8346 419.811 Q71.0245 419.811 67.9458 415.228 Q64.8903 410.621 64.8903 401.894 Q64.8903 393.144 67.9458 388.561 Q71.0245 383.955 76.8346 383.955 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M93.8484 413.26 L98.7327 413.26 L98.7327 419.14 L93.8484 419.14 L93.8484 413.26 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M103.941 418.422 L103.941 414.163 Q105.7 414.996 107.506 415.436 Q109.311 415.876 111.047 415.876 Q115.677 415.876 118.108 412.774 Q120.561 409.649 120.908 403.306 Q119.566 405.297 117.506 406.362 Q115.446 407.427 112.946 407.427 Q107.76 407.427 104.728 404.302 Q101.719 401.154 101.719 395.714 Q101.719 390.39 104.867 387.172 Q108.015 383.955 113.246 383.955 Q119.242 383.955 122.39 388.561 Q125.561 393.144 125.561 401.894 Q125.561 410.066 121.672 414.95 Q117.807 419.811 111.256 419.811 Q109.497 419.811 107.691 419.464 Q105.885 419.116 103.941 418.422 M113.246 403.769 Q116.395 403.769 118.223 401.617 Q120.075 399.464 120.075 395.714 Q120.075 391.987 118.223 389.834 Q116.395 387.658 113.246 387.658 Q110.098 387.658 108.247 389.834 Q106.418 391.987 106.418 395.714 Q106.418 399.464 108.247 401.617 Q110.098 403.769 113.246 403.769 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M129.45 384.58 L151.672 384.58 L151.672 386.57 L139.126 419.14 L134.242 419.14 L146.047 388.515 L129.45 388.515 L129.45 384.58 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M156.788 384.58 L175.144 384.58 L175.144 388.515 L161.07 388.515 L161.07 396.987 Q162.089 396.64 163.107 396.478 Q164.126 396.292 165.144 396.292 Q170.931 396.292 174.311 399.464 Q177.691 402.635 177.691 408.052 Q177.691 413.63 174.218 416.732 Q170.746 419.811 164.427 419.811 Q162.251 419.811 159.982 419.441 Q157.737 419.07 155.33 418.329 L155.33 413.63 Q157.413 414.765 159.635 415.32 Q161.857 415.876 164.334 415.876 Q168.339 415.876 170.677 413.769 Q173.015 411.663 173.015 408.052 Q173.015 404.441 170.677 402.334 Q168.339 400.228 164.334 400.228 Q162.459 400.228 160.584 400.644 Q158.732 401.061 156.788 401.941 L156.788 384.58 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M66.7884 101.321 L74.4272 101.321 L74.4272 74.9555 L66.1171 76.6222 L66.1171 72.3629 L74.381 70.6963 L79.0569 70.6963 L79.0569 101.321 L86.6957 101.321 L86.6957 105.256 L66.7884 105.256 L66.7884 101.321 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M91.7651 99.3767 L96.6494 99.3767 L96.6494 105.256 L91.7651 105.256 L91.7651 99.3767 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M111.719 73.775 Q108.108 73.775 106.279 77.3398 Q104.473 80.8814 104.473 88.011 Q104.473 95.1174 106.279 98.6822 Q108.108 102.224 111.719 102.224 Q115.353 102.224 117.159 98.6822 Q118.987 95.1174 118.987 88.011 Q118.987 80.8814 117.159 77.3398 Q115.353 73.775 111.719 73.775 M111.719 70.0713 Q117.529 70.0713 120.584 74.6777 Q123.663 79.261 123.663 88.011 Q123.663 96.7378 120.584 101.344 Q117.529 105.928 111.719 105.928 Q105.909 105.928 102.83 101.344 Q99.7743 96.7378 99.7743 88.011 Q99.7743 79.261 102.83 74.6777 Q105.909 70.0713 111.719 70.0713 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M138.732 73.775 Q135.121 73.775 133.293 77.3398 Q131.487 80.8814 131.487 88.011 Q131.487 95.1174 133.293 98.6822 Q135.121 102.224 138.732 102.224 Q142.367 102.224 144.172 98.6822 Q146.001 95.1174 146.001 88.011 Q146.001 80.8814 144.172 77.3398 Q142.367 73.775 138.732 73.775 M138.732 70.0713 Q144.543 70.0713 147.598 74.6777 Q150.677 79.261 150.677 88.011 Q150.677 96.7378 147.598 101.344 Q144.543 105.928 138.732 105.928 Q132.922 105.928 129.844 101.344 Q126.788 96.7378 126.788 88.011 Q126.788 79.261 129.844 74.6777 Q132.922 70.0713 138.732 70.0713 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M165.746 73.775 Q162.135 73.775 160.306 77.3398 Q158.501 80.8814 158.501 88.011 Q158.501 95.1174 160.306 98.6822 Q162.135 102.224 165.746 102.224 Q169.38 102.224 171.186 98.6822 Q173.015 95.1174 173.015 88.011 Q173.015 80.8814 171.186 77.3398 Q169.38 73.775 165.746 73.775 M165.746 70.0713 Q171.556 70.0713 174.612 74.6777 Q177.691 79.261 177.691 88.011 Q177.691 96.7378 174.612 101.344 Q171.556 105.928 165.746 105.928 Q159.936 105.928 156.857 101.344 Q153.802 96.7378 153.802 88.011 Q153.802 79.261 156.857 74.6777 Q159.936 70.0713 165.746 70.0713 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip242)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  262.57,87.9763 272.716,87.9763 282.863,87.9763 293.009,87.9763 303.156,87.9763 313.302,87.9763 323.449,87.9763 333.596,87.9763 343.742,87.9763 353.889,87.9763 \n",
       "  364.035,87.9763 374.182,87.9763 384.328,87.9763 394.475,87.9763 404.621,87.9763 414.768,87.9763 424.914,87.9763 435.061,87.9763 445.207,87.9763 455.354,87.9763 \n",
       "  465.5,87.9763 475.647,87.9763 485.794,87.9763 495.94,87.9763 506.087,87.9763 516.233,87.9763 526.38,87.9763 536.526,87.9763 546.673,87.9763 556.819,87.9763 \n",
       "  566.966,87.9763 577.112,87.9763 587.259,87.9763 597.405,87.9763 607.552,87.9763 617.699,87.9763 627.845,87.9763 637.992,87.9763 648.138,87.9763 658.285,87.9763 \n",
       "  668.431,87.9763 678.578,87.9763 688.724,87.9763 698.871,87.9763 709.017,87.9763 719.164,87.9763 729.31,87.9763 739.457,87.9763 749.603,87.9763 759.75,87.9763 \n",
       "  769.897,87.9763 780.043,87.9763 790.19,87.9763 800.336,87.9763 810.483,87.9763 820.629,87.9763 830.776,87.9763 840.922,87.9763 851.069,87.9763 861.215,87.9763 \n",
       "  871.362,87.9763 881.508,87.9763 891.655,87.9763 901.801,87.9763 911.948,87.9763 922.095,87.9763 932.241,87.9763 942.388,87.9763 952.534,87.9763 962.681,87.9763 \n",
       "  972.827,87.9763 982.974,87.9763 993.12,87.9763 1003.27,87.9763 1013.41,87.9763 1023.56,87.9763 1033.71,87.9763 1043.85,87.9763 1054,87.9763 1064.15,87.9763 \n",
       "  1074.29,87.9763 1084.44,87.9763 1094.59,87.9763 1104.73,87.9763 1114.88,87.9763 1125.03,87.9763 1135.17,87.9763 1145.32,87.9763 1155.46,87.9763 1165.61,87.9763 \n",
       "  1175.76,87.9763 1185.9,87.9763 1196.05,87.9763 1206.2,87.9763 1216.34,87.9763 1226.49,87.9763 1236.64,87.9763 1246.78,87.9763 1256.93,87.9763 1267.08,87.9763 \n",
       "  1277.22,87.9763 1287.37,87.9763 1297.52,87.9763 1307.66,87.9763 1317.81,87.9763 1327.96,87.9763 1338.1,87.9763 1348.25,87.9763 1358.4,87.9763 1368.54,87.9763 \n",
       "  1378.69,87.9763 1388.84,87.9763 1398.98,87.9763 1409.13,87.9763 1419.27,87.9763 1429.42,87.9763 1439.57,87.9763 1449.71,87.9763 1459.86,87.9763 1470.01,87.9763 \n",
       "  1480.15,87.9763 1490.3,87.9763 1500.45,87.9763 1510.59,87.9763 1520.74,87.9763 1530.89,87.9763 1541.03,87.9763 1551.18,87.9763 1561.33,87.9763 1571.47,87.9763 \n",
       "  1581.62,87.9763 1591.77,87.9763 1601.91,87.9763 1612.06,87.9763 1622.21,87.9763 1632.35,87.9763 1642.5,87.9763 1652.65,87.9763 1662.79,87.9763 1672.94,87.9763 \n",
       "  1683.08,87.9763 1693.23,87.9763 1703.38,87.9763 1713.52,87.9763 1723.67,87.9763 1733.82,87.9763 1743.96,87.9763 1754.11,87.9763 1764.26,87.9763 1774.4,87.9763 \n",
       "  1784.55,87.9763 1794.7,87.9763 1804.84,87.9763 1814.99,87.9763 1825.14,87.9763 1835.28,87.9763 1845.43,87.9763 1855.58,87.9763 1865.72,87.9763 1875.87,87.9763 \n",
       "  1886.02,87.9763 1896.16,87.9763 1906.31,87.9763 1916.45,87.9763 1926.6,87.9763 1936.75,87.9763 1946.89,87.9763 1957.04,87.9763 1967.19,87.9763 1977.33,87.9763 \n",
       "  1987.48,87.9763 1997.63,87.9763 2007.77,87.9763 2017.92,87.9763 2028.07,87.9763 2038.21,87.9763 2048.36,87.9763 2058.51,87.9763 2068.65,87.9763 2078.8,87.9763 \n",
       "  2088.95,87.9763 2099.09,87.9763 2109.24,87.9763 2119.39,87.9763 2129.53,87.9763 2139.68,87.9763 2149.83,87.9763 2159.97,87.9763 2170.12,87.9763 2180.26,87.9763 \n",
       "  2190.41,87.9763 2200.56,87.9763 2210.7,87.9763 2220.85,87.9763 2231,87.9763 2241.14,87.9763 2251.29,87.9763 2261.44,87.9763 2271.58,87.9763 2281.73,87.9763 \n",
       "  2291.88,87.9763 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip242)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  262.57,1445.72 272.716,619.048 282.863,473.755 293.009,709.23 303.156,458.724 313.302,433.674 323.449,493.795 333.596,373.552 343.742,438.684 353.889,448.704 \n",
       "  364.035,498.805 374.182,523.856 384.328,378.563 394.475,388.583 404.621,468.745 414.768,433.674 424.914,453.714 435.061,423.654 445.207,543.896 455.354,438.684 \n",
       "  465.5,433.674 475.647,433.674 485.794,428.664 495.94,458.724 506.087,353.512 516.233,413.633 526.38,418.643 536.526,418.643 546.673,408.623 556.819,403.613 \n",
       "  566.966,418.643 577.112,408.623 587.259,518.846 597.405,508.825 607.552,498.805 617.699,418.643 627.845,458.724 637.992,473.755 648.138,493.795 658.285,503.815 \n",
       "  668.431,508.825 678.578,448.704 688.724,468.745 698.871,463.734 709.017,523.856 719.164,518.846 729.31,493.795 739.457,483.775 749.603,488.785 759.75,508.825 \n",
       "  769.897,503.815 780.043,443.694 790.19,453.714 800.336,473.755 810.483,493.795 820.629,473.755 830.776,473.755 840.922,478.765 851.069,483.775 861.215,463.734 \n",
       "  871.362,468.745 881.508,468.745 891.655,423.654 901.801,413.633 911.948,408.623 922.095,388.583 932.241,413.633 942.388,403.613 952.534,413.633 962.681,403.613 \n",
       "  972.827,383.573 982.974,428.664 993.12,473.755 1003.27,463.734 1013.41,443.694 1023.56,443.694 1033.71,448.704 1043.85,453.714 1054,463.734 1064.15,418.643 \n",
       "  1074.29,403.613 1084.44,433.674 1094.59,463.734 1104.73,468.745 1114.88,453.714 1125.03,503.815 1135.17,468.745 1145.32,478.765 1155.46,428.664 1165.61,463.734 \n",
       "  1175.76,428.664 1185.9,423.654 1196.05,448.704 1206.2,448.704 1216.34,423.654 1226.49,463.734 1236.64,488.785 1246.78,508.825 1256.93,453.714 1267.08,463.734 \n",
       "  1277.22,483.775 1287.37,453.714 1297.52,443.694 1307.66,483.775 1317.81,488.785 1327.96,448.704 1338.1,478.765 1348.25,463.734 1358.4,453.714 1368.54,433.674 \n",
       "  1378.69,473.755 1388.84,468.745 1398.98,458.724 1409.13,478.765 1419.27,463.734 1429.42,528.866 1439.57,493.795 1449.71,468.745 1459.86,518.846 1470.01,473.755 \n",
       "  1480.15,513.836 1490.3,458.724 1500.45,488.785 1510.59,508.825 1520.74,448.704 1530.89,488.785 1541.03,493.795 1551.18,498.805 1561.33,483.775 1571.47,493.795 \n",
       "  1581.62,503.815 1591.77,458.724 1601.91,448.704 1612.06,458.724 1622.21,488.785 1632.35,538.886 1642.5,528.866 1652.65,453.714 1662.79,508.825 1672.94,503.815 \n",
       "  1683.08,493.795 1693.23,488.785 1703.38,498.805 1713.52,498.805 1723.67,493.795 1733.82,488.785 1743.96,538.886 1754.11,508.825 1764.26,523.856 1774.4,543.896 \n",
       "  1784.55,523.856 1794.7,503.815 1804.84,593.997 1814.99,578.967 1825.14,588.987 1835.28,568.947 1845.43,543.896 1855.58,553.916 1865.72,503.815 1875.87,558.926 \n",
       "  1886.02,558.926 1896.16,543.896 1906.31,538.886 1916.45,503.815 1926.6,488.785 1936.75,508.825 1946.89,448.704 1957.04,508.825 1967.19,503.815 1977.33,468.745 \n",
       "  1987.48,488.785 1997.63,493.795 2007.77,468.745 2017.92,488.785 2028.07,503.815 2038.21,513.836 2048.36,513.836 2058.51,468.745 2068.65,478.765 2078.8,468.745 \n",
       "  2088.95,518.846 2099.09,478.765 2109.24,443.694 2119.39,473.755 2129.53,478.765 2139.68,468.745 2149.83,493.795 2159.97,553.916 2170.12,453.714 2180.26,458.724 \n",
       "  2190.41,478.765 2200.56,488.785 2210.7,488.785 2220.85,473.755 2231,453.714 2241.14,448.704 2251.29,453.714 2261.44,483.775 2271.58,463.734 2281.73,438.684 \n",
       "  2291.88,428.664 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip240)\" d=\"\n",
       "M1731.15 276.658 L2281.05 276.658 L2281.05 95.2176 L1731.15 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip240)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1731.15,276.658 2281.05,276.658 2281.05,95.2176 1731.15,95.2176 1731.15,276.658 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip240)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1755.05,155.698 1898.45,155.698 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip240)\" d=\"M 0 0 M1922.35 138.418 L1951.59 138.418 L1951.59 142.353 L1939.32 142.353 L1939.32 172.978 L1934.62 172.978 L1934.62 142.353 L1922.35 142.353 L1922.35 138.418 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M1964.11 151.033 Q1963.39 150.617 1962.54 150.431 Q1961.7 150.223 1960.68 150.223 Q1957.07 150.223 1955.13 152.584 Q1953.21 154.922 1953.21 159.32 L1953.21 172.978 L1948.93 172.978 L1948.93 147.052 L1953.21 147.052 L1953.21 151.08 Q1954.55 148.718 1956.7 147.584 Q1958.86 146.427 1961.93 146.427 Q1962.37 146.427 1962.91 146.496 Q1963.44 146.543 1964.09 146.658 L1964.11 151.033 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M1980.36 159.945 Q1975.2 159.945 1973.21 161.126 Q1971.22 162.306 1971.22 165.154 Q1971.22 167.422 1972.7 168.765 Q1974.2 170.084 1976.77 170.084 Q1980.31 170.084 1982.44 167.584 Q1984.6 165.061 1984.6 160.894 L1984.6 159.945 L1980.36 159.945 M1988.86 158.186 L1988.86 172.978 L1984.6 172.978 L1984.6 169.042 Q1983.14 171.403 1980.96 172.538 Q1978.79 173.649 1975.64 173.649 Q1971.66 173.649 1969.3 171.427 Q1966.96 169.181 1966.96 165.431 Q1966.96 161.056 1969.87 158.834 Q1972.81 156.612 1978.62 156.612 L1984.6 156.612 L1984.6 156.195 Q1984.6 153.255 1982.65 151.658 Q1980.73 150.038 1977.24 150.038 Q1975.01 150.038 1972.91 150.57 Q1970.8 151.103 1968.86 152.167 L1968.86 148.232 Q1971.19 147.33 1973.39 146.89 Q1975.59 146.427 1977.67 146.427 Q1983.3 146.427 1986.08 149.343 Q1988.86 152.26 1988.86 158.186 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M1993.32 147.052 L1997.58 147.052 L1997.58 172.978 L1993.32 172.978 L1993.32 147.052 M1993.32 136.959 L1997.58 136.959 L1997.58 142.353 L1993.32 142.353 L1993.32 136.959 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M2023.6 157.329 L2023.6 172.978 L2019.34 172.978 L2019.34 157.468 Q2019.34 153.788 2017.91 151.959 Q2016.47 150.13 2013.6 150.13 Q2010.15 150.13 2008.16 152.33 Q2006.17 154.529 2006.17 158.325 L2006.17 172.978 L2001.89 172.978 L2001.89 147.052 L2006.17 147.052 L2006.17 151.08 Q2007.7 148.742 2009.76 147.584 Q2011.84 146.427 2014.55 146.427 Q2019.02 146.427 2021.31 149.205 Q2023.6 151.959 2023.6 157.329 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M2028.07 147.052 L2032.33 147.052 L2032.33 172.978 L2028.07 172.978 L2028.07 147.052 M2028.07 136.959 L2032.33 136.959 L2032.33 142.353 L2028.07 142.353 L2028.07 136.959 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M2058.35 157.329 L2058.35 172.978 L2054.09 172.978 L2054.09 157.468 Q2054.09 153.788 2052.65 151.959 Q2051.22 150.13 2048.35 150.13 Q2044.9 150.13 2042.91 152.33 Q2040.92 154.529 2040.92 158.325 L2040.92 172.978 L2036.63 172.978 L2036.63 147.052 L2040.92 147.052 L2040.92 151.08 Q2042.44 148.742 2044.5 147.584 Q2046.59 146.427 2049.29 146.427 Q2053.76 146.427 2056.05 149.205 Q2058.35 151.959 2058.35 157.329 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M2079.87 159.714 Q2079.87 155.084 2077.95 152.538 Q2076.05 149.992 2072.6 149.992 Q2069.18 149.992 2067.26 152.538 Q2065.36 155.084 2065.36 159.714 Q2065.36 164.32 2067.26 166.866 Q2069.18 169.413 2072.6 169.413 Q2076.05 169.413 2077.95 166.866 Q2079.87 164.32 2079.87 159.714 M2084.13 169.76 Q2084.13 176.38 2081.19 179.598 Q2078.25 182.839 2072.19 182.839 Q2069.94 182.839 2067.95 182.491 Q2065.96 182.167 2064.09 181.473 L2064.09 177.329 Q2065.96 178.348 2067.79 178.834 Q2069.62 179.32 2071.52 179.32 Q2075.71 179.32 2077.79 177.121 Q2079.87 174.945 2079.87 170.524 L2079.87 168.417 Q2078.55 170.709 2076.49 171.843 Q2074.43 172.978 2071.56 172.978 Q2066.79 172.978 2063.88 169.343 Q2060.96 165.709 2060.96 159.714 Q2060.96 153.695 2063.88 150.061 Q2066.79 146.427 2071.56 146.427 Q2074.43 146.427 2076.49 147.561 Q2078.55 148.695 2079.87 150.987 L2079.87 147.052 L2084.13 147.052 L2084.13 169.76 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M2103.85 138.418 L2108.53 138.418 L2108.53 169.042 L2125.36 169.042 L2125.36 172.978 L2103.85 172.978 L2103.85 138.418 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M2139.04 150.038 Q2135.61 150.038 2133.62 152.723 Q2131.63 155.385 2131.63 160.038 Q2131.63 164.691 2133.6 167.376 Q2135.59 170.038 2139.04 170.038 Q2142.44 170.038 2144.43 167.353 Q2146.42 164.667 2146.42 160.038 Q2146.42 155.431 2144.43 152.746 Q2142.44 150.038 2139.04 150.038 M2139.04 146.427 Q2144.6 146.427 2147.77 150.038 Q2150.94 153.649 2150.94 160.038 Q2150.94 166.404 2147.77 170.038 Q2144.6 173.649 2139.04 173.649 Q2133.46 173.649 2130.29 170.038 Q2127.14 166.404 2127.14 160.038 Q2127.14 153.649 2130.29 150.038 Q2133.46 146.427 2139.04 146.427 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M2171.93 147.816 L2171.93 151.843 Q2170.13 150.917 2168.18 150.455 Q2166.24 149.992 2164.16 149.992 Q2160.98 149.992 2159.39 150.964 Q2157.81 151.936 2157.81 153.88 Q2157.81 155.362 2158.95 156.218 Q2160.08 157.052 2163.51 157.816 L2164.97 158.14 Q2169.5 159.112 2171.4 160.894 Q2173.32 162.654 2173.32 165.825 Q2173.32 169.436 2170.45 171.542 Q2167.6 173.649 2162.6 173.649 Q2160.52 173.649 2158.25 173.232 Q2156.01 172.839 2153.51 172.028 L2153.51 167.63 Q2155.87 168.857 2158.16 169.482 Q2160.45 170.084 2162.7 170.084 Q2165.71 170.084 2167.33 169.066 Q2168.95 168.024 2168.95 166.149 Q2168.95 164.413 2167.77 163.487 Q2166.61 162.561 2162.65 161.704 L2161.17 161.357 Q2157.21 160.524 2155.45 158.811 Q2153.69 157.075 2153.69 154.066 Q2153.69 150.408 2156.29 148.418 Q2158.88 146.427 2163.65 146.427 Q2166.01 146.427 2168.09 146.774 Q2170.17 147.121 2171.93 147.816 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M2194.32 147.816 L2194.32 151.843 Q2192.51 150.917 2190.57 150.455 Q2188.62 149.992 2186.54 149.992 Q2183.37 149.992 2181.77 150.964 Q2180.2 151.936 2180.2 153.88 Q2180.2 155.362 2181.33 156.218 Q2182.47 157.052 2185.89 157.816 L2187.35 158.14 Q2191.89 159.112 2193.78 160.894 Q2195.71 162.654 2195.71 165.825 Q2195.71 169.436 2192.84 171.542 Q2189.99 173.649 2184.99 173.649 Q2182.91 173.649 2180.64 173.232 Q2178.39 172.839 2175.89 172.028 L2175.89 167.63 Q2178.25 168.857 2180.54 169.482 Q2182.84 170.084 2185.08 170.084 Q2188.09 170.084 2189.71 169.066 Q2191.33 168.024 2191.33 166.149 Q2191.33 164.413 2190.15 163.487 Q2188.99 162.561 2185.03 161.704 L2183.55 161.357 Q2179.6 160.524 2177.84 158.811 Q2176.08 157.075 2176.08 154.066 Q2176.08 150.408 2178.67 148.418 Q2181.26 146.427 2186.03 146.427 Q2188.39 146.427 2190.47 146.774 Q2192.56 147.121 2194.32 147.816 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip240)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1755.05,216.178 1898.45,216.178 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip240)\" d=\"M 0 0 M1935.55 233.458 L1922.35 198.898 L1927.24 198.898 L1938.18 227.995 L1949.16 198.898 L1954.02 198.898 L1940.85 233.458 L1935.55 233.458 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M1966.59 220.425 Q1961.43 220.425 1959.43 221.606 Q1957.44 222.786 1957.44 225.634 Q1957.44 227.902 1958.93 229.245 Q1960.43 230.564 1963 230.564 Q1966.54 230.564 1968.67 228.064 Q1970.82 225.541 1970.82 221.374 L1970.82 220.425 L1966.59 220.425 M1975.08 218.666 L1975.08 233.458 L1970.82 233.458 L1970.82 229.522 Q1969.36 231.883 1967.19 233.018 Q1965.01 234.129 1961.86 234.129 Q1957.88 234.129 1955.52 231.907 Q1953.18 229.661 1953.18 225.911 Q1953.18 221.536 1956.1 219.314 Q1959.04 217.092 1964.85 217.092 L1970.82 217.092 L1970.82 216.675 Q1970.82 213.735 1968.88 212.138 Q1966.96 210.518 1963.46 210.518 Q1961.24 210.518 1959.13 211.05 Q1957.03 211.583 1955.08 212.647 L1955.08 208.712 Q1957.42 207.81 1959.62 207.37 Q1961.82 206.907 1963.9 206.907 Q1969.53 206.907 1972.3 209.823 Q1975.08 212.74 1975.08 218.666 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M1979.55 197.439 L1983.81 197.439 L1983.81 233.458 L1979.55 233.458 L1979.55 197.439 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M1988.28 207.532 L1992.54 207.532 L1992.54 233.458 L1988.28 233.458 L1988.28 207.532 M1988.28 197.439 L1992.54 197.439 L1992.54 202.833 L1988.28 202.833 L1988.28 197.439 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M2014.06 211.467 L2014.06 197.439 L2018.32 197.439 L2018.32 233.458 L2014.06 233.458 L2014.06 229.569 Q2012.72 231.883 2010.66 233.018 Q2008.62 234.129 2005.75 234.129 Q2001.05 234.129 1998.09 230.379 Q1995.15 226.629 1995.15 220.518 Q1995.15 214.407 1998.09 210.657 Q2001.05 206.907 2005.75 206.907 Q2008.62 206.907 2010.66 208.041 Q2012.72 209.152 2014.06 211.467 M1999.55 220.518 Q1999.55 225.217 2001.47 227.902 Q2003.42 230.564 2006.8 230.564 Q2010.17 230.564 2012.12 227.902 Q2014.06 225.217 2014.06 220.518 Q2014.06 215.819 2012.12 213.157 Q2010.17 210.472 2006.8 210.472 Q2003.42 210.472 2001.47 213.157 Q1999.55 215.819 1999.55 220.518 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M2034.57 220.425 Q2029.41 220.425 2027.42 221.606 Q2025.43 222.786 2025.43 225.634 Q2025.43 227.902 2026.91 229.245 Q2028.42 230.564 2030.98 230.564 Q2034.53 230.564 2036.66 228.064 Q2038.81 225.541 2038.81 221.374 L2038.81 220.425 L2034.57 220.425 M2043.07 218.666 L2043.07 233.458 L2038.81 233.458 L2038.81 229.522 Q2037.35 231.883 2035.17 233.018 Q2033 234.129 2029.85 234.129 Q2025.87 234.129 2023.51 231.907 Q2021.17 229.661 2021.17 225.911 Q2021.17 221.536 2024.09 219.314 Q2027.03 217.092 2032.84 217.092 L2038.81 217.092 L2038.81 216.675 Q2038.81 213.735 2036.86 212.138 Q2034.94 210.518 2031.45 210.518 Q2029.23 210.518 2027.12 211.05 Q2025.01 211.583 2023.07 212.647 L2023.07 208.712 Q2025.41 207.81 2027.61 207.37 Q2029.8 206.907 2031.89 206.907 Q2037.51 206.907 2040.29 209.823 Q2043.07 212.74 2043.07 218.666 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M2051.75 200.171 L2051.75 207.532 L2060.52 207.532 L2060.52 210.842 L2051.75 210.842 L2051.75 224.916 Q2051.75 228.087 2052.61 228.99 Q2053.48 229.893 2056.15 229.893 L2060.52 229.893 L2060.52 233.458 L2056.15 233.458 Q2051.22 233.458 2049.34 231.629 Q2047.47 229.777 2047.47 224.916 L2047.47 210.842 L2044.34 210.842 L2044.34 207.532 L2047.47 207.532 L2047.47 200.171 L2051.75 200.171 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M2064.99 207.532 L2069.25 207.532 L2069.25 233.458 L2064.99 233.458 L2064.99 207.532 M2064.99 197.439 L2069.25 197.439 L2069.25 202.833 L2064.99 202.833 L2064.99 197.439 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M2083.76 210.518 Q2080.34 210.518 2078.35 213.203 Q2076.35 215.865 2076.35 220.518 Q2076.35 225.171 2078.32 227.856 Q2080.31 230.518 2083.76 230.518 Q2087.17 230.518 2089.16 227.833 Q2091.15 225.147 2091.15 220.518 Q2091.15 215.911 2089.16 213.226 Q2087.17 210.518 2083.76 210.518 M2083.76 206.907 Q2089.32 206.907 2092.49 210.518 Q2095.66 214.129 2095.66 220.518 Q2095.66 226.884 2092.49 230.518 Q2089.32 234.129 2083.76 234.129 Q2078.18 234.129 2075.01 230.518 Q2071.86 226.884 2071.86 220.518 Q2071.86 214.129 2075.01 210.518 Q2078.18 206.907 2083.76 206.907 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M2121.68 217.809 L2121.68 233.458 L2117.42 233.458 L2117.42 217.948 Q2117.42 214.268 2115.98 212.439 Q2114.55 210.61 2111.68 210.61 Q2108.23 210.61 2106.24 212.81 Q2104.25 215.009 2104.25 218.805 L2104.25 233.458 L2099.97 233.458 L2099.97 207.532 L2104.25 207.532 L2104.25 211.56 Q2105.78 209.222 2107.84 208.064 Q2109.92 206.907 2112.63 206.907 Q2117.1 206.907 2119.39 209.685 Q2121.68 212.439 2121.68 217.809 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M2141.4 198.898 L2146.08 198.898 L2146.08 229.522 L2162.91 229.522 L2162.91 233.458 L2141.4 233.458 L2141.4 198.898 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M2176.59 210.518 Q2173.16 210.518 2171.17 213.203 Q2169.18 215.865 2169.18 220.518 Q2169.18 225.171 2171.15 227.856 Q2173.14 230.518 2176.59 230.518 Q2179.99 230.518 2181.98 227.833 Q2183.97 225.147 2183.97 220.518 Q2183.97 215.911 2181.98 213.226 Q2179.99 210.518 2176.59 210.518 M2176.59 206.907 Q2182.14 206.907 2185.31 210.518 Q2188.48 214.129 2188.48 220.518 Q2188.48 226.884 2185.31 230.518 Q2182.14 234.129 2176.59 234.129 Q2171.01 234.129 2167.84 230.518 Q2164.69 226.884 2164.69 220.518 Q2164.69 214.129 2167.84 210.518 Q2171.01 206.907 2176.59 206.907 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M2209.48 208.296 L2209.48 212.323 Q2207.67 211.397 2205.73 210.935 Q2203.78 210.472 2201.7 210.472 Q2198.53 210.472 2196.93 211.444 Q2195.36 212.416 2195.36 214.36 Q2195.36 215.842 2196.49 216.698 Q2197.63 217.532 2201.05 218.296 L2202.51 218.62 Q2207.05 219.592 2208.95 221.374 Q2210.87 223.134 2210.87 226.305 Q2210.87 229.916 2208 232.022 Q2205.15 234.129 2200.15 234.129 Q2198.07 234.129 2195.8 233.712 Q2193.55 233.319 2191.05 232.508 L2191.05 228.11 Q2193.41 229.337 2195.71 229.962 Q2198 230.564 2200.24 230.564 Q2203.25 230.564 2204.87 229.546 Q2206.49 228.504 2206.49 226.629 Q2206.49 224.893 2205.31 223.967 Q2204.16 223.041 2200.2 222.184 L2198.72 221.837 Q2194.76 221.004 2193 219.291 Q2191.24 217.555 2191.24 214.546 Q2191.24 210.888 2193.83 208.898 Q2196.42 206.907 2201.19 206.907 Q2203.55 206.907 2205.64 207.254 Q2207.72 207.601 2209.48 208.296 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip240)\" d=\"M 0 0 M2231.86 208.296 L2231.86 212.323 Q2230.06 211.397 2228.11 210.935 Q2226.17 210.472 2224.09 210.472 Q2220.91 210.472 2219.32 211.444 Q2217.74 212.416 2217.74 214.36 Q2217.74 215.842 2218.88 216.698 Q2220.01 217.532 2223.44 218.296 L2224.9 218.62 Q2229.43 219.592 2231.33 221.374 Q2233.25 223.134 2233.25 226.305 Q2233.25 229.916 2230.38 232.022 Q2227.53 234.129 2222.53 234.129 Q2220.45 234.129 2218.18 233.712 Q2215.94 233.319 2213.44 232.508 L2213.44 228.11 Q2215.8 229.337 2218.09 229.962 Q2220.38 230.564 2222.63 230.564 Q2225.64 230.564 2227.26 229.546 Q2228.88 228.504 2228.88 226.629 Q2228.88 224.893 2227.7 223.967 Q2226.54 223.041 2222.58 222.184 L2221.1 221.837 Q2217.14 221.004 2215.38 219.291 Q2213.62 217.555 2213.62 214.546 Q2213.62 210.888 2216.22 208.898 Q2218.81 206.907 2223.58 206.907 Q2225.94 206.907 2228.02 207.254 Q2230.1 207.601 2231.86 208.296 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(data_schedule, training_losses, label=\"Training Loss\")\n",
    "plot!(data_schedule, valid_losses, label=\"Validation Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(\n",
       "    max_depth = -1,\n",
       "    min_samples_leaf = 1,\n",
       "    min_samples_split = 2,\n",
       "    min_purity_increase = 0.0,\n",
       "    n_subfeatures = 0,\n",
       "    post_prune = false,\n",
       "    merge_purity_threshold = 0.09596,\n",
       "    pdf_smoothing = 0.0,\n",
       "    display_depth = 5)\u001b[34m @959\u001b[39m"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dt = dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @587\u001b[39m trained 0 times.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @735\u001b[39m ⏎ `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @377\u001b[39m ⏎ `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Tree = machine(final_dt, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{DecisionTreeClassifier} @587\u001b[39m.\n",
      "└ @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/machines.jl:322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 3, Threshold 1.0845743415\n",
      "L-> Feature 3, Threshold 0.3457475635\n",
      "    L-> Feature 3, Threshold 0.163776564\n",
      "        L-> Feature 3, Threshold -0.09493500099999999\n",
      "            L-> 1 : 1594/1594\n",
      "            R-> Feature 3, Threshold -0.0948241945\n",
      "                L-> 2 : 1/1\n",
      "                R-> \n",
      "        R-> Feature 2, Threshold 45.557603549999996\n",
      "            L-> Feature 2, Threshold 45.54981163\n",
      "                L-> \n",
      "                R-> 2 : 1/1\n",
      "            R-> Feature 3, Threshold 0.1639058065\n",
      "                L-> 2 : 1/1\n",
      "                R-> \n",
      "    R-> Feature 6, Threshold 27.994632285\n",
      "        L-> Feature 3, Threshold 0.7677057494999999\n",
      "            L-> Feature 2, Threshold 37.455441855000004\n",
      "                L-> 1 : 351/351\n",
      "                R-> \n",
      "            R-> Feature 2, Threshold 42.859770995000005\n",
      "                L-> \n",
      "                R-> \n",
      "        R-> Feature 3, Threshold 0.817397867\n",
      "            L-> Feature 7, Threshold 3.1218967575\n",
      "                L-> \n",
      "                R-> \n",
      "            R-> Feature 4, Threshold 2.2153734335\n",
      "                L-> \n",
      "                R-> \n",
      "R-> Feature 3, Threshold 1.5225476735\n",
      "    L-> Feature 6, Threshold 23.409673395\n",
      "        L-> Feature 3, Threshold 1.3639256185000002\n",
      "            L-> Feature 1, Threshold 91.375\n",
      "                L-> \n",
      "                R-> 2 : 2/2\n",
      "            R-> 2 : 3/3\n",
      "        R-> Feature 7, Threshold 1.618563661\n",
      "            L-> Feature 1, Threshold 69.51953125\n",
      "                L-> 1 : 8/8\n",
      "                R-> \n",
      "            R-> Feature 3, Threshold 1.1187952934999998\n",
      "                L-> \n",
      "                R-> \n",
      "    R-> Feature 3, Threshold 2.670348647\n",
      "        L-> Feature 7, Threshold 0.37629415499999996\n",
      "            L-> Feature 7, Threshold 0.171747004\n",
      "                L-> \n",
      "                R-> \n",
      "            R-> Feature 1, Threshold 66.484375\n",
      "                L-> \n",
      "                R-> \n",
      "        R-> Feature 2, Threshold 39.136276145\n",
      "            L-> 2 : 511/511\n",
      "            R-> Feature 2, Threshold 40.376768165\n",
      "                L-> \n",
      "                R-> 2 : 84/84\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @587\u001b[39m trained 1 time.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @735\u001b[39m ⏎ `Table{AbstractArray{Continuous,1}}`\n",
       "    2:\t\u001b[34mSource @377\u001b[39m ⏎ `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(Final_Tree, rows=train, verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "ŷ2 = MLJ.predict(Final_Tree, X[test,:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2081671527078377"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(ŷ2, y[test]) |> mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9664804469273743"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(ŷ2, y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The classes are un-ordered,\n",
      "│ using: negative='0' and positive='1'.\n",
      "│ To suppress this warning, consider coercing to OrderedFactor.\n",
      "└ @ MLJBase /home/andrew/.julia/packages/MLJBase/cJmIS/src/measures/confusion_matrix.jl:83\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "              ┌───────────────────────────┐\n",
       "              │       Ground Truth        │\n",
       "┌─────────────┼─────────────┬─────────────┤\n",
       "│  Predicted  │      0      │      1      │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      0      │    4788     │     90      │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      1      │     90      │     402     │\n",
       "└─────────────┴─────────────┴─────────────┘\n"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(mode.(ŷ2), y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
