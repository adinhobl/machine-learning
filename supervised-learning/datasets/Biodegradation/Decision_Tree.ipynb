{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using CSV\n",
    "using MLJ\n",
    "using DecisionTree: print_tree\n",
    "using Plots\n",
    "using StatsBase\n",
    "\n",
    "include(\"../../lib.jl\")\n",
    "\n",
    "ENV[\"LINES\"]=30;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "IOError: mkdir: file already exists (EEXIST)",
     "output_type": "error",
     "traceback": [
      "IOError: mkdir: file already exists (EEXIST)",
      "",
      "Stacktrace:",
      " [1] uv_error at ./libuv.jl:97 [inlined]",
      " [2] mkdir(::String; mode::UInt16) at ./file.jl:177",
      " [3] mkdir(::String) at ./file.jl:170",
      " [4] top-level scope at In[9]:1",
      " [5] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "mkdir(\"Figures/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>10</th><th>11</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Float64</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>1,055 rows × 42 columns (omitted printing of 31 columns)</p><tr><th>1</th><td>3.919</td><td>2.6909</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>31.4</td><td>2</td><td>0</td><td>0</td></tr><tr><th>2</th><td>4.17</td><td>2.1144</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>30.8</td><td>1</td><td>1</td><td>0</td></tr><tr><th>3</th><td>3.932</td><td>3.2512</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>26.7</td><td>2</td><td>4</td><td>0</td></tr><tr><th>4</th><td>3.0</td><td>2.7098</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>20.0</td><td>0</td><td>2</td><td>0</td></tr><tr><th>5</th><td>4.236</td><td>3.3944</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>29.4</td><td>2</td><td>4</td><td>0</td></tr><tr><th>6</th><td>4.236</td><td>3.4286</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>28.6</td><td>2</td><td>4</td><td>0</td></tr><tr><th>7</th><td>5.0</td><td>5.0476</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>11.1</td><td>0</td><td>3</td><td>0</td></tr><tr><th>8</th><td>4.525</td><td>3.8301</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>31.6</td><td>3</td><td>2</td><td>0</td></tr><tr><th>9</th><td>4.596</td><td>3.0777</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>44.4</td><td>2</td><td>0</td><td>0</td></tr><tr><th>10</th><td>5.04</td><td>3.6112</td><td>0</td><td>0</td><td>1</td><td>0</td><td>2</td><td>41.2</td><td>0</td><td>4</td><td>3</td></tr><tr><th>11</th><td>4.91</td><td>2.7414</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>52.9</td><td>0</td><td>2</td><td>0</td></tr><tr><th>12</th><td>3.618</td><td>2.1906</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>29.4</td><td>2</td><td>0</td><td>0</td></tr><tr><th>13</th><td>4.214</td><td>2.6272</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>30.0</td><td>3</td><td>0</td><td>0</td></tr><tr><th>14</th><td>3.732</td><td>2.3391</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>30.0</td><td>2</td><td>0</td><td>0</td></tr><tr><th>15</th><td>3.879</td><td>2.5951</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>31.0</td><td>2</td><td>0</td><td>0</td></tr><tr><th>16</th><td>3.942</td><td>2.7719</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>31.6</td><td>2</td><td>0</td><td>0</td></tr><tr><th>17</th><td>3.966</td><td>2.852</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>32.0</td><td>2</td><td>0</td><td>0</td></tr><tr><th>18</th><td>3.732</td><td>2.3761</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>26.3</td><td>2</td><td>0</td><td>1</td></tr><tr><th>19</th><td>4.0</td><td>2.6264</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>23.1</td><td>0</td><td>0</td><td>0</td></tr><tr><th>20</th><td>2.0</td><td>1.1521</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>16.7</td><td>1</td><td>1</td><td>0</td></tr><tr><th>21</th><td>3.732</td><td>2.4062</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>27.8</td><td>2</td><td>1</td><td>0</td></tr><tr><th>22</th><td>4.0</td><td>2.3699</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>30.0</td><td>1</td><td>1</td><td>0</td></tr><tr><th>23</th><td>3.414</td><td>2.2525</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>20.0</td><td>2</td><td>2</td><td>0</td></tr><tr><th>24</th><td>4.17</td><td>2.8042</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>23.1</td><td>2</td><td>2</td><td>0</td></tr><tr><th>25</th><td>4.303</td><td>2.9558</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>25.0</td><td>2</td><td>2</td><td>0</td></tr><tr><th>26</th><td>3.414</td><td>2.6294</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>37.5</td><td>1</td><td>1</td><td>0</td></tr><tr><th>27</th><td>4.214</td><td>3.0057</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>25.0</td><td>1</td><td>2</td><td>0</td></tr><tr><th>28</th><td>3.848</td><td>2.8521</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>27.3</td><td>2</td><td>2</td><td>0</td></tr><tr><th>29</th><td>3.414</td><td>2.3729</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>30.0</td><td>1</td><td>1</td><td>0</td></tr><tr><th>30</th><td>4.393</td><td>3.6458</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>37.0</td><td>3</td><td>1</td><td>0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccccc}\n",
       "\t& 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Int64 & Int64 & Int64 & Int64 & Int64 & Float64 & Int64 & Int64 & Int64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 3.919 & 2.6909 & 0 & 0 & 0 & 0 & 0 & 31.4 & 2 & 0 & 0 & $\\dots$ \\\\\n",
       "\t2 & 4.17 & 2.1144 & 0 & 0 & 0 & 0 & 0 & 30.8 & 1 & 1 & 0 & $\\dots$ \\\\\n",
       "\t3 & 3.932 & 3.2512 & 0 & 0 & 0 & 0 & 0 & 26.7 & 2 & 4 & 0 & $\\dots$ \\\\\n",
       "\t4 & 3.0 & 2.7098 & 0 & 0 & 0 & 0 & 0 & 20.0 & 0 & 2 & 0 & $\\dots$ \\\\\n",
       "\t5 & 4.236 & 3.3944 & 0 & 0 & 0 & 0 & 0 & 29.4 & 2 & 4 & 0 & $\\dots$ \\\\\n",
       "\t6 & 4.236 & 3.4286 & 0 & 0 & 0 & 0 & 0 & 28.6 & 2 & 4 & 0 & $\\dots$ \\\\\n",
       "\t7 & 5.0 & 5.0476 & 1 & 0 & 0 & 0 & 0 & 11.1 & 0 & 3 & 0 & $\\dots$ \\\\\n",
       "\t8 & 4.525 & 3.8301 & 0 & 0 & 0 & 0 & 0 & 31.6 & 3 & 2 & 0 & $\\dots$ \\\\\n",
       "\t9 & 4.596 & 3.0777 & 0 & 0 & 0 & 0 & 2 & 44.4 & 2 & 0 & 0 & $\\dots$ \\\\\n",
       "\t10 & 5.04 & 3.6112 & 0 & 0 & 1 & 0 & 2 & 41.2 & 0 & 4 & 3 & $\\dots$ \\\\\n",
       "\t11 & 4.91 & 2.7414 & 0 & 0 & 0 & 0 & 2 & 52.9 & 0 & 2 & 0 & $\\dots$ \\\\\n",
       "\t12 & 3.618 & 2.1906 & 0 & 0 & 0 & 0 & 0 & 29.4 & 2 & 0 & 0 & $\\dots$ \\\\\n",
       "\t13 & 4.214 & 2.6272 & 0 & 0 & 0 & 0 & 0 & 30.0 & 3 & 0 & 0 & $\\dots$ \\\\\n",
       "\t14 & 3.732 & 2.3391 & 0 & 0 & 0 & 0 & 0 & 30.0 & 2 & 0 & 0 & $\\dots$ \\\\\n",
       "\t15 & 3.879 & 2.5951 & 0 & 0 & 0 & 0 & 0 & 31.0 & 2 & 0 & 0 & $\\dots$ \\\\\n",
       "\t16 & 3.942 & 2.7719 & 1 & 0 & 0 & 0 & 0 & 31.6 & 2 & 0 & 0 & $\\dots$ \\\\\n",
       "\t17 & 3.966 & 2.852 & 1 & 0 & 0 & 0 & 0 & 32.0 & 2 & 0 & 0 & $\\dots$ \\\\\n",
       "\t18 & 3.732 & 2.3761 & 0 & 0 & 1 & 0 & 0 & 26.3 & 2 & 0 & 1 & $\\dots$ \\\\\n",
       "\t19 & 4.0 & 2.6264 & 0 & 0 & 0 & 0 & 0 & 23.1 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t20 & 2.0 & 1.1521 & 0 & 0 & 0 & 0 & 0 & 16.7 & 1 & 1 & 0 & $\\dots$ \\\\\n",
       "\t21 & 3.732 & 2.4062 & 0 & 0 & 0 & 0 & 0 & 27.8 & 2 & 1 & 0 & $\\dots$ \\\\\n",
       "\t22 & 4.0 & 2.3699 & 0 & 0 & 0 & 0 & 0 & 30.0 & 1 & 1 & 0 & $\\dots$ \\\\\n",
       "\t23 & 3.414 & 2.2525 & 0 & 0 & 0 & 0 & 0 & 20.0 & 2 & 2 & 0 & $\\dots$ \\\\\n",
       "\t24 & 4.17 & 2.8042 & 0 & 0 & 0 & 0 & 0 & 23.1 & 2 & 2 & 0 & $\\dots$ \\\\\n",
       "\t25 & 4.303 & 2.9558 & 0 & 0 & 0 & 0 & 0 & 25.0 & 2 & 2 & 0 & $\\dots$ \\\\\n",
       "\t26 & 3.414 & 2.6294 & 0 & 0 & 0 & 0 & 0 & 37.5 & 1 & 1 & 0 & $\\dots$ \\\\\n",
       "\t27 & 4.214 & 3.0057 & 0 & 0 & 0 & 0 & 0 & 25.0 & 1 & 2 & 0 & $\\dots$ \\\\\n",
       "\t28 & 3.848 & 2.8521 & 0 & 0 & 0 & 0 & 0 & 27.3 & 2 & 2 & 0 & $\\dots$ \\\\\n",
       "\t29 & 3.414 & 2.3729 & 0 & 0 & 0 & 0 & 0 & 30.0 & 1 & 1 & 0 & $\\dots$ \\\\\n",
       "\t30 & 4.393 & 3.6458 & 0 & 0 & 0 & 0 & 0 & 37.0 & 3 & 1 & 0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "1055×42 DataFrame. Omitted printing of 34 columns\n",
       "│ Row  │ 1       │ 2       │ 3     │ 4     │ 5     │ 6     │ 7     │ 8       │\n",
       "│      │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mFloat64\u001b[39m │\n",
       "├──────┼─────────┼─────────┼───────┼───────┼───────┼───────┼───────┼─────────┤\n",
       "│ 1    │ 3.919   │ 2.6909  │ 0     │ 0     │ 0     │ 0     │ 0     │ 31.4    │\n",
       "│ 2    │ 4.17    │ 2.1144  │ 0     │ 0     │ 0     │ 0     │ 0     │ 30.8    │\n",
       "│ 3    │ 3.932   │ 3.2512  │ 0     │ 0     │ 0     │ 0     │ 0     │ 26.7    │\n",
       "│ 4    │ 3.0     │ 2.7098  │ 0     │ 0     │ 0     │ 0     │ 0     │ 20.0    │\n",
       "│ 5    │ 4.236   │ 3.3944  │ 0     │ 0     │ 0     │ 0     │ 0     │ 29.4    │\n",
       "│ 6    │ 4.236   │ 3.4286  │ 0     │ 0     │ 0     │ 0     │ 0     │ 28.6    │\n",
       "│ 7    │ 5.0     │ 5.0476  │ 1     │ 0     │ 0     │ 0     │ 0     │ 11.1    │\n",
       "│ 8    │ 4.525   │ 3.8301  │ 0     │ 0     │ 0     │ 0     │ 0     │ 31.6    │\n",
       "│ 9    │ 4.596   │ 3.0777  │ 0     │ 0     │ 0     │ 0     │ 2     │ 44.4    │\n",
       "│ 10   │ 5.04    │ 3.6112  │ 0     │ 0     │ 1     │ 0     │ 2     │ 41.2    │\n",
       "⋮\n",
       "│ 1045 │ 4.807   │ 3.3179  │ 1     │ 0     │ 0     │ 0     │ 3     │ 43.8    │\n",
       "│ 1046 │ 4.607   │ 3.0008  │ 1     │ 0     │ 0     │ 0     │ 2     │ 41.2    │\n",
       "│ 1047 │ 5.313   │ 2.7782  │ 0     │ 0     │ 0     │ 1     │ 2     │ 40.0    │\n",
       "│ 1048 │ 5.103   │ 3.9184  │ 0     │ 0     │ 4     │ 0     │ 4     │ 35.0    │\n",
       "│ 1049 │ 5.265   │ 3.3444  │ 2     │ 0     │ 6     │ 0     │ 1     │ 35.3    │\n",
       "│ 1050 │ 5.029   │ 2.5966  │ 0     │ 0     │ 0     │ 0     │ 4     │ 46.7    │\n",
       "│ 1051 │ 5.431   │ 2.8955  │ 0     │ 0     │ 0     │ 2     │ 0     │ 32.1    │\n",
       "│ 1052 │ 5.287   │ 3.3732  │ 0     │ 0     │ 9     │ 0     │ 0     │ 35.3    │\n",
       "│ 1053 │ 4.869   │ 1.767   │ 0     │ 1     │ 9     │ 0     │ 5     │ 44.4    │\n",
       "│ 1054 │ 5.158   │ 1.6914  │ 2     │ 0     │ 36    │ 0     │ 9     │ 56.1    │\n",
       "│ 1055 │ 5.076   │ 2.6588  │ 2     │ 0     │ 0     │ 0     │ 4     │ 54.5    │"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = CSV.read(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at class labels to see if dataset is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Int64} with 2 entries:\n",
       "  \"RB\"  => 356\n",
       "  \"NRB\" => 699"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = countmap(data[:(Class)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 0.33744075829383885\n",
       " 0.6625592417061611"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect(label_counts[i] / size(data)[1] for i in keys(label_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data ready for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌\u001b[0m─────────\u001b[0m┬\u001b[0m─────────\u001b[0m┬\u001b[0m────────────\u001b[0m┐\u001b[0m\n",
       "│\u001b[0m\u001b[22m _.names \u001b[0m│\u001b[0m\u001b[22m _.types \u001b[0m│\u001b[0m\u001b[22m _.scitypes \u001b[0m│\u001b[0m\n",
       "├\u001b[0m─────────\u001b[0m┼\u001b[0m─────────\u001b[0m┼\u001b[0m────────────\u001b[0m┤\u001b[0m\n",
       "│\u001b[0m 1       \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 2       \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 3       \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 4       \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 5       \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 6       \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 7       \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 8       \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 9       \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 10      \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 11      \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 12      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 13      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 14      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 15      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 16      \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 17      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 18      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 19      \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 20      \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 21      \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 22      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 23      \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 24      \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 25      \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 26      \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 27      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 28      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 29      \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 30      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 31      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 32      \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 33      \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 34      \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 35      \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 36      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 37      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 38      \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 39      \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 40      \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 41      \u001b[0m│\u001b[0m Int64   \u001b[0m│\u001b[0m Count      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m Class   \u001b[0m│\u001b[0m String  \u001b[0m│\u001b[0m Textual    \u001b[0m│\u001b[0m\n",
       "└\u001b[0m─────────\u001b[0m┴\u001b[0m─────────\u001b[0m┴\u001b[0m────────────\u001b[0m┘\u001b[0m\n",
       "_.nrows = 1055\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌\u001b[0m─────────\u001b[0m┬\u001b[0m─────────────────────────────────\u001b[0m┬\u001b[0m───────────────\u001b[0m┐\u001b[0m\n",
       "│\u001b[0m\u001b[22m _.names \u001b[0m│\u001b[0m\u001b[22m _.types                         \u001b[0m│\u001b[0m\u001b[22m _.scitypes    \u001b[0m│\u001b[0m\n",
       "├\u001b[0m─────────\u001b[0m┼\u001b[0m─────────────────────────────────\u001b[0m┼\u001b[0m───────────────\u001b[0m┤\u001b[0m\n",
       "│\u001b[0m 1       \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 2       \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 3       \u001b[0m│\u001b[0m Int64                           \u001b[0m│\u001b[0m Count         \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 4       \u001b[0m│\u001b[0m Int64                           \u001b[0m│\u001b[0m Count         \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 5       \u001b[0m│\u001b[0m Int64                           \u001b[0m│\u001b[0m Count         \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 6       \u001b[0m│\u001b[0m Int64                           \u001b[0m│\u001b[0m Count         \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 7       \u001b[0m│\u001b[0m Int64                           \u001b[0m│\u001b[0m Count         \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 8       \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 9       \u001b[0m│\u001b[0m Int64                           \u001b[0m│\u001b[0m Count         \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 10      \u001b[0m│\u001b[0m Int64                           \u001b[0m│\u001b[0m Count         \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 11      \u001b[0m│\u001b[0m Int64                           \u001b[0m│\u001b[0m Count         \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 12      \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 13      \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 14      \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 15      \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 16      \u001b[0m│\u001b[0m Int64                           \u001b[0m│\u001b[0m Count         \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 17      \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 18      \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 19      \u001b[0m│\u001b[0m Int64                           \u001b[0m│\u001b[0m Count         \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 20      \u001b[0m│\u001b[0m Int64                           \u001b[0m│\u001b[0m Count         \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 21      \u001b[0m│\u001b[0m Int64                           \u001b[0m│\u001b[0m Count         \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 22      \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 23      \u001b[0m│\u001b[0m Int64                           \u001b[0m│\u001b[0m Count         \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 24      \u001b[0m│\u001b[0m Int64                           \u001b[0m│\u001b[0m Count         \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 25      \u001b[0m│\u001b[0m Int64                           \u001b[0m│\u001b[0m Count         \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 26      \u001b[0m│\u001b[0m Int64                           \u001b[0m│\u001b[0m Count         \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 27      \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 28      \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 29      \u001b[0m│\u001b[0m Int64                           \u001b[0m│\u001b[0m Count         \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 30      \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 31      \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 32      \u001b[0m│\u001b[0m Int64                           \u001b[0m│\u001b[0m Count         \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 33      \u001b[0m│\u001b[0m Int64                           \u001b[0m│\u001b[0m Count         \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 34      \u001b[0m│\u001b[0m Int64                           \u001b[0m│\u001b[0m Count         \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 35      \u001b[0m│\u001b[0m Int64                           \u001b[0m│\u001b[0m Count         \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 36      \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 37      \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 38      \u001b[0m│\u001b[0m Int64                           \u001b[0m│\u001b[0m Count         \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 39      \u001b[0m│\u001b[0m Float64                         \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 40      \u001b[0m│\u001b[0m Int64                           \u001b[0m│\u001b[0m Count         \u001b[0m│\u001b[0m\n",
       "│\u001b[0m 41      \u001b[0m│\u001b[0m Int64                           \u001b[0m│\u001b[0m Count         \u001b[0m│\u001b[0m\n",
       "│\u001b[0m Class   \u001b[0m│\u001b[0m CategoricalValue{String,UInt32} \u001b[0m│\u001b[0m Multiclass{2} \u001b[0m│\u001b[0m\n",
       "└\u001b[0m─────────\u001b[0m┴\u001b[0m─────────────────────────────────\u001b[0m┴\u001b[0m───────────────\u001b[0m┘\u001b[0m\n",
       "_.nrows = 1055\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coerce!(data, :Class=>Multiclass)\n",
    "schema(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CategoricalValue{String,UInt32}[\"RB\", \"RB\", \"RB\", \"RB\", \"RB\", \"RB\", \"RB\", \"RB\", \"RB\", \"RB\"  …  \"NRB\", \"NRB\", \"NRB\", \"NRB\", \"NRB\", \"NRB\", \"NRB\", \"NRB\", \"NRB\", \"NRB\"], 1055×41 DataFrame. Omitted printing of 33 columns\n",
       "│ Row  │ 1       │ 2       │ 3     │ 4     │ 5     │ 6     │ 7     │ 8       │\n",
       "│      │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mFloat64\u001b[39m │\n",
       "├──────┼─────────┼─────────┼───────┼───────┼───────┼───────┼───────┼─────────┤\n",
       "│ 1    │ 3.919   │ 2.6909  │ 0     │ 0     │ 0     │ 0     │ 0     │ 31.4    │\n",
       "│ 2    │ 4.17    │ 2.1144  │ 0     │ 0     │ 0     │ 0     │ 0     │ 30.8    │\n",
       "│ 3    │ 3.932   │ 3.2512  │ 0     │ 0     │ 0     │ 0     │ 0     │ 26.7    │\n",
       "│ 4    │ 3.0     │ 2.7098  │ 0     │ 0     │ 0     │ 0     │ 0     │ 20.0    │\n",
       "│ 5    │ 4.236   │ 3.3944  │ 0     │ 0     │ 0     │ 0     │ 0     │ 29.4    │\n",
       "│ 6    │ 4.236   │ 3.4286  │ 0     │ 0     │ 0     │ 0     │ 0     │ 28.6    │\n",
       "│ 7    │ 5.0     │ 5.0476  │ 1     │ 0     │ 0     │ 0     │ 0     │ 11.1    │\n",
       "│ 8    │ 4.525   │ 3.8301  │ 0     │ 0     │ 0     │ 0     │ 0     │ 31.6    │\n",
       "│ 9    │ 4.596   │ 3.0777  │ 0     │ 0     │ 0     │ 0     │ 2     │ 44.4    │\n",
       "│ 10   │ 5.04    │ 3.6112  │ 0     │ 0     │ 1     │ 0     │ 2     │ 41.2    │\n",
       "⋮\n",
       "│ 1045 │ 4.807   │ 3.3179  │ 1     │ 0     │ 0     │ 0     │ 3     │ 43.8    │\n",
       "│ 1046 │ 4.607   │ 3.0008  │ 1     │ 0     │ 0     │ 0     │ 2     │ 41.2    │\n",
       "│ 1047 │ 5.313   │ 2.7782  │ 0     │ 0     │ 0     │ 1     │ 2     │ 40.0    │\n",
       "│ 1048 │ 5.103   │ 3.9184  │ 0     │ 0     │ 4     │ 0     │ 4     │ 35.0    │\n",
       "│ 1049 │ 5.265   │ 3.3444  │ 2     │ 0     │ 6     │ 0     │ 1     │ 35.3    │\n",
       "│ 1050 │ 5.029   │ 2.5966  │ 0     │ 0     │ 0     │ 0     │ 4     │ 46.7    │\n",
       "│ 1051 │ 5.431   │ 2.8955  │ 0     │ 0     │ 0     │ 2     │ 0     │ 32.1    │\n",
       "│ 1052 │ 5.287   │ 3.3732  │ 0     │ 0     │ 9     │ 0     │ 0     │ 35.3    │\n",
       "│ 1053 │ 4.869   │ 1.767   │ 0     │ 1     │ 9     │ 0     │ 5     │ 44.4    │\n",
       "│ 1054 │ 5.158   │ 1.6914  │ 2     │ 0     │ 36    │ 0     │ 9     │ 56.1    │\n",
       "│ 1055 │ 5.076   │ 2.6588  │ 2     │ 0     │ 0     │ 0     │ 4     │ 54.5    │)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, X = unpack(data, ==(:Class), colname->true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition train and test data accoring to class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([465, 562, 278, 619, 161, 972, 782, 321, 537, 760  …  12, 913, 471, 13, 1006, 802, 112, 840, 744, 261], [196, 586, 245, 77, 1028, 432, 215, 987, 137, 411  …  975, 610, 886, 848, 731, 1024, 805, 500, 659, 415])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data to use when trying to fit a single validation set\n",
    "train, test = partition(eachindex(y), 0.7, shuffle=true, rng=123, stratify=values(data[:Class])) # gives 70:30 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 0.33739837398373984\n",
       " 0.6626016260162602"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_counts = countmap(data[train,:Class])\n",
    "collect(train_counts[i] / size(train)[1] for i in keys(train_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 0.33753943217665616\n",
       " 0.6624605678233438"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_counts = countmap(data[test,:Class])\n",
    "collect(test_counts[i] / size(test)[1] for i in keys(test_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{Standardizer} @873\u001b[39m.\n",
      "└ @ MLJBase /home/andrew/.julia/packages/MLJBase/uKzAz/src/machines.jl:319\n"
     ]
    }
   ],
   "source": [
    "standardizer = Standardizer()\n",
    "stand = machine(standardizer, X[train,:]) #only want to standardize on training distribution\n",
    "fit!(stand)\n",
    "X_stand = MLJ.transform(stand, X);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Five Learning Algorithms\n",
    "\n",
    "* Decision trees with some form of pruning\n",
    "* Neural networks\n",
    "* Boosting\n",
    "* Support Vector Machines\n",
    "* k-nearest neighbors\n",
    "\n",
    "\n",
    "##### Testing\n",
    "* Implement the algorithms\n",
    "* Design two *interesting* classification problems. For the purposes of this assignment, a classification problem is just a set of training examples and a set of test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Array{NamedTuple{(:name, :package_name, :is_supervised, :docstring, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :is_pure_julia, :is_wrapper, :load_path, :package_license, :package_url, :package_uuid, :prediction_type, :supports_online, :supports_weights, :input_scitype, :target_scitype, :output_scitype),T} where T<:Tuple,1}:\n",
       " (name = AdaBoostStumpClassifier, package_name = DecisionTree, ... )\n",
       " (name = ConstantClassifier, package_name = MLJModels, ... )\n",
       " (name = DecisionTreeClassifier, package_name = DecisionTree, ... )\n",
       " (name = DeterministicConstantClassifier, package_name = MLJModels, ... )\n",
       " (name = RandomForestClassifier, package_name = DecisionTree, ... )\n",
       " (name = RandomForestClassifier, package_name = ScikitLearn, ... )"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models(matching(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJModels ✔\n",
      "import DecisionTree ✔\n",
      "import MLJModels.DecisionTree_ ✔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Loading into module \"Main\": \n",
      "└ @ MLJModels /home/andrew/.julia/packages/MLJModels/mUBFt/src/loading.jl:70\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(\n",
       "    max_depth = -1,\n",
       "    min_samples_leaf = 1,\n",
       "    min_samples_split = 2,\n",
       "    min_purity_increase = 0.0,\n",
       "    n_subfeatures = 0,\n",
       "    post_prune = false,\n",
       "    merge_purity_threshold = 1.0,\n",
       "    pdf_smoothing = 0.0,\n",
       "    display_depth = 5)\u001b[34m @777\u001b[39m"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@load DecisionTreeClassifier verbosity=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees\n",
    "* Be sure to use some form of pruning. \n",
    "* You are not required to use information gain (for example, there is something called the GINI index that is sometimes used) to split attributes, but you should describe whatever it is that you do use.\n",
    "\n",
    "1. https://alan-turing-institute.github.io/MLJ.jl/dev/transformers/#MLJModels.UnivariateDiscretizer\n",
    "1. https://alan-turing-institute.github.io/MLJ.jl/dev/getting_started/#Getting-Started-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No post-pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(\n",
       "    max_depth = -1,\n",
       "    min_samples_leaf = 1,\n",
       "    min_samples_split = 2,\n",
       "    min_purity_increase = 0.0,\n",
       "    n_subfeatures = 0,\n",
       "    post_prune = false,\n",
       "    merge_purity_threshold = 1.0,\n",
       "    pdf_smoothing = 0.0,\n",
       "    display_depth = 8)\u001b[34m @847\u001b[39m"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(post_prune=false, display_depth=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @012\u001b[39m trained 0 times.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @239\u001b[39m ⏎ `Table{Union{AbstractArray{Continuous,1}, AbstractArray{Count,1}}}`\n",
       "    2:\t\u001b[34mSource @756\u001b[39m ⏎ `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tree = machine(dt, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{DecisionTreeClassifier} @012\u001b[39m.\n",
      "└ @ MLJBase /home/andrew/.julia/packages/MLJBase/uKzAz/src/machines.jl:319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 36, Threshold 3.8005\n",
      "L-> Feature 27, Threshold 2.2380000000000004\n",
      "    L-> Feature 34, Threshold 2.5\n",
      "        L-> Feature 9, Threshold 3.5\n",
      "            L-> Feature 10, Threshold 1.5\n",
      "                L-> Feature 36, Threshold 3.5940000000000003\n",
      "                    L-> Feature 9, Threshold 1.5\n",
      "                        L-> Feature 18, Threshold 1.1745\n",
      "                            L-> \n",
      "                            R-> 1 : 5/5\n",
      "                        R-> Feature 13, Threshold 3.151\n",
      "                            L-> 2 : 26/26\n",
      "                            R-> \n",
      "                    R-> Feature 16, Threshold 1.5\n",
      "                        L-> Feature 8, Threshold 50.7\n",
      "                            L-> \n",
      "                            R-> 2 : 1/1\n",
      "                        R-> Feature 2, Threshold 2.73755\n",
      "                            L-> 1 : 2/2\n",
      "                            R-> \n",
      "                R-> Feature 18, Threshold 1.175\n",
      "                    L-> Feature 6, Threshold 0.5\n",
      "                        L-> Feature 41, Threshold 1.5\n",
      "                            L-> 2 : 92/92\n",
      "                            R-> 1 : 1/1\n",
      "                        R-> Feature 37, Threshold 2.542\n",
      "                            L-> 2 : 2/2\n",
      "                            R-> \n",
      "                    R-> 1 : 3/3\n",
      "            R-> Feature 13, Threshold 3.6745\n",
      "                L-> 1 : 13/13\n",
      "                R-> 2 : 2/2\n",
      "        R-> Feature 16, Threshold 1.5\n",
      "            L-> 1 : 27/27\n",
      "            R-> Feature 19, Threshold 0.5\n",
      "                L-> 2 : 5/5\n",
      "                R-> 1 : 2/2\n",
      "    R-> Feature 30, Threshold 5.1245\n",
      "        L-> Feature 8, Threshold 25.3\n",
      "            L-> 2 : 2/2\n",
      "            R-> Feature 28, Threshold -0.0015\n",
      "                L-> Feature 28, Threshold -0.006500000000000001\n",
      "                    L-> 1 : 14/14\n",
      "                    R-> Feature 18, Threshold 1.1284999999999998\n",
      "                        L-> Feature 39, Threshold 8.038\n",
      "                            L-> 1 : 1/1\n",
      "                            R-> 2 : 2/2\n",
      "                        R-> 1 : 3/3\n",
      "                R-> 1 : 50/50\n",
      "        R-> Feature 38, Threshold 0.5\n",
      "            L-> Feature 1, Threshold 5.097\n",
      "                L-> Feature 2, Threshold 2.4012000000000002\n",
      "                    L-> Feature 31, Threshold 3.016\n",
      "                        L-> 1 : 4/4\n",
      "                        R-> Feature 17, Threshold 0.9844999999999999\n",
      "                            L-> 1 : 2/2\n",
      "                            R-> 2 : 8/8\n",
      "                    R-> 2 : 27/27\n",
      "                R-> Feature 1, Threshold 5.371\n",
      "                    L-> 1 : 12/12\n",
      "                    R-> 2 : 2/2\n",
      "            R-> Feature 17, Threshold 1.0225\n",
      "                L-> 1 : 19/19\n",
      "                R-> Feature 36, Threshold 3.7555\n",
      "                    L-> 2 : 3/3\n",
      "                    R-> Feature 11, Threshold 1.5\n",
      "                        L-> 2 : 1/1\n",
      "                        R-> 1 : 4/4\n",
      "R-> Feature 12, Threshold -0.5695\n",
      "    L-> Feature 22, Threshold 1.2275\n",
      "        L-> Feature 39, Threshold 9.043\n",
      "            L-> Feature 5, Threshold 1.5\n",
      "                L-> 2 : 8/8\n",
      "                R-> 1 : 1/1\n",
      "            R-> Feature 39, Threshold 9.908999999999999\n",
      "                L-> 1 : 6/6\n",
      "                R-> 2 : 1/1\n",
      "        R-> Feature 13, Threshold 3.4015\n",
      "            L-> 2 : 2/2\n",
      "            R-> 1 : 26/26\n",
      "    R-> Feature 27, Threshold 2.3585000000000003\n",
      "        L-> Feature 17, Threshold 0.9935\n",
      "            L-> Feature 17, Threshold 0.9915\n",
      "                L-> Feature 37, Threshold 1.9740000000000002\n",
      "                    L-> Feature 31, Threshold 9.782499999999999\n",
      "                        L-> 1 : 14/14\n",
      "                        R-> 2 : 1/1\n",
      "                    R-> Feature 37, Threshold 2.1285\n",
      "                        L-> Feature 22, Threshold 1.3975\n",
      "                            L-> 2 : 3/3\n",
      "                            R-> \n",
      "                        R-> 1 : 4/4\n",
      "                R-> 2 : 3/3\n",
      "            R-> Feature 18, Threshold 1.1185\n",
      "                L-> Feature 1, Threshold 5.291\n",
      "                    L-> Feature 18, Threshold 1.1035\n",
      "                        L-> Feature 39, Threshold 8.783\n",
      "                            L-> 2 : 1/1\n",
      "                            R-> \n",
      "                        R-> 1 : 25/25\n",
      "                    R-> 2 : 3/3\n",
      "                R-> 1 : 72/72\n",
      "        R-> 1 : 118/118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @012\u001b[39m trained 1 time.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @239\u001b[39m ⏎ `Table{Union{AbstractArray{Continuous,1}, AbstractArray{Count,1}}}`\n",
       "    2:\t\u001b[34mSource @756\u001b[39m ⏎ `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(Tree, rows=train, verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 6 folds: 100%[=========================] Time: 0:00:04\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "┌\u001b[0m───────────────\u001b[0m┬\u001b[0m───────────────\u001b[0m┬\u001b[0m───────────────────────────────────────────\u001b[0m┐\u001b[0m\n",
       "│\u001b[0m\u001b[22m _.measure     \u001b[0m│\u001b[0m\u001b[22m _.measurement \u001b[0m│\u001b[0m\u001b[22m _.per_fold                                \u001b[0m│\u001b[0m\n",
       "├\u001b[0m───────────────\u001b[0m┼\u001b[0m───────────────\u001b[0m┼\u001b[0m───────────────────────────────────────────\u001b[0m┤\u001b[0m\n",
       "│\u001b[0m cross_entropy \u001b[0m│\u001b[0m 7.07          \u001b[0m│\u001b[0m [6.96, 7.58, 6.55, 7.99, 6.35, 7.0]       \u001b[0m│\u001b[0m\n",
       "│\u001b[0m acc           \u001b[0m│\u001b[0m 0.804         \u001b[0m│\u001b[0m [0.807, 0.79, 0.818, 0.778, 0.824, 0.806] \u001b[0m│\u001b[0m\n",
       "└\u001b[0m───────────────\u001b[0m┴\u001b[0m───────────────\u001b[0m┴\u001b[0m───────────────────────────────────────────\u001b[0m┘\u001b[0m\n",
       "_.per_observation = [[[2.22e-16, 2.22e-16, ..., 2.22e-16], [36.0, 36.0, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 36.0]], missing]\n",
       "_.fitted_params_per_fold = [ … ]\n",
       "_.report_per_fold = [ … ]\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_acc = evaluate!(Tree, resampling=CV(shuffle=true), measure=[cross_entropy, acc], verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 36, Threshold 3.7954999999999997\n",
      "L-> Feature 34, Threshold 2.5\n",
      "    L-> Feature 1, Threshold 5.0760000000000005\n",
      "        L-> Feature 10, Threshold 1.5\n",
      "            L-> Feature 36, Threshold 3.5915\n",
      "                L-> Feature 38, Threshold 1.5\n",
      "                    L-> Feature 13, Threshold 2.4745\n",
      "                        L-> 2 : 23/23\n",
      "                        R-> Feature 2, Threshold 2.3737500000000002\n",
      "                            L-> Feature 28, Threshold -0.0655\n",
      "                                L-> 2 : 3/3\n",
      "                                R-> Feature 18, Threshold 1.1389999999999998\n",
      "                                    L-> 1 : 10/10\n",
      "                                    R-> Feature 2, Threshold 2.16075\n",
      "                                        L-> 2 : 2/2\n",
      "                                        R-> 1 : 3/3\n",
      "                            R-> Feature 12, Threshold 0.004\n",
      "                                L-> Feature 2, Threshold 3.13815\n",
      "                                    L-> Feature 39, Threshold 8.165\n",
      "                                        L-> Feature 17, Threshold 0.972\n",
      "                                            L-> 2 : 14/14\n",
      "                                            R-> Feature 37, Threshold 2.0385\n",
      "                                                L-> 1 : 3/3\n",
      "                                                R-> Feature 39, Threshold 6.858\n",
      "                                                    L-> 1 : 1/1\n",
      "                                                    R-> 2 : 16/16\n",
      "                                        R-> Feature 8, Threshold 32.0\n",
      "                                            L-> 1 : 5/5\n",
      "                                            R-> 2 : 2/2\n",
      "                                    R-> Feature 14, Threshold 0.8865000000000001\n",
      "                                        L-> Feature 22, Threshold 1.2925\n",
      "                                            L-> 2 : 2/2\n",
      "                                            R-> 1 : 1/1\n",
      "                                        R-> 1 : 6/6\n",
      "                                R-> 2 : 13/13\n",
      "                    R-> 1 : 8/8\n",
      "                R-> Feature 37, Threshold 2.3005\n",
      "                    L-> Feature 18, Threshold 1.0945\n",
      "                        L-> 2 : 1/1\n",
      "                        R-> Feature 1, Threshold 4.7509999999999994\n",
      "                            L-> Feature 17, Threshold 0.99\n",
      "                                L-> Feature 17, Threshold 0.971\n",
      "                                    L-> Feature 1, Threshold 4.666\n",
      "                                        L-> Feature 17, Threshold 0.967\n",
      "                                            L-> 1 : 1/1\n",
      "                                            R-> 2 : 2/2\n",
      "                                        R-> 1 : 3/3\n",
      "                                    R-> 1 : 13/13\n",
      "                                R-> 2 : 2/2\n",
      "                            R-> 1 : 22/22\n",
      "                    R-> Feature 16, Threshold 1.5\n",
      "                        L-> Feature 17, Threshold 0.998\n",
      "                            L-> Feature 27, Threshold 2.151\n",
      "                                L-> 2 : 1/1\n",
      "                                R-> 1 : 1/1\n",
      "                            R-> 1 : 6/6\n",
      "                        R-> Feature 2, Threshold 3.05025\n",
      "                            L-> 2 : 8/8\n",
      "                            R-> Feature 5, Threshold 1.5\n",
      "                                L-> Feature 15, Threshold 9.847999999999999\n",
      "                                    L-> Feature 31, Threshold 1.5155\n",
      "                                        L-> Feature 5, Threshold 0.5\n",
      "                                            L-> Feature 2, Threshold 3.2492\n",
      "                                                L-> 2 : 1/1\n",
      "                                                R-> 1 : 1/1\n",
      "                                            R-> 1 : 2/2\n",
      "                                        R-> 2 : 1/1\n",
      "                                    R-> 1 : 2/2\n",
      "                                R-> 2 : 2/2\n",
      "            R-> Feature 5, Threshold 0.5\n",
      "                L-> Feature 14, Threshold 0.899\n",
      "                    L-> Feature 12, Threshold -0.023\n",
      "                        L-> Feature 30, Threshold 17.049500000000002\n",
      "                            L-> 2 : 8/8\n",
      "                            R-> Feature 10, Threshold 3.5\n",
      "                                L-> 1 : 2/2\n",
      "                                R-> 2 : 1/1\n",
      "                        R-> Feature 2, Threshold 3.1976500000000003\n",
      "                            L-> 1 : 8/8\n",
      "                            R-> 2 : 1/1\n",
      "                    R-> Feature 31, Threshold 3.5709999999999997\n",
      "                        L-> Feature 4, Threshold 0.5\n",
      "                            L-> 2 : 92/92\n",
      "                            R-> 1 : 1/1\n",
      "                        R-> Feature 30, Threshold 5.138\n",
      "                            L-> Feature 31, Threshold 4.2875\n",
      "                                L-> 1 : 4/4\n",
      "                                R-> 2 : 3/3\n",
      "                            R-> Feature 2, Threshold 3.0694\n",
      "                                L-> Feature 35, Threshold 0.5\n",
      "                                    L-> Feature 12, Threshold -0.875\n",
      "                                        L-> 2 : 5/5\n",
      "                                        R-> 1 : 3/3\n",
      "                                    R-> 2 : 9/9\n",
      "                                R-> 2 : 29/29\n",
      "                R-> Feature 28, Threshold 0.009000000000000001\n",
      "                    L-> Feature 11, Threshold 2.5\n",
      "                        L-> 1 : 10/10\n",
      "                        R-> 2 : 2/2\n",
      "                    R-> 2 : 2/2\n",
      "        R-> Feature 39, Threshold 8.489\n",
      "            L-> Feature 12, Threshold -0.911\n",
      "                L-> 2 : 3/3\n",
      "                R-> Feature 32, Threshold 0.5\n",
      "                    L-> Feature 30, Threshold 10.221\n",
      "                        L-> 1 : 22/22\n",
      "                        R-> Feature 30, Threshold 10.4465\n",
      "                            L-> 2 : 2/2\n",
      "                            R-> Feature 31, Threshold 3.5519999999999996\n",
      "                                L-> 1 : 7/7\n",
      "                                R-> 2 : 1/1\n",
      "                    R-> Feature 17, Threshold 0.984\n",
      "                        L-> Feature 22, Threshold 1.2774999999999999\n",
      "                            L-> 2 : 4/4\n",
      "                            R-> 1 : 1/1\n",
      "                        R-> 1 : 3/3\n",
      "            R-> 1 : 20/20\n",
      "    R-> Feature 12, Threshold -0.3895\n",
      "        L-> Feature 30, Threshold 20.2635\n",
      "            L-> 2 : 3/3\n",
      "            R-> Feature 17, Threshold 1.01\n",
      "                L-> 2 : 2/2\n",
      "                R-> Feature 11, Threshold 1.5\n",
      "                    L-> Feature 34, Threshold 3.5\n",
      "                        L-> 1 : 1/1\n",
      "                        R-> 2 : 1/1\n",
      "                    R-> 1 : 7/7\n",
      "        R-> Feature 37, Threshold 1.588\n",
      "            L-> 2 : 1/1\n",
      "            R-> Feature 34, Threshold 3.5\n",
      "                L-> Feature 39, Threshold 8.014\n",
      "                    L-> 1 : 15/15\n",
      "                    R-> Feature 36, Threshold 3.6145\n",
      "                        L-> 2 : 3/3\n",
      "                        R-> 1 : 4/4\n",
      "                R-> 1 : 45/45\n",
      "R-> Feature 12, Threshold -0.579\n",
      "    L-> Feature 39, Threshold 9.0245\n",
      "        L-> Feature 1, Threshold 5.1785\n",
      "            L-> Feature 31, Threshold 1.8865\n",
      "                L-> 2 : 10/10\n",
      "                R-> Feature 36, Threshold 3.8185000000000002\n",
      "                    L-> 2 : 2/2\n",
      "                    R-> Feature 34, Threshold 1.0\n",
      "                        L-> 1 : 4/4\n",
      "                        R-> Feature 1, Threshold 4.862\n",
      "                            L-> 2 : 2/2\n",
      "                            R-> 1 : 1/1\n",
      "            R-> 1 : 5/5\n",
      "        R-> 1 : 27/27\n",
      "    R-> Feature 11, Threshold 0.5\n",
      "        L-> Feature 30, Threshold 12.8505\n",
      "            L-> Feature 1, Threshold 5.102\n",
      "                L-> Feature 17, Threshold 0.9935\n",
      "                    L-> Feature 22, Threshold 1.2485\n",
      "                        L-> 2 : 3/3\n",
      "                        R-> Feature 17, Threshold 0.9924999999999999\n",
      "                            L-> Feature 36, Threshold 6.872999999999999\n",
      "                                L-> 1 : 19/19\n",
      "                                R-> Feature 17, Threshold 0.9735\n",
      "                                    L-> 1 : 1/1\n",
      "                                    R-> 2 : 2/2\n",
      "                            R-> 2 : 2/2\n",
      "                    R-> Feature 22, Threshold 1.3370000000000002\n",
      "                        L-> Feature 22, Threshold 1.3335\n",
      "                            L-> 1 : 26/26\n",
      "                            R-> 2 : 2/2\n",
      "                        R-> 1 : 35/35\n",
      "                R-> 1 : 78/78\n",
      "            R-> Feature 36, Threshold 4.6705000000000005\n",
      "                L-> Feature 14, Threshold 0.6435\n",
      "                    L-> 2 : 2/2\n",
      "                    R-> 1 : 12/12\n",
      "                R-> Feature 18, Threshold 1.1604999999999999\n",
      "                    L-> 2 : 6/6\n",
      "                    R-> 1 : 1/1\n",
      "        R-> Feature 36, Threshold 3.8215000000000003\n",
      "            L-> Feature 14, Threshold 1.2225000000000001\n",
      "                L-> 1 : 3/3\n",
      "                R-> 2 : 1/1\n",
      "            R-> 1 : 130/130\n"
     ]
    }
   ],
   "source": [
    "fitted_params(Tree) \n",
    "print_tree(Tree.fitresult[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(classes_seen = CategoricalValue{String,UInt32}[\"NRB\", \"RB\"],\n",
       " print_tree = TreePrinter object (call with display depth),)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report(Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Post-pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(\n",
       "    max_depth = -1,\n",
       "    min_samples_leaf = 1,\n",
       "    min_samples_split = 2,\n",
       "    min_purity_increase = 0.0,\n",
       "    n_subfeatures = 0,\n",
       "    post_prune = true,\n",
       "    merge_purity_threshold = 1.0,\n",
       "    pdf_smoothing = 0.0,\n",
       "    display_depth = 5)\u001b[34m @895\u001b[39m"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt2 = DecisionTreeClassifier(post_prune=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @250\u001b[39m trained 0 times.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @276\u001b[39m ⏎ `Table{Union{AbstractArray{Continuous,1}, AbstractArray{Count,1}}}`\n",
       "    2:\t\u001b[34mSource @976\u001b[39m ⏎ `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tree2 = machine(dt2, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 36, Threshold 3.8005\n",
      "L-> Feature 27, Threshold 2.2380000000000004\n",
      "    L-> Feature 34, Threshold 2.5\n",
      "        L-> Feature 9, Threshold 3.5\n",
      "            L-> Feature 10, Threshold 1.5\n",
      "                L-> \n",
      "                R-> \n",
      "            R-> Feature 14, Threshold 2.4295\n",
      "                L-> 1 : 13/13\n",
      "                R-> 2 : 2/2\n",
      "        R-> Feature 16, Threshold 1.5\n",
      "            L-> 1 : 27/27\n",
      "            R-> Feature 19, Threshold 0.5\n",
      "                L-> 2 : 5/5\n",
      "                R-> 1 : 2/2\n",
      "    R-> Feature 30, Threshold 5.1245\n",
      "        L-> Feature 8, Threshold 25.3\n",
      "            L-> 2 : 2/2\n",
      "            R-> Feature 28, Threshold -0.0015\n",
      "                L-> \n",
      "                R-> 1 : 50/50\n",
      "        R-> Feature 38, Threshold 0.5\n",
      "            L-> Feature 1, Threshold 5.097\n",
      "                L-> \n",
      "                R-> \n",
      "            R-> Feature 17, Threshold 1.0225\n",
      "                L-> 1 : 19/19\n",
      "                R-> \n",
      "R-> Feature 12, Threshold -0.5695\n",
      "    L-> Feature 22, Threshold 1.2275\n",
      "        L-> Feature 15, Threshold 10.858\n",
      "            L-> Feature 11, Threshold 2.5\n",
      "                L-> 2 : 8/8\n",
      "                R-> 1 : 1/1\n",
      "            R-> Feature 8, Threshold 27.15\n",
      "                L-> 2 : 1/1\n",
      "                R-> 1 : 6/6\n",
      "        R-> Feature 31, Threshold 1.0785\n",
      "            L-> 2 : 2/2\n",
      "            R-> 1 : 26/26\n",
      "    R-> Feature 27, Threshold 2.3585000000000003\n",
      "        L-> Feature 17, Threshold 0.9935\n",
      "            L-> Feature 17, Threshold 0.9915\n",
      "                L-> \n",
      "                R-> 2 : 3/3\n",
      "            R-> Feature 18, Threshold 1.1185\n",
      "                L-> \n",
      "                R-> 1 : 72/72\n",
      "        R-> 1 : 118/118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{DecisionTreeClassifier} @250\u001b[39m.\n",
      "└ @ MLJBase /home/andrew/.julia/packages/MLJBase/uKzAz/src/machines.jl:319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @250\u001b[39m trained 1 time.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @276\u001b[39m ⏎ `Table{Union{AbstractArray{Continuous,1}, AbstractArray{Count,1}}}`\n",
       "    2:\t\u001b[34mSource @976\u001b[39m ⏎ `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(Tree2, rows=train, verbosity=2, force=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 6 folds: 100%[=========================] Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "┌\u001b[0m───────────────\u001b[0m┬\u001b[0m───────────────\u001b[0m┬\u001b[0m───────────────────────────────────────────\u001b[0m┐\u001b[0m\n",
       "│\u001b[0m\u001b[22m _.measure     \u001b[0m│\u001b[0m\u001b[22m _.measurement \u001b[0m│\u001b[0m\u001b[22m _.per_fold                                \u001b[0m│\u001b[0m\n",
       "├\u001b[0m───────────────\u001b[0m┼\u001b[0m───────────────\u001b[0m┼\u001b[0m───────────────────────────────────────────\u001b[0m┤\u001b[0m\n",
       "│\u001b[0m cross_entropy \u001b[0m│\u001b[0m 6.53          \u001b[0m│\u001b[0m [6.55, 7.58, 5.94, 6.55, 6.35, 6.18]      \u001b[0m│\u001b[0m\n",
       "│\u001b[0m acc           \u001b[0m│\u001b[0m 0.819         \u001b[0m│\u001b[0m [0.818, 0.79, 0.835, 0.818, 0.824, 0.829] \u001b[0m│\u001b[0m\n",
       "└\u001b[0m───────────────\u001b[0m┴\u001b[0m───────────────\u001b[0m┴\u001b[0m───────────────────────────────────────────\u001b[0m┘\u001b[0m\n",
       "_.per_observation = [[[2.22e-16, 2.22e-16, ..., 36.0], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16], [36.0, 2.22e-16, ..., 2.22e-16]], missing]\n",
       "_.fitted_params_per_fold = [ … ]\n",
       "_.report_per_fold = [ … ]\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_acc = evaluate!(Tree2, resampling=CV(shuffle=true), measure=[cross_entropy, acc], verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate!(Tree2, resampling=CV(shuffle=true), measure=[tnr,tpr,fnr,fpr], verbosity=1, operation=predict_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tree = Decision Tree\n",
       "Leaves: 91\n",
       "Depth:  14,\n",
       " encoding = Dict{CategoricalValue{String,UInt32},UInt32}(\"RB\" => 0x00000002,\"NRB\" => 0x00000001),)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_params(Tree2) \n",
    "# print_tree(Tree.fitresult[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(classes_seen = CategoricalValue{String,UInt32}[\"NRB\", \"RB\"],\n",
       " print_tree = TreePrinter object (call with display depth),)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report(Tree2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @601\u001b[39m trained 0 times.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @207\u001b[39m ⏎ `Table{Union{AbstractArray{Continuous,1}, AbstractArray{Count,1}}}`\n",
       "    2:\t\u001b[34mSource @371\u001b[39m ⏎ `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tree2 = machine(dt2, X_stand, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 36, Threshold -0.12825137807558387\n",
      "L-> Feature 27, Threshold 0.07521584446798363\n",
      "    L-> Feature 34, Threshold 2.5\n",
      "        L-> Feature 9, Threshold 3.5\n",
      "            L-> Feature 10, Threshold 1.5\n",
      "                L-> \n",
      "                R-> \n",
      "            R-> Feature 14, Threshold 1.3906961718405968\n",
      "                L-> 1 : 13/13\n",
      "                R-> 2 : 2/2\n",
      "        R-> Feature 16, Threshold 1.5\n",
      "            L-> 1 : 27/27\n",
      "            R-> Feature 19, Threshold 0.5\n",
      "                L-> 2 : 5/5\n",
      "                R-> 1 : 2/2\n",
      "    R-> Feature 30, Threshold -0.3357589809933843\n",
      "        L-> Feature 18, Threshold 0.8458535790485455\n",
      "            L-> Feature 28, Threshold -0.0009349274458750583\n",
      "                L-> \n",
      "                R-> 1 : 50/50\n",
      "            R-> 2 : 2/2\n",
      "        R-> Feature 38, Threshold 0.5\n",
      "            L-> Feature 1, Threshold 0.5495250770015527\n",
      "                L-> \n",
      "                R-> \n",
      "            R-> Feature 17, Threshold 0.15868787400437176\n",
      "                L-> 1 : 19/19\n",
      "                R-> \n",
      "R-> Feature 12, Threshold -0.41462228207904994\n",
      "    L-> Feature 22, Threshold -0.11272486563975931\n",
      "        L-> Feature 15, Threshold 0.9581677637501542\n",
      "            L-> Feature 5, Threshold 1.5\n",
      "                L-> 2 : 8/8\n",
      "                R-> 1 : 1/1\n",
      "            R-> Feature 10, Threshold 9.0\n",
      "                L-> 1 : 6/6\n",
      "                R-> 2 : 1/1\n",
      "        R-> Feature 39, Threshold -0.04633476932379839\n",
      "            L-> 2 : 2/2\n",
      "            R-> 1 : 26/26\n",
      "    R-> Feature 27, Threshold 0.6120432788735517\n",
      "        L-> Feature 17, Threshold -0.4586976703405704\n",
      "            L-> Feature 17, Threshold -0.50127598374367\n",
      "                L-> \n",
      "                R-> 2 : 3/3\n",
      "            R-> Feature 18, Threshold -0.4212758495766108\n",
      "                L-> \n",
      "                R-> 1 : 72/72\n",
      "        R-> 1 : 118/118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{DecisionTreeClassifier} @601\u001b[39m.\n",
      "└ @ MLJBase /home/andrew/.julia/packages/MLJBase/uKzAz/src/machines.jl:319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @601\u001b[39m trained 1 time.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @207\u001b[39m ⏎ `Table{Union{AbstractArray{Continuous,1}, AbstractArray{Count,1}}}`\n",
       "    2:\t\u001b[34mSource @371\u001b[39m ⏎ `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(Tree2, rows=train, verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 6 folds: 100%[=========================] Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "┌\u001b[0m───────────────\u001b[0m┬\u001b[0m───────────────\u001b[0m┬\u001b[0m──────────────────────────────────────────\u001b[0m┐\u001b[0m\n",
       "│\u001b[0m\u001b[22m _.measure     \u001b[0m│\u001b[0m\u001b[22m _.measurement \u001b[0m│\u001b[0m\u001b[22m _.per_fold                               \u001b[0m│\u001b[0m\n",
       "├\u001b[0m───────────────\u001b[0m┼\u001b[0m───────────────\u001b[0m┼\u001b[0m──────────────────────────────────────────\u001b[0m┤\u001b[0m\n",
       "│\u001b[0m cross_entropy \u001b[0m│\u001b[0m 6.83          \u001b[0m│\u001b[0m [7.78, 6.14, 7.99, 6.35, 6.96, 5.77]     \u001b[0m│\u001b[0m\n",
       "│\u001b[0m acc           \u001b[0m│\u001b[0m 0.81          \u001b[0m│\u001b[0m [0.784, 0.83, 0.778, 0.824, 0.807, 0.84] \u001b[0m│\u001b[0m\n",
       "└\u001b[0m───────────────\u001b[0m┴\u001b[0m───────────────\u001b[0m┴\u001b[0m──────────────────────────────────────────\u001b[0m┘\u001b[0m\n",
       "_.per_observation = [[[2.22e-16, 2.22e-16, ..., 2.22e-16], [2.22e-16, 36.0, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 36.0], [36.0, 2.22e-16, ..., 2.22e-16], [36.0, 2.22e-16, ..., 2.22e-16], [2.22e-16, 2.22e-16, ..., 2.22e-16]], missing]\n",
       "_.fitted_params_per_fold = [ … ]\n",
       "_.report_per_fold = [ … ]\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_acc = evaluate!(Tree2, resampling=CV(shuffle=true), measure=[cross_entropy, acc], verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tree = Decision Tree\n",
       "Leaves: 85\n",
       "Depth:  12,\n",
       " encoding = Dict{CategoricalValue{String,UInt32},UInt32}(\"RB\" => 0x00000002,\"NRB\" => 0x00000001),)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_params(Tree2) \n",
    "# print_tree(Tree.fitresult[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(classes_seen = CategoricalValue{String,UInt32}[\"NRB\", \"RB\"],\n",
       " print_tree = TreePrinter object (call with display depth),)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report(Tree2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch / RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @101\u001b[39m trained 0 times.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @514\u001b[39m ⏎ `Table{Union{AbstractArray{Continuous,1}, AbstractArray{Count,1}}}`\n",
       "    2:\t\u001b[34mSource @477\u001b[39m ⏎ `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(post_prune=true, merge_purity_threshold=0.8)\n",
    "Tree = machine(dt, X_stand, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{ProbabilisticTunedModel{Grid,…}} @958\u001b[39m.\n",
      "└ @ MLJBase /home/andrew/.julia/packages/MLJBase/uKzAz/src/machines.jl:319\n",
      "┌ Info: Attempting to evaluate 30 models.\n",
      "└ @ MLJTuning /home/andrew/.julia/packages/MLJTuning/Bbgvk/src/tuned_models.jl:494\n",
      "\u001b[33mEvaluating over 30 metamodels: 100%[=========================] Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(parameter_name = \"merge_purity_threshold\",\n",
       " parameter_scale = :linear,\n",
       " parameter_values = [0.0, 0.034482758620689655, 0.06896551724137931, 0.10344827586206896, 0.13793103448275862, 0.1724137931034483, 0.20689655172413793, 0.2413793103448276, 0.27586206896551724, 0.3103448275862069  …  0.6896551724137931, 0.7241379310344828, 0.7586206896551724, 0.7931034482758621, 0.8275862068965517, 0.8620689655172413, 0.896551724137931, 0.9310344827586207, 0.9655172413793104, 1.0],\n",
       " measurements = [0.7775545705341723, 0.7775545705341723, 0.7775545705341723, 0.7775545705341723, 0.7775545705341723, 0.7775545705341723, 0.7775545705341723, 0.7775545705341723, 0.7775545705341723, 0.7775545705341723  …  5.856657348170542, 5.939243780271187, 7.088033134519147, 6.853655645691759, 6.869770156646301, 7.811963242383548, 7.986535513892967, 8.120470230207578, 8.714594555946572, 8.74351156807756],)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = range(dt, :merge_purity_threshold, lower=0, upper=1)\n",
    "curve = learning_curve(Tree, \n",
    "                        range=r, \n",
    "#                         resampling=Holdout(fraction_train=0.7), \n",
    "                        resampling=CV(), \n",
    "                        measure=cross_entropy, \n",
    "                        acceleration=CPUThreads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip080\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip080)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip081\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip080)\" d=\"\n",
       "M175.445 1423.18 L2352.76 1423.18 L2352.76 47.2441 L175.445 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip082\">\n",
       "    <rect x=\"175\" y=\"47\" width=\"2178\" height=\"1377\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  237.067,1423.18 237.067,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  750.584,1423.18 750.584,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1264.1,1423.18 1264.1,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1777.62,1423.18 1777.62,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2291.13,1423.18 2291.13,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  175.445,1185.04 2352.76,1185.04 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  175.445,859.141 2352.76,859.141 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  175.445,533.241 2352.76,533.241 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip082)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  175.445,207.341 2352.76,207.341 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  175.445,1423.18 2352.76,1423.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  175.445,1423.18 175.445,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  237.067,1423.18 237.067,1406.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  750.584,1423.18 750.584,1406.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1264.1,1423.18 1264.1,1406.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1777.62,1423.18 1777.62,1406.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2291.13,1423.18 2291.13,1406.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  175.445,1185.04 201.573,1185.04 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  175.445,859.141 201.573,859.141 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  175.445,533.241 201.573,533.241 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  175.445,207.341 201.573,207.341 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip080)\" d=\"M 0 0 M205.077 1445.17 Q201.466 1445.17 199.637 1448.74 Q197.831 1452.28 197.831 1459.41 Q197.831 1466.51 199.637 1470.08 Q201.466 1473.62 205.077 1473.62 Q208.711 1473.62 210.516 1470.08 Q212.345 1466.51 212.345 1459.41 Q212.345 1452.28 210.516 1448.74 Q208.711 1445.17 205.077 1445.17 M205.077 1441.47 Q210.887 1441.47 213.942 1446.07 Q217.021 1450.66 217.021 1459.41 Q217.021 1468.13 213.942 1472.74 Q210.887 1477.32 205.077 1477.32 Q199.266 1477.32 196.188 1472.74 Q193.132 1468.13 193.132 1459.41 Q193.132 1450.66 196.188 1446.07 Q199.266 1441.47 205.077 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M222.09 1470.77 L226.975 1470.77 L226.975 1476.65 L222.09 1476.65 L222.09 1470.77 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M242.044 1445.17 Q238.433 1445.17 236.604 1448.74 Q234.799 1452.28 234.799 1459.41 Q234.799 1466.51 236.604 1470.08 Q238.433 1473.62 242.044 1473.62 Q245.678 1473.62 247.484 1470.08 Q249.313 1466.51 249.313 1459.41 Q249.313 1452.28 247.484 1448.74 Q245.678 1445.17 242.044 1445.17 M242.044 1441.47 Q247.854 1441.47 250.91 1446.07 Q253.988 1450.66 253.988 1459.41 Q253.988 1468.13 250.91 1472.74 Q247.854 1477.32 242.044 1477.32 Q236.234 1477.32 233.155 1472.74 Q230.1 1468.13 230.1 1459.41 Q230.1 1450.66 233.155 1446.07 Q236.234 1441.47 242.044 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M269.058 1445.17 Q265.447 1445.17 263.618 1448.74 Q261.812 1452.28 261.812 1459.41 Q261.812 1466.51 263.618 1470.08 Q265.447 1473.62 269.058 1473.62 Q272.692 1473.62 274.498 1470.08 Q276.326 1466.51 276.326 1459.41 Q276.326 1452.28 274.498 1448.74 Q272.692 1445.17 269.058 1445.17 M269.058 1441.47 Q274.868 1441.47 277.923 1446.07 Q281.002 1450.66 281.002 1459.41 Q281.002 1468.13 277.923 1472.74 Q274.868 1477.32 269.058 1477.32 Q263.248 1477.32 260.169 1472.74 Q257.113 1468.13 257.113 1459.41 Q257.113 1450.66 260.169 1446.07 Q263.248 1441.47 269.058 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M719.89 1445.17 Q716.279 1445.17 714.45 1448.74 Q712.644 1452.28 712.644 1459.41 Q712.644 1466.51 714.45 1470.08 Q716.279 1473.62 719.89 1473.62 Q723.524 1473.62 725.329 1470.08 Q727.158 1466.51 727.158 1459.41 Q727.158 1452.28 725.329 1448.74 Q723.524 1445.17 719.89 1445.17 M719.89 1441.47 Q725.7 1441.47 728.755 1446.07 Q731.834 1450.66 731.834 1459.41 Q731.834 1468.13 728.755 1472.74 Q725.7 1477.32 719.89 1477.32 Q714.079 1477.32 711.001 1472.74 Q707.945 1468.13 707.945 1459.41 Q707.945 1450.66 711.001 1446.07 Q714.079 1441.47 719.89 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M736.903 1470.77 L741.788 1470.77 L741.788 1476.65 L736.903 1476.65 L736.903 1470.77 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M750.885 1472.72 L767.204 1472.72 L767.204 1476.65 L745.26 1476.65 L745.26 1472.72 Q747.922 1469.96 752.505 1465.33 Q757.112 1460.68 758.292 1459.34 Q760.538 1456.81 761.417 1455.08 Q762.32 1453.32 762.32 1451.63 Q762.32 1448.87 760.375 1447.14 Q758.454 1445.4 755.352 1445.4 Q753.153 1445.4 750.7 1446.17 Q748.269 1446.93 745.491 1448.48 L745.491 1443.76 Q748.315 1442.62 750.769 1442.05 Q753.223 1441.47 755.26 1441.47 Q760.63 1441.47 763.825 1444.15 Q767.019 1446.84 767.019 1451.33 Q767.019 1453.46 766.209 1455.38 Q765.422 1457.28 763.315 1459.87 Q762.737 1460.54 759.635 1463.76 Q756.533 1466.95 750.885 1472.72 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M772.32 1442.09 L790.676 1442.09 L790.676 1446.03 L776.602 1446.03 L776.602 1454.5 Q777.621 1454.15 778.639 1453.99 Q779.658 1453.8 780.676 1453.8 Q786.463 1453.8 789.843 1456.98 Q793.223 1460.15 793.223 1465.56 Q793.223 1471.14 789.75 1474.24 Q786.278 1477.32 779.959 1477.32 Q777.783 1477.32 775.514 1476.95 Q773.269 1476.58 770.862 1475.84 L770.862 1471.14 Q772.945 1472.28 775.167 1472.83 Q777.389 1473.39 779.866 1473.39 Q783.871 1473.39 786.209 1471.28 Q788.547 1469.18 788.547 1465.56 Q788.547 1461.95 786.209 1459.85 Q783.871 1457.74 779.866 1457.74 Q777.991 1457.74 776.116 1458.16 Q774.264 1458.57 772.32 1459.45 L772.32 1442.09 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1232.61 1445.17 Q1229 1445.17 1227.17 1448.74 Q1225.36 1452.28 1225.36 1459.41 Q1225.36 1466.51 1227.17 1470.08 Q1229 1473.62 1232.61 1473.62 Q1236.24 1473.62 1238.05 1470.08 Q1239.88 1466.51 1239.88 1459.41 Q1239.88 1452.28 1238.05 1448.74 Q1236.24 1445.17 1232.61 1445.17 M1232.61 1441.47 Q1238.42 1441.47 1241.47 1446.07 Q1244.55 1450.66 1244.55 1459.41 Q1244.55 1468.13 1241.47 1472.74 Q1238.42 1477.32 1232.61 1477.32 Q1226.8 1477.32 1223.72 1472.74 Q1220.66 1468.13 1220.66 1459.41 Q1220.66 1450.66 1223.72 1446.07 Q1226.8 1441.47 1232.61 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1249.62 1470.77 L1254.51 1470.77 L1254.51 1476.65 L1249.62 1476.65 L1249.62 1470.77 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1259.62 1442.09 L1277.98 1442.09 L1277.98 1446.03 L1263.9 1446.03 L1263.9 1454.5 Q1264.92 1454.15 1265.94 1453.99 Q1266.96 1453.8 1267.98 1453.8 Q1273.76 1453.8 1277.14 1456.98 Q1280.52 1460.15 1280.52 1465.56 Q1280.52 1471.14 1277.05 1474.24 Q1273.58 1477.32 1267.26 1477.32 Q1265.08 1477.32 1262.82 1476.95 Q1260.57 1476.58 1258.16 1475.84 L1258.16 1471.14 Q1260.25 1472.28 1262.47 1472.83 Q1264.69 1473.39 1267.17 1473.39 Q1271.17 1473.39 1273.51 1471.28 Q1275.85 1469.18 1275.85 1465.56 Q1275.85 1461.95 1273.51 1459.85 Q1271.17 1457.74 1267.17 1457.74 Q1265.29 1457.74 1263.42 1458.16 Q1261.57 1458.57 1259.62 1459.45 L1259.62 1442.09 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1295.59 1445.17 Q1291.98 1445.17 1290.15 1448.74 Q1288.35 1452.28 1288.35 1459.41 Q1288.35 1466.51 1290.15 1470.08 Q1291.98 1473.62 1295.59 1473.62 Q1299.23 1473.62 1301.03 1470.08 Q1302.86 1466.51 1302.86 1459.41 Q1302.86 1452.28 1301.03 1448.74 Q1299.23 1445.17 1295.59 1445.17 M1295.59 1441.47 Q1301.4 1441.47 1304.46 1446.07 Q1307.54 1450.66 1307.54 1459.41 Q1307.54 1468.13 1304.46 1472.74 Q1301.4 1477.32 1295.59 1477.32 Q1289.78 1477.32 1286.7 1472.74 Q1283.65 1468.13 1283.65 1459.41 Q1283.65 1450.66 1286.7 1446.07 Q1289.78 1441.47 1295.59 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1746.58 1445.17 Q1742.96 1445.17 1741.14 1448.74 Q1739.33 1452.28 1739.33 1459.41 Q1739.33 1466.51 1741.14 1470.08 Q1742.96 1473.62 1746.58 1473.62 Q1750.21 1473.62 1752.02 1470.08 Q1753.84 1466.51 1753.84 1459.41 Q1753.84 1452.28 1752.02 1448.74 Q1750.21 1445.17 1746.58 1445.17 M1746.58 1441.47 Q1752.39 1441.47 1755.44 1446.07 Q1758.52 1450.66 1758.52 1459.41 Q1758.52 1468.13 1755.44 1472.74 Q1752.39 1477.32 1746.58 1477.32 Q1740.77 1477.32 1737.69 1472.74 Q1734.63 1468.13 1734.63 1459.41 Q1734.63 1450.66 1737.69 1446.07 Q1740.77 1441.47 1746.58 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1763.59 1470.77 L1768.47 1470.77 L1768.47 1476.65 L1763.59 1476.65 L1763.59 1470.77 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1772.36 1442.09 L1794.58 1442.09 L1794.58 1444.08 L1782.04 1476.65 L1777.15 1476.65 L1788.96 1446.03 L1772.36 1446.03 L1772.36 1442.09 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1799.7 1442.09 L1818.06 1442.09 L1818.06 1446.03 L1803.98 1446.03 L1803.98 1454.5 Q1805 1454.15 1806.02 1453.99 Q1807.04 1453.8 1808.06 1453.8 Q1813.84 1453.8 1817.22 1456.98 Q1820.6 1460.15 1820.6 1465.56 Q1820.6 1471.14 1817.13 1474.24 Q1813.66 1477.32 1807.34 1477.32 Q1805.16 1477.32 1802.89 1476.95 Q1800.65 1476.58 1798.24 1475.84 L1798.24 1471.14 Q1800.33 1472.28 1802.55 1472.83 Q1804.77 1473.39 1807.25 1473.39 Q1811.25 1473.39 1813.59 1471.28 Q1815.93 1469.18 1815.93 1465.56 Q1815.93 1461.95 1813.59 1459.85 Q1811.25 1457.74 1807.25 1457.74 Q1805.37 1457.74 1803.5 1458.16 Q1801.64 1458.57 1799.7 1459.45 L1799.7 1442.09 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M2249.53 1472.72 L2257.16 1472.72 L2257.16 1446.35 L2248.85 1448.02 L2248.85 1443.76 L2257.12 1442.09 L2261.79 1442.09 L2261.79 1472.72 L2269.43 1472.72 L2269.43 1476.65 L2249.53 1476.65 L2249.53 1472.72 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M2274.5 1470.77 L2279.39 1470.77 L2279.39 1476.65 L2274.5 1476.65 L2274.5 1470.77 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M2294.46 1445.17 Q2290.84 1445.17 2289.02 1448.74 Q2287.21 1452.28 2287.21 1459.41 Q2287.21 1466.51 2289.02 1470.08 Q2290.84 1473.62 2294.46 1473.62 Q2298.09 1473.62 2299.9 1470.08 Q2301.72 1466.51 2301.72 1459.41 Q2301.72 1452.28 2299.9 1448.74 Q2298.09 1445.17 2294.46 1445.17 M2294.46 1441.47 Q2300.27 1441.47 2303.32 1446.07 Q2306.4 1450.66 2306.4 1459.41 Q2306.4 1468.13 2303.32 1472.74 Q2300.27 1477.32 2294.46 1477.32 Q2288.65 1477.32 2285.57 1472.74 Q2282.51 1468.13 2282.51 1459.41 Q2282.51 1450.66 2285.57 1446.07 Q2288.65 1441.47 2294.46 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M2321.47 1445.17 Q2317.86 1445.17 2316.03 1448.74 Q2314.22 1452.28 2314.22 1459.41 Q2314.22 1466.51 2316.03 1470.08 Q2317.86 1473.62 2321.47 1473.62 Q2325.1 1473.62 2326.91 1470.08 Q2328.74 1466.51 2328.74 1459.41 Q2328.74 1452.28 2326.91 1448.74 Q2325.1 1445.17 2321.47 1445.17 M2321.47 1441.47 Q2327.28 1441.47 2330.34 1446.07 Q2333.41 1450.66 2333.41 1459.41 Q2333.41 1468.13 2330.34 1472.74 Q2327.28 1477.32 2321.47 1477.32 Q2315.66 1477.32 2312.58 1472.74 Q2309.53 1468.13 2309.53 1459.41 Q2309.53 1450.66 2312.58 1446.07 Q2315.66 1441.47 2321.47 1441.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M135.126 1198.39 L151.445 1198.39 L151.445 1202.32 L129.501 1202.32 L129.501 1198.39 Q132.163 1195.63 136.746 1191 Q141.353 1186.35 142.533 1185.01 Q144.779 1182.48 145.658 1180.75 Q146.561 1178.99 146.561 1177.3 Q146.561 1174.54 144.617 1172.81 Q142.695 1171.07 139.593 1171.07 Q137.394 1171.07 134.941 1171.83 Q132.51 1172.6 129.732 1174.15 L129.732 1169.43 Q132.556 1168.29 135.01 1167.71 Q137.464 1167.14 139.501 1167.14 Q144.871 1167.14 148.066 1169.82 Q151.26 1172.51 151.26 1177 Q151.26 1179.13 150.45 1181.05 Q149.663 1182.95 147.556 1185.54 Q146.978 1186.21 143.876 1189.43 Q140.774 1192.62 135.126 1198.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M141.862 845.935 L130.056 864.384 L141.862 864.384 L141.862 845.935 M140.635 841.861 L146.515 841.861 L146.515 864.384 L151.445 864.384 L151.445 868.273 L146.515 868.273 L146.515 876.421 L141.862 876.421 L141.862 868.273 L126.26 868.273 L126.26 863.759 L140.635 841.861 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M139.917 531.377 Q136.769 531.377 134.918 533.53 Q133.089 535.683 133.089 539.433 Q133.089 543.16 134.918 545.336 Q136.769 547.488 139.917 547.488 Q143.066 547.488 144.894 545.336 Q146.746 543.16 146.746 539.433 Q146.746 535.683 144.894 533.53 Q143.066 531.377 139.917 531.377 M149.2 516.725 L149.2 520.984 Q147.441 520.151 145.635 519.711 Q143.853 519.271 142.093 519.271 Q137.464 519.271 135.01 522.396 Q132.58 525.521 132.232 531.84 Q133.598 529.827 135.658 528.762 Q137.718 527.674 140.195 527.674 Q145.404 527.674 148.413 530.845 Q151.445 533.993 151.445 539.433 Q151.445 544.757 148.297 547.975 Q145.149 551.192 139.917 551.192 Q133.922 551.192 130.751 546.609 Q127.58 542.002 127.58 533.276 Q127.58 525.081 131.468 520.22 Q135.357 515.336 141.908 515.336 Q143.667 515.336 145.45 515.683 Q147.255 516.03 149.2 516.725 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M139.593 208.209 Q136.26 208.209 134.339 209.991 Q132.441 211.774 132.441 214.899 Q132.441 218.024 134.339 219.806 Q136.26 221.588 139.593 221.588 Q142.927 221.588 144.848 219.806 Q146.769 218.001 146.769 214.899 Q146.769 211.774 144.848 209.991 Q142.95 208.209 139.593 208.209 M134.918 206.218 Q131.908 205.477 130.218 203.417 Q128.552 201.357 128.552 198.394 Q128.552 194.251 131.492 191.843 Q134.455 189.436 139.593 189.436 Q144.755 189.436 147.695 191.843 Q150.635 194.251 150.635 198.394 Q150.635 201.357 148.945 203.417 Q147.279 205.477 144.292 206.218 Q147.672 207.005 149.547 209.297 Q151.445 211.589 151.445 214.899 Q151.445 219.922 148.367 222.607 Q145.311 225.292 139.593 225.292 Q133.876 225.292 130.797 222.607 Q127.742 219.922 127.742 214.899 Q127.742 211.589 129.64 209.297 Q131.538 207.005 134.918 206.218 M133.205 198.834 Q133.205 201.519 134.871 203.024 Q136.561 204.528 139.593 204.528 Q142.603 204.528 144.292 203.024 Q146.005 201.519 146.005 198.834 Q146.005 196.149 144.292 194.644 Q142.603 193.14 139.593 193.14 Q136.561 193.14 134.871 194.644 Q133.205 196.149 133.205 198.834 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M943.269 1527.24 Q945.465 1523.29 948.521 1521.41 Q951.576 1519.54 955.714 1519.54 Q961.284 1519.54 964.308 1523.45 Q967.331 1527.33 967.331 1534.53 L967.331 1556.04 L961.443 1556.04 L961.443 1534.72 Q961.443 1529.59 959.629 1527.11 Q957.815 1524.63 954.091 1524.63 Q949.539 1524.63 946.897 1527.65 Q944.256 1530.68 944.256 1535.9 L944.256 1556.04 L938.367 1556.04 L938.367 1534.72 Q938.367 1529.56 936.553 1527.11 Q934.739 1524.63 930.951 1524.63 Q926.463 1524.63 923.822 1527.68 Q921.18 1530.71 921.18 1535.9 L921.18 1556.04 L915.292 1556.04 L915.292 1520.4 L921.18 1520.4 L921.18 1525.93 Q923.185 1522.66 925.986 1521.1 Q928.787 1519.54 932.638 1519.54 Q936.521 1519.54 939.227 1521.51 Q941.964 1523.48 943.269 1527.24 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1003.97 1536.76 L1003.97 1539.62 L977.039 1539.62 Q977.421 1545.67 980.667 1548.85 Q983.946 1552 989.77 1552 Q993.144 1552 996.295 1551.17 Q999.478 1550.35 1002.6 1548.69 L1002.6 1554.23 Q999.446 1555.57 996.136 1556.27 Q992.826 1556.97 989.42 1556.97 Q980.89 1556.97 975.893 1552 Q970.928 1547.04 970.928 1538.57 Q970.928 1529.82 975.639 1524.69 Q980.381 1519.54 988.402 1519.54 Q995.595 1519.54 999.765 1524.18 Q1003.97 1528.8 1003.97 1536.76 M998.11 1535.04 Q998.046 1530.23 995.404 1527.37 Q992.794 1524.5 988.465 1524.5 Q983.564 1524.5 980.604 1527.27 Q977.676 1530.04 977.23 1535.07 L998.11 1535.04 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1030.77 1525.87 Q1029.78 1525.3 1028.6 1525.04 Q1027.46 1524.76 1026.05 1524.76 Q1021.09 1524.76 1018.42 1528 Q1015.77 1531.22 1015.77 1537.27 L1015.77 1556.04 L1009.89 1556.04 L1009.89 1520.4 L1015.77 1520.4 L1015.77 1525.93 Q1017.62 1522.69 1020.58 1521.13 Q1023.54 1519.54 1027.77 1519.54 Q1028.38 1519.54 1029.11 1519.63 Q1029.84 1519.7 1030.73 1519.85 L1030.77 1525.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1059.22 1537.81 Q1059.22 1531.44 1056.58 1527.94 Q1053.97 1524.44 1049.23 1524.44 Q1044.52 1524.44 1041.87 1527.94 Q1039.26 1531.44 1039.26 1537.81 Q1039.26 1544.14 1041.87 1547.64 Q1044.52 1551.14 1049.23 1551.14 Q1053.97 1551.14 1056.58 1547.64 Q1059.22 1544.14 1059.22 1537.81 M1065.08 1551.62 Q1065.08 1560.72 1061.03 1565.15 Q1056.99 1569.6 1048.65 1569.6 Q1045.57 1569.6 1042.83 1569.13 Q1040.09 1568.68 1037.51 1567.72 L1037.51 1562.03 Q1040.09 1563.43 1042.61 1564.1 Q1045.12 1564.76 1047.73 1564.76 Q1053.49 1564.76 1056.36 1561.74 Q1059.22 1558.75 1059.22 1552.67 L1059.22 1549.77 Q1057.41 1552.92 1054.57 1554.48 Q1051.74 1556.04 1047.79 1556.04 Q1041.24 1556.04 1037.23 1551.05 Q1033.22 1546.05 1033.22 1537.81 Q1033.22 1529.53 1037.23 1524.53 Q1041.24 1519.54 1047.79 1519.54 Q1051.74 1519.54 1054.57 1521.1 Q1057.41 1522.66 1059.22 1525.81 L1059.22 1520.4 L1065.08 1520.4 L1065.08 1551.62 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1101.71 1536.76 L1101.71 1539.62 L1074.78 1539.62 Q1075.17 1545.67 1078.41 1548.85 Q1081.69 1552 1087.52 1552 Q1090.89 1552 1094.04 1551.17 Q1097.22 1550.35 1100.34 1548.69 L1100.34 1554.23 Q1097.19 1555.57 1093.88 1556.27 Q1090.57 1556.97 1087.17 1556.97 Q1078.64 1556.97 1073.64 1552 Q1068.67 1547.04 1068.67 1538.57 Q1068.67 1529.82 1073.38 1524.69 Q1078.13 1519.54 1086.15 1519.54 Q1093.34 1519.54 1097.51 1524.18 Q1101.71 1528.8 1101.71 1536.76 M1095.85 1535.04 Q1095.79 1530.23 1093.15 1527.37 Q1090.54 1524.5 1086.21 1524.5 Q1081.31 1524.5 1078.35 1527.27 Q1075.42 1530.04 1074.98 1535.07 L1095.85 1535.04 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1134.94 1566.87 L1134.94 1571.42 L1101.07 1571.42 L1101.07 1566.87 L1134.94 1566.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1146.75 1550.7 L1146.75 1569.6 L1140.86 1569.6 L1140.86 1520.4 L1146.75 1520.4 L1146.75 1525.81 Q1148.59 1522.62 1151.4 1521.1 Q1154.23 1519.54 1158.14 1519.54 Q1164.64 1519.54 1168.68 1524.69 Q1172.75 1529.85 1172.75 1538.25 Q1172.75 1546.65 1168.68 1551.81 Q1164.64 1556.97 1158.14 1556.97 Q1154.23 1556.97 1151.4 1555.44 Q1148.59 1553.88 1146.75 1550.7 M1166.67 1538.25 Q1166.67 1531.79 1164 1528.13 Q1161.36 1524.44 1156.71 1524.44 Q1152.06 1524.44 1149.39 1528.13 Q1146.75 1531.79 1146.75 1538.25 Q1146.75 1544.71 1149.39 1548.4 Q1152.06 1552.07 1156.71 1552.07 Q1161.36 1552.07 1164 1548.4 Q1166.67 1544.71 1166.67 1538.25 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1178.29 1541.98 L1178.29 1520.4 L1184.15 1520.4 L1184.15 1541.75 Q1184.15 1546.81 1186.12 1549.36 Q1188.09 1551.87 1192.04 1551.87 Q1196.78 1551.87 1199.52 1548.85 Q1202.29 1545.83 1202.29 1540.61 L1202.29 1520.4 L1208.15 1520.4 L1208.15 1556.04 L1202.29 1556.04 L1202.29 1550.57 Q1200.16 1553.82 1197.32 1555.41 Q1194.52 1556.97 1190.8 1556.97 Q1184.66 1556.97 1181.47 1553.15 Q1178.29 1549.33 1178.29 1541.98 M1193.03 1519.54 L1193.03 1519.54 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1234.95 1525.87 Q1233.96 1525.3 1232.78 1525.04 Q1231.64 1524.76 1230.23 1524.76 Q1225.27 1524.76 1222.6 1528 Q1219.95 1531.22 1219.95 1537.27 L1219.95 1556.04 L1214.07 1556.04 L1214.07 1520.4 L1219.95 1520.4 L1219.95 1525.93 Q1221.8 1522.69 1224.76 1521.13 Q1227.72 1519.54 1231.95 1519.54 Q1232.56 1519.54 1233.29 1519.63 Q1234.02 1519.7 1234.91 1519.85 L1234.95 1525.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1241.09 1520.4 L1246.94 1520.4 L1246.94 1556.04 L1241.09 1556.04 L1241.09 1520.4 M1241.09 1506.52 L1246.94 1506.52 L1246.94 1513.93 L1241.09 1513.93 L1241.09 1506.52 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1258.88 1510.27 L1258.88 1520.4 L1270.94 1520.4 L1270.94 1524.95 L1258.88 1524.95 L1258.88 1544.3 Q1258.88 1548.66 1260.06 1549.9 Q1261.27 1551.14 1264.93 1551.14 L1270.94 1551.14 L1270.94 1556.04 L1264.93 1556.04 Q1258.15 1556.04 1255.57 1553.53 Q1252.99 1550.98 1252.99 1544.3 L1252.99 1524.95 L1248.7 1524.95 L1248.7 1520.4 L1252.99 1520.4 L1252.99 1510.27 L1258.88 1510.27 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1291.92 1559.35 Q1289.44 1565.72 1287.08 1567.66 Q1284.73 1569.6 1280.78 1569.6 L1276.1 1569.6 L1276.1 1564.7 L1279.54 1564.7 Q1281.96 1564.7 1283.29 1563.56 Q1284.63 1562.41 1286.25 1558.14 L1287.3 1555.47 L1272.89 1520.4 L1279.09 1520.4 L1290.23 1548.28 L1301.37 1520.4 L1307.58 1520.4 L1291.92 1559.35 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1340.81 1566.87 L1340.81 1571.42 L1306.94 1571.42 L1306.94 1566.87 L1340.81 1566.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1352.74 1510.27 L1352.74 1520.4 L1364.81 1520.4 L1364.81 1524.95 L1352.74 1524.95 L1352.74 1544.3 Q1352.74 1548.66 1353.92 1549.9 Q1355.13 1551.14 1358.79 1551.14 L1364.81 1551.14 L1364.81 1556.04 L1358.79 1556.04 Q1352.01 1556.04 1349.43 1553.53 Q1346.85 1550.98 1346.85 1544.3 L1346.85 1524.95 L1342.56 1524.95 L1342.56 1520.4 L1346.85 1520.4 L1346.85 1510.27 L1352.74 1510.27 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1400.58 1534.53 L1400.58 1556.04 L1394.72 1556.04 L1394.72 1534.72 Q1394.72 1529.66 1392.75 1527.14 Q1390.78 1524.63 1386.83 1524.63 Q1382.09 1524.63 1379.35 1527.65 Q1376.61 1530.68 1376.61 1535.9 L1376.61 1556.04 L1370.73 1556.04 L1370.73 1506.52 L1376.61 1506.52 L1376.61 1525.93 Q1378.72 1522.72 1381.55 1521.13 Q1384.41 1519.54 1388.14 1519.54 Q1394.28 1519.54 1397.43 1523.36 Q1400.58 1527.14 1400.58 1534.53 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1427.38 1525.87 Q1426.39 1525.3 1425.22 1525.04 Q1424.07 1524.76 1422.67 1524.76 Q1417.71 1524.76 1415.03 1528 Q1412.39 1531.22 1412.39 1537.27 L1412.39 1556.04 L1406.5 1556.04 L1406.5 1520.4 L1412.39 1520.4 L1412.39 1525.93 Q1414.24 1522.69 1417.2 1521.13 Q1420.16 1519.54 1424.39 1519.54 Q1424.99 1519.54 1425.73 1519.63 Q1426.46 1519.7 1427.35 1519.85 L1427.38 1525.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1462.58 1536.76 L1462.58 1539.62 L1435.66 1539.62 Q1436.04 1545.67 1439.28 1548.85 Q1442.56 1552 1448.39 1552 Q1451.76 1552 1454.91 1551.17 Q1458.1 1550.35 1461.21 1548.69 L1461.21 1554.23 Q1458.06 1555.57 1454.75 1556.27 Q1451.44 1556.97 1448.04 1556.97 Q1439.51 1556.97 1434.51 1552 Q1429.55 1547.04 1429.55 1538.57 Q1429.55 1529.82 1434.26 1524.69 Q1439 1519.54 1447.02 1519.54 Q1454.21 1519.54 1458.38 1524.18 Q1462.58 1528.8 1462.58 1536.76 M1456.73 1535.04 Q1456.66 1530.23 1454.02 1527.37 Q1451.41 1524.5 1447.08 1524.5 Q1442.18 1524.5 1439.22 1527.27 Q1436.29 1530.04 1435.85 1535.07 L1456.73 1535.04 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1491.45 1521.45 L1491.45 1526.98 Q1488.97 1525.71 1486.3 1525.07 Q1483.62 1524.44 1480.76 1524.44 Q1476.4 1524.44 1474.2 1525.77 Q1472.04 1527.11 1472.04 1529.79 Q1472.04 1531.82 1473.6 1533 Q1475.16 1534.15 1479.87 1535.2 L1481.87 1535.64 Q1488.11 1536.98 1490.72 1539.43 Q1493.36 1541.85 1493.36 1546.21 Q1493.36 1551.17 1489.41 1554.07 Q1485.5 1556.97 1478.62 1556.97 Q1475.76 1556.97 1472.64 1556.39 Q1469.55 1555.85 1466.12 1554.74 L1466.12 1548.69 Q1469.36 1550.38 1472.51 1551.24 Q1475.66 1552.07 1478.75 1552.07 Q1482.89 1552.07 1485.12 1550.66 Q1487.35 1549.23 1487.35 1546.65 Q1487.35 1544.27 1485.72 1542.99 Q1484.13 1541.72 1478.69 1540.54 L1476.65 1540.07 Q1471.21 1538.92 1468.79 1536.56 Q1466.37 1534.18 1466.37 1530.04 Q1466.37 1525.01 1469.94 1522.27 Q1473.5 1519.54 1480.06 1519.54 Q1483.3 1519.54 1486.17 1520.01 Q1489.03 1520.49 1491.45 1521.45 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1529.14 1534.53 L1529.14 1556.04 L1523.28 1556.04 L1523.28 1534.72 Q1523.28 1529.66 1521.31 1527.14 Q1519.33 1524.63 1515.39 1524.63 Q1510.64 1524.63 1507.91 1527.65 Q1505.17 1530.68 1505.17 1535.9 L1505.17 1556.04 L1499.28 1556.04 L1499.28 1506.52 L1505.17 1506.52 L1505.17 1525.93 Q1507.27 1522.72 1510.1 1521.13 Q1512.97 1519.54 1516.69 1519.54 Q1522.83 1519.54 1525.99 1523.36 Q1529.14 1527.14 1529.14 1534.53 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1549.09 1524.5 Q1544.38 1524.5 1541.65 1528.19 Q1538.91 1531.85 1538.91 1538.25 Q1538.91 1544.65 1541.61 1548.34 Q1544.35 1552 1549.09 1552 Q1553.77 1552 1556.51 1548.31 Q1559.25 1544.62 1559.25 1538.25 Q1559.25 1531.92 1556.51 1528.23 Q1553.77 1524.5 1549.09 1524.5 M1549.09 1519.54 Q1556.73 1519.54 1561.09 1524.5 Q1565.45 1529.47 1565.45 1538.25 Q1565.45 1547 1561.09 1552 Q1556.73 1556.97 1549.09 1556.97 Q1541.42 1556.97 1537.06 1552 Q1532.73 1547 1532.73 1538.25 Q1532.73 1529.47 1537.06 1524.5 Q1541.42 1519.54 1549.09 1519.54 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1571.6 1506.52 L1577.45 1506.52 L1577.45 1556.04 L1571.6 1556.04 L1571.6 1506.52 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M1607.05 1525.81 L1607.05 1506.52 L1612.91 1506.52 L1612.91 1556.04 L1607.05 1556.04 L1607.05 1550.7 Q1605.21 1553.88 1602.37 1555.44 Q1599.57 1556.97 1595.63 1556.97 Q1589.17 1556.97 1585.09 1551.81 Q1581.05 1546.65 1581.05 1538.25 Q1581.05 1529.85 1585.09 1524.69 Q1589.17 1519.54 1595.63 1519.54 Q1599.57 1519.54 1602.37 1521.1 Q1605.21 1522.62 1607.05 1525.81 M1587.1 1538.25 Q1587.1 1544.71 1589.74 1548.4 Q1592.41 1552.07 1597.06 1552.07 Q1601.71 1552.07 1604.38 1548.4 Q1607.05 1544.71 1607.05 1538.25 Q1607.05 1531.79 1604.38 1528.13 Q1601.71 1524.44 1597.06 1524.44 Q1592.41 1524.44 1589.74 1528.13 Q1587.1 1531.79 1587.1 1538.25 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M44.1444 904.492 L50.9239 904.492 Q47.9002 907.739 46.4043 911.431 Q44.9083 915.091 44.9083 919.229 Q44.9083 927.377 49.9054 931.705 Q54.8707 936.034 64.2919 936.034 Q73.6813 936.034 78.6784 931.705 Q83.6436 927.377 83.6436 919.229 Q83.6436 915.091 82.1477 911.431 Q80.6518 907.739 77.6281 904.492 L84.3439 904.492 Q86.6355 907.866 87.7814 911.653 Q88.9272 915.409 88.9272 919.611 Q88.9272 930.4 82.3387 936.607 Q75.7183 942.814 64.2919 942.814 Q52.8336 942.814 46.2451 936.607 Q39.6248 930.4 39.6248 919.611 Q39.6248 915.346 40.7706 911.59 Q41.8846 907.802 44.1444 904.492 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M57.8307 877.692 Q57.2578 878.679 57.0032 879.857 Q56.7167 881.003 56.7167 882.403 Q56.7167 887.368 59.9632 890.042 Q63.1779 892.684 69.2253 892.684 L88.0042 892.684 L88.0042 898.572 L52.3562 898.572 L52.3562 892.684 L57.8944 892.684 Q54.6479 890.838 53.0883 887.878 Q51.4968 884.917 51.4968 880.684 Q51.4968 880.08 51.5923 879.347 Q51.656 878.615 51.8151 877.724 L57.8307 877.692 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M56.4621 859.168 Q56.4621 863.879 60.1542 866.616 Q63.8145 869.353 70.212 869.353 Q76.6095 869.353 80.3017 866.648 Q83.9619 863.911 83.9619 859.168 Q83.9619 854.489 80.2698 851.752 Q76.5777 849.015 70.212 849.015 Q63.8781 849.015 60.186 851.752 Q56.4621 854.489 56.4621 859.168 M51.4968 859.168 Q51.4968 851.529 56.4621 847.169 Q61.4273 842.808 70.212 842.808 Q78.9649 842.808 83.9619 847.169 Q88.9272 851.529 88.9272 859.168 Q88.9272 866.839 83.9619 871.199 Q78.9649 875.528 70.212 875.528 Q61.4273 875.528 56.4621 871.199 Q51.4968 866.839 51.4968 859.168 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M53.4065 813.94 L58.9447 813.94 Q57.6716 816.422 57.035 819.096 Q56.3984 821.77 56.3984 824.634 Q56.3984 828.995 57.7352 831.191 Q59.072 833.355 61.7456 833.355 Q63.7826 833.355 64.9603 831.796 Q66.1061 830.236 67.1565 825.525 L67.6021 823.52 Q68.9389 817.282 71.3897 814.672 Q73.8086 812.03 78.1691 812.03 Q83.1344 812.03 86.0308 815.977 Q88.9272 819.892 88.9272 826.767 Q88.9272 829.631 88.3543 832.751 Q87.8132 835.838 86.6992 839.275 L80.6518 839.275 Q82.3387 836.029 83.198 832.878 Q84.0256 829.727 84.0256 826.639 Q84.0256 822.502 82.6251 820.274 Q81.1929 818.046 78.6147 818.046 Q76.2276 818.046 74.9545 819.669 Q73.6813 821.26 72.5037 826.703 L72.0262 828.74 Q70.8804 834.183 68.5251 836.602 Q66.138 839.021 62.0002 839.021 Q56.9713 839.021 54.2341 835.456 Q51.4968 831.891 51.4968 825.334 Q51.4968 822.088 51.9743 819.223 Q52.4517 816.359 53.4065 813.94 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M53.4065 783.162 L58.9447 783.162 Q57.6716 785.644 57.035 788.318 Q56.3984 790.991 56.3984 793.856 Q56.3984 798.217 57.7352 800.413 Q59.072 802.577 61.7456 802.577 Q63.7826 802.577 64.9603 801.017 Q66.1061 799.458 67.1565 794.747 L67.6021 792.742 Q68.9389 786.504 71.3897 783.894 Q73.8086 781.252 78.1691 781.252 Q83.1344 781.252 86.0308 785.199 Q88.9272 789.114 88.9272 795.989 Q88.9272 798.853 88.3543 801.972 Q87.8132 805.06 86.6992 808.497 L80.6518 808.497 Q82.3387 805.251 83.198 802.1 Q84.0256 798.949 84.0256 795.861 Q84.0256 791.724 82.6251 789.496 Q81.1929 787.268 78.6147 787.268 Q76.2276 787.268 74.9545 788.891 Q73.6813 790.482 72.5037 795.925 L72.0262 797.962 Q70.8804 803.405 68.5251 805.824 Q66.138 808.243 62.0002 808.243 Q56.9713 808.243 54.2341 804.678 Q51.4968 801.113 51.4968 794.556 Q51.4968 791.31 51.9743 788.445 Q52.4517 785.581 53.4065 783.162 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M40.4842 754.134 L40.4842 724.088 L45.895 724.088 L45.895 747.705 L59.9632 747.705 L59.9632 725.075 L65.3741 725.075 L65.3741 747.705 L82.5933 747.705 L82.5933 723.515 L88.0042 723.515 L88.0042 754.134 L40.4842 754.134 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M66.4881 687.74 L88.0042 687.74 L88.0042 693.596 L66.679 693.596 Q61.6183 693.596 59.1038 695.57 Q56.5894 697.543 56.5894 701.49 Q56.5894 706.232 59.6131 708.969 Q62.6368 711.707 67.8567 711.707 L88.0042 711.707 L88.0042 717.595 L52.3562 717.595 L52.3562 711.707 L57.8944 711.707 Q54.6797 709.606 53.0883 706.773 Q51.4968 703.909 51.4968 700.185 Q51.4968 694.042 55.3163 690.891 Q59.1038 687.74 66.4881 687.74 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M42.2347 675.804 L52.3562 675.804 L52.3562 663.741 L56.9077 663.741 L56.9077 675.804 L76.2594 675.804 Q80.6199 675.804 81.8613 674.626 Q83.1026 673.417 83.1026 669.757 L83.1026 663.741 L88.0042 663.741 L88.0042 669.757 Q88.0042 676.536 85.4897 679.114 Q82.9434 681.692 76.2594 681.692 L56.9077 681.692 L56.9077 685.989 L52.3562 685.989 L52.3562 681.692 L42.2347 681.692 L42.2347 675.804 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M57.8307 636.941 Q57.2578 637.928 57.0032 639.106 Q56.7167 640.252 56.7167 641.652 Q56.7167 646.617 59.9632 649.291 Q63.1779 651.933 69.2253 651.933 L88.0042 651.933 L88.0042 657.821 L52.3562 657.821 L52.3562 651.933 L57.8944 651.933 Q54.6479 650.087 53.0883 647.127 Q51.4968 644.166 51.4968 639.933 Q51.4968 639.329 51.5923 638.596 Q51.656 637.864 51.8151 636.973 L57.8307 636.941 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M56.4621 618.417 Q56.4621 623.128 60.1542 625.865 Q63.8145 628.602 70.212 628.602 Q76.6095 628.602 80.3017 625.897 Q83.9619 623.16 83.9619 618.417 Q83.9619 613.738 80.2698 611.001 Q76.5777 608.264 70.212 608.264 Q63.8781 608.264 60.186 611.001 Q56.4621 613.738 56.4621 618.417 M51.4968 618.417 Q51.4968 610.778 56.4621 606.418 Q61.4273 602.057 70.212 602.057 Q78.9649 602.057 83.9619 606.418 Q88.9272 610.778 88.9272 618.417 Q88.9272 626.088 83.9619 630.448 Q78.9649 634.777 70.212 634.777 Q61.4273 634.777 56.4621 630.448 Q51.4968 626.088 51.4968 618.417 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M82.657 590.249 L101.563 590.249 L101.563 596.137 L52.3562 596.137 L52.3562 590.249 L57.7671 590.249 Q54.5842 588.403 53.0564 585.602 Q51.4968 582.769 51.4968 578.854 Q51.4968 572.361 56.6531 568.319 Q61.8093 564.245 70.212 564.245 Q78.6147 564.245 83.771 568.319 Q88.9272 572.361 88.9272 578.854 Q88.9272 582.769 87.3994 585.602 Q85.8398 588.403 82.657 590.249 M70.212 570.324 Q63.7508 570.324 60.0905 572.998 Q56.3984 575.64 56.3984 580.287 Q56.3984 584.934 60.0905 587.607 Q63.7508 590.249 70.212 590.249 Q76.6732 590.249 80.3653 587.607 Q84.0256 584.934 84.0256 580.287 Q84.0256 575.64 80.3653 572.998 Q76.6732 570.324 70.212 570.324 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M91.3143 543.27 Q97.68 545.753 99.6216 548.108 Q101.563 550.463 101.563 554.41 L101.563 559.089 L96.6615 559.089 L96.6615 555.651 Q96.6615 553.232 95.5157 551.896 Q94.3699 550.559 90.1048 548.935 L87.4312 547.885 L52.3562 562.303 L52.3562 556.097 L80.238 544.957 L52.3562 533.817 L52.3562 527.61 L91.3143 543.27 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip082)\" style=\"stroke:#009af9; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  237.067,1384.24 307.897,1384.24 378.727,1384.24 449.557,1384.24 520.387,1384.24 591.217,1384.24 662.047,1384.24 732.876,1384.24 803.706,1384.24 874.536,1384.24 \n",
       "  945.366,1384.24 1016.2,1384.24 1087.03,1384.24 1157.86,1384.24 1228.69,1384.24 1299.52,1077.95 1370.35,1020.61 1441.18,981.376 1512.01,749.215 1582.84,745.847 \n",
       "  1653.66,556.599 1724.49,543.141 1795.32,355.946 1866.15,394.138 1936.98,391.512 2007.81,237.981 2078.64,209.535 2149.47,187.71 2220.3,90.8977 2291.13,86.1857 \n",
       "  \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip080)\" d=\"\n",
       "M1838.93 214.069 L2280.18 214.069 L2280.18 93.1086 L1838.93 93.1086  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1838.93,214.069 2280.18,214.069 2280.18,93.1086 1838.93,93.1086 1838.93,214.069 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip080)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1863.12,153.589 2008.27,153.589 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip080)\" d=\"M 0 0 M2045.66 170.869 L2032.47 136.309 L2037.35 136.309 L2048.3 165.406 L2059.27 136.309 L2064.13 136.309 L2050.96 170.869 L2045.66 170.869 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M2076.7 157.836 Q2071.54 157.836 2069.55 159.017 Q2067.56 160.197 2067.56 163.045 Q2067.56 165.313 2069.04 166.656 Q2070.55 167.975 2073.11 167.975 Q2076.66 167.975 2078.79 165.475 Q2080.94 162.952 2080.94 158.785 L2080.94 157.836 L2076.7 157.836 M2085.2 156.077 L2085.2 170.869 L2080.94 170.869 L2080.94 166.933 Q2079.48 169.295 2077.3 170.429 Q2075.13 171.54 2071.98 171.54 Q2068 171.54 2065.64 169.318 Q2063.3 167.072 2063.3 163.322 Q2063.3 158.947 2066.22 156.725 Q2069.16 154.503 2074.97 154.503 L2080.94 154.503 L2080.94 154.086 Q2080.94 151.147 2078.99 149.549 Q2077.07 147.929 2073.58 147.929 Q2071.36 147.929 2069.25 148.461 Q2067.14 148.994 2065.2 150.059 L2065.2 146.123 Q2067.54 145.221 2069.73 144.781 Q2071.93 144.318 2074.02 144.318 Q2079.64 144.318 2082.42 147.234 Q2085.2 150.151 2085.2 156.077 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M2089.67 134.85 L2093.92 134.85 L2093.92 170.869 L2089.67 170.869 L2089.67 134.85 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M2098.39 144.943 L2102.65 144.943 L2102.65 170.869 L2098.39 170.869 L2098.39 144.943 M2098.39 134.85 L2102.65 134.85 L2102.65 140.244 L2098.39 140.244 L2098.39 134.85 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M2124.18 148.878 L2124.18 134.85 L2128.44 134.85 L2128.44 170.869 L2124.18 170.869 L2124.18 166.98 Q2122.84 169.295 2120.78 170.429 Q2118.74 171.54 2115.87 171.54 Q2111.17 171.54 2108.21 167.79 Q2105.27 164.04 2105.27 157.929 Q2105.27 151.818 2108.21 148.068 Q2111.17 144.318 2115.87 144.318 Q2118.74 144.318 2120.78 145.452 Q2122.84 146.563 2124.18 148.878 M2109.67 157.929 Q2109.67 162.628 2111.59 165.313 Q2113.53 167.975 2116.91 167.975 Q2120.29 167.975 2122.23 165.313 Q2124.18 162.628 2124.18 157.929 Q2124.18 153.23 2122.23 150.568 Q2120.29 147.883 2116.91 147.883 Q2113.53 147.883 2111.59 150.568 Q2109.67 153.23 2109.67 157.929 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M2144.69 157.836 Q2139.53 157.836 2137.54 159.017 Q2135.54 160.197 2135.54 163.045 Q2135.54 165.313 2137.03 166.656 Q2138.53 167.975 2141.1 167.975 Q2144.64 167.975 2146.77 165.475 Q2148.92 162.952 2148.92 158.785 L2148.92 157.836 L2144.69 157.836 M2153.18 156.077 L2153.18 170.869 L2148.92 170.869 L2148.92 166.933 Q2147.47 169.295 2145.29 170.429 Q2143.11 171.54 2139.97 171.54 Q2135.98 171.54 2133.62 169.318 Q2131.29 167.072 2131.29 163.322 Q2131.29 158.947 2134.2 156.725 Q2137.14 154.503 2142.95 154.503 L2148.92 154.503 L2148.92 154.086 Q2148.92 151.147 2146.98 149.549 Q2145.06 147.929 2141.56 147.929 Q2139.34 147.929 2137.23 148.461 Q2135.13 148.994 2133.18 150.059 L2133.18 146.123 Q2135.52 145.221 2137.72 144.781 Q2139.92 144.318 2142 144.318 Q2147.63 144.318 2150.41 147.234 Q2153.18 150.151 2153.18 156.077 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M2161.86 137.582 L2161.86 144.943 L2170.64 144.943 L2170.64 148.253 L2161.86 148.253 L2161.86 162.327 Q2161.86 165.498 2162.72 166.401 Q2163.6 167.304 2166.26 167.304 L2170.64 167.304 L2170.64 170.869 L2166.26 170.869 Q2161.33 170.869 2159.46 169.04 Q2157.58 167.188 2157.58 162.327 L2157.58 148.253 L2154.46 148.253 L2154.46 144.943 L2157.58 144.943 L2157.58 137.582 L2161.86 137.582 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M2175.1 144.943 L2179.36 144.943 L2179.36 170.869 L2175.1 170.869 L2175.1 144.943 M2175.1 134.85 L2179.36 134.85 L2179.36 140.244 L2175.1 140.244 L2175.1 134.85 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M2193.88 147.929 Q2190.45 147.929 2188.46 150.614 Q2186.47 153.276 2186.47 157.929 Q2186.47 162.582 2188.44 165.267 Q2190.43 167.929 2193.88 167.929 Q2197.28 167.929 2199.27 165.244 Q2201.26 162.558 2201.26 157.929 Q2201.26 153.322 2199.27 150.637 Q2197.28 147.929 2193.88 147.929 M2193.88 144.318 Q2199.43 144.318 2202.6 147.929 Q2205.78 151.54 2205.78 157.929 Q2205.78 164.295 2202.6 167.929 Q2199.43 171.54 2193.88 171.54 Q2188.3 171.54 2185.13 167.929 Q2181.98 164.295 2181.98 157.929 Q2181.98 151.54 2185.13 147.929 Q2188.3 144.318 2193.88 144.318 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip080)\" d=\"M 0 0 M2231.79 155.221 L2231.79 170.869 L2227.53 170.869 L2227.53 155.359 Q2227.53 151.679 2226.1 149.85 Q2224.66 148.022 2221.79 148.022 Q2218.35 148.022 2216.35 150.221 Q2214.36 152.42 2214.36 156.216 L2214.36 170.869 L2210.08 170.869 L2210.08 144.943 L2214.36 144.943 L2214.36 148.971 Q2215.89 146.633 2217.95 145.475 Q2220.04 144.318 2222.74 144.318 Q2227.21 144.318 2229.5 147.096 Q2231.79 149.85 2231.79 155.221 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(curve.parameter_values,\n",
    "     curve.measurements,\n",
    "     xlab=curve.parameter_name,\n",
    "     ylab=\"Cross Entropy\",\n",
    "     label=\"Validation\", lw=2)\n",
    "# plot!(Net2.report.training_losses, label=\"Training\", lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77755"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = round(minimum(curve.measurements), digits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLJBase.NumericRange(Float64, :merge_purity_threshold, ... )"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param1 = :merge_purity_threshold\n",
    "\n",
    "r1 = range(dt, param1, lower=0, upper=1, scale=:linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProbabilisticTunedModel(\n",
       "    model = DecisionTreeClassifier(\n",
       "            max_depth = -1,\n",
       "            min_samples_leaf = 1,\n",
       "            min_samples_split = 2,\n",
       "            min_purity_increase = 0.0,\n",
       "            n_subfeatures = 0,\n",
       "            post_prune = true,\n",
       "            merge_purity_threshold = 0.8,\n",
       "            pdf_smoothing = 0.0,\n",
       "            display_depth = 5),\n",
       "    tuning = Grid(\n",
       "            goal = 100,\n",
       "            resolution = 10,\n",
       "            shuffle = true,\n",
       "            rng = Random._GLOBAL_RNG()),\n",
       "    resampling = CV(\n",
       "            nfolds = 6,\n",
       "            shuffle = false,\n",
       "            rng = Random._GLOBAL_RNG()),\n",
       "    measure = accuracy(),\n",
       "    weights = nothing,\n",
       "    operation = MLJModelInterface.predict_mode,\n",
       "    range = MLJBase.NumericRange{Float64,MLJBase.Bounded,Symbol}[\u001b[34mNumericRange{Float64,…} @283\u001b[39m],\n",
       "    train_best = true,\n",
       "    repeats = 1,\n",
       "    n = nothing,\n",
       "    acceleration = CPUThreads{Int64}(1),\n",
       "    acceleration_resampling = CPU1{Nothing}(nothing),\n",
       "    check_measure = true)\u001b[34m @276\u001b[39m"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_tuning_dt_model = TunedModel(model=dt,\n",
    "                                    tuning=Grid(goal=100),\n",
    "                                    resampling=CV(), \n",
    "                                    measure=accuracy,\n",
    "                                    acceleration=CPUThreads(),\n",
    "                                    range=[r1],\n",
    "                                    operation=predict_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{ProbabilisticTunedModel{Grid,…}} @963\u001b[39m trained 0 times.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @083\u001b[39m ⏎ `Table{Union{AbstractArray{Continuous,1}, AbstractArray{Count,1}}}`\n",
       "    2:\t\u001b[34mSource @845\u001b[39m ⏎ `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_tuning_dt = machine(self_tuning_dt_model, X_stand, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{ProbabilisticTunedModel{Grid,…}} @963\u001b[39m.\n",
      "└ @ MLJBase /home/andrew/.julia/packages/MLJBase/uKzAz/src/machines.jl:319\n",
      "┌ Info: Attempting to evaluate 100 models.\n",
      "└ @ MLJTuning /home/andrew/.julia/packages/MLJTuning/Bbgvk/src/tuned_models.jl:494\n",
      "\u001b[33mEvaluating over 100 metamodels: 100%[=========================] Time: 0:00:04\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{ProbabilisticTunedModel{Grid,…}} @963\u001b[39m trained 1 time.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @083\u001b[39m ⏎ `Table{Union{AbstractArray{Continuous,1}, AbstractArray{Count,1}}}`\n",
       "    2:\t\u001b[34mSource @845\u001b[39m ⏎ `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = fit!(self_tuning_dt, rows=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(best_model = \u001b[34mDecisionTreeClassifier @020\u001b[39m,\n",
       " best_fitted_params = (tree = Decision Tree\n",
       "Leaves: 66\n",
       "Depth:  14,\n",
       "                       encoding = Dict{CategoricalValue{String,UInt32},UInt32}(\"RB\" => 0x00000002,\"NRB\" => 0x00000001),),)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = fitted_params(self_tuning_dt)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(\n",
       "    max_depth = -1,\n",
       "    min_samples_leaf = 1,\n",
       "    min_samples_split = 2,\n",
       "    min_purity_increase = 0.0,\n",
       "    n_subfeatures = 0,\n",
       "    post_prune = true,\n",
       "    merge_purity_threshold = 0.8686868686868687,\n",
       "    pdf_smoothing = 0.0,\n",
       "    display_depth = 5)\u001b[34m @020\u001b[39m"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8252"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_loss = round(z.report.best_result.measurement[1],digits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86869"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mpt = round(best.best_model.merge_purity_threshold,digits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"Figures/LearningCurve_DT_merge_purity_thresh:$(best_mpt)_loss:$(best_loss)\"\n",
    "png(replace(fn,'.' => ','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(\n",
       "    max_depth = -1,\n",
       "    min_samples_leaf = 1,\n",
       "    min_samples_split = 2,\n",
       "    min_purity_increase = 0.0,\n",
       "    n_subfeatures = 0,\n",
       "    post_prune = true,\n",
       "    merge_purity_threshold = 0.86869,\n",
       "    pdf_smoothing = 0.0,\n",
       "    display_depth = 5)\u001b[34m @195\u001b[39m"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(post_prune=true, merge_purity_threshold=best_mpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(d, train_metric, valid_metric) = (10, 0.9, 0.7027027027027027)\n",
      "(d, train_metric, valid_metric) = (15, 1.0, 0.6283783783783784)\n",
      "(d, train_metric, valid_metric) = (20, 1.0, 0.6824324324324325)\n",
      "(d, train_metric, valid_metric) = (25, 1.0, 0.7297297297297297)\n",
      "(d, train_metric, valid_metric) = (30, 1.0, 0.7162162162162162)\n",
      "(d, train_metric, valid_metric) = (35, 1.0, 0.7162162162162162)\n",
      "(d, train_metric, valid_metric) = (40, 1.0, 0.7364864864864865)\n",
      "(d, train_metric, valid_metric) = (45, 1.0, 0.7162162162162162)\n",
      "(d, train_metric, valid_metric) = (50, 0.98, 0.7567567567567568)\n",
      "(d, train_metric, valid_metric) = (55, 1.0, 0.8243243243243243)\n",
      "(d, train_metric, valid_metric) = (60, 1.0, 0.7027027027027027)\n",
      "(d, train_metric, valid_metric) = (65, 0.9846153846153847, 0.75)\n",
      "(d, train_metric, valid_metric) = (70, 1.0, 0.6959459459459459)\n",
      "(d, train_metric, valid_metric) = (75, 1.0, 0.6959459459459459)\n",
      "(d, train_metric, valid_metric) = (80, 0.9875, 0.6959459459459459)\n",
      "(d, train_metric, valid_metric) = (85, 0.9882352941176471, 0.7297297297297297)\n",
      "(d, train_metric, valid_metric) = (90, 1.0, 0.7162162162162162)\n",
      "(d, train_metric, valid_metric) = (95, 0.9789473684210527, 0.75)\n",
      "(d, train_metric, valid_metric) = (100, 1.0, 0.6959459459459459)\n",
      "(d, train_metric, valid_metric) = (105, 0.9809523809523809, 0.7162162162162162)\n",
      "(d, train_metric, valid_metric) = (110, 1.0, 0.7905405405405406)\n",
      "(d, train_metric, valid_metric) = (115, 1.0, 0.777027027027027)\n",
      "(d, train_metric, valid_metric) = (120, 1.0, 0.7905405405405406)\n",
      "(d, train_metric, valid_metric) = (125, 1.0, 0.7905405405405406)\n",
      "(d, train_metric, valid_metric) = (130, 1.0, 0.777027027027027)\n",
      "(d, train_metric, valid_metric) = (135, 1.0, 0.7837837837837838)\n",
      "(d, train_metric, valid_metric) = (140, 0.9928571428571429, 0.7702702702702703)\n",
      "(d, train_metric, valid_metric) = (145, 0.9862068965517241, 0.7635135135135135)\n",
      "(d, train_metric, valid_metric) = (150, 0.9866666666666667, 0.8108108108108109)\n",
      "(d, train_metric, valid_metric) = (155, 0.9935483870967742, 0.7635135135135135)\n",
      "(d, train_metric, valid_metric) = (160, 0.9875, 0.8175675675675675)\n",
      "(d, train_metric, valid_metric) = (165, 0.9939393939393939, 0.8040540540540541)\n",
      "(d, train_metric, valid_metric) = (170, 0.9941176470588236, 0.75)\n",
      "(d, train_metric, valid_metric) = (175, 0.9885714285714285, 0.7837837837837838)\n",
      "(d, train_metric, valid_metric) = (180, 0.9888888888888889, 0.8243243243243243)\n",
      "(d, train_metric, valid_metric) = (185, 0.9891891891891892, 0.7905405405405406)\n",
      "(d, train_metric, valid_metric) = (190, 0.9789473684210527, 0.7702702702702703)\n",
      "(d, train_metric, valid_metric) = (195, 0.9846153846153847, 0.7837837837837838)\n",
      "(d, train_metric, valid_metric) = (200, 0.995, 0.7567567567567568)\n",
      "(d, train_metric, valid_metric) = (205, 0.9951219512195122, 0.7837837837837838)\n",
      "(d, train_metric, valid_metric) = (210, 0.9904761904761905, 0.7837837837837838)\n",
      "(d, train_metric, valid_metric) = (215, 0.9953488372093023, 0.7972972972972973)\n",
      "(d, train_metric, valid_metric) = (220, 0.9954545454545455, 0.7905405405405406)\n",
      "(d, train_metric, valid_metric) = (225, 0.9955555555555555, 0.7972972972972973)\n",
      "(d, train_metric, valid_metric) = (230, 0.9956521739130435, 0.7567567567567568)\n",
      "(d, train_metric, valid_metric) = (235, 0.9957446808510638, 0.777027027027027)\n",
      "(d, train_metric, valid_metric) = (240, 0.9916666666666667, 0.7702702702702703)\n",
      "(d, train_metric, valid_metric) = (245, 0.9918367346938776, 0.8040540540540541)\n",
      "(d, train_metric, valid_metric) = (250, 0.996, 0.777027027027027)\n",
      "(d, train_metric, valid_metric) = (255, 0.9882352941176471, 0.8243243243243243)\n",
      "(d, train_metric, valid_metric) = (260, 0.9884615384615385, 0.8108108108108109)\n",
      "(d, train_metric, valid_metric) = (265, 0.9886792452830189, 0.8108108108108109)\n",
      "(d, train_metric, valid_metric) = (270, 0.9888888888888889, 0.8175675675675675)\n",
      "(d, train_metric, valid_metric) = (275, 0.9927272727272727, 0.7905405405405406)\n",
      "(d, train_metric, valid_metric) = (280, 0.9892857142857143, 0.8040540540540541)\n",
      "(d, train_metric, valid_metric) = (285, 0.9824561403508771, 0.7702702702702703)\n",
      "(d, train_metric, valid_metric) = (290, 0.9896551724137931, 0.8445945945945946)\n",
      "(d, train_metric, valid_metric) = (295, 0.9898305084745763, 0.8445945945945946)\n",
      "(d, train_metric, valid_metric) = (300, 0.99, 0.8378378378378378)\n",
      "(d, train_metric, valid_metric) = (305, 0.9901639344262295, 0.8378378378378378)\n",
      "(d, train_metric, valid_metric) = (310, 0.9870967741935484, 0.8175675675675675)\n",
      "(d, train_metric, valid_metric) = (315, 0.9968253968253968, 0.75)\n",
      "(d, train_metric, valid_metric) = (320, 0.996875, 0.7837837837837838)\n",
      "(d, train_metric, valid_metric) = (325, 0.9969230769230769, 0.8108108108108109)\n",
      "(d, train_metric, valid_metric) = (330, 0.990909090909091, 0.7972972972972973)\n",
      "(d, train_metric, valid_metric) = (335, 0.9880597014925373, 0.75)\n",
      "(d, train_metric, valid_metric) = (340, 0.9882352941176471, 0.8108108108108109)\n",
      "(d, train_metric, valid_metric) = (345, 0.991304347826087, 0.8040540540540541)\n",
      "(d, train_metric, valid_metric) = (350, 0.9914285714285714, 0.8175675675675675)\n",
      "(d, train_metric, valid_metric) = (355, 0.9859154929577465, 0.8040540540540541)\n",
      "(d, train_metric, valid_metric) = (360, 0.9861111111111112, 0.777027027027027)\n",
      "(d, train_metric, valid_metric) = (365, 0.9945205479452055, 0.7702702702702703)\n",
      "(d, train_metric, valid_metric) = (370, 0.9972972972972973, 0.8378378378378378)\n",
      "(d, train_metric, valid_metric) = (375, 0.9973333333333333, 0.8445945945945946)\n",
      "(d, train_metric, valid_metric) = (380, 0.9894736842105263, 0.8175675675675675)\n",
      "(d, train_metric, valid_metric) = (385, 0.9922077922077922, 0.8108108108108109)\n",
      "(d, train_metric, valid_metric) = (390, 0.9948717948717949, 0.8108108108108109)\n",
      "(d, train_metric, valid_metric) = (395, 0.9974683544303797, 0.7635135135135135)\n",
      "(d, train_metric, valid_metric) = (400, 0.995, 0.8445945945945946)\n",
      "(d, train_metric, valid_metric) = (405, 0.9975308641975309, 0.8581081081081081)\n",
      "(d, train_metric, valid_metric) = (410, 0.9975609756097561, 0.8581081081081081)\n",
      "(d, train_metric, valid_metric) = (415, 0.9975903614457832, 0.8648648648648649)\n",
      "(d, train_metric, valid_metric) = (420, 0.9976190476190476, 0.8513513513513513)\n",
      "(d, train_metric, valid_metric) = (425, 0.9976470588235294, 0.831081081081081)\n",
      "(d, train_metric, valid_metric) = (430, 0.9976744186046511, 0.831081081081081)\n",
      "(d, train_metric, valid_metric) = (435, 0.9977011494252873, 0.8445945945945946)\n",
      "(d, train_metric, valid_metric) = (440, 0.9977272727272727, 0.7905405405405406)\n",
      "(d, train_metric, valid_metric) = (445, 0.9932584269662922, 0.7837837837837838)\n",
      "(d, train_metric, valid_metric) = (450, 0.9933333333333333, 0.8108108108108109)\n",
      "(d, train_metric, valid_metric) = (455, 0.9934065934065934, 0.7837837837837838)\n",
      "(d, train_metric, valid_metric) = (460, 0.9934782608695653, 0.7635135135135135)\n",
      "(d, train_metric, valid_metric) = (465, 0.9913978494623656, 0.7972972972972973)\n",
      "(d, train_metric, valid_metric) = (470, 0.9957446808510638, 0.7567567567567568)\n",
      "(d, train_metric, valid_metric) = (475, 1.0, 0.8445945945945946)\n",
      "(d, train_metric, valid_metric) = (480, 0.9958333333333333, 0.777027027027027)\n",
      "(d, train_metric, valid_metric) = (485, 0.9938144329896907, 0.75)\n",
      "(d, train_metric, valid_metric) = (490, 0.9938775510204082, 0.777027027027027)\n",
      "(d, train_metric, valid_metric) = (495, 0.9939393939393939, 0.777027027027027)\n",
      "(d, train_metric, valid_metric) = (500, 0.99, 0.777027027027027)\n",
      "(d, train_metric, valid_metric) = (505, 0.996039603960396, 0.7635135135135135)\n",
      "(d, train_metric, valid_metric) = (510, 0.9882352941176471, 0.7837837837837838)\n",
      "(d, train_metric, valid_metric) = (515, 0.9941747572815534, 0.777027027027027)\n",
      "(d, train_metric, valid_metric) = (520, 0.9980769230769231, 0.8108108108108109)\n",
      "(d, train_metric, valid_metric) = (525, 0.9980952380952381, 0.8040540540540541)\n",
      "(d, train_metric, valid_metric) = (530, 0.9981132075471698, 0.7837837837837838)\n",
      "(d, train_metric, valid_metric) = (535, 0.9962616822429906, 0.8108108108108109)\n",
      "(d, train_metric, valid_metric) = (540, 0.9962962962962963, 0.7837837837837838)\n",
      "(d, train_metric, valid_metric) = (545, 0.9963302752293578, 0.7905405405405406)\n",
      "(d, train_metric, valid_metric) = (550, 0.9963636363636363, 0.8040540540540541)\n",
      "(d, train_metric, valid_metric) = (555, 0.9981981981981982, 0.8040540540540541)\n",
      "(d, train_metric, valid_metric) = (560, 0.9982142857142857, 0.8040540540540541)\n",
      "(d, train_metric, valid_metric) = (565, 0.9982300884955753, 0.7905405405405406)\n",
      "(d, train_metric, valid_metric) = (570, 0.9964912280701754, 0.8175675675675675)\n",
      "(d, train_metric, valid_metric) = (575, 0.9965217391304347, 0.8445945945945946)\n",
      "(d, train_metric, valid_metric) = (580, 0.9948275862068966, 0.8108108108108109)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(d, train_metric, valid_metric) = (585, 0.9965811965811966, 0.8378378378378378)\n",
      "(d, train_metric, valid_metric) = (590, 0.9949152542372881, 0.8108108108108109)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10:5:590, Any[0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0  …  0.9963302752293578, 0.9963636363636363, 0.9981981981981982, 0.9982142857142857, 0.9982300884955753, 0.9964912280701754, 0.9965217391304347, 0.9948275862068966, 0.9965811965811966, 0.9949152542372881], Any[0.7027027027027027, 0.6283783783783784, 0.6824324324324325, 0.7297297297297297, 0.7162162162162162, 0.7162162162162162, 0.7364864864864865, 0.7162162162162162, 0.7567567567567568, 0.8243243243243243  …  0.7905405405405406, 0.8040540540540541, 0.8040540540540541, 0.8040540540540541, 0.7905405405405406, 0.8175675675675675, 0.8445945945945946, 0.8108108108108109, 0.8378378378378378, 0.8108108108108109])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_schedule, training_losses, valid_losses = learn_curve(dt, X_stand[train,:], y[train], acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip120\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip120)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip121\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip120)\" d=\"\n",
       "M147.756 1486.45 L2352.76 1486.45 L2352.76 47.2441 L147.756 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip122\">\n",
       "    <rect x=\"147\" y=\"47\" width=\"2206\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip122)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  174.296,1486.45 174.296,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip122)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  532.949,1486.45 532.949,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip122)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  891.603,1486.45 891.603,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip122)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1250.26,1486.45 1250.26,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip122)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1608.91,1486.45 1608.91,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip122)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1967.56,1486.45 1967.56,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip122)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2326.22,1486.45 2326.22,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip122)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  147.756,1184.04 2352.76,1184.04 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip122)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  147.756,818.687 2352.76,818.687 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip122)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  147.756,453.332 2352.76,453.332 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip122)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  147.756,87.9763 2352.76,87.9763 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  147.756,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  147.756,1486.45 147.756,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.296,1486.45 174.296,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  532.949,1486.45 532.949,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  891.603,1486.45 891.603,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1250.26,1486.45 1250.26,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1608.91,1486.45 1608.91,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1967.56,1486.45 1967.56,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2326.22,1486.45 2326.22,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  147.756,1184.04 174.216,1184.04 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  147.756,818.687 174.216,818.687 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  147.756,453.332 174.216,453.332 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  147.756,87.9763 174.216,87.9763 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip120)\" d=\"M 0 0 M174.296 1508.44 Q170.685 1508.44 168.856 1512 Q167.051 1515.55 167.051 1522.67 Q167.051 1529.78 168.856 1533.35 Q170.685 1536.89 174.296 1536.89 Q177.93 1536.89 179.736 1533.35 Q181.565 1529.78 181.565 1522.67 Q181.565 1515.55 179.736 1512 Q177.93 1508.44 174.296 1508.44 M174.296 1504.73 Q180.106 1504.73 183.162 1509.34 Q186.24 1513.92 186.24 1522.67 Q186.24 1531.4 183.162 1536.01 Q180.106 1540.59 174.296 1540.59 Q168.486 1540.59 165.407 1536.01 Q162.352 1531.4 162.352 1522.67 Q162.352 1513.92 165.407 1509.34 Q168.486 1504.73 174.296 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M496.318 1535.98 L503.956 1535.98 L503.956 1509.62 L495.646 1511.29 L495.646 1507.03 L503.91 1505.36 L508.586 1505.36 L508.586 1535.98 L516.225 1535.98 L516.225 1539.92 L496.318 1539.92 L496.318 1535.98 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M531.294 1508.44 Q527.683 1508.44 525.854 1512 Q524.049 1515.55 524.049 1522.67 Q524.049 1529.78 525.854 1533.35 Q527.683 1536.89 531.294 1536.89 Q534.928 1536.89 536.734 1533.35 Q538.563 1529.78 538.563 1522.67 Q538.563 1515.55 536.734 1512 Q534.928 1508.44 531.294 1508.44 M531.294 1504.73 Q537.104 1504.73 540.16 1509.34 Q543.239 1513.92 543.239 1522.67 Q543.239 1531.4 540.16 1536.01 Q537.104 1540.59 531.294 1540.59 Q525.484 1540.59 522.405 1536.01 Q519.35 1531.4 519.35 1522.67 Q519.35 1513.92 522.405 1509.34 Q525.484 1504.73 531.294 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M558.308 1508.44 Q554.697 1508.44 552.868 1512 Q551.063 1515.55 551.063 1522.67 Q551.063 1529.78 552.868 1533.35 Q554.697 1536.89 558.308 1536.89 Q561.942 1536.89 563.748 1533.35 Q565.576 1529.78 565.576 1522.67 Q565.576 1515.55 563.748 1512 Q561.942 1508.44 558.308 1508.44 M558.308 1504.73 Q564.118 1504.73 567.174 1509.34 Q570.252 1513.92 570.252 1522.67 Q570.252 1531.4 567.174 1536.01 Q564.118 1540.59 558.308 1540.59 Q552.498 1540.59 549.419 1536.01 Q546.364 1531.4 546.364 1522.67 Q546.364 1513.92 549.419 1509.34 Q552.498 1504.73 558.308 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M859.242 1535.98 L875.561 1535.98 L875.561 1539.92 L853.617 1539.92 L853.617 1535.98 Q856.279 1533.23 860.862 1528.6 Q865.468 1523.95 866.649 1522.61 Q868.894 1520.08 869.774 1518.35 Q870.677 1516.59 870.677 1514.9 Q870.677 1512.14 868.732 1510.41 Q866.811 1508.67 863.709 1508.67 Q861.51 1508.67 859.056 1509.43 Q856.626 1510.2 853.848 1511.75 L853.848 1507.03 Q856.672 1505.89 859.126 1505.31 Q861.58 1504.73 863.617 1504.73 Q868.987 1504.73 872.181 1507.42 Q875.376 1510.11 875.376 1514.6 Q875.376 1516.73 874.566 1518.65 Q873.779 1520.54 871.672 1523.14 Q871.093 1523.81 867.992 1527.03 Q864.89 1530.22 859.242 1535.98 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M890.63 1508.44 Q887.019 1508.44 885.191 1512 Q883.385 1515.55 883.385 1522.67 Q883.385 1529.78 885.191 1533.35 Q887.019 1536.89 890.63 1536.89 Q894.265 1536.89 896.07 1533.35 Q897.899 1529.78 897.899 1522.67 Q897.899 1515.55 896.07 1512 Q894.265 1508.44 890.63 1508.44 M890.63 1504.73 Q896.44 1504.73 899.496 1509.34 Q902.575 1513.92 902.575 1522.67 Q902.575 1531.4 899.496 1536.01 Q896.44 1540.59 890.63 1540.59 Q884.82 1540.59 881.741 1536.01 Q878.686 1531.4 878.686 1522.67 Q878.686 1513.92 881.741 1509.34 Q884.82 1504.73 890.63 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M917.644 1508.44 Q914.033 1508.44 912.204 1512 Q910.399 1515.55 910.399 1522.67 Q910.399 1529.78 912.204 1533.35 Q914.033 1536.89 917.644 1536.89 Q921.278 1536.89 923.084 1533.35 Q924.913 1529.78 924.913 1522.67 Q924.913 1515.55 923.084 1512 Q921.278 1508.44 917.644 1508.44 M917.644 1504.73 Q923.454 1504.73 926.51 1509.34 Q929.588 1513.92 929.588 1522.67 Q929.588 1531.4 926.51 1536.01 Q923.454 1540.59 917.644 1540.59 Q911.834 1540.59 908.755 1536.01 Q905.7 1531.4 905.7 1522.67 Q905.7 1513.92 908.755 1509.34 Q911.834 1504.73 917.644 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M1227.49 1521.29 Q1230.85 1522 1232.72 1524.27 Q1234.62 1526.54 1234.62 1529.87 Q1234.62 1534.99 1231.1 1537.79 Q1227.58 1540.59 1221.1 1540.59 Q1218.92 1540.59 1216.61 1540.15 Q1214.32 1539.73 1211.86 1538.88 L1211.86 1534.36 Q1213.81 1535.5 1216.12 1536.08 Q1218.44 1536.66 1220.96 1536.66 Q1225.36 1536.66 1227.65 1534.92 Q1229.97 1533.18 1229.97 1529.87 Q1229.97 1526.82 1227.81 1525.11 Q1225.68 1523.37 1221.86 1523.37 L1217.84 1523.37 L1217.84 1519.53 L1222.05 1519.53 Q1225.5 1519.53 1227.33 1518.16 Q1229.16 1516.77 1229.16 1514.18 Q1229.16 1511.52 1227.26 1510.11 Q1225.38 1508.67 1221.86 1508.67 Q1219.94 1508.67 1217.74 1509.09 Q1215.55 1509.5 1212.91 1510.38 L1212.91 1506.22 Q1215.57 1505.48 1217.88 1505.11 Q1220.22 1504.73 1222.28 1504.73 Q1227.61 1504.73 1230.71 1507.17 Q1233.81 1509.57 1233.81 1513.69 Q1233.81 1516.56 1232.17 1518.55 Q1230.52 1520.52 1227.49 1521.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M1249.69 1508.44 Q1246.08 1508.44 1244.25 1512 Q1242.44 1515.55 1242.44 1522.67 Q1242.44 1529.78 1244.25 1533.35 Q1246.08 1536.89 1249.69 1536.89 Q1253.32 1536.89 1255.13 1533.35 Q1256.96 1529.78 1256.96 1522.67 Q1256.96 1515.55 1255.13 1512 Q1253.32 1508.44 1249.69 1508.44 M1249.69 1504.73 Q1255.5 1504.73 1258.55 1509.34 Q1261.63 1513.92 1261.63 1522.67 Q1261.63 1531.4 1258.55 1536.01 Q1255.5 1540.59 1249.69 1540.59 Q1243.88 1540.59 1240.8 1536.01 Q1237.74 1531.4 1237.74 1522.67 Q1237.74 1513.92 1240.8 1509.34 Q1243.88 1504.73 1249.69 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M1276.7 1508.44 Q1273.09 1508.44 1271.26 1512 Q1269.46 1515.55 1269.46 1522.67 Q1269.46 1529.78 1271.26 1533.35 Q1273.09 1536.89 1276.7 1536.89 Q1280.34 1536.89 1282.14 1533.35 Q1283.97 1529.78 1283.97 1522.67 Q1283.97 1515.55 1282.14 1512 Q1280.34 1508.44 1276.7 1508.44 M1276.7 1504.73 Q1282.51 1504.73 1285.57 1509.34 Q1288.65 1513.92 1288.65 1522.67 Q1288.65 1531.4 1285.57 1536.01 Q1282.51 1540.59 1276.7 1540.59 Q1270.89 1540.59 1267.81 1536.01 Q1264.76 1531.4 1264.76 1522.67 Q1264.76 1513.92 1267.81 1509.34 Q1270.89 1504.73 1276.7 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M1584.9 1509.43 L1573.1 1527.88 L1584.9 1527.88 L1584.9 1509.43 M1583.68 1505.36 L1589.56 1505.36 L1589.56 1527.88 L1594.49 1527.88 L1594.49 1531.77 L1589.56 1531.77 L1589.56 1539.92 L1584.9 1539.92 L1584.9 1531.77 L1569.3 1531.77 L1569.3 1527.26 L1583.68 1505.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M1609.56 1508.44 Q1605.95 1508.44 1604.12 1512 Q1602.31 1515.55 1602.31 1522.67 Q1602.31 1529.78 1604.12 1533.35 Q1605.95 1536.89 1609.56 1536.89 Q1613.19 1536.89 1615 1533.35 Q1616.83 1529.78 1616.83 1522.67 Q1616.83 1515.55 1615 1512 Q1613.19 1508.44 1609.56 1508.44 M1609.56 1504.73 Q1615.37 1504.73 1618.42 1509.34 Q1621.5 1513.92 1621.5 1522.67 Q1621.5 1531.4 1618.42 1536.01 Q1615.37 1540.59 1609.56 1540.59 Q1603.75 1540.59 1600.67 1536.01 Q1597.61 1531.4 1597.61 1522.67 Q1597.61 1513.92 1600.67 1509.34 Q1603.75 1504.73 1609.56 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M1636.57 1508.44 Q1632.96 1508.44 1631.13 1512 Q1629.33 1515.55 1629.33 1522.67 Q1629.33 1529.78 1631.13 1533.35 Q1632.96 1536.89 1636.57 1536.89 Q1640.21 1536.89 1642.01 1533.35 Q1643.84 1529.78 1643.84 1522.67 Q1643.84 1515.55 1642.01 1512 Q1640.21 1508.44 1636.57 1508.44 M1636.57 1504.73 Q1642.38 1504.73 1645.44 1509.34 Q1648.52 1513.92 1648.52 1522.67 Q1648.52 1531.4 1645.44 1536.01 Q1642.38 1540.59 1636.57 1540.59 Q1630.76 1540.59 1627.68 1536.01 Q1624.63 1531.4 1624.63 1522.67 Q1624.63 1513.92 1627.68 1509.34 Q1630.76 1504.73 1636.57 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M1930.83 1505.36 L1949.18 1505.36 L1949.18 1509.3 L1935.11 1509.3 L1935.11 1517.77 Q1936.13 1517.42 1937.15 1517.26 Q1938.16 1517.07 1939.18 1517.07 Q1944.97 1517.07 1948.35 1520.24 Q1951.73 1523.42 1951.73 1528.83 Q1951.73 1534.41 1948.26 1537.51 Q1944.78 1540.59 1938.47 1540.59 Q1936.29 1540.59 1934.02 1540.22 Q1931.78 1539.85 1929.37 1539.11 L1929.37 1534.41 Q1931.45 1535.54 1933.67 1536.1 Q1935.9 1536.66 1938.37 1536.66 Q1942.38 1536.66 1944.72 1534.55 Q1947.05 1532.44 1947.05 1528.83 Q1947.05 1525.22 1944.72 1523.11 Q1942.38 1521.01 1938.37 1521.01 Q1936.5 1521.01 1934.62 1521.42 Q1932.77 1521.84 1930.83 1522.72 L1930.83 1505.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M1966.8 1508.44 Q1963.19 1508.44 1961.36 1512 Q1959.55 1515.55 1959.55 1522.67 Q1959.55 1529.78 1961.36 1533.35 Q1963.19 1536.89 1966.8 1536.89 Q1970.43 1536.89 1972.24 1533.35 Q1974.07 1529.78 1974.07 1522.67 Q1974.07 1515.55 1972.24 1512 Q1970.43 1508.44 1966.8 1508.44 M1966.8 1504.73 Q1972.61 1504.73 1975.66 1509.34 Q1978.74 1513.92 1978.74 1522.67 Q1978.74 1531.4 1975.66 1536.01 Q1972.61 1540.59 1966.8 1540.59 Q1960.99 1540.59 1957.91 1536.01 Q1954.85 1531.4 1954.85 1522.67 Q1954.85 1513.92 1957.91 1509.34 Q1960.99 1504.73 1966.8 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M1993.81 1508.44 Q1990.2 1508.44 1988.37 1512 Q1986.57 1515.55 1986.57 1522.67 Q1986.57 1529.78 1988.37 1533.35 Q1990.2 1536.89 1993.81 1536.89 Q1997.45 1536.89 1999.25 1533.35 Q2001.08 1529.78 2001.08 1522.67 Q2001.08 1515.55 1999.25 1512 Q1997.45 1508.44 1993.81 1508.44 M1993.81 1504.73 Q1999.62 1504.73 2002.68 1509.34 Q2005.76 1513.92 2005.76 1522.67 Q2005.76 1531.4 2002.68 1536.01 Q1999.62 1540.59 1993.81 1540.59 Q1988 1540.59 1984.92 1536.01 Q1981.87 1531.4 1981.87 1522.67 Q1981.87 1513.92 1984.92 1509.34 Q1988 1504.73 1993.81 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M2299.61 1520.78 Q2296.46 1520.78 2294.61 1522.93 Q2292.78 1525.08 2292.78 1528.83 Q2292.78 1532.56 2294.61 1534.73 Q2296.46 1536.89 2299.61 1536.89 Q2302.76 1536.89 2304.58 1534.73 Q2306.44 1532.56 2306.44 1528.83 Q2306.44 1525.08 2304.58 1522.93 Q2302.76 1520.78 2299.61 1520.78 M2308.89 1506.12 L2308.89 1510.38 Q2307.13 1509.55 2305.32 1509.11 Q2303.54 1508.67 2301.78 1508.67 Q2297.15 1508.67 2294.7 1511.8 Q2292.27 1514.92 2291.92 1521.24 Q2293.29 1519.23 2295.35 1518.16 Q2297.41 1517.07 2299.88 1517.07 Q2305.09 1517.07 2308.1 1520.24 Q2311.13 1523.39 2311.13 1528.83 Q2311.13 1534.16 2307.99 1537.37 Q2304.84 1540.59 2299.61 1540.59 Q2293.61 1540.59 2290.44 1536.01 Q2287.27 1531.4 2287.27 1522.67 Q2287.27 1514.48 2291.16 1509.62 Q2295.05 1504.73 2301.6 1504.73 Q2303.36 1504.73 2305.14 1505.08 Q2306.94 1505.43 2308.89 1506.12 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M2326.2 1508.44 Q2322.59 1508.44 2320.76 1512 Q2318.96 1515.55 2318.96 1522.67 Q2318.96 1529.78 2320.76 1533.35 Q2322.59 1536.89 2326.2 1536.89 Q2329.84 1536.89 2331.64 1533.35 Q2333.47 1529.78 2333.47 1522.67 Q2333.47 1515.55 2331.64 1512 Q2329.84 1508.44 2326.2 1508.44 M2326.2 1504.73 Q2332.01 1504.73 2335.07 1509.34 Q2338.15 1513.92 2338.15 1522.67 Q2338.15 1531.4 2335.07 1536.01 Q2332.01 1540.59 2326.2 1540.59 Q2320.39 1540.59 2317.32 1536.01 Q2314.26 1531.4 2314.26 1522.67 Q2314.26 1513.92 2317.32 1509.34 Q2320.39 1504.73 2326.2 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M2353.22 1508.44 Q2349.61 1508.44 2347.78 1512 Q2345.97 1515.55 2345.97 1522.67 Q2345.97 1529.78 2347.78 1533.35 Q2349.61 1536.89 2353.22 1536.89 Q2356.85 1536.89 2358.66 1533.35 Q2360.49 1529.78 2360.49 1522.67 Q2360.49 1515.55 2358.66 1512 Q2356.85 1508.44 2353.22 1508.44 M2353.22 1504.73 Q2359.03 1504.73 2362.08 1509.34 Q2365.16 1513.92 2365.16 1522.67 Q2365.16 1531.4 2362.08 1536.01 Q2359.03 1540.59 2353.22 1540.59 Q2347.41 1540.59 2344.33 1536.01 Q2341.27 1531.4 2341.27 1522.67 Q2341.27 1513.92 2344.33 1509.34 Q2347.41 1504.73 2353.22 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M75.7467 1169.84 Q72.1356 1169.84 70.3069 1173.41 Q68.5014 1176.95 68.5014 1184.08 Q68.5014 1191.18 70.3069 1194.75 Q72.1356 1198.29 75.7467 1198.29 Q79.3809 1198.29 81.1865 1194.75 Q83.0152 1191.18 83.0152 1184.08 Q83.0152 1176.95 81.1865 1173.41 Q79.3809 1169.84 75.7467 1169.84 M75.7467 1166.14 Q81.5568 1166.14 84.6124 1170.74 Q87.6911 1175.33 87.6911 1184.08 Q87.6911 1192.8 84.6124 1197.41 Q81.5568 1201.99 75.7467 1201.99 Q69.9365 1201.99 66.8578 1197.41 Q63.8023 1192.8 63.8023 1184.08 Q63.8023 1175.33 66.8578 1170.74 Q69.9365 1166.14 75.7467 1166.14 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M92.7605 1195.44 L97.6447 1195.44 L97.6447 1201.32 L92.7605 1201.32 L92.7605 1195.44 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M101.534 1166.76 L123.756 1166.76 L123.756 1168.75 L111.209 1201.32 L106.325 1201.32 L118.131 1170.7 L101.534 1170.7 L101.534 1166.76 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M74.9365 804.486 Q71.3254 804.486 69.4967 808.05 Q67.6912 811.592 67.6912 818.722 Q67.6912 825.828 69.4967 829.393 Q71.3254 832.935 74.9365 832.935 Q78.5707 832.935 80.3763 829.393 Q82.205 825.828 82.205 818.722 Q82.205 811.592 80.3763 808.05 Q78.5707 804.486 74.9365 804.486 M74.9365 800.782 Q80.7467 800.782 83.8022 805.388 Q86.8809 809.972 86.8809 818.722 Q86.8809 827.448 83.8022 832.055 Q80.7467 836.638 74.9365 836.638 Q69.1264 836.638 66.0477 832.055 Q62.9921 827.448 62.9921 818.722 Q62.9921 809.972 66.0477 805.388 Q69.1264 800.782 74.9365 800.782 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M91.9503 830.087 L96.8345 830.087 L96.8345 835.967 L91.9503 835.967 L91.9503 830.087 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M111.904 819.555 Q108.571 819.555 106.649 821.337 Q104.751 823.12 104.751 826.245 Q104.751 829.37 106.649 831.152 Q108.571 832.935 111.904 832.935 Q115.237 832.935 117.159 831.152 Q119.08 829.347 119.08 826.245 Q119.08 823.12 117.159 821.337 Q115.26 819.555 111.904 819.555 M107.228 817.564 Q104.219 816.824 102.529 814.763 Q100.862 812.703 100.862 809.74 Q100.862 805.597 103.802 803.189 Q106.765 800.782 111.904 800.782 Q117.066 800.782 120.006 803.189 Q122.946 805.597 122.946 809.74 Q122.946 812.703 121.256 814.763 Q119.589 816.824 116.603 817.564 Q119.983 818.351 121.858 820.643 Q123.756 822.935 123.756 826.245 Q123.756 831.268 120.677 833.953 Q117.621 836.638 111.904 836.638 Q106.186 836.638 103.108 833.953 Q100.052 831.268 100.052 826.245 Q100.052 822.935 101.95 820.643 Q103.848 818.351 107.228 817.564 M105.515 810.18 Q105.515 812.865 107.182 814.37 Q108.872 815.874 111.904 815.874 Q114.913 815.874 116.603 814.37 Q118.316 812.865 118.316 810.18 Q118.316 807.495 116.603 805.99 Q114.913 804.486 111.904 804.486 Q108.872 804.486 107.182 805.99 Q105.515 807.495 105.515 810.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M75.0291 439.13 Q71.418 439.13 69.5893 442.695 Q67.7838 446.237 67.7838 453.366 Q67.7838 460.473 69.5893 464.038 Q71.418 467.579 75.0291 467.579 Q78.6633 467.579 80.4689 464.038 Q82.2976 460.473 82.2976 453.366 Q82.2976 446.237 80.4689 442.695 Q78.6633 439.13 75.0291 439.13 M75.0291 435.427 Q80.8393 435.427 83.8948 440.033 Q86.9735 444.616 86.9735 453.366 Q86.9735 462.093 83.8948 466.7 Q80.8393 471.283 75.0291 471.283 Q69.2189 471.283 66.1403 466.7 Q63.0847 462.093 63.0847 453.366 Q63.0847 444.616 66.1403 440.033 Q69.2189 435.427 75.0291 435.427 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M92.0429 464.732 L96.9271 464.732 L96.9271 470.612 L92.0429 470.612 L92.0429 464.732 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M102.135 469.894 L102.135 465.635 Q103.895 466.468 105.7 466.908 Q107.506 467.348 109.242 467.348 Q113.871 467.348 116.302 464.246 Q118.756 461.121 119.103 454.778 Q117.76 456.769 115.7 457.834 Q113.64 458.899 111.14 458.899 Q105.955 458.899 102.922 455.774 Q99.9132 452.626 99.9132 447.186 Q99.9132 441.862 103.061 438.644 Q106.209 435.427 111.441 435.427 Q117.436 435.427 120.584 440.033 Q123.756 444.616 123.756 453.366 Q123.756 461.538 119.867 466.422 Q116.001 471.283 109.45 471.283 Q107.691 471.283 105.885 470.936 Q104.08 470.588 102.135 469.894 M111.441 455.241 Q114.589 455.241 116.418 453.089 Q118.27 450.936 118.27 447.186 Q118.27 443.459 116.418 441.306 Q114.589 439.13 111.441 439.13 Q108.293 439.13 106.441 441.306 Q104.612 443.459 104.612 447.186 Q104.612 450.936 106.441 453.089 Q108.293 455.241 111.441 455.241 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M66.881 101.321 L74.5198 101.321 L74.5198 74.9555 L66.2097 76.6222 L66.2097 72.3629 L74.4735 70.6963 L79.1494 70.6963 L79.1494 101.321 L86.7883 101.321 L86.7883 105.256 L66.881 105.256 L66.881 101.321 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M91.8577 99.3767 L96.7419 99.3767 L96.7419 105.256 L91.8577 105.256 L91.8577 99.3767 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M111.811 73.775 Q108.2 73.775 106.372 77.3398 Q104.566 80.8814 104.566 88.011 Q104.566 95.1174 106.372 98.6822 Q108.2 102.224 111.811 102.224 Q115.446 102.224 117.251 98.6822 Q119.08 95.1174 119.08 88.011 Q119.08 80.8814 117.251 77.3398 Q115.446 73.775 111.811 73.775 M111.811 70.0713 Q117.621 70.0713 120.677 74.6777 Q123.756 79.261 123.756 88.011 Q123.756 96.7378 120.677 101.344 Q117.621 105.928 111.811 105.928 Q106.001 105.928 102.922 101.344 Q99.8669 96.7378 99.8669 88.011 Q99.8669 79.261 102.922 74.6777 Q106.001 70.0713 111.811 70.0713 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip122)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  210.161,453.332 228.094,87.9763 246.027,87.9763 263.959,87.9763 281.892,87.9763 299.825,87.9763 317.757,87.9763 335.69,87.9763 353.623,161.047 371.555,87.9763 \n",
       "  389.488,87.9763 407.421,144.185 425.353,87.9763 443.286,87.9763 461.219,133.646 479.151,130.959 497.084,87.9763 515.017,164.893 532.949,87.9763 550.882,157.568 \n",
       "  568.815,87.9763 586.747,87.9763 604.68,87.9763 622.613,87.9763 640.545,87.9763 658.478,87.9763 676.411,114.073 694.343,138.37 712.276,136.69 730.209,111.548 \n",
       "  748.141,133.646 766.074,110.119 784.007,109.468 801.939,129.731 819.872,128.571 837.805,127.474 855.737,164.893 873.67,144.185 891.603,106.244 909.535,105.798 \n",
       "  927.468,122.772 945.401,104.97 963.333,104.583 981.266,104.214 999.199,103.861 1017.13,103.523 1035.06,118.423 1053,117.801 1070.93,102.59 1088.86,130.959 \n",
       "  1106.79,130.133 1124.73,129.337 1142.66,128.571 1160.59,114.548 1178.53,127.121 1196.46,152.074 1214.39,125.772 1232.32,125.131 1250.26,124.512 1268.19,123.913 \n",
       "  1286.12,135.119 1304.05,99.5749 1321.99,99.3936 1339.92,99.218 1357.85,121.19 1375.78,131.601 1393.72,130.959 1411.65,119.746 1429.58,119.292 1447.52,139.435 \n",
       "  1465.45,138.72 1483.38,107.996 1501.31,97.8507 1519.25,97.7191 1537.18,126.435 1555.11,116.446 1573.04,106.712 1590.98,97.2258 1608.91,106.244 1626.84,96.9974 \n",
       "  1644.77,96.8874 1662.71,96.78 1680.64,96.6752 1698.57,96.5729 1716.51,96.4729 1734.44,96.3753 1752.37,96.2798 1770.3,112.607 1788.24,112.333 1806.17,112.066 \n",
       "  1824.1,111.804 1842.03,119.405 1859.97,103.523 1877.9,87.9763 1895.83,103.199 1913.76,110.576 1931.7,110.345 1949.63,110.119 1967.56,124.512 1985.49,102.446 \n",
       "  2003.43,130.959 2021.36,109.259 2039.29,95.0023 2057.23,94.9354 2075.16,94.8698 2093.09,101.634 2111.02,101.508 2128.96,101.384 2146.89,101.262 2164.82,94.5593 \n",
       "  2182.75,94.5005 2200.69,94.4427 2218.62,100.796 2236.55,100.684 2254.48,106.874 2272.42,100.467 2290.35,106.554 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip122)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  210.161,1174.17 228.094,1445.72 246.027,1248.23 263.959,1075.42 281.892,1124.8 299.825,1124.8 317.757,1050.74 335.69,1124.8 353.623,976.678 371.555,729.817 \n",
       "  389.488,1174.17 407.421,1001.36 425.353,1198.85 443.286,1198.85 461.219,1198.85 479.151,1075.42 497.084,1124.8 515.017,1001.36 532.949,1198.85 550.882,1124.8 \n",
       "  568.815,853.248 586.747,902.62 604.68,853.248 622.613,853.248 640.545,902.62 658.478,877.934 676.411,927.306 694.343,951.992 712.276,779.189 730.209,951.992 \n",
       "  748.141,754.503 766.074,803.875 784.007,1001.36 801.939,877.934 819.872,729.817 837.805,853.248 855.737,927.306 873.67,877.934 891.603,976.678 909.535,877.934 \n",
       "  927.468,877.934 945.401,828.561 963.333,853.248 981.266,828.561 999.199,976.678 1017.13,902.62 1035.06,927.306 1053,803.875 1070.93,902.62 1088.86,729.817 \n",
       "  1106.79,779.189 1124.73,779.189 1142.66,754.503 1160.59,853.248 1178.53,803.875 1196.46,927.306 1214.39,655.758 1232.32,655.758 1250.26,680.444 1268.19,680.444 \n",
       "  1286.12,754.503 1304.05,1001.36 1321.99,877.934 1339.92,779.189 1357.85,828.561 1375.78,1001.36 1393.72,779.189 1411.65,803.875 1429.58,754.503 1447.52,803.875 \n",
       "  1465.45,902.62 1483.38,927.306 1501.31,680.444 1519.25,655.758 1537.18,754.503 1555.11,779.189 1573.04,779.189 1590.98,951.992 1608.91,655.758 1626.84,606.386 \n",
       "  1644.77,606.386 1662.71,581.7 1680.64,631.072 1698.57,705.131 1716.51,705.131 1734.44,655.758 1752.37,853.248 1770.3,877.934 1788.24,779.189 1806.17,877.934 \n",
       "  1824.1,951.992 1842.03,828.561 1859.97,976.678 1877.9,655.758 1895.83,902.62 1913.76,1001.36 1931.7,902.62 1949.63,902.62 1967.56,902.62 1985.49,951.992 \n",
       "  2003.43,877.934 2021.36,902.62 2039.29,779.189 2057.23,803.875 2075.16,877.934 2093.09,779.189 2111.02,877.934 2128.96,853.248 2146.89,803.875 2164.82,803.875 \n",
       "  2182.75,803.875 2200.69,853.248 2218.62,754.503 2236.55,655.758 2254.48,779.189 2272.42,680.444 2290.35,779.189 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip120)\" d=\"\n",
       "M1983.24 276.658 L2279.26 276.658 L2279.26 95.2176 L1983.24 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1983.24,276.658 2279.26,276.658 2279.26,95.2176 1983.24,95.2176 1983.24,276.658 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip120)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2007.74,155.698 2154.74,155.698 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip120)\" d=\"M 0 0 M2193.08 175.385 Q2191.27 180.015 2189.56 181.427 Q2187.85 182.839 2184.98 182.839 L2181.58 182.839 L2181.58 179.274 L2184.08 179.274 Q2185.83 179.274 2186.81 178.44 Q2187.78 177.607 2188.96 174.505 L2189.72 172.561 L2179.24 147.052 L2183.75 147.052 L2191.85 167.329 L2199.96 147.052 L2204.47 147.052 L2193.08 175.385 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M2210.35 169.042 L2217.99 169.042 L2217.99 142.677 L2209.68 144.343 L2209.68 140.084 L2217.94 138.418 L2222.62 138.418 L2222.62 169.042 L2230.26 169.042 L2230.26 172.978 L2210.35 172.978 L2210.35 169.042 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip120)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2007.74,216.178 2154.74,216.178 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip120)\" d=\"M 0 0 M2193.08 235.865 Q2191.27 240.495 2189.56 241.907 Q2187.85 243.319 2184.98 243.319 L2181.58 243.319 L2181.58 239.754 L2184.08 239.754 Q2185.83 239.754 2186.81 238.92 Q2187.78 238.087 2188.96 234.985 L2189.72 233.041 L2179.24 207.532 L2183.75 207.532 L2191.85 227.809 L2199.96 207.532 L2204.47 207.532 L2193.08 235.865 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip120)\" d=\"M 0 0 M2213.57 229.522 L2229.89 229.522 L2229.89 233.458 L2207.94 233.458 L2207.94 229.522 Q2210.6 226.768 2215.19 222.138 Q2219.79 217.485 2220.97 216.143 Q2223.22 213.62 2224.1 211.884 Q2225 210.124 2225 208.435 Q2225 205.68 2223.06 203.944 Q2221.14 202.208 2218.03 202.208 Q2215.83 202.208 2213.38 202.972 Q2210.95 203.735 2208.17 205.286 L2208.17 200.564 Q2211 199.43 2213.45 198.851 Q2215.9 198.273 2217.94 198.273 Q2223.31 198.273 2226.51 200.958 Q2229.7 203.643 2229.7 208.134 Q2229.7 210.263 2228.89 212.185 Q2228.1 214.083 2226 216.675 Q2225.42 217.347 2222.32 220.564 Q2219.21 223.759 2213.57 229.522 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(data_schedule, training_losses)\n",
    "plot!(data_schedule, valid_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(\n",
       "    max_depth = -1,\n",
       "    min_samples_leaf = 1,\n",
       "    min_samples_split = 2,\n",
       "    min_purity_increase = 0.0,\n",
       "    n_subfeatures = 0,\n",
       "    post_prune = true,\n",
       "    merge_purity_threshold = 0.8686868686868687,\n",
       "    pdf_smoothing = 0.0,\n",
       "    display_depth = 5)\u001b[34m @020\u001b[39m"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dt = best.best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @572\u001b[39m trained 0 times.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @168\u001b[39m ⏎ `Table{Union{AbstractArray{Continuous,1}, AbstractArray{Count,1}}}`\n",
       "    2:\t\u001b[34mSource @446\u001b[39m ⏎ `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Tree = machine(final_dt, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 36, Threshold 3.8005\n",
      "L-> Feature 27, Threshold 2.2380000000000004\n",
      "    L-> Feature 34, Threshold 2.5\n",
      "        L-> Feature 9, Threshold 3.5\n",
      "            L-> Feature 10, Threshold 1.5\n",
      "                L-> \n",
      "                R-> \n",
      "            R-> Feature 39, Threshold 8.564\n",
      "                L-> 1 : 13/13\n",
      "                R-> 2 : 2/2\n",
      "        R-> Feature 16, Threshold 1.5\n",
      "            L-> 1 : 27/27\n",
      "            R-> Feature 4, Threshold 0.5\n",
      "                L-> 2 : 5/5\n",
      "                R-> 1 : 2/2\n",
      "    R-> Feature 30, Threshold 5.1245\n",
      "        L-> Feature 18, Threshold 1.1575\n",
      "            L-> Feature 28, Threshold -0.0015\n",
      "                L-> \n",
      "                R-> 1 : 50/50\n",
      "            R-> 2 : 2/2\n",
      "        R-> Feature 11, Threshold 0.5\n",
      "            L-> Feature 1, Threshold 5.097\n",
      "                L-> \n",
      "                R-> \n",
      "            R-> Feature 17, Threshold 1.0225\n",
      "                L-> 1 : 19/19\n",
      "                R-> \n",
      "R-> Feature 12, Threshold -0.5695\n",
      "    L-> Feature 22, Threshold 1.2275\n",
      "        L-> Feature 15, Threshold 10.858\n",
      "            L-> 2 : 8/9\n",
      "            R-> Feature 39, Threshold 9.908999999999999\n",
      "                L-> 1 : 6/6\n",
      "                R-> 2 : 1/1\n",
      "        R-> 1 : 26/28\n",
      "    R-> Feature 27, Threshold 2.3585000000000003\n",
      "        L-> Feature 17, Threshold 0.9935\n",
      "            L-> Feature 17, Threshold 0.9915\n",
      "                L-> \n",
      "                R-> 2 : 3/3\n",
      "            R-> Feature 18, Threshold 1.1185\n",
      "                L-> \n",
      "                R-> 1 : 72/72\n",
      "        R-> 1 : 118/118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{DecisionTreeClassifier} @572\u001b[39m.\n",
      "└ @ MLJBase /home/andrew/.julia/packages/MLJBase/uKzAz/src/machines.jl:319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @572\u001b[39m trained 1 time.\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @168\u001b[39m ⏎ `Table{Union{AbstractArray{Continuous,1}, AbstractArray{Count,1}}}`\n",
       "    2:\t\u001b[34mSource @446\u001b[39m ⏎ `AbstractArray{Multiclass{2},1}`\n"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(Final_Tree, rows=train, verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "ŷ2 = MLJ.predict(Final_Tree, X[test,:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.386669512543516"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(ŷ2, y[test]) |> mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8107255520504731"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(ŷ2, y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The classes are un-ordered,\n",
      "│ using: negative='NRB' and positive='RB'.\n",
      "│ To suppress this warning, consider coercing to OrderedFactor.\n",
      "└ @ MLJBase /home/andrew/.julia/packages/MLJBase/uKzAz/src/measures/confusion_matrix.jl:83\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "              ┌───────────────────────────┐\n",
       "              │       Ground Truth        │\n",
       "┌─────────────┼─────────────┬─────────────┤\n",
       "│  Predicted  │     NRB     │     RB      │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│     NRB     │     174     │     24      │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│     RB      │     36      │     83      │\n",
       "└─────────────┴─────────────┴─────────────┘\n"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(mode.(ŷ2), y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
